I0430 15:49:02.894271 11505 caffe.cpp:218] Using GPUs 0
I0430 15:49:02.912206 11505 caffe.cpp:223] GPU 0: GeForce GTX 950M
I0430 15:49:03.144248 11505 solver.cpp:44] Initializing solver from parameters: 
test_iter: 10
test_interval: 1000
base_lr: 0.001
display: 100
max_iter: 60000
lr_policy: "step"
gamma: 1
momentum: 0.9
stepsize: 5000
snapshot: 10000
snapshot_prefix: "examples/cifar10_full_sigmoid"
solver_mode: GPU
device_id: 0
net: "ECE595/cifar/train_test/var_everything/cifar_train_test_4.prototxt"
train_state {
  level: 0
  stage: ""
}
I0430 15:49:03.144404 11505 solver.cpp:87] Creating training net from net file: ECE595/cifar/train_test/var_everything/cifar_train_test_4.prototxt
I0430 15:49:03.144569 11505 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0430 15:49:03.144578 11505 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0430 15:49:03.144636 11505 net.cpp:51] Initializing net from parameters: 
name: "CIFAR"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_train_lmdb"
    batch_size: 111
    backend: LMDB
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "data"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 160
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "reLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0430 15:49:03.144677 11505 layer_factory.hpp:77] Creating layer cifar
I0430 15:49:03.144783 11505 db_lmdb.cpp:35] Opened lmdb examples/cifar10/cifar10_train_lmdb
I0430 15:49:03.144811 11505 net.cpp:84] Creating Layer cifar
I0430 15:49:03.144819 11505 net.cpp:380] cifar -> data
I0430 15:49:03.144842 11505 net.cpp:380] cifar -> label
I0430 15:49:03.144856 11505 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I0430 15:49:03.145869 11505 data_layer.cpp:45] output data size: 111,3,32,32
I0430 15:49:03.150321 11505 net.cpp:122] Setting up cifar
I0430 15:49:03.150344 11505 net.cpp:129] Top shape: 111 3 32 32 (340992)
I0430 15:49:03.150349 11505 net.cpp:129] Top shape: 111 (111)
I0430 15:49:03.150352 11505 net.cpp:137] Memory required for data: 1364412
I0430 15:49:03.150375 11505 layer_factory.hpp:77] Creating layer ip1
I0430 15:49:03.150393 11505 net.cpp:84] Creating Layer ip1
I0430 15:49:03.150400 11505 net.cpp:406] ip1 <- data
I0430 15:49:03.150415 11505 net.cpp:380] ip1 -> ip1
I0430 15:49:03.160528 11505 net.cpp:122] Setting up ip1
I0430 15:49:03.160545 11505 net.cpp:129] Top shape: 111 160 (17760)
I0430 15:49:03.160547 11505 net.cpp:137] Memory required for data: 1435452
I0430 15:49:03.160567 11505 layer_factory.hpp:77] Creating layer relu1
F0430 15:49:03.160598 11505 layer_factory.hpp:81] Check failed: registry.count(type) == 1 (0 vs. 1) Unknown layer type: reLU (known types: AbsVal, Accuracy, ArgMax, BNLL, BatchNorm, BatchReindex, Bias, Concat, ContrastiveLoss, Convolution, Crop, Data, Deconvolution, Dropout, DummyData, ELU, Eltwise, Embed, EuclideanLoss, Exp, Filter, Flatten, HDF5Data, HDF5Output, HingeLoss, Im2col, ImageData, InfogainLoss, InnerProduct, Input, LRN, LSTM, LSTMUnit, Log, MVN, MemoryData, MultinomialLogisticLoss, PReLU, Parameter, Pooling, Power, RNN, ReLU, Reduction, Reshape, SPP, Scale, Sigmoid, SigmoidCrossEntropyLoss, Silence, Slice, Softmax, SoftmaxWithLoss, Split, TanH, Threshold, Tile, WindowData)
*** Check failure stack trace: ***
    @     0x7f7fe1f3c5cd  google::LogMessage::Fail()
    @     0x7f7fe1f3e433  google::LogMessage::SendToLog()
    @     0x7f7fe1f3c15b  google::LogMessage::Flush()
    @     0x7f7fe1f3ee1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f7fe26c4d5c  caffe::Net<>::Init()
    @     0x7f7fe26c646e  caffe::Net<>::Net()
    @     0x7f7fe268c275  caffe::Solver<>::InitTrainNet()
    @     0x7f7fe268d6b5  caffe::Solver<>::Init()
    @     0x7f7fe268d9df  caffe::Solver<>::Solver()
    @     0x7f7fe269dcf1  caffe::Creator_SGDSolver<>()
    @           0x40a9f8  train()
    @           0x4072f0  main
    @     0x7f7fe0ead830  __libc_start_main
    @           0x407b19  _start
    @              (nil)  (unknown)
