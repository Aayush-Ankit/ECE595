I0430 15:49:01.477634 11475 caffe.cpp:218] Using GPUs 0
I0430 15:49:01.494685 11475 caffe.cpp:223] GPU 0: GeForce GTX 950M
I0430 15:49:01.723734 11475 solver.cpp:44] Initializing solver from parameters: 
test_iter: 10
test_interval: 1000
base_lr: 0.001
display: 100
max_iter: 60000
lr_policy: "step"
gamma: 1
momentum: 0.9
stepsize: 5000
snapshot: 10000
snapshot_prefix: "examples/cifar10_full_sigmoid"
solver_mode: GPU
device_id: 0
net: "ECE595/cifar/train_test/var_everything/cifar_train_test_1.prototxt"
train_state {
  level: 0
  stage: ""
}
I0430 15:49:01.723881 11475 solver.cpp:87] Creating training net from net file: ECE595/cifar/train_test/var_everything/cifar_train_test_1.prototxt
I0430 15:49:01.724052 11475 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0430 15:49:01.724066 11475 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0430 15:49:01.724128 11475 net.cpp:51] Initializing net from parameters: 
name: "CIFAR"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_train_lmdb"
    batch_size: 111
    backend: LMDB
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "data"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 20
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "reLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0430 15:49:01.724189 11475 layer_factory.hpp:77] Creating layer cifar
I0430 15:49:01.724292 11475 db_lmdb.cpp:35] Opened lmdb examples/cifar10/cifar10_train_lmdb
I0430 15:49:01.724324 11475 net.cpp:84] Creating Layer cifar
I0430 15:49:01.724335 11475 net.cpp:380] cifar -> data
I0430 15:49:01.724359 11475 net.cpp:380] cifar -> label
I0430 15:49:01.724376 11475 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I0430 15:49:01.725328 11475 data_layer.cpp:45] output data size: 111,3,32,32
I0430 15:49:01.729776 11475 net.cpp:122] Setting up cifar
I0430 15:49:01.729802 11475 net.cpp:129] Top shape: 111 3 32 32 (340992)
I0430 15:49:01.729809 11475 net.cpp:129] Top shape: 111 (111)
I0430 15:49:01.729815 11475 net.cpp:137] Memory required for data: 1364412
I0430 15:49:01.729825 11475 layer_factory.hpp:77] Creating layer ip1
I0430 15:49:01.729842 11475 net.cpp:84] Creating Layer ip1
I0430 15:49:01.729849 11475 net.cpp:406] ip1 <- data
I0430 15:49:01.729867 11475 net.cpp:380] ip1 -> ip1
I0430 15:49:01.731612 11475 net.cpp:122] Setting up ip1
I0430 15:49:01.731626 11475 net.cpp:129] Top shape: 111 20 (2220)
I0430 15:49:01.731631 11475 net.cpp:137] Memory required for data: 1373292
I0430 15:49:01.731653 11475 layer_factory.hpp:77] Creating layer relu1
F0430 15:49:01.731688 11475 layer_factory.hpp:81] Check failed: registry.count(type) == 1 (0 vs. 1) Unknown layer type: reLU (known types: AbsVal, Accuracy, ArgMax, BNLL, BatchNorm, BatchReindex, Bias, Concat, ContrastiveLoss, Convolution, Crop, Data, Deconvolution, Dropout, DummyData, ELU, Eltwise, Embed, EuclideanLoss, Exp, Filter, Flatten, HDF5Data, HDF5Output, HingeLoss, Im2col, ImageData, InfogainLoss, InnerProduct, Input, LRN, LSTM, LSTMUnit, Log, MVN, MemoryData, MultinomialLogisticLoss, PReLU, Parameter, Pooling, Power, RNN, ReLU, Reduction, Reshape, SPP, Scale, Sigmoid, SigmoidCrossEntropyLoss, Silence, Slice, Softmax, SoftmaxWithLoss, Split, TanH, Threshold, Tile, WindowData)
*** Check failure stack trace: ***
    @     0x7fa96eb705cd  google::LogMessage::Fail()
    @     0x7fa96eb72433  google::LogMessage::SendToLog()
    @     0x7fa96eb7015b  google::LogMessage::Flush()
    @     0x7fa96eb72e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7fa96f2f8d5c  caffe::Net<>::Init()
    @     0x7fa96f2fa46e  caffe::Net<>::Net()
    @     0x7fa96f2c0275  caffe::Solver<>::InitTrainNet()
    @     0x7fa96f2c16b5  caffe::Solver<>::Init()
    @     0x7fa96f2c19df  caffe::Solver<>::Solver()
    @     0x7fa96f2d1cf1  caffe::Creator_SGDSolver<>()
    @           0x40a9f8  train()
    @           0x4072f0  main
    @     0x7fa96dae1830  __libc_start_main
    @           0x407b19  _start
    @              (nil)  (unknown)
