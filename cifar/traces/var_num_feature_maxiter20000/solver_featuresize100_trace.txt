I0426 12:51:48.849591 14069 caffe.cpp:218] Using GPUs 0
I0426 12:51:48.863932 14069 caffe.cpp:223] GPU 0: GeForce GTX 950M
I0426 12:51:49.040879 14069 solver.cpp:44] Initializing solver from parameters: 
test_iter: 10
test_interval: 1000
base_lr: 0.001
display: 100
max_iter: 20000
lr_policy: "step"
gamma: 1
momentum: 0.9
stepsize: 5000
snapshot: 10000
snapshot_prefix: "examples/cifar10_full_sigmoid"
solver_mode: GPU
device_id: 0
net: "ECE595/cifar/train_test/var_num_feature_maxiter20000/cifar_train_test_featuresize100.prototxt"
train_state {
  level: 0
  stage: ""
}
I0426 12:51:49.041067 14069 solver.cpp:87] Creating training net from net file: ECE595/cifar/train_test/var_num_feature_maxiter20000/cifar_train_test_featuresize100.prototxt
I0426 12:51:49.041316 14069 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0426 12:51:49.041343 14069 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0426 12:51:49.041462 14069 net.cpp:51] Initializing net from parameters: 
name: "CIFAR"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_train_lmdb"
    batch_size: 111
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Sigmoid0"
  type: "Sigmoid"
  bottom: "conv0"
  top: "Sigmoid0"
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "Sigmoid0"
  top: "pool0"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Sigmoid1"
  type: "Sigmoid"
  bottom: "conv1"
  top: "Sigmoid1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "Sigmoid1"
  top: "pool1"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Sigmoid2"
  type: "Sigmoid"
  bottom: "conv2"
  top: "Sigmoid2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "Sigmoid2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0426 12:51:49.041564 14069 layer_factory.hpp:77] Creating layer cifar
I0426 12:51:49.041733 14069 db_lmdb.cpp:35] Opened lmdb examples/cifar10/cifar10_train_lmdb
I0426 12:51:49.041754 14069 net.cpp:84] Creating Layer cifar
I0426 12:51:49.041779 14069 net.cpp:380] cifar -> data
I0426 12:51:49.041795 14069 net.cpp:380] cifar -> label
I0426 12:51:49.041805 14069 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I0426 12:51:49.042577 14069 data_layer.cpp:45] output data size: 111,3,32,32
I0426 12:51:49.046238 14069 net.cpp:122] Setting up cifar
I0426 12:51:49.046255 14069 net.cpp:129] Top shape: 111 3 32 32 (340992)
I0426 12:51:49.046306 14069 net.cpp:129] Top shape: 111 (111)
I0426 12:51:49.046308 14069 net.cpp:137] Memory required for data: 1364412
I0426 12:51:49.046315 14069 layer_factory.hpp:77] Creating layer conv0
I0426 12:51:49.046332 14069 net.cpp:84] Creating Layer conv0
I0426 12:51:49.046337 14069 net.cpp:406] conv0 <- data
I0426 12:51:49.046382 14069 net.cpp:380] conv0 -> conv0
I0426 12:51:49.047447 14069 net.cpp:122] Setting up conv0
I0426 12:51:49.047475 14069 net.cpp:129] Top shape: 111 100 32 32 (11366400)
I0426 12:51:49.047477 14069 net.cpp:137] Memory required for data: 46830012
I0426 12:51:49.047509 14069 layer_factory.hpp:77] Creating layer Sigmoid0
I0426 12:51:49.047528 14069 net.cpp:84] Creating Layer Sigmoid0
I0426 12:51:49.047531 14069 net.cpp:406] Sigmoid0 <- conv0
I0426 12:51:49.047554 14069 net.cpp:380] Sigmoid0 -> Sigmoid0
I0426 12:51:49.047574 14069 net.cpp:122] Setting up Sigmoid0
I0426 12:51:49.047595 14069 net.cpp:129] Top shape: 111 100 32 32 (11366400)
I0426 12:51:49.047597 14069 net.cpp:137] Memory required for data: 92295612
I0426 12:51:49.047600 14069 layer_factory.hpp:77] Creating layer pool0
I0426 12:51:49.047623 14069 net.cpp:84] Creating Layer pool0
I0426 12:51:49.047626 14069 net.cpp:406] pool0 <- Sigmoid0
I0426 12:51:49.047628 14069 net.cpp:380] pool0 -> pool0
I0426 12:51:49.047979 14069 net.cpp:122] Setting up pool0
I0426 12:51:49.048007 14069 net.cpp:129] Top shape: 111 100 16 16 (2841600)
I0426 12:51:49.048009 14069 net.cpp:137] Memory required for data: 103662012
I0426 12:51:49.048012 14069 layer_factory.hpp:77] Creating layer conv1
I0426 12:51:49.048038 14069 net.cpp:84] Creating Layer conv1
I0426 12:51:49.048054 14069 net.cpp:406] conv1 <- pool0
I0426 12:51:49.048060 14069 net.cpp:380] conv1 -> conv1
I0426 12:51:49.050789 14069 net.cpp:122] Setting up conv1
I0426 12:51:49.050819 14069 net.cpp:129] Top shape: 111 100 16 16 (2841600)
I0426 12:51:49.050822 14069 net.cpp:137] Memory required for data: 115028412
I0426 12:51:49.050829 14069 layer_factory.hpp:77] Creating layer Sigmoid1
I0426 12:51:49.050835 14069 net.cpp:84] Creating Layer Sigmoid1
I0426 12:51:49.050837 14069 net.cpp:406] Sigmoid1 <- conv1
I0426 12:51:49.050843 14069 net.cpp:380] Sigmoid1 -> Sigmoid1
I0426 12:51:49.050874 14069 net.cpp:122] Setting up Sigmoid1
I0426 12:51:49.050879 14069 net.cpp:129] Top shape: 111 100 16 16 (2841600)
I0426 12:51:49.050881 14069 net.cpp:137] Memory required for data: 126394812
I0426 12:51:49.050899 14069 layer_factory.hpp:77] Creating layer pool1
I0426 12:51:49.050902 14069 net.cpp:84] Creating Layer pool1
I0426 12:51:49.050905 14069 net.cpp:406] pool1 <- Sigmoid1
I0426 12:51:49.050927 14069 net.cpp:380] pool1 -> pool1
I0426 12:51:49.050973 14069 net.cpp:122] Setting up pool1
I0426 12:51:49.050977 14069 net.cpp:129] Top shape: 111 100 8 8 (710400)
I0426 12:51:49.050981 14069 net.cpp:137] Memory required for data: 129236412
I0426 12:51:49.051002 14069 layer_factory.hpp:77] Creating layer conv2
I0426 12:51:49.051008 14069 net.cpp:84] Creating Layer conv2
I0426 12:51:49.051012 14069 net.cpp:406] conv2 <- pool1
I0426 12:51:49.051015 14069 net.cpp:380] conv2 -> conv2
I0426 12:51:49.053766 14069 net.cpp:122] Setting up conv2
I0426 12:51:49.053784 14069 net.cpp:129] Top shape: 111 100 8 8 (710400)
I0426 12:51:49.053807 14069 net.cpp:137] Memory required for data: 132078012
I0426 12:51:49.053820 14069 layer_factory.hpp:77] Creating layer Sigmoid2
I0426 12:51:49.053877 14069 net.cpp:84] Creating Layer Sigmoid2
I0426 12:51:49.053882 14069 net.cpp:406] Sigmoid2 <- conv2
I0426 12:51:49.053906 14069 net.cpp:380] Sigmoid2 -> Sigmoid2
I0426 12:51:49.053946 14069 net.cpp:122] Setting up Sigmoid2
I0426 12:51:49.053949 14069 net.cpp:129] Top shape: 111 100 8 8 (710400)
I0426 12:51:49.053951 14069 net.cpp:137] Memory required for data: 134919612
I0426 12:51:49.053972 14069 layer_factory.hpp:77] Creating layer pool2
I0426 12:51:49.053977 14069 net.cpp:84] Creating Layer pool2
I0426 12:51:49.053978 14069 net.cpp:406] pool2 <- Sigmoid2
I0426 12:51:49.053982 14069 net.cpp:380] pool2 -> pool2
I0426 12:51:49.054009 14069 net.cpp:122] Setting up pool2
I0426 12:51:49.054015 14069 net.cpp:129] Top shape: 111 100 4 4 (177600)
I0426 12:51:49.054016 14069 net.cpp:137] Memory required for data: 135630012
I0426 12:51:49.054018 14069 layer_factory.hpp:77] Creating layer ip1
I0426 12:51:49.054024 14069 net.cpp:84] Creating Layer ip1
I0426 12:51:49.054028 14069 net.cpp:406] ip1 <- pool2
I0426 12:51:49.054049 14069 net.cpp:380] ip1 -> ip1
I0426 12:51:49.054314 14069 net.cpp:122] Setting up ip1
I0426 12:51:49.054319 14069 net.cpp:129] Top shape: 111 10 (1110)
I0426 12:51:49.054339 14069 net.cpp:137] Memory required for data: 135634452
I0426 12:51:49.054343 14069 layer_factory.hpp:77] Creating layer loss
I0426 12:51:49.054347 14069 net.cpp:84] Creating Layer loss
I0426 12:51:49.054349 14069 net.cpp:406] loss <- ip1
I0426 12:51:49.054352 14069 net.cpp:406] loss <- label
I0426 12:51:49.054356 14069 net.cpp:380] loss -> loss
I0426 12:51:49.054383 14069 layer_factory.hpp:77] Creating layer loss
I0426 12:51:49.054455 14069 net.cpp:122] Setting up loss
I0426 12:51:49.054479 14069 net.cpp:129] Top shape: (1)
I0426 12:51:49.054481 14069 net.cpp:132]     with loss weight 1
I0426 12:51:49.054527 14069 net.cpp:137] Memory required for data: 135634456
I0426 12:51:49.054528 14069 net.cpp:198] loss needs backward computation.
I0426 12:51:49.054534 14069 net.cpp:198] ip1 needs backward computation.
I0426 12:51:49.054551 14069 net.cpp:198] pool2 needs backward computation.
I0426 12:51:49.054553 14069 net.cpp:198] Sigmoid2 needs backward computation.
I0426 12:51:49.054555 14069 net.cpp:198] conv2 needs backward computation.
I0426 12:51:49.054558 14069 net.cpp:198] pool1 needs backward computation.
I0426 12:51:49.054560 14069 net.cpp:198] Sigmoid1 needs backward computation.
I0426 12:51:49.054581 14069 net.cpp:198] conv1 needs backward computation.
I0426 12:51:49.054584 14069 net.cpp:198] pool0 needs backward computation.
I0426 12:51:49.054589 14069 net.cpp:198] Sigmoid0 needs backward computation.
I0426 12:51:49.054606 14069 net.cpp:198] conv0 needs backward computation.
I0426 12:51:49.054608 14069 net.cpp:200] cifar does not need backward computation.
I0426 12:51:49.054610 14069 net.cpp:242] This network produces output loss
I0426 12:51:49.054638 14069 net.cpp:255] Network initialization done.
I0426 12:51:49.054906 14069 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/cifar/train_test/var_num_feature_maxiter20000/cifar_train_test_featuresize100.prototxt
I0426 12:51:49.054936 14069 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0426 12:51:49.055145 14069 net.cpp:51] Initializing net from parameters: 
name: "CIFAR"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_test_lmdb"
    batch_size: 1000
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Sigmoid0"
  type: "Sigmoid"
  bottom: "conv0"
  top: "Sigmoid0"
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "Sigmoid0"
  top: "pool0"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Sigmoid1"
  type: "Sigmoid"
  bottom: "conv1"
  top: "Sigmoid1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "Sigmoid1"
  top: "pool1"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Sigmoid2"
  type: "Sigmoid"
  bottom: "conv2"
  top: "Sigmoid2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "Sigmoid2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0426 12:51:49.055238 14069 layer_factory.hpp:77] Creating layer cifar
I0426 12:51:49.055297 14069 db_lmdb.cpp:35] Opened lmdb examples/cifar10/cifar10_test_lmdb
I0426 12:51:49.055308 14069 net.cpp:84] Creating Layer cifar
I0426 12:51:49.055312 14069 net.cpp:380] cifar -> data
I0426 12:51:49.055323 14069 net.cpp:380] cifar -> label
I0426 12:51:49.055348 14069 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I0426 12:51:49.055501 14069 data_layer.cpp:45] output data size: 1000,3,32,32
I0426 12:51:49.078878 14069 net.cpp:122] Setting up cifar
I0426 12:51:49.078912 14069 net.cpp:129] Top shape: 1000 3 32 32 (3072000)
I0426 12:51:49.078917 14069 net.cpp:129] Top shape: 1000 (1000)
I0426 12:51:49.078917 14069 net.cpp:137] Memory required for data: 12292000
I0426 12:51:49.078940 14069 layer_factory.hpp:77] Creating layer label_cifar_1_split
I0426 12:51:49.078949 14069 net.cpp:84] Creating Layer label_cifar_1_split
I0426 12:51:49.078953 14069 net.cpp:406] label_cifar_1_split <- label
I0426 12:51:49.078979 14069 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I0426 12:51:49.079000 14069 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I0426 12:51:49.079151 14069 net.cpp:122] Setting up label_cifar_1_split
I0426 12:51:49.079161 14069 net.cpp:129] Top shape: 1000 (1000)
I0426 12:51:49.079164 14069 net.cpp:129] Top shape: 1000 (1000)
I0426 12:51:49.079166 14069 net.cpp:137] Memory required for data: 12300000
I0426 12:51:49.079183 14069 layer_factory.hpp:77] Creating layer conv0
I0426 12:51:49.079212 14069 net.cpp:84] Creating Layer conv0
I0426 12:51:49.079237 14069 net.cpp:406] conv0 <- data
I0426 12:51:49.079244 14069 net.cpp:380] conv0 -> conv0
I0426 12:51:49.079546 14069 net.cpp:122] Setting up conv0
I0426 12:51:49.079552 14069 net.cpp:129] Top shape: 1000 100 32 32 (102400000)
I0426 12:51:49.079555 14069 net.cpp:137] Memory required for data: 421900000
I0426 12:51:49.079562 14069 layer_factory.hpp:77] Creating layer Sigmoid0
I0426 12:51:49.079589 14069 net.cpp:84] Creating Layer Sigmoid0
I0426 12:51:49.079591 14069 net.cpp:406] Sigmoid0 <- conv0
I0426 12:51:49.079596 14069 net.cpp:380] Sigmoid0 -> Sigmoid0
I0426 12:51:49.079641 14069 net.cpp:122] Setting up Sigmoid0
I0426 12:51:49.079645 14069 net.cpp:129] Top shape: 1000 100 32 32 (102400000)
I0426 12:51:49.079648 14069 net.cpp:137] Memory required for data: 831500000
I0426 12:51:49.079649 14069 layer_factory.hpp:77] Creating layer pool0
I0426 12:51:49.079656 14069 net.cpp:84] Creating Layer pool0
I0426 12:51:49.079659 14069 net.cpp:406] pool0 <- Sigmoid0
I0426 12:51:49.079663 14069 net.cpp:380] pool0 -> pool0
I0426 12:51:49.079680 14069 net.cpp:122] Setting up pool0
I0426 12:51:49.079685 14069 net.cpp:129] Top shape: 1000 100 16 16 (25600000)
I0426 12:51:49.079687 14069 net.cpp:137] Memory required for data: 933900000
I0426 12:51:49.079704 14069 layer_factory.hpp:77] Creating layer conv1
I0426 12:51:49.079757 14069 net.cpp:84] Creating Layer conv1
I0426 12:51:49.079761 14069 net.cpp:406] conv1 <- pool0
I0426 12:51:49.079782 14069 net.cpp:380] conv1 -> conv1
I0426 12:51:49.082423 14069 net.cpp:122] Setting up conv1
I0426 12:51:49.082434 14069 net.cpp:129] Top shape: 1000 100 16 16 (25600000)
I0426 12:51:49.082437 14069 net.cpp:137] Memory required for data: 1036300000
I0426 12:51:49.082445 14069 layer_factory.hpp:77] Creating layer Sigmoid1
I0426 12:51:49.082469 14069 net.cpp:84] Creating Layer Sigmoid1
I0426 12:51:49.082471 14069 net.cpp:406] Sigmoid1 <- conv1
I0426 12:51:49.082475 14069 net.cpp:380] Sigmoid1 -> Sigmoid1
I0426 12:51:49.082494 14069 net.cpp:122] Setting up Sigmoid1
I0426 12:51:49.082499 14069 net.cpp:129] Top shape: 1000 100 16 16 (25600000)
I0426 12:51:49.082500 14069 net.cpp:137] Memory required for data: 1138700000
I0426 12:51:49.082502 14069 layer_factory.hpp:77] Creating layer pool1
I0426 12:51:49.082526 14069 net.cpp:84] Creating Layer pool1
I0426 12:51:49.082547 14069 net.cpp:406] pool1 <- Sigmoid1
I0426 12:51:49.082551 14069 net.cpp:380] pool1 -> pool1
I0426 12:51:49.082567 14069 net.cpp:122] Setting up pool1
I0426 12:51:49.082572 14069 net.cpp:129] Top shape: 1000 100 8 8 (6400000)
I0426 12:51:49.082574 14069 net.cpp:137] Memory required for data: 1164300000
I0426 12:51:49.082576 14069 layer_factory.hpp:77] Creating layer conv2
I0426 12:51:49.082586 14069 net.cpp:84] Creating Layer conv2
I0426 12:51:49.082589 14069 net.cpp:406] conv2 <- pool1
I0426 12:51:49.082594 14069 net.cpp:380] conv2 -> conv2
I0426 12:51:49.085142 14069 net.cpp:122] Setting up conv2
I0426 12:51:49.085152 14069 net.cpp:129] Top shape: 1000 100 8 8 (6400000)
I0426 12:51:49.085155 14069 net.cpp:137] Memory required for data: 1189900000
I0426 12:51:49.085162 14069 layer_factory.hpp:77] Creating layer Sigmoid2
I0426 12:51:49.085186 14069 net.cpp:84] Creating Layer Sigmoid2
I0426 12:51:49.085188 14069 net.cpp:406] Sigmoid2 <- conv2
I0426 12:51:49.085194 14069 net.cpp:380] Sigmoid2 -> Sigmoid2
I0426 12:51:49.085212 14069 net.cpp:122] Setting up Sigmoid2
I0426 12:51:49.085217 14069 net.cpp:129] Top shape: 1000 100 8 8 (6400000)
I0426 12:51:49.085218 14069 net.cpp:137] Memory required for data: 1215500000
I0426 12:51:49.085222 14069 layer_factory.hpp:77] Creating layer pool2
I0426 12:51:49.085229 14069 net.cpp:84] Creating Layer pool2
I0426 12:51:49.085233 14069 net.cpp:406] pool2 <- Sigmoid2
I0426 12:51:49.085237 14069 net.cpp:380] pool2 -> pool2
I0426 12:51:49.085253 14069 net.cpp:122] Setting up pool2
I0426 12:51:49.085258 14069 net.cpp:129] Top shape: 1000 100 4 4 (1600000)
I0426 12:51:49.085259 14069 net.cpp:137] Memory required for data: 1221900000
I0426 12:51:49.085261 14069 layer_factory.hpp:77] Creating layer ip1
I0426 12:51:49.085280 14069 net.cpp:84] Creating Layer ip1
I0426 12:51:49.085283 14069 net.cpp:406] ip1 <- pool2
I0426 12:51:49.085289 14069 net.cpp:380] ip1 -> ip1
I0426 12:51:49.085566 14069 net.cpp:122] Setting up ip1
I0426 12:51:49.085572 14069 net.cpp:129] Top shape: 1000 10 (10000)
I0426 12:51:49.085573 14069 net.cpp:137] Memory required for data: 1221940000
I0426 12:51:49.085577 14069 layer_factory.hpp:77] Creating layer ip1_ip1_0_split
I0426 12:51:49.085580 14069 net.cpp:84] Creating Layer ip1_ip1_0_split
I0426 12:51:49.085584 14069 net.cpp:406] ip1_ip1_0_split <- ip1
I0426 12:51:49.085608 14069 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0426 12:51:49.085613 14069 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0426 12:51:49.085638 14069 net.cpp:122] Setting up ip1_ip1_0_split
I0426 12:51:49.085657 14069 net.cpp:129] Top shape: 1000 10 (10000)
I0426 12:51:49.085660 14069 net.cpp:129] Top shape: 1000 10 (10000)
I0426 12:51:49.085661 14069 net.cpp:137] Memory required for data: 1222020000
I0426 12:51:49.085664 14069 layer_factory.hpp:77] Creating layer accuracy
I0426 12:51:49.085681 14069 net.cpp:84] Creating Layer accuracy
I0426 12:51:49.085685 14069 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I0426 12:51:49.085707 14069 net.cpp:406] accuracy <- label_cifar_1_split_0
I0426 12:51:49.085722 14069 net.cpp:380] accuracy -> accuracy
I0426 12:51:49.085731 14069 net.cpp:122] Setting up accuracy
I0426 12:51:49.085736 14069 net.cpp:129] Top shape: (1)
I0426 12:51:49.085738 14069 net.cpp:137] Memory required for data: 1222020004
I0426 12:51:49.085741 14069 layer_factory.hpp:77] Creating layer loss
I0426 12:51:49.085743 14069 net.cpp:84] Creating Layer loss
I0426 12:51:49.085760 14069 net.cpp:406] loss <- ip1_ip1_0_split_1
I0426 12:51:49.085763 14069 net.cpp:406] loss <- label_cifar_1_split_1
I0426 12:51:49.085767 14069 net.cpp:380] loss -> loss
I0426 12:51:49.085772 14069 layer_factory.hpp:77] Creating layer loss
I0426 12:51:49.085852 14069 net.cpp:122] Setting up loss
I0426 12:51:49.085857 14069 net.cpp:129] Top shape: (1)
I0426 12:51:49.085860 14069 net.cpp:132]     with loss weight 1
I0426 12:51:49.085868 14069 net.cpp:137] Memory required for data: 1222020008
I0426 12:51:49.085870 14069 net.cpp:198] loss needs backward computation.
I0426 12:51:49.085893 14069 net.cpp:200] accuracy does not need backward computation.
I0426 12:51:49.085897 14069 net.cpp:198] ip1_ip1_0_split needs backward computation.
I0426 12:51:49.085901 14069 net.cpp:198] ip1 needs backward computation.
I0426 12:51:49.085916 14069 net.cpp:198] pool2 needs backward computation.
I0426 12:51:49.085921 14069 net.cpp:198] Sigmoid2 needs backward computation.
I0426 12:51:49.085923 14069 net.cpp:198] conv2 needs backward computation.
I0426 12:51:49.085927 14069 net.cpp:198] pool1 needs backward computation.
I0426 12:51:49.085929 14069 net.cpp:198] Sigmoid1 needs backward computation.
I0426 12:51:49.085934 14069 net.cpp:198] conv1 needs backward computation.
I0426 12:51:49.085937 14069 net.cpp:198] pool0 needs backward computation.
I0426 12:51:49.085939 14069 net.cpp:198] Sigmoid0 needs backward computation.
I0426 12:51:49.085943 14069 net.cpp:198] conv0 needs backward computation.
I0426 12:51:49.085947 14069 net.cpp:200] label_cifar_1_split does not need backward computation.
I0426 12:51:49.085950 14069 net.cpp:200] cifar does not need backward computation.
I0426 12:51:49.085952 14069 net.cpp:242] This network produces output accuracy
I0426 12:51:49.085955 14069 net.cpp:242] This network produces output loss
I0426 12:51:49.085969 14069 net.cpp:255] Network initialization done.
I0426 12:51:49.086064 14069 solver.cpp:56] Solver scaffolding done.
I0426 12:51:49.086323 14069 caffe.cpp:248] Starting Optimization
I0426 12:51:49.086328 14069 solver.cpp:273] Solving CIFAR
I0426 12:51:49.086328 14069 solver.cpp:274] Learning Rate Policy: step
I0426 12:51:49.086875 14069 solver.cpp:331] Iteration 0, Testing net (#0)
I0426 12:51:49.087589 14069 blocking_queue.cpp:49] Waiting for data
I0426 12:52:07.998904 14078 data_layer.cpp:73] Restarting data prefetching from start.
I0426 12:52:20.541163 14069 solver.cpp:398]     Test net output #0: accuracy = 0.0964
I0426 12:52:20.541208 14069 solver.cpp:398]     Test net output #1: loss = 2.30935 (* 1 = 2.30935 loss)
I0426 12:52:21.330477 14069 solver.cpp:219] Iteration 0 (0 iter/s, 32.2447s/100 iters), loss = 2.30707
I0426 12:52:21.330507 14069 solver.cpp:238]     Train net output #0: loss = 2.30707 (* 1 = 2.30707 loss)
I0426 12:52:21.330518 14069 sgd_solver.cpp:105] Iteration 0, lr = 0.001
I0426 12:53:39.452775 14069 solver.cpp:219] Iteration 100 (1.28002 iter/s, 78.1237s/100 iters), loss = 2.33615
I0426 12:53:39.452991 14069 solver.cpp:238]     Train net output #0: loss = 2.33615 (* 1 = 2.33615 loss)
I0426 12:53:39.452999 14069 sgd_solver.cpp:105] Iteration 100, lr = 0.001
I0426 12:54:57.350631 14069 solver.cpp:219] Iteration 200 (1.28371 iter/s, 77.8992s/100 iters), loss = 2.32222
I0426 12:54:57.350805 14069 solver.cpp:238]     Train net output #0: loss = 2.32222 (* 1 = 2.32222 loss)
I0426 12:54:57.350812 14069 sgd_solver.cpp:105] Iteration 200, lr = 0.001
I0426 12:56:18.906945 14069 solver.cpp:219] Iteration 300 (1.22613 iter/s, 81.5577s/100 iters), loss = 2.29658
I0426 12:56:18.907032 14069 solver.cpp:238]     Train net output #0: loss = 2.29658 (* 1 = 2.29658 loss)
I0426 12:56:18.907040 14069 sgd_solver.cpp:105] Iteration 300, lr = 0.001
I0426 12:57:37.378320 14069 solver.cpp:219] Iteration 400 (1.27433 iter/s, 78.4728s/100 iters), loss = 2.30344
I0426 12:57:37.378515 14069 solver.cpp:238]     Train net output #0: loss = 2.30344 (* 1 = 2.30344 loss)
I0426 12:57:37.378526 14069 sgd_solver.cpp:105] Iteration 400, lr = 0.001
I0426 12:58:13.563797 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 12:58:56.371683 14069 solver.cpp:219] Iteration 500 (1.26591 iter/s, 78.9947s/100 iters), loss = 2.30905
I0426 12:58:56.371891 14069 solver.cpp:238]     Train net output #0: loss = 2.30905 (* 1 = 2.30905 loss)
I0426 12:58:56.371901 14069 sgd_solver.cpp:105] Iteration 500, lr = 0.001
I0426 13:00:16.417439 14069 solver.cpp:219] Iteration 600 (1.24926 iter/s, 80.0471s/100 iters), loss = 2.29072
I0426 13:00:16.417582 14069 solver.cpp:238]     Train net output #0: loss = 2.29072 (* 1 = 2.29072 loss)
I0426 13:00:16.417592 14069 sgd_solver.cpp:105] Iteration 600, lr = 0.001
I0426 13:01:34.345950 14069 solver.cpp:219] Iteration 700 (1.28321 iter/s, 77.9299s/100 iters), loss = 2.23042
I0426 13:01:34.346166 14069 solver.cpp:238]     Train net output #0: loss = 2.23042 (* 1 = 2.23042 loss)
I0426 13:01:34.346174 14069 sgd_solver.cpp:105] Iteration 700, lr = 0.001
I0426 13:02:55.731429 14069 solver.cpp:219] Iteration 800 (1.2287 iter/s, 81.3868s/100 iters), loss = 2.09429
I0426 13:02:55.731600 14069 solver.cpp:238]     Train net output #0: loss = 2.09429 (* 1 = 2.09429 loss)
I0426 13:02:55.731611 14069 sgd_solver.cpp:105] Iteration 800, lr = 0.001
I0426 13:04:12.168982 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 13:04:15.284574 14069 solver.cpp:219] Iteration 900 (1.257 iter/s, 79.5545s/100 iters), loss = 2.07278
I0426 13:04:15.284610 14069 solver.cpp:238]     Train net output #0: loss = 2.07278 (* 1 = 2.07278 loss)
I0426 13:04:15.284616 14069 sgd_solver.cpp:105] Iteration 900, lr = 0.001
I0426 13:05:31.968559 14069 solver.cpp:331] Iteration 1000, Testing net (#0)
I0426 13:05:51.132455 14078 data_layer.cpp:73] Restarting data prefetching from start.
I0426 13:06:03.680734 14069 solver.cpp:398]     Test net output #0: accuracy = 0.2215
I0426 13:06:03.680928 14069 solver.cpp:398]     Test net output #1: loss = 2.04961 (* 1 = 2.04961 loss)
I0426 13:06:04.465675 14069 solver.cpp:219] Iteration 1000 (0.915892 iter/s, 109.183s/100 iters), loss = 2.01935
I0426 13:06:04.465708 14069 solver.cpp:238]     Train net output #0: loss = 2.01935 (* 1 = 2.01935 loss)
I0426 13:06:04.465715 14069 sgd_solver.cpp:105] Iteration 1000, lr = 0.001
I0426 13:07:22.285929 14069 solver.cpp:219] Iteration 1100 (1.28499 iter/s, 77.8217s/100 iters), loss = 2.02725
I0426 13:07:22.286061 14069 solver.cpp:238]     Train net output #0: loss = 2.02725 (* 1 = 2.02725 loss)
I0426 13:07:22.286068 14069 sgd_solver.cpp:105] Iteration 1100, lr = 0.001
I0426 13:08:40.108750 14069 solver.cpp:219] Iteration 1200 (1.28495 iter/s, 77.8242s/100 iters), loss = 2.09892
I0426 13:08:40.108844 14069 solver.cpp:238]     Train net output #0: loss = 2.09892 (* 1 = 2.09892 loss)
I0426 13:08:40.108866 14069 sgd_solver.cpp:105] Iteration 1200, lr = 0.001
I0426 13:09:57.956495 14069 solver.cpp:219] Iteration 1300 (1.28454 iter/s, 77.8492s/100 iters), loss = 2.04577
I0426 13:09:57.956542 14069 solver.cpp:238]     Train net output #0: loss = 2.04577 (* 1 = 2.04577 loss)
I0426 13:09:57.956547 14069 sgd_solver.cpp:105] Iteration 1300, lr = 0.001
I0426 13:10:34.547554 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 13:11:15.792001 14069 solver.cpp:219] Iteration 1400 (1.28474 iter/s, 77.837s/100 iters), loss = 1.99917
I0426 13:11:15.792054 14069 solver.cpp:238]     Train net output #0: loss = 1.99917 (* 1 = 1.99917 loss)
I0426 13:11:15.792062 14069 sgd_solver.cpp:105] Iteration 1400, lr = 0.001
I0426 13:12:33.568886 14069 solver.cpp:219] Iteration 1500 (1.28571 iter/s, 77.7783s/100 iters), loss = 2.04658
I0426 13:12:33.569115 14069 solver.cpp:238]     Train net output #0: loss = 2.04658 (* 1 = 2.04658 loss)
I0426 13:12:33.569124 14069 sgd_solver.cpp:105] Iteration 1500, lr = 0.001
I0426 13:13:51.402956 14069 solver.cpp:219] Iteration 1600 (1.28476 iter/s, 77.8353s/100 iters), loss = 2.09504
I0426 13:13:51.403018 14069 solver.cpp:238]     Train net output #0: loss = 2.09504 (* 1 = 2.09504 loss)
I0426 13:13:51.403025 14069 sgd_solver.cpp:105] Iteration 1600, lr = 0.001
I0426 13:15:09.580754 14069 solver.cpp:219] Iteration 1700 (1.27911 iter/s, 78.1792s/100 iters), loss = 1.92808
I0426 13:15:09.580849 14069 solver.cpp:238]     Train net output #0: loss = 1.92808 (* 1 = 1.92808 loss)
I0426 13:15:09.580873 14069 sgd_solver.cpp:105] Iteration 1700, lr = 0.001
I0426 13:16:25.168897 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 13:16:27.523013 14069 solver.cpp:219] Iteration 1800 (1.28298 iter/s, 77.9437s/100 iters), loss = 1.8653
I0426 13:16:27.523051 14069 solver.cpp:238]     Train net output #0: loss = 1.8653 (* 1 = 1.8653 loss)
I0426 13:16:27.523057 14069 sgd_solver.cpp:105] Iteration 1800, lr = 0.001
I0426 13:17:45.421749 14069 solver.cpp:219] Iteration 1900 (1.28369 iter/s, 77.9002s/100 iters), loss = 1.85126
I0426 13:17:45.421943 14069 solver.cpp:238]     Train net output #0: loss = 1.85126 (* 1 = 1.85126 loss)
I0426 13:17:45.421953 14069 sgd_solver.cpp:105] Iteration 1900, lr = 0.001
I0426 13:19:06.262532 14069 solver.cpp:331] Iteration 2000, Testing net (#0)
I0426 13:19:25.466176 14078 data_layer.cpp:73] Restarting data prefetching from start.
I0426 13:19:37.990213 14069 solver.cpp:398]     Test net output #0: accuracy = 0.2819
I0426 13:19:37.990309 14069 solver.cpp:398]     Test net output #1: loss = 1.95786 (* 1 = 1.95786 loss)
I0426 13:19:38.775362 14069 solver.cpp:219] Iteration 2000 (0.88218 iter/s, 113.356s/100 iters), loss = 1.94573
I0426 13:19:38.775394 14069 solver.cpp:238]     Train net output #0: loss = 1.94573 (* 1 = 1.94573 loss)
I0426 13:19:38.775401 14069 sgd_solver.cpp:105] Iteration 2000, lr = 0.001
I0426 13:20:56.628952 14069 solver.cpp:219] Iteration 2100 (1.28444 iter/s, 77.855s/100 iters), loss = 1.87568
I0426 13:20:56.629120 14069 solver.cpp:238]     Train net output #0: loss = 1.87568 (* 1 = 1.87568 loss)
I0426 13:20:56.629127 14069 sgd_solver.cpp:105] Iteration 2100, lr = 0.001
I0426 13:22:14.497007 14069 solver.cpp:219] Iteration 2200 (1.2842 iter/s, 77.8694s/100 iters), loss = 1.91178
I0426 13:22:14.497133 14069 solver.cpp:238]     Train net output #0: loss = 1.91178 (* 1 = 1.91178 loss)
I0426 13:22:14.497139 14069 sgd_solver.cpp:105] Iteration 2200, lr = 0.001
I0426 13:22:51.894306 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 13:23:32.379595 14069 solver.cpp:219] Iteration 2300 (1.28396 iter/s, 77.884s/100 iters), loss = 1.78119
I0426 13:23:32.379765 14069 solver.cpp:238]     Train net output #0: loss = 1.78119 (* 1 = 1.78119 loss)
I0426 13:23:32.379770 14069 sgd_solver.cpp:105] Iteration 2300, lr = 0.001
I0426 13:24:50.309747 14069 solver.cpp:219] Iteration 2400 (1.28318 iter/s, 77.9315s/100 iters), loss = 1.92482
I0426 13:24:50.309973 14069 solver.cpp:238]     Train net output #0: loss = 1.92482 (* 1 = 1.92482 loss)
I0426 13:24:50.309980 14069 sgd_solver.cpp:105] Iteration 2400, lr = 0.001
I0426 13:26:08.221483 14069 solver.cpp:219] Iteration 2500 (1.28348 iter/s, 77.913s/100 iters), loss = 1.89
I0426 13:26:08.221617 14069 solver.cpp:238]     Train net output #0: loss = 1.89 (* 1 = 1.89 loss)
I0426 13:26:08.221626 14069 sgd_solver.cpp:105] Iteration 2500, lr = 0.001
I0426 13:27:26.039783 14069 solver.cpp:219] Iteration 2600 (1.28502 iter/s, 77.8197s/100 iters), loss = 1.96506
I0426 13:27:26.039973 14069 solver.cpp:238]     Train net output #0: loss = 1.96506 (* 1 = 1.96506 loss)
I0426 13:27:26.039980 14069 sgd_solver.cpp:105] Iteration 2600, lr = 0.001
I0426 13:28:42.365842 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 13:28:43.937566 14069 solver.cpp:219] Iteration 2700 (1.28371 iter/s, 77.8991s/100 iters), loss = 1.87271
I0426 13:28:43.937613 14069 solver.cpp:238]     Train net output #0: loss = 1.87271 (* 1 = 1.87271 loss)
I0426 13:28:43.937618 14069 sgd_solver.cpp:105] Iteration 2700, lr = 0.001
I0426 13:30:01.830195 14069 solver.cpp:219] Iteration 2800 (1.28379 iter/s, 77.8941s/100 iters), loss = 1.89922
I0426 13:30:01.830276 14069 solver.cpp:238]     Train net output #0: loss = 1.89922 (* 1 = 1.89922 loss)
I0426 13:30:01.830282 14069 sgd_solver.cpp:105] Iteration 2800, lr = 0.001
I0426 13:31:19.676942 14069 solver.cpp:219] Iteration 2900 (1.28455 iter/s, 77.8482s/100 iters), loss = 1.89918
I0426 13:31:19.677076 14069 solver.cpp:238]     Train net output #0: loss = 1.89918 (* 1 = 1.89918 loss)
I0426 13:31:19.677084 14069 sgd_solver.cpp:105] Iteration 2900, lr = 0.001
I0426 13:32:36.408278 14069 solver.cpp:331] Iteration 3000, Testing net (#0)
I0426 13:32:55.610065 14078 data_layer.cpp:73] Restarting data prefetching from start.
I0426 13:33:08.176985 14069 solver.cpp:398]     Test net output #0: accuracy = 0.3079
I0426 13:33:08.177067 14069 solver.cpp:398]     Test net output #1: loss = 1.88406 (* 1 = 1.88406 loss)
I0426 13:33:08.961079 14069 solver.cpp:219] Iteration 3000 (0.91503 iter/s, 109.286s/100 iters), loss = 1.96542
I0426 13:33:08.961112 14069 solver.cpp:238]     Train net output #0: loss = 1.96542 (* 1 = 1.96542 loss)
I0426 13:33:08.961120 14069 sgd_solver.cpp:105] Iteration 3000, lr = 0.001
I0426 13:34:26.810155 14069 solver.cpp:219] Iteration 3100 (1.28451 iter/s, 77.8505s/100 iters), loss = 1.911
I0426 13:34:26.810345 14069 solver.cpp:238]     Train net output #0: loss = 1.911 (* 1 = 1.911 loss)
I0426 13:34:26.810355 14069 sgd_solver.cpp:105] Iteration 3100, lr = 0.001
I0426 13:35:04.958727 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 13:35:44.634204 14069 solver.cpp:219] Iteration 3200 (1.28493 iter/s, 77.8253s/100 iters), loss = 1.96189
I0426 13:35:44.634369 14069 solver.cpp:238]     Train net output #0: loss = 1.96189 (* 1 = 1.96189 loss)
I0426 13:35:44.634393 14069 sgd_solver.cpp:105] Iteration 3200, lr = 0.001
I0426 13:37:02.487689 14069 solver.cpp:219] Iteration 3300 (1.28444 iter/s, 77.8548s/100 iters), loss = 1.98802
I0426 13:37:02.487876 14069 solver.cpp:238]     Train net output #0: loss = 1.98802 (* 1 = 1.98802 loss)
I0426 13:37:02.487884 14069 sgd_solver.cpp:105] Iteration 3300, lr = 0.001
I0426 13:38:20.353365 14069 solver.cpp:219] Iteration 3400 (1.28424 iter/s, 77.867s/100 iters), loss = 1.9638
I0426 13:38:20.353413 14069 solver.cpp:238]     Train net output #0: loss = 1.9638 (* 1 = 1.9638 loss)
I0426 13:38:20.353418 14069 sgd_solver.cpp:105] Iteration 3400, lr = 0.001
I0426 13:39:38.253957 14069 solver.cpp:219] Iteration 3500 (1.28366 iter/s, 77.902s/100 iters), loss = 1.73277
I0426 13:39:38.254137 14069 solver.cpp:238]     Train net output #0: loss = 1.73277 (* 1 = 1.73277 loss)
I0426 13:39:38.254143 14069 sgd_solver.cpp:105] Iteration 3500, lr = 0.001
I0426 13:40:55.427639 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 13:40:56.211012 14069 solver.cpp:219] Iteration 3600 (1.28274 iter/s, 77.9584s/100 iters), loss = 1.926
I0426 13:40:56.211046 14069 solver.cpp:238]     Train net output #0: loss = 1.926 (* 1 = 1.926 loss)
I0426 13:40:56.211053 14069 sgd_solver.cpp:105] Iteration 3600, lr = 0.001
I0426 13:42:14.138304 14069 solver.cpp:219] Iteration 3700 (1.28322 iter/s, 77.9287s/100 iters), loss = 1.78272
I0426 13:42:14.138401 14069 solver.cpp:238]     Train net output #0: loss = 1.78272 (* 1 = 1.78272 loss)
I0426 13:42:14.138406 14069 sgd_solver.cpp:105] Iteration 3700, lr = 0.001
I0426 13:43:32.051072 14069 solver.cpp:219] Iteration 3800 (1.28346 iter/s, 77.9142s/100 iters), loss = 1.86848
I0426 13:43:32.051128 14069 solver.cpp:238]     Train net output #0: loss = 1.86848 (* 1 = 1.86848 loss)
I0426 13:43:32.051136 14069 sgd_solver.cpp:105] Iteration 3800, lr = 0.001
I0426 13:44:49.967118 14069 solver.cpp:219] Iteration 3900 (1.28341 iter/s, 77.9175s/100 iters), loss = 1.86787
I0426 13:44:49.967198 14069 solver.cpp:238]     Train net output #0: loss = 1.86787 (* 1 = 1.86787 loss)
I0426 13:44:49.967206 14069 sgd_solver.cpp:105] Iteration 3900, lr = 0.001
I0426 13:46:06.691370 14069 solver.cpp:331] Iteration 4000, Testing net (#0)
I0426 13:46:25.888240 14078 data_layer.cpp:73] Restarting data prefetching from start.
I0426 13:46:38.397851 14069 solver.cpp:398]     Test net output #0: accuracy = 0.3503
I0426 13:46:38.398027 14069 solver.cpp:398]     Test net output #1: loss = 1.81317 (* 1 = 1.81317 loss)
I0426 13:46:39.182663 14069 solver.cpp:219] Iteration 4000 (0.915604 iter/s, 109.218s/100 iters), loss = 1.85738
I0426 13:46:39.182696 14069 solver.cpp:238]     Train net output #0: loss = 1.85738 (* 1 = 1.85738 loss)
I0426 13:46:39.182704 14069 sgd_solver.cpp:105] Iteration 4000, lr = 0.001
I0426 13:47:18.150661 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 13:47:57.114207 14069 solver.cpp:219] Iteration 4100 (1.28315 iter/s, 77.9329s/100 iters), loss = 2.01851
I0426 13:47:57.114262 14069 solver.cpp:238]     Train net output #0: loss = 2.01851 (* 1 = 2.01851 loss)
I0426 13:47:57.114269 14069 sgd_solver.cpp:105] Iteration 4100, lr = 0.001
I0426 13:49:15.055915 14069 solver.cpp:219] Iteration 4200 (1.28299 iter/s, 77.9431s/100 iters), loss = 1.78827
I0426 13:49:15.056092 14069 solver.cpp:238]     Train net output #0: loss = 1.78827 (* 1 = 1.78827 loss)
I0426 13:49:15.056098 14069 sgd_solver.cpp:105] Iteration 4200, lr = 0.001
I0426 13:50:32.971042 14069 solver.cpp:219] Iteration 4300 (1.28343 iter/s, 77.9164s/100 iters), loss = 1.72212
I0426 13:50:32.971240 14069 solver.cpp:238]     Train net output #0: loss = 1.72212 (* 1 = 1.72212 loss)
I0426 13:50:32.971247 14069 sgd_solver.cpp:105] Iteration 4300, lr = 0.001
I0426 13:51:50.896446 14069 solver.cpp:219] Iteration 4400 (1.28326 iter/s, 77.9267s/100 iters), loss = 1.77464
I0426 13:51:50.896656 14069 solver.cpp:238]     Train net output #0: loss = 1.77464 (* 1 = 1.77464 loss)
I0426 13:51:50.896667 14069 sgd_solver.cpp:105] Iteration 4400, lr = 0.001
I0426 13:53:08.807322 14069 solver.cpp:219] Iteration 4500 (1.2835 iter/s, 77.9121s/100 iters), loss = 1.81538
I0426 13:53:08.807377 14069 solver.cpp:238]     Train net output #0: loss = 1.81538 (* 1 = 1.81538 loss)
I0426 13:53:08.807385 14069 sgd_solver.cpp:105] Iteration 4500, lr = 0.001
I0426 13:53:08.810264 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 13:54:26.683611 14069 solver.cpp:219] Iteration 4600 (1.28406 iter/s, 77.8777s/100 iters), loss = 1.82276
I0426 13:54:26.683800 14069 solver.cpp:238]     Train net output #0: loss = 1.82276 (* 1 = 1.82276 loss)
I0426 13:54:26.683809 14069 sgd_solver.cpp:105] Iteration 4600, lr = 0.001
I0426 13:55:44.584623 14069 solver.cpp:219] Iteration 4700 (1.28366 iter/s, 77.9023s/100 iters), loss = 1.70937
I0426 13:55:44.584677 14069 solver.cpp:238]     Train net output #0: loss = 1.70937 (* 1 = 1.70937 loss)
I0426 13:55:44.584684 14069 sgd_solver.cpp:105] Iteration 4700, lr = 0.001
I0426 13:57:02.447253 14069 solver.cpp:219] Iteration 4800 (1.28429 iter/s, 77.8641s/100 iters), loss = 1.99523
I0426 13:57:02.447307 14069 solver.cpp:238]     Train net output #0: loss = 1.99523 (* 1 = 1.99523 loss)
I0426 13:57:02.447314 14069 sgd_solver.cpp:105] Iteration 4800, lr = 0.001
I0426 13:58:20.633561 14069 solver.cpp:219] Iteration 4900 (1.27897 iter/s, 78.1877s/100 iters), loss = 1.7206
I0426 13:58:20.633697 14069 solver.cpp:238]     Train net output #0: loss = 1.7206 (* 1 = 1.7206 loss)
I0426 13:58:20.633723 14069 sgd_solver.cpp:105] Iteration 4900, lr = 0.001
I0426 13:58:59.888995 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 13:59:37.740178 14069 solver.cpp:331] Iteration 5000, Testing net (#0)
I0426 13:59:56.999176 14078 data_layer.cpp:73] Restarting data prefetching from start.
I0426 14:00:09.599745 14069 solver.cpp:398]     Test net output #0: accuracy = 0.3585
I0426 14:00:09.599941 14069 solver.cpp:398]     Test net output #1: loss = 1.77734 (* 1 = 1.77734 loss)
I0426 14:00:10.393671 14069 solver.cpp:219] Iteration 5000 (0.911061 iter/s, 109.762s/100 iters), loss = 1.82089
I0426 14:00:10.393708 14069 solver.cpp:238]     Train net output #0: loss = 1.82089 (* 1 = 1.82089 loss)
I0426 14:00:10.393715 14069 sgd_solver.cpp:105] Iteration 5000, lr = 0.001
I0426 14:01:28.302614 14069 solver.cpp:219] Iteration 5100 (1.28353 iter/s, 77.9104s/100 iters), loss = 1.74203
I0426 14:01:28.302697 14069 solver.cpp:238]     Train net output #0: loss = 1.74203 (* 1 = 1.74203 loss)
I0426 14:01:28.302702 14069 sgd_solver.cpp:105] Iteration 5100, lr = 0.001
I0426 14:02:46.235296 14069 solver.cpp:219] Iteration 5200 (1.28314 iter/s, 77.9341s/100 iters), loss = 1.85109
I0426 14:02:46.235342 14069 solver.cpp:238]     Train net output #0: loss = 1.85109 (* 1 = 1.85109 loss)
I0426 14:02:46.235375 14069 sgd_solver.cpp:105] Iteration 5200, lr = 0.001
I0426 14:04:04.169440 14069 solver.cpp:219] Iteration 5300 (1.28311 iter/s, 77.9356s/100 iters), loss = 1.68095
I0426 14:04:04.169611 14069 solver.cpp:238]     Train net output #0: loss = 1.68095 (* 1 = 1.68095 loss)
I0426 14:04:04.169618 14069 sgd_solver.cpp:105] Iteration 5300, lr = 0.001
I0426 14:05:22.082578 14069 solver.cpp:219] Iteration 5400 (1.28346 iter/s, 77.9145s/100 iters), loss = 1.80515
I0426 14:05:22.082744 14069 solver.cpp:238]     Train net output #0: loss = 1.80515 (* 1 = 1.80515 loss)
I0426 14:05:22.082751 14069 sgd_solver.cpp:105] Iteration 5400, lr = 0.001
I0426 14:05:22.879374 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 14:06:40.055795 14069 solver.cpp:219] Iteration 5500 (1.28247 iter/s, 77.9745s/100 iters), loss = 1.86233
I0426 14:06:40.055927 14069 solver.cpp:238]     Train net output #0: loss = 1.86233 (* 1 = 1.86233 loss)
I0426 14:06:40.055933 14069 sgd_solver.cpp:105] Iteration 5500, lr = 0.001
I0426 14:07:58.004443 14069 solver.cpp:219] Iteration 5600 (1.28287 iter/s, 77.95s/100 iters), loss = 1.59249
I0426 14:07:58.004642 14069 solver.cpp:238]     Train net output #0: loss = 1.59249 (* 1 = 1.59249 loss)
I0426 14:07:58.004649 14069 sgd_solver.cpp:105] Iteration 5600, lr = 0.001
I0426 14:09:15.971370 14069 solver.cpp:219] Iteration 5700 (1.28257 iter/s, 77.9682s/100 iters), loss = 1.75282
I0426 14:09:15.971426 14069 solver.cpp:238]     Train net output #0: loss = 1.75282 (* 1 = 1.75282 loss)
I0426 14:09:15.971432 14069 sgd_solver.cpp:105] Iteration 5700, lr = 0.001
I0426 14:10:33.904778 14069 solver.cpp:219] Iteration 5800 (1.28312 iter/s, 77.9348s/100 iters), loss = 1.81151
I0426 14:10:33.904969 14069 solver.cpp:238]     Train net output #0: loss = 1.81151 (* 1 = 1.81151 loss)
I0426 14:10:33.904978 14069 sgd_solver.cpp:105] Iteration 5800, lr = 0.001
I0426 14:11:13.678733 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 14:11:51.915587 14069 solver.cpp:219] Iteration 5900 (1.28185 iter/s, 78.0121s/100 iters), loss = 1.64649
I0426 14:11:51.915766 14069 solver.cpp:238]     Train net output #0: loss = 1.64649 (* 1 = 1.64649 loss)
I0426 14:11:51.915773 14069 sgd_solver.cpp:105] Iteration 5900, lr = 0.001
I0426 14:13:08.726620 14069 solver.cpp:331] Iteration 6000, Testing net (#0)
I0426 14:13:27.968993 14078 data_layer.cpp:73] Restarting data prefetching from start.
I0426 14:13:40.548841 14069 solver.cpp:398]     Test net output #0: accuracy = 0.3942
I0426 14:13:40.548940 14069 solver.cpp:398]     Test net output #1: loss = 1.7103 (* 1 = 1.7103 loss)
I0426 14:13:41.342478 14069 solver.cpp:219] Iteration 6000 (0.913836 iter/s, 109.429s/100 iters), loss = 1.61062
I0426 14:13:41.342514 14069 solver.cpp:238]     Train net output #0: loss = 1.61062 (* 1 = 1.61062 loss)
I0426 14:13:41.342520 14069 sgd_solver.cpp:105] Iteration 6000, lr = 0.001
I0426 14:14:59.261323 14069 solver.cpp:219] Iteration 6100 (1.28336 iter/s, 77.9203s/100 iters), loss = 1.62244
I0426 14:14:59.261468 14069 solver.cpp:238]     Train net output #0: loss = 1.62244 (* 1 = 1.62244 loss)
I0426 14:14:59.261476 14069 sgd_solver.cpp:105] Iteration 6100, lr = 0.001
I0426 14:16:17.222833 14069 solver.cpp:219] Iteration 6200 (1.28266 iter/s, 77.9629s/100 iters), loss = 1.84652
I0426 14:16:17.223067 14069 solver.cpp:238]     Train net output #0: loss = 1.84652 (* 1 = 1.84652 loss)
I0426 14:16:17.223076 14069 sgd_solver.cpp:105] Iteration 6200, lr = 0.001
I0426 14:17:35.179891 14069 solver.cpp:219] Iteration 6300 (1.28274 iter/s, 77.9583s/100 iters), loss = 1.70111
I0426 14:17:35.180079 14069 solver.cpp:238]     Train net output #0: loss = 1.70111 (* 1 = 1.70111 loss)
I0426 14:17:35.180088 14069 sgd_solver.cpp:105] Iteration 6300, lr = 0.001
I0426 14:17:36.762969 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 14:18:53.156967 14069 solver.cpp:219] Iteration 6400 (1.28241 iter/s, 77.9784s/100 iters), loss = 1.8451
I0426 14:18:53.157157 14069 solver.cpp:238]     Train net output #0: loss = 1.8451 (* 1 = 1.8451 loss)
I0426 14:18:53.157166 14069 sgd_solver.cpp:105] Iteration 6400, lr = 0.001
I0426 14:20:11.120296 14069 solver.cpp:219] Iteration 6500 (1.28263 iter/s, 77.9646s/100 iters), loss = 1.57919
I0426 14:20:11.120349 14069 solver.cpp:238]     Train net output #0: loss = 1.57919 (* 1 = 1.57919 loss)
I0426 14:20:11.120357 14069 sgd_solver.cpp:105] Iteration 6500, lr = 0.001
I0426 14:21:29.075791 14069 solver.cpp:219] Iteration 6600 (1.28276 iter/s, 77.9569s/100 iters), loss = 1.78489
I0426 14:21:29.075846 14069 solver.cpp:238]     Train net output #0: loss = 1.78489 (* 1 = 1.78489 loss)
I0426 14:21:29.075853 14069 sgd_solver.cpp:105] Iteration 6600, lr = 0.001
I0426 14:22:47.041188 14069 solver.cpp:219] Iteration 6700 (1.2826 iter/s, 77.9668s/100 iters), loss = 1.68886
I0426 14:22:47.041375 14069 solver.cpp:238]     Train net output #0: loss = 1.68886 (* 1 = 1.68886 loss)
I0426 14:22:47.041384 14069 sgd_solver.cpp:105] Iteration 6700, lr = 0.001
I0426 14:23:27.602352 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 14:24:05.078832 14069 solver.cpp:219] Iteration 6800 (1.28141 iter/s, 78.0389s/100 iters), loss = 1.85267
I0426 14:24:05.079051 14069 solver.cpp:238]     Train net output #0: loss = 1.85267 (* 1 = 1.85267 loss)
I0426 14:24:05.079071 14069 sgd_solver.cpp:105] Iteration 6800, lr = 0.001
I0426 14:25:23.029750 14069 solver.cpp:219] Iteration 6900 (1.28284 iter/s, 77.9522s/100 iters), loss = 1.80458
I0426 14:25:23.029923 14069 solver.cpp:238]     Train net output #0: loss = 1.80458 (* 1 = 1.80458 loss)
I0426 14:25:23.029930 14069 sgd_solver.cpp:105] Iteration 6900, lr = 0.001
I0426 14:26:39.799777 14069 solver.cpp:331] Iteration 7000, Testing net (#0)
I0426 14:26:59.044312 14078 data_layer.cpp:73] Restarting data prefetching from start.
I0426 14:27:11.642771 14069 solver.cpp:398]     Test net output #0: accuracy = 0.3908
I0426 14:27:11.642856 14069 solver.cpp:398]     Test net output #1: loss = 1.67923 (* 1 = 1.67923 loss)
I0426 14:27:12.434408 14069 solver.cpp:219] Iteration 7000 (0.914023 iter/s, 109.406s/100 iters), loss = 1.81905
I0426 14:27:12.434442 14069 solver.cpp:238]     Train net output #0: loss = 1.81905 (* 1 = 1.81905 loss)
I0426 14:27:12.434447 14069 sgd_solver.cpp:105] Iteration 7000, lr = 0.001
I0426 14:28:30.339771 14069 solver.cpp:219] Iteration 7100 (1.28359 iter/s, 77.9067s/100 iters), loss = 1.74271
I0426 14:28:30.339818 14069 solver.cpp:238]     Train net output #0: loss = 1.74271 (* 1 = 1.74271 loss)
I0426 14:28:30.339823 14069 sgd_solver.cpp:105] Iteration 7100, lr = 0.001
I0426 14:29:48.234033 14069 solver.cpp:219] Iteration 7200 (1.28377 iter/s, 77.8956s/100 iters), loss = 1.57866
I0426 14:29:48.234094 14069 solver.cpp:238]     Train net output #0: loss = 1.57866 (* 1 = 1.57866 loss)
I0426 14:29:48.234100 14069 sgd_solver.cpp:105] Iteration 7200, lr = 0.001
I0426 14:29:50.592725 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 14:31:06.159804 14069 solver.cpp:219] Iteration 7300 (1.28325 iter/s, 77.9271s/100 iters), loss = 1.73709
I0426 14:31:06.159986 14069 solver.cpp:238]     Train net output #0: loss = 1.73709 (* 1 = 1.73709 loss)
I0426 14:31:06.159991 14069 sgd_solver.cpp:105] Iteration 7300, lr = 0.001
I0426 14:32:24.050288 14069 solver.cpp:219] Iteration 7400 (1.28383 iter/s, 77.8917s/100 iters), loss = 1.749
I0426 14:32:24.050365 14069 solver.cpp:238]     Train net output #0: loss = 1.749 (* 1 = 1.749 loss)
I0426 14:32:24.050371 14069 sgd_solver.cpp:105] Iteration 7400, lr = 0.001
I0426 14:33:41.929903 14069 solver.cpp:219] Iteration 7500 (1.28401 iter/s, 77.8809s/100 iters), loss = 1.60896
I0426 14:33:41.930032 14069 solver.cpp:238]     Train net output #0: loss = 1.60896 (* 1 = 1.60896 loss)
I0426 14:33:41.930038 14069 sgd_solver.cpp:105] Iteration 7500, lr = 0.001
I0426 14:34:59.816035 14069 solver.cpp:219] Iteration 7600 (1.28391 iter/s, 77.8874s/100 iters), loss = 1.61961
I0426 14:34:59.816093 14069 solver.cpp:238]     Train net output #0: loss = 1.61961 (* 1 = 1.61961 loss)
I0426 14:34:59.816112 14069 sgd_solver.cpp:105] Iteration 7600, lr = 0.001
I0426 14:35:41.129175 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 14:36:17.764694 14069 solver.cpp:219] Iteration 7700 (1.28287 iter/s, 77.95s/100 iters), loss = 1.52021
I0426 14:36:17.764832 14069 solver.cpp:238]     Train net output #0: loss = 1.52021 (* 1 = 1.52021 loss)
I0426 14:36:17.764839 14069 sgd_solver.cpp:105] Iteration 7700, lr = 0.001
I0426 14:37:35.656245 14069 solver.cpp:219] Iteration 7800 (1.28382 iter/s, 77.8928s/100 iters), loss = 1.83376
I0426 14:37:35.656407 14069 solver.cpp:238]     Train net output #0: loss = 1.83376 (* 1 = 1.83376 loss)
I0426 14:37:35.656414 14069 sgd_solver.cpp:105] Iteration 7800, lr = 0.001
I0426 14:38:53.548992 14069 solver.cpp:219] Iteration 7900 (1.2838 iter/s, 77.8939s/100 iters), loss = 1.80928
I0426 14:38:53.549037 14069 solver.cpp:238]     Train net output #0: loss = 1.80928 (* 1 = 1.80928 loss)
I0426 14:38:53.549043 14069 sgd_solver.cpp:105] Iteration 7900, lr = 0.001
I0426 14:40:10.287534 14069 solver.cpp:331] Iteration 8000, Testing net (#0)
I0426 14:40:29.493980 14078 data_layer.cpp:73] Restarting data prefetching from start.
I0426 14:40:42.071599 14069 solver.cpp:398]     Test net output #0: accuracy = 0.4138
I0426 14:40:42.071756 14069 solver.cpp:398]     Test net output #1: loss = 1.64249 (* 1 = 1.64249 loss)
I0426 14:40:42.863360 14069 solver.cpp:219] Iteration 8000 (0.914777 iter/s, 109.316s/100 iters), loss = 1.71811
I0426 14:40:42.863394 14069 solver.cpp:238]     Train net output #0: loss = 1.71811 (* 1 = 1.71811 loss)
I0426 14:40:42.863399 14069 sgd_solver.cpp:105] Iteration 8000, lr = 0.001
I0426 14:42:00.743690 14069 solver.cpp:219] Iteration 8100 (1.284 iter/s, 77.8817s/100 iters), loss = 1.57435
I0426 14:42:00.743741 14069 solver.cpp:238]     Train net output #0: loss = 1.57435 (* 1 = 1.57435 loss)
I0426 14:42:00.743747 14069 sgd_solver.cpp:105] Iteration 8100, lr = 0.001
I0426 14:42:03.887274 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 14:43:18.625016 14069 solver.cpp:219] Iteration 8200 (1.28398 iter/s, 77.8826s/100 iters), loss = 1.86277
I0426 14:43:18.625063 14069 solver.cpp:238]     Train net output #0: loss = 1.86277 (* 1 = 1.86277 loss)
I0426 14:43:18.625069 14069 sgd_solver.cpp:105] Iteration 8200, lr = 0.001
I0426 14:44:36.533327 14069 solver.cpp:219] Iteration 8300 (1.28354 iter/s, 77.9096s/100 iters), loss = 1.76569
I0426 14:44:36.533385 14069 solver.cpp:238]     Train net output #0: loss = 1.76569 (* 1 = 1.76569 loss)
I0426 14:44:36.533391 14069 sgd_solver.cpp:105] Iteration 8300, lr = 0.001
I0426 14:45:54.393460 14069 solver.cpp:219] Iteration 8400 (1.28433 iter/s, 77.8614s/100 iters), loss = 1.54285
I0426 14:45:54.393636 14069 solver.cpp:238]     Train net output #0: loss = 1.54285 (* 1 = 1.54285 loss)
I0426 14:45:54.393643 14069 sgd_solver.cpp:105] Iteration 8400, lr = 0.001
I0426 14:47:12.259841 14069 solver.cpp:219] Iteration 8500 (1.28423 iter/s, 77.8676s/100 iters), loss = 1.68095
I0426 14:47:12.259888 14069 solver.cpp:238]     Train net output #0: loss = 1.68095 (* 1 = 1.68095 loss)
I0426 14:47:12.259894 14069 sgd_solver.cpp:105] Iteration 8500, lr = 0.001
I0426 14:47:54.326021 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 14:48:30.165004 14069 solver.cpp:219] Iteration 8600 (1.28359 iter/s, 77.9065s/100 iters), loss = 1.62438
I0426 14:48:30.165148 14069 solver.cpp:238]     Train net output #0: loss = 1.62438 (* 1 = 1.62438 loss)
I0426 14:48:30.165155 14069 sgd_solver.cpp:105] Iteration 8600, lr = 0.001
I0426 14:49:48.052781 14069 solver.cpp:219] Iteration 8700 (1.28388 iter/s, 77.889s/100 iters), loss = 1.70058
I0426 14:49:48.052927 14069 solver.cpp:238]     Train net output #0: loss = 1.70058 (* 1 = 1.70058 loss)
I0426 14:49:48.052934 14069 sgd_solver.cpp:105] Iteration 8700, lr = 0.001
I0426 14:51:05.942056 14069 solver.cpp:219] Iteration 8800 (1.28385 iter/s, 77.8905s/100 iters), loss = 1.66333
I0426 14:51:05.942104 14069 solver.cpp:238]     Train net output #0: loss = 1.66333 (* 1 = 1.66333 loss)
I0426 14:51:05.942109 14069 sgd_solver.cpp:105] Iteration 8800, lr = 0.001
I0426 14:52:23.809573 14069 solver.cpp:219] Iteration 8900 (1.28421 iter/s, 77.8688s/100 iters), loss = 1.69762
I0426 14:52:23.809662 14069 solver.cpp:238]     Train net output #0: loss = 1.69762 (* 1 = 1.69762 loss)
I0426 14:52:23.809669 14069 sgd_solver.cpp:105] Iteration 8900, lr = 0.001
I0426 14:53:40.546891 14069 solver.cpp:331] Iteration 9000, Testing net (#0)
I0426 14:53:59.760753 14078 data_layer.cpp:73] Restarting data prefetching from start.
I0426 14:54:12.332314 14069 solver.cpp:398]     Test net output #0: accuracy = 0.4141
I0426 14:54:12.332355 14069 solver.cpp:398]     Test net output #1: loss = 1.62058 (* 1 = 1.62058 loss)
I0426 14:54:13.126049 14069 solver.cpp:219] Iteration 9000 (0.91476 iter/s, 109.318s/100 iters), loss = 1.72657
I0426 14:54:13.126080 14069 solver.cpp:238]     Train net output #0: loss = 1.72657 (* 1 = 1.72657 loss)
I0426 14:54:13.126086 14069 sgd_solver.cpp:105] Iteration 9000, lr = 0.001
I0426 14:54:17.046546 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 14:55:31.012130 14069 solver.cpp:219] Iteration 9100 (1.2839 iter/s, 77.8874s/100 iters), loss = 1.75908
I0426 14:55:31.012186 14069 solver.cpp:238]     Train net output #0: loss = 1.75908 (* 1 = 1.75908 loss)
I0426 14:55:31.012190 14069 sgd_solver.cpp:105] Iteration 9100, lr = 0.001
I0426 14:56:48.850786 14069 solver.cpp:219] Iteration 9200 (1.28469 iter/s, 77.84s/100 iters), loss = 1.52812
I0426 14:56:48.850878 14069 solver.cpp:238]     Train net output #0: loss = 1.52812 (* 1 = 1.52812 loss)
I0426 14:56:48.850883 14069 sgd_solver.cpp:105] Iteration 9200, lr = 0.001
I0426 14:58:06.736886 14069 solver.cpp:219] Iteration 9300 (1.28391 iter/s, 77.8874s/100 iters), loss = 1.59057
I0426 14:58:06.736930 14069 solver.cpp:238]     Train net output #0: loss = 1.59057 (* 1 = 1.59057 loss)
I0426 14:58:06.736935 14069 sgd_solver.cpp:105] Iteration 9300, lr = 0.001
I0426 14:59:24.595793 14069 solver.cpp:219] Iteration 9400 (1.28435 iter/s, 77.8602s/100 iters), loss = 1.70177
I0426 14:59:24.595963 14069 solver.cpp:238]     Train net output #0: loss = 1.70177 (* 1 = 1.70177 loss)
I0426 14:59:24.595969 14069 sgd_solver.cpp:105] Iteration 9400, lr = 0.001
I0426 15:00:07.500974 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 15:00:42.567301 14069 solver.cpp:219] Iteration 9500 (1.2825 iter/s, 77.9727s/100 iters), loss = 1.59034
I0426 15:00:42.567391 14069 solver.cpp:238]     Train net output #0: loss = 1.59034 (* 1 = 1.59034 loss)
I0426 15:00:42.567396 14069 sgd_solver.cpp:105] Iteration 9500, lr = 0.001
I0426 15:02:00.454327 14069 solver.cpp:219] Iteration 9600 (1.28389 iter/s, 77.8883s/100 iters), loss = 1.6254
I0426 15:02:00.454377 14069 solver.cpp:238]     Train net output #0: loss = 1.6254 (* 1 = 1.6254 loss)
I0426 15:02:00.454383 14069 sgd_solver.cpp:105] Iteration 9600, lr = 0.001
I0426 15:03:18.312918 14069 solver.cpp:219] Iteration 9700 (1.28436 iter/s, 77.8599s/100 iters), loss = 1.61536
I0426 15:03:18.313007 14069 solver.cpp:238]     Train net output #0: loss = 1.61536 (* 1 = 1.61536 loss)
I0426 15:03:18.313014 14069 sgd_solver.cpp:105] Iteration 9700, lr = 0.001
I0426 15:04:36.145802 14069 solver.cpp:219] Iteration 9800 (1.28478 iter/s, 77.8342s/100 iters), loss = 1.58212
I0426 15:04:36.145887 14069 solver.cpp:238]     Train net output #0: loss = 1.58212 (* 1 = 1.58212 loss)
I0426 15:04:36.145894 14069 sgd_solver.cpp:105] Iteration 9800, lr = 0.001
I0426 15:05:54.010596 14069 solver.cpp:219] Iteration 9900 (1.28426 iter/s, 77.8661s/100 iters), loss = 1.63829
I0426 15:05:54.010712 14069 solver.cpp:238]     Train net output #0: loss = 1.63829 (* 1 = 1.63829 loss)
I0426 15:05:54.010718 14069 sgd_solver.cpp:105] Iteration 9900, lr = 0.001
I0426 15:05:57.928233 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 15:07:10.744202 14069 solver.cpp:448] Snapshotting to binary proto file examples/cifar10_full_sigmoid_iter_10000.caffemodel
I0426 15:07:11.123641 14069 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_sigmoid_iter_10000.solverstate
I0426 15:07:11.126709 14069 solver.cpp:331] Iteration 10000, Testing net (#0)
I0426 15:07:30.018466 14078 data_layer.cpp:73] Restarting data prefetching from start.
I0426 15:07:42.607692 14069 solver.cpp:398]     Test net output #0: accuracy = 0.4201
I0426 15:07:42.607852 14069 solver.cpp:398]     Test net output #1: loss = 1.59434 (* 1 = 1.59434 loss)
I0426 15:07:43.401257 14069 solver.cpp:219] Iteration 10000 (0.91414 iter/s, 109.392s/100 iters), loss = 1.51047
I0426 15:07:43.401288 14069 solver.cpp:238]     Train net output #0: loss = 1.51047 (* 1 = 1.51047 loss)
I0426 15:07:43.401294 14069 sgd_solver.cpp:105] Iteration 10000, lr = 0.001
I0426 15:09:01.310772 14069 solver.cpp:219] Iteration 10100 (1.28352 iter/s, 77.9109s/100 iters), loss = 1.56849
I0426 15:09:01.310885 14069 solver.cpp:238]     Train net output #0: loss = 1.56849 (* 1 = 1.56849 loss)
I0426 15:09:01.310890 14069 sgd_solver.cpp:105] Iteration 10100, lr = 0.001
I0426 15:10:19.184427 14069 solver.cpp:219] Iteration 10200 (1.28411 iter/s, 77.8749s/100 iters), loss = 1.75151
I0426 15:10:19.184522 14069 solver.cpp:238]     Train net output #0: loss = 1.75151 (* 1 = 1.75151 loss)
I0426 15:10:19.184528 14069 sgd_solver.cpp:105] Iteration 10200, lr = 0.001
I0426 15:11:37.062500 14069 solver.cpp:219] Iteration 10300 (1.28404 iter/s, 77.8793s/100 iters), loss = 1.53705
I0426 15:11:37.062580 14069 solver.cpp:238]     Train net output #0: loss = 1.53705 (* 1 = 1.53705 loss)
I0426 15:11:37.062585 14069 sgd_solver.cpp:105] Iteration 10300, lr = 0.001
I0426 15:12:20.719348 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 15:12:55.023808 14069 solver.cpp:219] Iteration 10400 (1.28267 iter/s, 77.9626s/100 iters), loss = 1.75648
I0426 15:12:55.023854 14069 solver.cpp:238]     Train net output #0: loss = 1.75648 (* 1 = 1.75648 loss)
I0426 15:12:55.023860 14069 sgd_solver.cpp:105] Iteration 10400, lr = 0.001
I0426 15:14:12.908255 14069 solver.cpp:219] Iteration 10500 (1.28393 iter/s, 77.8858s/100 iters), loss = 1.79959
I0426 15:14:12.908341 14069 solver.cpp:238]     Train net output #0: loss = 1.79959 (* 1 = 1.79959 loss)
I0426 15:14:12.908346 14069 sgd_solver.cpp:105] Iteration 10500, lr = 0.001
I0426 15:15:30.793316 14069 solver.cpp:219] Iteration 10600 (1.28392 iter/s, 77.8863s/100 iters), loss = 1.58375
I0426 15:15:30.793362 14069 solver.cpp:238]     Train net output #0: loss = 1.58375 (* 1 = 1.58375 loss)
I0426 15:15:30.793367 14069 sgd_solver.cpp:105] Iteration 10600, lr = 0.001
I0426 15:16:48.680382 14069 solver.cpp:219] Iteration 10700 (1.28389 iter/s, 77.8884s/100 iters), loss = 1.63799
I0426 15:16:48.680429 14069 solver.cpp:238]     Train net output #0: loss = 1.63799 (* 1 = 1.63799 loss)
I0426 15:16:48.680435 14069 sgd_solver.cpp:105] Iteration 10700, lr = 0.001
I0426 15:18:06.542111 14069 solver.cpp:219] Iteration 10800 (1.28431 iter/s, 77.863s/100 iters), loss = 1.50273
I0426 15:18:06.542161 14069 solver.cpp:238]     Train net output #0: loss = 1.50273 (* 1 = 1.50273 loss)
I0426 15:18:06.542167 14069 sgd_solver.cpp:105] Iteration 10800, lr = 0.001
I0426 15:18:11.237746 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 15:19:24.396402 14069 solver.cpp:219] Iteration 10900 (1.28443 iter/s, 77.8556s/100 iters), loss = 1.58044
I0426 15:19:24.396469 14069 solver.cpp:238]     Train net output #0: loss = 1.58044 (* 1 = 1.58044 loss)
I0426 15:19:24.396476 14069 sgd_solver.cpp:105] Iteration 10900, lr = 0.001
I0426 15:20:41.140214 14069 solver.cpp:331] Iteration 11000, Testing net (#0)
I0426 15:21:00.383167 14078 data_layer.cpp:73] Restarting data prefetching from start.
I0426 15:21:12.971647 14069 solver.cpp:398]     Test net output #0: accuracy = 0.4264
I0426 15:21:12.971828 14069 solver.cpp:398]     Test net output #1: loss = 1.58087 (* 1 = 1.58087 loss)
I0426 15:21:13.763857 14069 solver.cpp:219] Iteration 11000 (0.914333 iter/s, 109.369s/100 iters), loss = 1.6256
I0426 15:21:13.763895 14069 solver.cpp:238]     Train net output #0: loss = 1.6256 (* 1 = 1.6256 loss)
I0426 15:21:13.763901 14069 sgd_solver.cpp:105] Iteration 11000, lr = 0.001
I0426 15:22:31.647341 14069 solver.cpp:219] Iteration 11100 (1.28395 iter/s, 77.8848s/100 iters), loss = 1.52532
I0426 15:22:31.647425 14069 solver.cpp:238]     Train net output #0: loss = 1.52532 (* 1 = 1.52532 loss)
I0426 15:22:31.647430 14069 sgd_solver.cpp:105] Iteration 11100, lr = 0.001
I0426 15:23:49.515059 14069 solver.cpp:219] Iteration 11200 (1.28421 iter/s, 77.869s/100 iters), loss = 1.66626
I0426 15:23:49.515105 14069 solver.cpp:238]     Train net output #0: loss = 1.66626 (* 1 = 1.66626 loss)
I0426 15:23:49.515108 14069 sgd_solver.cpp:105] Iteration 11200, lr = 0.001
I0426 15:24:33.937126 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 15:25:07.440439 14069 solver.cpp:219] Iteration 11300 (1.28326 iter/s, 77.9267s/100 iters), loss = 1.5601
I0426 15:25:07.440480 14069 solver.cpp:238]     Train net output #0: loss = 1.5601 (* 1 = 1.5601 loss)
I0426 15:25:07.440485 14069 sgd_solver.cpp:105] Iteration 11300, lr = 0.001
I0426 15:26:25.314358 14069 solver.cpp:219] Iteration 11400 (1.28411 iter/s, 77.8752s/100 iters), loss = 1.76745
I0426 15:26:25.314446 14069 solver.cpp:238]     Train net output #0: loss = 1.76745 (* 1 = 1.76745 loss)
I0426 15:26:25.314451 14069 sgd_solver.cpp:105] Iteration 11400, lr = 0.001
I0426 15:27:43.182569 14069 solver.cpp:219] Iteration 11500 (1.2842 iter/s, 77.8695s/100 iters), loss = 1.57882
I0426 15:27:43.182615 14069 solver.cpp:238]     Train net output #0: loss = 1.57882 (* 1 = 1.57882 loss)
I0426 15:27:43.182621 14069 sgd_solver.cpp:105] Iteration 11500, lr = 0.001
I0426 15:29:01.054046 14069 solver.cpp:219] Iteration 11600 (1.28415 iter/s, 77.8728s/100 iters), loss = 1.57135
I0426 15:29:01.054137 14069 solver.cpp:238]     Train net output #0: loss = 1.57135 (* 1 = 1.57135 loss)
I0426 15:29:01.054143 14069 sgd_solver.cpp:105] Iteration 11600, lr = 0.001
I0426 15:30:18.940244 14069 solver.cpp:219] Iteration 11700 (1.2839 iter/s, 77.8875s/100 iters), loss = 1.55066
I0426 15:30:18.940331 14069 solver.cpp:238]     Train net output #0: loss = 1.55066 (* 1 = 1.55066 loss)
I0426 15:30:18.940336 14069 sgd_solver.cpp:105] Iteration 11700, lr = 0.001
I0426 15:30:24.423452 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 15:31:36.798846 14069 solver.cpp:219] Iteration 11800 (1.28436 iter/s, 77.8599s/100 iters), loss = 1.51385
I0426 15:31:36.799031 14069 solver.cpp:238]     Train net output #0: loss = 1.51385 (* 1 = 1.51385 loss)
I0426 15:31:36.799037 14069 sgd_solver.cpp:105] Iteration 11800, lr = 0.001
I0426 15:32:54.660858 14069 solver.cpp:219] Iteration 11900 (1.2843 iter/s, 77.8632s/100 iters), loss = 1.41371
I0426 15:32:54.660907 14069 solver.cpp:238]     Train net output #0: loss = 1.41371 (* 1 = 1.41371 loss)
I0426 15:32:54.660914 14069 sgd_solver.cpp:105] Iteration 11900, lr = 0.001
I0426 15:34:11.398716 14069 solver.cpp:331] Iteration 12000, Testing net (#0)
I0426 15:34:30.613481 14078 data_layer.cpp:73] Restarting data prefetching from start.
I0426 15:34:43.190831 14069 solver.cpp:398]     Test net output #0: accuracy = 0.4319
I0426 15:34:43.190969 14069 solver.cpp:398]     Test net output #1: loss = 1.56518 (* 1 = 1.56518 loss)
I0426 15:34:43.982393 14069 solver.cpp:219] Iteration 12000 (0.914717 iter/s, 109.323s/100 iters), loss = 1.65939
I0426 15:34:43.982431 14069 solver.cpp:238]     Train net output #0: loss = 1.65939 (* 1 = 1.65939 loss)
I0426 15:34:43.982439 14069 sgd_solver.cpp:105] Iteration 12000, lr = 0.001
I0426 15:36:01.847004 14069 solver.cpp:219] Iteration 12100 (1.28426 iter/s, 77.866s/100 iters), loss = 1.43029
I0426 15:36:01.847110 14069 solver.cpp:238]     Train net output #0: loss = 1.43029 (* 1 = 1.43029 loss)
I0426 15:36:01.847117 14069 sgd_solver.cpp:105] Iteration 12100, lr = 0.001
I0426 15:36:47.032762 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 15:37:19.752585 14069 solver.cpp:219] Iteration 12200 (1.28358 iter/s, 77.9069s/100 iters), loss = 1.57685
I0426 15:37:19.752638 14069 solver.cpp:238]     Train net output #0: loss = 1.57685 (* 1 = 1.57685 loss)
I0426 15:37:19.752645 14069 sgd_solver.cpp:105] Iteration 12200, lr = 0.001
I0426 15:38:37.621956 14069 solver.cpp:219] Iteration 12300 (1.28418 iter/s, 77.8707s/100 iters), loss = 1.66951
I0426 15:38:37.622004 14069 solver.cpp:238]     Train net output #0: loss = 1.66951 (* 1 = 1.66951 loss)
I0426 15:38:37.622009 14069 sgd_solver.cpp:105] Iteration 12300, lr = 0.001
I0426 15:39:55.507334 14069 solver.cpp:219] Iteration 12400 (1.28392 iter/s, 77.8867s/100 iters), loss = 1.60388
I0426 15:39:55.507514 14069 solver.cpp:238]     Train net output #0: loss = 1.60388 (* 1 = 1.60388 loss)
I0426 15:39:55.507521 14069 sgd_solver.cpp:105] Iteration 12400, lr = 0.001
I0426 15:41:13.373317 14069 solver.cpp:219] Iteration 12500 (1.28424 iter/s, 77.8672s/100 iters), loss = 1.57119
I0426 15:41:13.373494 14069 solver.cpp:238]     Train net output #0: loss = 1.57119 (* 1 = 1.57119 loss)
I0426 15:41:13.373502 14069 sgd_solver.cpp:105] Iteration 12500, lr = 0.001
I0426 15:42:31.277109 14069 solver.cpp:219] Iteration 12600 (1.28361 iter/s, 77.905s/100 iters), loss = 1.57582
I0426 15:42:31.277159 14069 solver.cpp:238]     Train net output #0: loss = 1.57582 (* 1 = 1.57582 loss)
I0426 15:42:31.277166 14069 sgd_solver.cpp:105] Iteration 12600, lr = 0.001
I0426 15:42:37.548216 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 15:43:49.176169 14069 solver.cpp:219] Iteration 12700 (1.28369 iter/s, 77.9004s/100 iters), loss = 1.56646
I0426 15:43:49.176296 14069 solver.cpp:238]     Train net output #0: loss = 1.56646 (* 1 = 1.56646 loss)
I0426 15:43:49.176304 14069 sgd_solver.cpp:105] Iteration 12700, lr = 0.001
I0426 15:45:07.052444 14069 solver.cpp:219] Iteration 12800 (1.28407 iter/s, 77.8775s/100 iters), loss = 1.4972
I0426 15:45:07.052495 14069 solver.cpp:238]     Train net output #0: loss = 1.4972 (* 1 = 1.4972 loss)
I0426 15:45:07.052501 14069 sgd_solver.cpp:105] Iteration 12800, lr = 0.001
I0426 15:46:24.940907 14069 solver.cpp:219] Iteration 12900 (1.28387 iter/s, 77.8898s/100 iters), loss = 1.51481
I0426 15:46:24.941079 14069 solver.cpp:238]     Train net output #0: loss = 1.51481 (* 1 = 1.51481 loss)
I0426 15:46:24.941087 14069 sgd_solver.cpp:105] Iteration 12900, lr = 0.001
I0426 15:47:41.676329 14069 solver.cpp:331] Iteration 13000, Testing net (#0)
I0426 15:48:01.348295 14078 data_layer.cpp:73] Restarting data prefetching from start.
I0426 15:48:17.494223 14069 solver.cpp:398]     Test net output #0: accuracy = 0.4409
I0426 15:48:17.494390 14069 solver.cpp:398]     Test net output #1: loss = 1.54393 (* 1 = 1.54393 loss)
I0426 15:48:18.278210 14069 solver.cpp:219] Iteration 13000 (0.882308 iter/s, 113.339s/100 iters), loss = 1.52303
I0426 15:48:18.278239 14069 solver.cpp:238]     Train net output #0: loss = 1.52303 (* 1 = 1.52303 loss)
I0426 15:48:18.278244 14069 sgd_solver.cpp:105] Iteration 13000, lr = 0.001
I0426 15:49:04.179982 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 15:49:36.059952 14069 solver.cpp:219] Iteration 13100 (1.28563 iter/s, 77.7831s/100 iters), loss = 1.54846
I0426 15:49:36.059994 14069 solver.cpp:238]     Train net output #0: loss = 1.54846 (* 1 = 1.54846 loss)
I0426 15:49:36.060000 14069 sgd_solver.cpp:105] Iteration 13100, lr = 0.001
I0426 15:50:53.865515 14069 solver.cpp:219] Iteration 13200 (1.28523 iter/s, 77.8069s/100 iters), loss = 1.48682
I0426 15:50:53.865713 14069 solver.cpp:238]     Train net output #0: loss = 1.48682 (* 1 = 1.48682 loss)
I0426 15:50:53.865721 14069 sgd_solver.cpp:105] Iteration 13200, lr = 0.001
I0426 15:52:11.636940 14069 solver.cpp:219] Iteration 13300 (1.2858 iter/s, 77.7726s/100 iters), loss = 1.53265
I0426 15:52:11.636989 14069 solver.cpp:238]     Train net output #0: loss = 1.53265 (* 1 = 1.53265 loss)
I0426 15:52:11.636996 14069 sgd_solver.cpp:105] Iteration 13300, lr = 0.001
I0426 15:53:29.418321 14069 solver.cpp:219] Iteration 13400 (1.28563 iter/s, 77.7827s/100 iters), loss = 1.50948
I0426 15:53:29.418368 14069 solver.cpp:238]     Train net output #0: loss = 1.50948 (* 1 = 1.50948 loss)
I0426 15:53:29.418375 14069 sgd_solver.cpp:105] Iteration 13400, lr = 0.001
I0426 15:54:47.206156 14069 solver.cpp:219] Iteration 13500 (1.28553 iter/s, 77.7892s/100 iters), loss = 1.48332
I0426 15:54:47.206203 14069 solver.cpp:238]     Train net output #0: loss = 1.48332 (* 1 = 1.48332 loss)
I0426 15:54:47.206208 14069 sgd_solver.cpp:105] Iteration 13500, lr = 0.001
I0426 15:54:54.219004 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 15:56:05.002755 14069 solver.cpp:219] Iteration 13600 (1.28538 iter/s, 77.7979s/100 iters), loss = 1.57706
I0426 15:56:05.002923 14069 solver.cpp:238]     Train net output #0: loss = 1.57706 (* 1 = 1.57706 loss)
I0426 15:56:05.002929 14069 sgd_solver.cpp:105] Iteration 13600, lr = 0.001
I0426 15:57:22.749135 14069 solver.cpp:219] Iteration 13700 (1.28621 iter/s, 77.7476s/100 iters), loss = 1.59706
I0426 15:57:22.749181 14069 solver.cpp:238]     Train net output #0: loss = 1.59706 (* 1 = 1.59706 loss)
I0426 15:57:22.749186 14069 sgd_solver.cpp:105] Iteration 13700, lr = 0.001
I0426 15:58:40.534384 14069 solver.cpp:219] Iteration 13800 (1.28557 iter/s, 77.7866s/100 iters), loss = 1.76791
I0426 15:58:40.534469 14069 solver.cpp:238]     Train net output #0: loss = 1.76791 (* 1 = 1.76791 loss)
I0426 15:58:40.534474 14069 sgd_solver.cpp:105] Iteration 13800, lr = 0.001
I0426 15:59:58.300601 14069 solver.cpp:219] Iteration 13900 (1.28588 iter/s, 77.7675s/100 iters), loss = 1.62311
I0426 15:59:58.300647 14069 solver.cpp:238]     Train net output #0: loss = 1.62311 (* 1 = 1.62311 loss)
I0426 15:59:58.300652 14069 sgd_solver.cpp:105] Iteration 13900, lr = 0.001
I0426 16:00:44.207087 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 16:01:14.979063 14069 solver.cpp:331] Iteration 14000, Testing net (#0)
I0426 16:01:34.133064 14078 data_layer.cpp:73] Restarting data prefetching from start.
I0426 16:01:46.670317 14069 solver.cpp:398]     Test net output #0: accuracy = 0.4426
I0426 16:01:46.670356 14069 solver.cpp:398]     Test net output #1: loss = 1.52758 (* 1 = 1.52758 loss)
I0426 16:01:47.455734 14069 solver.cpp:219] Iteration 14000 (0.916111 iter/s, 109.157s/100 iters), loss = 1.48818
I0426 16:01:47.455760 14069 solver.cpp:238]     Train net output #0: loss = 1.48818 (* 1 = 1.48818 loss)
I0426 16:01:47.455766 14069 sgd_solver.cpp:105] Iteration 14000, lr = 0.001
I0426 16:03:05.289942 14069 solver.cpp:219] Iteration 14100 (1.28476 iter/s, 77.8356s/100 iters), loss = 1.67357
I0426 16:03:05.290114 14069 solver.cpp:238]     Train net output #0: loss = 1.67357 (* 1 = 1.67357 loss)
I0426 16:03:05.290122 14069 sgd_solver.cpp:105] Iteration 14100, lr = 0.001
I0426 16:04:23.091681 14069 solver.cpp:219] Iteration 14200 (1.2853 iter/s, 77.803s/100 iters), loss = 1.72226
I0426 16:04:23.091727 14069 solver.cpp:238]     Train net output #0: loss = 1.72226 (* 1 = 1.72226 loss)
I0426 16:04:23.091732 14069 sgd_solver.cpp:105] Iteration 14200, lr = 0.001
I0426 16:05:40.869047 14069 solver.cpp:219] Iteration 14300 (1.2857 iter/s, 77.7787s/100 iters), loss = 1.58278
I0426 16:05:40.869139 14069 solver.cpp:238]     Train net output #0: loss = 1.58278 (* 1 = 1.58278 loss)
I0426 16:05:40.869145 14069 sgd_solver.cpp:105] Iteration 14300, lr = 0.001
I0426 16:06:58.656782 14069 solver.cpp:219] Iteration 14400 (1.28553 iter/s, 77.789s/100 iters), loss = 1.50659
I0426 16:06:58.656850 14069 solver.cpp:238]     Train net output #0: loss = 1.50659 (* 1 = 1.50659 loss)
I0426 16:06:58.656857 14069 sgd_solver.cpp:105] Iteration 14400, lr = 0.001
I0426 16:07:06.459836 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 16:08:16.457554 14069 solver.cpp:219] Iteration 14500 (1.28531 iter/s, 77.8021s/100 iters), loss = 1.56674
I0426 16:08:16.457607 14069 solver.cpp:238]     Train net output #0: loss = 1.56674 (* 1 = 1.56674 loss)
I0426 16:08:16.457613 14069 sgd_solver.cpp:105] Iteration 14500, lr = 0.001
I0426 16:09:34.254004 14069 solver.cpp:219] Iteration 14600 (1.28538 iter/s, 77.7978s/100 iters), loss = 1.57251
I0426 16:09:34.254050 14069 solver.cpp:238]     Train net output #0: loss = 1.57251 (* 1 = 1.57251 loss)
I0426 16:09:34.254056 14069 sgd_solver.cpp:105] Iteration 14600, lr = 0.001
I0426 16:10:52.485323 14069 solver.cpp:219] Iteration 14700 (1.27824 iter/s, 78.2327s/100 iters), loss = 1.54323
I0426 16:10:52.485492 14069 solver.cpp:238]     Train net output #0: loss = 1.54323 (* 1 = 1.54323 loss)
I0426 16:10:52.485501 14069 sgd_solver.cpp:105] Iteration 14700, lr = 0.001
I0426 16:12:10.384634 14069 solver.cpp:219] Iteration 14800 (1.28369 iter/s, 77.9005s/100 iters), loss = 1.5605
I0426 16:12:10.384824 14069 solver.cpp:238]     Train net output #0: loss = 1.5605 (* 1 = 1.5605 loss)
I0426 16:12:10.384832 14069 sgd_solver.cpp:105] Iteration 14800, lr = 0.001
I0426 16:12:57.295704 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 16:13:28.431682 14069 solver.cpp:219] Iteration 14900 (1.28126 iter/s, 78.0482s/100 iters), loss = 1.56093
I0426 16:13:28.431787 14069 solver.cpp:238]     Train net output #0: loss = 1.56093 (* 1 = 1.56093 loss)
I0426 16:13:28.431793 14069 sgd_solver.cpp:105] Iteration 14900, lr = 0.001
I0426 16:14:45.141331 14069 solver.cpp:331] Iteration 15000, Testing net (#0)
I0426 16:15:04.309289 14078 data_layer.cpp:73] Restarting data prefetching from start.
I0426 16:15:16.860306 14069 solver.cpp:398]     Test net output #0: accuracy = 0.4484
I0426 16:15:16.860468 14069 solver.cpp:398]     Test net output #1: loss = 1.52174 (* 1 = 1.52174 loss)
I0426 16:15:17.638552 14069 solver.cpp:219] Iteration 15000 (0.915678 iter/s, 109.209s/100 iters), loss = 1.66912
I0426 16:15:17.638576 14069 solver.cpp:238]     Train net output #0: loss = 1.66912 (* 1 = 1.66912 loss)
I0426 16:15:17.638582 14069 sgd_solver.cpp:105] Iteration 15000, lr = 0.001
I0426 16:16:35.475646 14069 solver.cpp:219] Iteration 15100 (1.28471 iter/s, 77.8385s/100 iters), loss = 1.45589
I0426 16:16:35.475697 14069 solver.cpp:238]     Train net output #0: loss = 1.45589 (* 1 = 1.45589 loss)
I0426 16:16:35.475703 14069 sgd_solver.cpp:105] Iteration 15100, lr = 0.001
I0426 16:17:53.312693 14069 solver.cpp:219] Iteration 15200 (1.28471 iter/s, 77.8384s/100 iters), loss = 1.39235
I0426 16:17:53.312820 14069 solver.cpp:238]     Train net output #0: loss = 1.39235 (* 1 = 1.39235 loss)
I0426 16:17:53.312826 14069 sgd_solver.cpp:105] Iteration 15200, lr = 0.001
I0426 16:19:11.139029 14069 solver.cpp:219] Iteration 15300 (1.28489 iter/s, 77.8276s/100 iters), loss = 1.55228
I0426 16:19:11.139082 14069 solver.cpp:238]     Train net output #0: loss = 1.55228 (* 1 = 1.55228 loss)
I0426 16:19:11.139089 14069 sgd_solver.cpp:105] Iteration 15300, lr = 0.001
I0426 16:19:19.705492 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 16:20:28.994525 14069 solver.cpp:219] Iteration 15400 (1.28441 iter/s, 77.8568s/100 iters), loss = 1.44921
I0426 16:20:28.994645 14069 solver.cpp:238]     Train net output #0: loss = 1.44921 (* 1 = 1.44921 loss)
I0426 16:20:28.994652 14069 sgd_solver.cpp:105] Iteration 15400, lr = 0.001
I0426 16:21:46.840507 14069 solver.cpp:219] Iteration 15500 (1.28457 iter/s, 77.8473s/100 iters), loss = 1.69437
I0426 16:21:46.840554 14069 solver.cpp:238]     Train net output #0: loss = 1.69437 (* 1 = 1.69437 loss)
I0426 16:21:46.840560 14069 sgd_solver.cpp:105] Iteration 15500, lr = 0.001
I0426 16:23:04.707650 14069 solver.cpp:219] Iteration 15600 (1.28422 iter/s, 77.8685s/100 iters), loss = 1.51971
I0426 16:23:04.707744 14069 solver.cpp:238]     Train net output #0: loss = 1.51971 (* 1 = 1.51971 loss)
I0426 16:23:04.707751 14069 sgd_solver.cpp:105] Iteration 15600, lr = 0.001
I0426 16:24:22.552592 14069 solver.cpp:219] Iteration 15700 (1.28458 iter/s, 77.8462s/100 iters), loss = 1.65885
I0426 16:24:22.552649 14069 solver.cpp:238]     Train net output #0: loss = 1.65885 (* 1 = 1.65885 loss)
I0426 16:24:22.552656 14069 sgd_solver.cpp:105] Iteration 15700, lr = 0.001
I0426 16:25:10.044775 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 16:25:40.523227 14069 solver.cpp:219] Iteration 15800 (1.28251 iter/s, 77.972s/100 iters), loss = 1.44756
I0426 16:25:40.523368 14069 solver.cpp:238]     Train net output #0: loss = 1.44756 (* 1 = 1.44756 loss)
I0426 16:25:40.523375 14069 sgd_solver.cpp:105] Iteration 15800, lr = 0.001
I0426 16:26:58.428941 14069 solver.cpp:219] Iteration 15900 (1.28358 iter/s, 77.907s/100 iters), loss = 1.55404
I0426 16:26:58.429083 14069 solver.cpp:238]     Train net output #0: loss = 1.55404 (* 1 = 1.55404 loss)
I0426 16:26:58.429090 14069 sgd_solver.cpp:105] Iteration 15900, lr = 0.001
I0426 16:28:15.204493 14069 solver.cpp:331] Iteration 16000, Testing net (#0)
I0426 16:28:34.417321 14078 data_layer.cpp:73] Restarting data prefetching from start.
I0426 16:28:47.021363 14069 solver.cpp:398]     Test net output #0: accuracy = 0.4525
I0426 16:28:47.021528 14069 solver.cpp:398]     Test net output #1: loss = 1.50377 (* 1 = 1.50377 loss)
I0426 16:28:47.815300 14069 solver.cpp:219] Iteration 16000 (0.914176 iter/s, 109.388s/100 iters), loss = 1.33725
I0426 16:28:47.815340 14069 solver.cpp:238]     Train net output #0: loss = 1.33725 (* 1 = 1.33725 loss)
I0426 16:28:47.815346 14069 sgd_solver.cpp:105] Iteration 16000, lr = 0.001
I0426 16:30:05.748390 14069 solver.cpp:219] Iteration 16100 (1.28313 iter/s, 77.9344s/100 iters), loss = 1.52448
I0426 16:30:05.748487 14069 solver.cpp:238]     Train net output #0: loss = 1.52448 (* 1 = 1.52448 loss)
I0426 16:30:05.748493 14069 sgd_solver.cpp:105] Iteration 16100, lr = 0.001
I0426 16:31:23.644345 14069 solver.cpp:219] Iteration 16200 (1.28374 iter/s, 77.8972s/100 iters), loss = 1.37336
I0426 16:31:23.644448 14069 solver.cpp:238]     Train net output #0: loss = 1.37336 (* 1 = 1.37336 loss)
I0426 16:31:23.644470 14069 sgd_solver.cpp:105] Iteration 16200, lr = 0.001
I0426 16:31:33.034507 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 16:32:41.528760 14069 solver.cpp:219] Iteration 16300 (1.28393 iter/s, 77.8857s/100 iters), loss = 1.45977
I0426 16:32:41.528808 14069 solver.cpp:238]     Train net output #0: loss = 1.45977 (* 1 = 1.45977 loss)
I0426 16:32:41.528815 14069 sgd_solver.cpp:105] Iteration 16300, lr = 0.001
I0426 16:33:59.418171 14069 solver.cpp:219] Iteration 16400 (1.28385 iter/s, 77.8907s/100 iters), loss = 1.42833
I0426 16:33:59.418218 14069 solver.cpp:238]     Train net output #0: loss = 1.42833 (* 1 = 1.42833 loss)
I0426 16:33:59.418225 14069 sgd_solver.cpp:105] Iteration 16400, lr = 0.001
I0426 16:35:17.297233 14069 solver.cpp:219] Iteration 16500 (1.28402 iter/s, 77.8804s/100 iters), loss = 1.51517
I0426 16:35:17.297415 14069 solver.cpp:238]     Train net output #0: loss = 1.51517 (* 1 = 1.51517 loss)
I0426 16:35:17.297421 14069 sgd_solver.cpp:105] Iteration 16500, lr = 0.001
I0426 16:36:35.205564 14069 solver.cpp:219] Iteration 16600 (1.28354 iter/s, 77.9095s/100 iters), loss = 1.39646
I0426 16:36:35.205737 14069 solver.cpp:238]     Train net output #0: loss = 1.39646 (* 1 = 1.39646 loss)
I0426 16:36:35.205744 14069 sgd_solver.cpp:105] Iteration 16600, lr = 0.001
I0426 16:37:27.893976 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 16:37:57.453474 14069 solver.cpp:219] Iteration 16700 (1.21582 iter/s, 82.2492s/100 iters), loss = 1.32183
I0426 16:37:57.453506 14069 solver.cpp:238]     Train net output #0: loss = 1.32183 (* 1 = 1.32183 loss)
I0426 16:37:57.453512 14069 sgd_solver.cpp:105] Iteration 16700, lr = 0.001
I0426 16:39:15.227324 14069 solver.cpp:219] Iteration 16800 (1.28576 iter/s, 77.7752s/100 iters), loss = 1.45869
I0426 16:39:15.227519 14069 solver.cpp:238]     Train net output #0: loss = 1.45869 (* 1 = 1.45869 loss)
I0426 16:39:15.227526 14069 sgd_solver.cpp:105] Iteration 16800, lr = 0.001
I0426 16:40:32.996556 14069 solver.cpp:219] Iteration 16900 (1.28584 iter/s, 77.7704s/100 iters), loss = 1.47831
I0426 16:40:32.996731 14069 solver.cpp:238]     Train net output #0: loss = 1.47831 (* 1 = 1.47831 loss)
I0426 16:40:32.996738 14069 sgd_solver.cpp:105] Iteration 16900, lr = 0.001
I0426 16:41:49.629848 14069 solver.cpp:331] Iteration 17000, Testing net (#0)
I0426 16:42:08.829993 14078 data_layer.cpp:73] Restarting data prefetching from start.
I0426 16:42:21.342803 14069 solver.cpp:398]     Test net output #0: accuracy = 0.4523
I0426 16:42:21.342900 14069 solver.cpp:398]     Test net output #1: loss = 1.50457 (* 1 = 1.50457 loss)
I0426 16:42:22.127734 14069 solver.cpp:219] Iteration 17000 (0.916313 iter/s, 109.133s/100 iters), loss = 1.41859
I0426 16:42:22.127759 14069 solver.cpp:238]     Train net output #0: loss = 1.41859 (* 1 = 1.41859 loss)
I0426 16:42:22.127765 14069 sgd_solver.cpp:105] Iteration 17000, lr = 0.001
I0426 16:43:39.885571 14069 solver.cpp:219] Iteration 17100 (1.28602 iter/s, 77.7592s/100 iters), loss = 1.38657
I0426 16:43:39.885668 14069 solver.cpp:238]     Train net output #0: loss = 1.38657 (* 1 = 1.38657 loss)
I0426 16:43:39.885674 14069 sgd_solver.cpp:105] Iteration 17100, lr = 0.001
I0426 16:43:50.003182 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 16:44:57.695915 14069 solver.cpp:219] Iteration 17200 (1.28515 iter/s, 77.8116s/100 iters), loss = 1.57462
I0426 16:44:57.695962 14069 solver.cpp:238]     Train net output #0: loss = 1.57462 (* 1 = 1.57462 loss)
I0426 16:44:57.695967 14069 sgd_solver.cpp:105] Iteration 17200, lr = 0.001
I0426 16:46:15.479080 14069 solver.cpp:219] Iteration 17300 (1.2856 iter/s, 77.7845s/100 iters), loss = 1.44282
I0426 16:46:15.479174 14069 solver.cpp:238]     Train net output #0: loss = 1.44282 (* 1 = 1.44282 loss)
I0426 16:46:15.479182 14069 sgd_solver.cpp:105] Iteration 17300, lr = 0.001
I0426 16:47:33.252929 14069 solver.cpp:219] Iteration 17400 (1.28576 iter/s, 77.7751s/100 iters), loss = 1.52852
I0426 16:47:33.253099 14069 solver.cpp:238]     Train net output #0: loss = 1.52852 (* 1 = 1.52852 loss)
I0426 16:47:33.253106 14069 sgd_solver.cpp:105] Iteration 17400, lr = 0.001
I0426 16:48:51.022075 14069 solver.cpp:219] Iteration 17500 (1.28584 iter/s, 77.7704s/100 iters), loss = 1.62773
I0426 16:48:51.022258 14069 solver.cpp:238]     Train net output #0: loss = 1.62773 (* 1 = 1.62773 loss)
I0426 16:48:51.022266 14069 sgd_solver.cpp:105] Iteration 17500, lr = 0.001
I0426 16:49:40.014420 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 16:50:08.805444 14069 solver.cpp:219] Iteration 17600 (1.2856 iter/s, 77.7846s/100 iters), loss = 1.55268
I0426 16:50:08.805471 14069 solver.cpp:238]     Train net output #0: loss = 1.55268 (* 1 = 1.55268 loss)
I0426 16:50:08.805475 14069 sgd_solver.cpp:105] Iteration 17600, lr = 0.001
I0426 16:51:26.587641 14069 solver.cpp:219] Iteration 17700 (1.28562 iter/s, 77.7836s/100 iters), loss = 1.5281
I0426 16:51:26.587810 14069 solver.cpp:238]     Train net output #0: loss = 1.5281 (* 1 = 1.5281 loss)
I0426 16:51:26.587816 14069 sgd_solver.cpp:105] Iteration 17700, lr = 0.001
I0426 16:52:44.364200 14069 solver.cpp:219] Iteration 17800 (1.28571 iter/s, 77.7778s/100 iters), loss = 1.50045
I0426 16:52:44.364380 14069 solver.cpp:238]     Train net output #0: loss = 1.50045 (* 1 = 1.50045 loss)
I0426 16:52:44.364387 14069 sgd_solver.cpp:105] Iteration 17800, lr = 0.001
I0426 16:54:02.151904 14069 solver.cpp:219] Iteration 17900 (1.28553 iter/s, 77.7889s/100 iters), loss = 1.63555
I0426 16:54:02.152086 14069 solver.cpp:238]     Train net output #0: loss = 1.63555 (* 1 = 1.63555 loss)
I0426 16:54:02.152093 14069 sgd_solver.cpp:105] Iteration 17900, lr = 0.001
I0426 16:55:18.813920 14069 solver.cpp:331] Iteration 18000, Testing net (#0)
I0426 16:55:37.968744 14078 data_layer.cpp:73] Restarting data prefetching from start.
I0426 16:55:50.491359 14069 solver.cpp:398]     Test net output #0: accuracy = 0.4609
I0426 16:55:50.491495 14069 solver.cpp:398]     Test net output #1: loss = 1.48715 (* 1 = 1.48715 loss)
I0426 16:55:51.295845 14069 solver.cpp:219] Iteration 18000 (0.916207 iter/s, 109.146s/100 iters), loss = 1.73991
I0426 16:55:51.295884 14069 solver.cpp:238]     Train net output #0: loss = 1.73991 (* 1 = 1.73991 loss)
I0426 16:55:51.295891 14069 sgd_solver.cpp:105] Iteration 18000, lr = 0.001
I0426 16:56:02.219863 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 16:57:09.128460 14069 solver.cpp:219] Iteration 18100 (1.28479 iter/s, 77.834s/100 iters), loss = 1.37352
I0426 16:57:09.128641 14069 solver.cpp:238]     Train net output #0: loss = 1.37352 (* 1 = 1.37352 loss)
I0426 16:57:09.128648 14069 sgd_solver.cpp:105] Iteration 18100, lr = 0.001
I0426 16:58:26.919648 14069 solver.cpp:219] Iteration 18200 (1.28547 iter/s, 77.7924s/100 iters), loss = 1.55325
I0426 16:58:26.919797 14069 solver.cpp:238]     Train net output #0: loss = 1.55325 (* 1 = 1.55325 loss)
I0426 16:58:26.919806 14069 sgd_solver.cpp:105] Iteration 18200, lr = 0.001
I0426 16:59:44.737982 14069 solver.cpp:219] Iteration 18300 (1.28502 iter/s, 77.8196s/100 iters), loss = 1.36901
I0426 16:59:44.738031 14069 solver.cpp:238]     Train net output #0: loss = 1.36901 (* 1 = 1.36901 loss)
I0426 16:59:44.738036 14069 sgd_solver.cpp:105] Iteration 18300, lr = 0.001
I0426 17:01:02.561031 14069 solver.cpp:219] Iteration 18400 (1.28494 iter/s, 77.8244s/100 iters), loss = 1.3782
I0426 17:01:02.561177 14069 solver.cpp:238]     Train net output #0: loss = 1.3782 (* 1 = 1.3782 loss)
I0426 17:01:02.561184 14069 sgd_solver.cpp:105] Iteration 18400, lr = 0.001
I0426 17:01:52.335558 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 17:02:20.354368 14069 solver.cpp:219] Iteration 18500 (1.28544 iter/s, 77.7946s/100 iters), loss = 1.44162
I0426 17:02:20.354398 14069 solver.cpp:238]     Train net output #0: loss = 1.44162 (* 1 = 1.44162 loss)
I0426 17:02:20.354403 14069 sgd_solver.cpp:105] Iteration 18500, lr = 0.001
I0426 17:03:38.138033 14069 solver.cpp:219] Iteration 18600 (1.28559 iter/s, 77.785s/100 iters), loss = 1.50117
I0426 17:03:38.138082 14069 solver.cpp:238]     Train net output #0: loss = 1.50117 (* 1 = 1.50117 loss)
I0426 17:03:38.138087 14069 sgd_solver.cpp:105] Iteration 18600, lr = 0.001
I0426 17:04:55.942680 14069 solver.cpp:219] Iteration 18700 (1.28525 iter/s, 77.806s/100 iters), loss = 1.44174
I0426 17:04:55.942766 14069 solver.cpp:238]     Train net output #0: loss = 1.44174 (* 1 = 1.44174 loss)
I0426 17:04:55.942772 14069 sgd_solver.cpp:105] Iteration 18700, lr = 0.001
I0426 17:06:13.765996 14069 solver.cpp:219] Iteration 18800 (1.28494 iter/s, 77.8246s/100 iters), loss = 1.51744
I0426 17:06:13.766170 14069 solver.cpp:238]     Train net output #0: loss = 1.51744 (* 1 = 1.51744 loss)
I0426 17:06:13.766177 14069 sgd_solver.cpp:105] Iteration 18800, lr = 0.001
I0426 17:07:31.512727 14069 solver.cpp:219] Iteration 18900 (1.28621 iter/s, 77.7479s/100 iters), loss = 1.4647
I0426 17:07:31.512820 14069 solver.cpp:238]     Train net output #0: loss = 1.4647 (* 1 = 1.4647 loss)
I0426 17:07:31.512827 14069 sgd_solver.cpp:105] Iteration 18900, lr = 0.001
I0426 17:07:42.408463 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 17:08:48.165372 14069 solver.cpp:331] Iteration 19000, Testing net (#0)
I0426 17:09:07.358669 14078 data_layer.cpp:73] Restarting data prefetching from start.
I0426 17:09:19.868254 14069 solver.cpp:398]     Test net output #0: accuracy = 0.4646
I0426 17:09:19.868340 14069 solver.cpp:398]     Test net output #1: loss = 1.46187 (* 1 = 1.46187 loss)
I0426 17:09:20.653331 14069 solver.cpp:219] Iteration 19000 (0.916234 iter/s, 109.142s/100 iters), loss = 1.59386
I0426 17:09:20.653359 14069 solver.cpp:238]     Train net output #0: loss = 1.59386 (* 1 = 1.59386 loss)
I0426 17:09:20.653364 14069 sgd_solver.cpp:105] Iteration 19000, lr = 0.001
I0426 17:10:38.415622 14069 solver.cpp:219] Iteration 19100 (1.28595 iter/s, 77.7636s/100 iters), loss = 1.42992
I0426 17:10:38.415696 14069 solver.cpp:238]     Train net output #0: loss = 1.42992 (* 1 = 1.42992 loss)
I0426 17:10:38.415704 14069 sgd_solver.cpp:105] Iteration 19100, lr = 0.001
I0426 17:11:56.231155 14069 solver.cpp:219] Iteration 19200 (1.28507 iter/s, 77.8168s/100 iters), loss = 1.34023
I0426 17:11:56.231338 14069 solver.cpp:238]     Train net output #0: loss = 1.34023 (* 1 = 1.34023 loss)
I0426 17:11:56.231345 14069 sgd_solver.cpp:105] Iteration 19200, lr = 0.001
I0426 17:13:14.032166 14069 solver.cpp:219] Iteration 19300 (1.28531 iter/s, 77.8022s/100 iters), loss = 1.29635
I0426 17:13:14.032214 14069 solver.cpp:238]     Train net output #0: loss = 1.29635 (* 1 = 1.29635 loss)
I0426 17:13:14.032219 14069 sgd_solver.cpp:105] Iteration 19300, lr = 0.001
I0426 17:14:04.594508 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 17:14:31.807153 14069 solver.cpp:219] Iteration 19400 (1.28574 iter/s, 77.7763s/100 iters), loss = 1.55248
I0426 17:14:31.807186 14069 solver.cpp:238]     Train net output #0: loss = 1.55248 (* 1 = 1.55248 loss)
I0426 17:14:31.807193 14069 sgd_solver.cpp:105] Iteration 19400, lr = 0.001
I0426 17:15:49.590250 14069 solver.cpp:219] Iteration 19500 (1.2856 iter/s, 77.7844s/100 iters), loss = 1.29251
I0426 17:15:49.590296 14069 solver.cpp:238]     Train net output #0: loss = 1.29251 (* 1 = 1.29251 loss)
I0426 17:15:49.590302 14069 sgd_solver.cpp:105] Iteration 19500, lr = 0.001
I0426 17:17:07.409457 14069 solver.cpp:219] Iteration 19600 (1.28501 iter/s, 77.8205s/100 iters), loss = 1.50455
I0426 17:17:07.409564 14069 solver.cpp:238]     Train net output #0: loss = 1.50455 (* 1 = 1.50455 loss)
I0426 17:17:07.409571 14069 sgd_solver.cpp:105] Iteration 19600, lr = 0.001
I0426 17:18:25.217720 14069 solver.cpp:219] Iteration 19700 (1.28519 iter/s, 77.8095s/100 iters), loss = 1.38286
I0426 17:18:25.217845 14069 solver.cpp:238]     Train net output #0: loss = 1.38286 (* 1 = 1.38286 loss)
I0426 17:18:25.217850 14069 sgd_solver.cpp:105] Iteration 19700, lr = 0.001
I0426 17:19:42.975800 14069 solver.cpp:219] Iteration 19800 (1.28602 iter/s, 77.7593s/100 iters), loss = 1.74068
I0426 17:19:42.975925 14069 solver.cpp:238]     Train net output #0: loss = 1.74068 (* 1 = 1.74068 loss)
I0426 17:19:42.975934 14069 sgd_solver.cpp:105] Iteration 19800, lr = 0.001
I0426 17:19:54.646500 14077 data_layer.cpp:73] Restarting data prefetching from start.
I0426 17:21:00.740753 14069 solver.cpp:219] Iteration 19900 (1.28591 iter/s, 77.7662s/100 iters), loss = 1.76765
I0426 17:21:00.740803 14069 solver.cpp:238]     Train net output #0: loss = 1.76765 (* 1 = 1.76765 loss)
I0426 17:21:00.740810 14069 sgd_solver.cpp:105] Iteration 19900, lr = 0.001
I0426 17:22:17.377872 14069 solver.cpp:448] Snapshotting to binary proto file examples/cifar10_full_sigmoid_iter_20000.caffemodel
I0426 17:22:17.749900 14069 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_sigmoid_iter_20000.solverstate
I0426 17:22:18.107938 14069 solver.cpp:311] Iteration 20000, loss = 1.51994
I0426 17:22:18.107959 14069 solver.cpp:331] Iteration 20000, Testing net (#0)
I0426 17:22:36.901317 14078 data_layer.cpp:73] Restarting data prefetching from start.
I0426 17:22:49.412041 14069 solver.cpp:398]     Test net output #0: accuracy = 0.4663
I0426 17:22:49.412117 14069 solver.cpp:398]     Test net output #1: loss = 1.467 (* 1 = 1.467 loss)
I0426 17:22:49.412122 14069 solver.cpp:316] Optimization Done.
I0426 17:22:49.412124 14069 caffe.cpp:259] Optimization Done.
