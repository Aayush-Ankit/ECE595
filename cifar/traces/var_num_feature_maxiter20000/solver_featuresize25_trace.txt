I0426 10:44:11.674963 12217 caffe.cpp:218] Using GPUs 0
I0426 10:44:11.692803 12217 caffe.cpp:223] GPU 0: GeForce GTX 950M
I0426 10:44:11.935827 12217 solver.cpp:44] Initializing solver from parameters: 
test_iter: 10
test_interval: 1000
base_lr: 0.001
display: 100
max_iter: 20000
lr_policy: "step"
gamma: 1
momentum: 0.9
stepsize: 5000
snapshot: 10000
snapshot_prefix: "examples/cifar10_full_sigmoid"
solver_mode: GPU
device_id: 0
net: "ECE595/cifar/train_test/var_num_feature_maxiter20000/cifar_train_test_featuresize25.prototxt"
train_state {
  level: 0
  stage: ""
}
I0426 10:44:11.935983 12217 solver.cpp:87] Creating training net from net file: ECE595/cifar/train_test/var_num_feature_maxiter20000/cifar_train_test_featuresize25.prototxt
I0426 10:44:11.936203 12217 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0426 10:44:11.936220 12217 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0426 10:44:11.936318 12217 net.cpp:51] Initializing net from parameters: 
name: "CIFAR"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_train_lmdb"
    batch_size: 111
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Sigmoid0"
  type: "Sigmoid"
  bottom: "conv0"
  top: "Sigmoid0"
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "Sigmoid0"
  top: "pool0"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Sigmoid1"
  type: "Sigmoid"
  bottom: "conv1"
  top: "Sigmoid1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "Sigmoid1"
  top: "pool1"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Sigmoid2"
  type: "Sigmoid"
  bottom: "conv2"
  top: "Sigmoid2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "Sigmoid2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0426 10:44:11.936399 12217 layer_factory.hpp:77] Creating layer cifar
I0426 10:44:11.936497 12217 db_lmdb.cpp:35] Opened lmdb examples/cifar10/cifar10_train_lmdb
I0426 10:44:11.936527 12217 net.cpp:84] Creating Layer cifar
I0426 10:44:11.936537 12217 net.cpp:380] cifar -> data
I0426 10:44:11.936561 12217 net.cpp:380] cifar -> label
I0426 10:44:11.936578 12217 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I0426 10:44:11.937512 12217 data_layer.cpp:45] output data size: 111,3,32,32
I0426 10:44:11.941953 12217 net.cpp:122] Setting up cifar
I0426 10:44:11.941978 12217 net.cpp:129] Top shape: 111 3 32 32 (340992)
I0426 10:44:11.942003 12217 net.cpp:129] Top shape: 111 (111)
I0426 10:44:11.942010 12217 net.cpp:137] Memory required for data: 1364412
I0426 10:44:11.942020 12217 layer_factory.hpp:77] Creating layer conv0
I0426 10:44:11.942047 12217 net.cpp:84] Creating Layer conv0
I0426 10:44:11.942054 12217 net.cpp:406] conv0 <- data
I0426 10:44:11.942071 12217 net.cpp:380] conv0 -> conv0
I0426 10:44:11.942726 12217 net.cpp:122] Setting up conv0
I0426 10:44:11.942739 12217 net.cpp:129] Top shape: 111 25 32 32 (2841600)
I0426 10:44:11.942744 12217 net.cpp:137] Memory required for data: 12730812
I0426 10:44:11.942765 12217 layer_factory.hpp:77] Creating layer Sigmoid0
I0426 10:44:11.942777 12217 net.cpp:84] Creating Layer Sigmoid0
I0426 10:44:11.942783 12217 net.cpp:406] Sigmoid0 <- conv0
I0426 10:44:11.942791 12217 net.cpp:380] Sigmoid0 -> Sigmoid0
I0426 10:44:11.942843 12217 net.cpp:122] Setting up Sigmoid0
I0426 10:44:11.942852 12217 net.cpp:129] Top shape: 111 25 32 32 (2841600)
I0426 10:44:11.942855 12217 net.cpp:137] Memory required for data: 24097212
I0426 10:44:11.942862 12217 layer_factory.hpp:77] Creating layer pool0
I0426 10:44:11.942872 12217 net.cpp:84] Creating Layer pool0
I0426 10:44:11.942876 12217 net.cpp:406] pool0 <- Sigmoid0
I0426 10:44:11.942888 12217 net.cpp:380] pool0 -> pool0
I0426 10:44:11.943101 12217 net.cpp:122] Setting up pool0
I0426 10:44:11.943111 12217 net.cpp:129] Top shape: 111 25 16 16 (710400)
I0426 10:44:11.943115 12217 net.cpp:137] Memory required for data: 26938812
I0426 10:44:11.943120 12217 layer_factory.hpp:77] Creating layer conv1
I0426 10:44:11.943133 12217 net.cpp:84] Creating Layer conv1
I0426 10:44:11.943140 12217 net.cpp:406] conv1 <- pool0
I0426 10:44:11.943148 12217 net.cpp:380] conv1 -> conv1
I0426 10:44:11.943914 12217 net.cpp:122] Setting up conv1
I0426 10:44:11.943927 12217 net.cpp:129] Top shape: 111 25 16 16 (710400)
I0426 10:44:11.943933 12217 net.cpp:137] Memory required for data: 29780412
I0426 10:44:11.943945 12217 layer_factory.hpp:77] Creating layer Sigmoid1
I0426 10:44:11.943953 12217 net.cpp:84] Creating Layer Sigmoid1
I0426 10:44:11.943959 12217 net.cpp:406] Sigmoid1 <- conv1
I0426 10:44:11.943969 12217 net.cpp:380] Sigmoid1 -> Sigmoid1
I0426 10:44:11.943991 12217 net.cpp:122] Setting up Sigmoid1
I0426 10:44:11.944000 12217 net.cpp:129] Top shape: 111 25 16 16 (710400)
I0426 10:44:11.944005 12217 net.cpp:137] Memory required for data: 32622012
I0426 10:44:11.944010 12217 layer_factory.hpp:77] Creating layer pool1
I0426 10:44:11.944017 12217 net.cpp:84] Creating Layer pool1
I0426 10:44:11.944022 12217 net.cpp:406] pool1 <- Sigmoid1
I0426 10:44:11.944031 12217 net.cpp:380] pool1 -> pool1
I0426 10:44:11.944057 12217 net.cpp:122] Setting up pool1
I0426 10:44:11.944066 12217 net.cpp:129] Top shape: 111 25 8 8 (177600)
I0426 10:44:11.944069 12217 net.cpp:137] Memory required for data: 33332412
I0426 10:44:11.944073 12217 layer_factory.hpp:77] Creating layer conv2
I0426 10:44:11.944087 12217 net.cpp:84] Creating Layer conv2
I0426 10:44:11.944090 12217 net.cpp:406] conv2 <- pool1
I0426 10:44:11.944099 12217 net.cpp:380] conv2 -> conv2
I0426 10:44:11.944489 12217 net.cpp:122] Setting up conv2
I0426 10:44:11.944499 12217 net.cpp:129] Top shape: 111 25 8 8 (177600)
I0426 10:44:11.944502 12217 net.cpp:137] Memory required for data: 34042812
I0426 10:44:11.944514 12217 layer_factory.hpp:77] Creating layer Sigmoid2
I0426 10:44:11.944524 12217 net.cpp:84] Creating Layer Sigmoid2
I0426 10:44:11.944530 12217 net.cpp:406] Sigmoid2 <- conv2
I0426 10:44:11.944536 12217 net.cpp:380] Sigmoid2 -> Sigmoid2
I0426 10:44:11.944777 12217 net.cpp:122] Setting up Sigmoid2
I0426 10:44:11.944784 12217 net.cpp:129] Top shape: 111 25 8 8 (177600)
I0426 10:44:11.944788 12217 net.cpp:137] Memory required for data: 34753212
I0426 10:44:11.944792 12217 layer_factory.hpp:77] Creating layer pool2
I0426 10:44:11.944802 12217 net.cpp:84] Creating Layer pool2
I0426 10:44:11.944808 12217 net.cpp:406] pool2 <- Sigmoid2
I0426 10:44:11.944814 12217 net.cpp:380] pool2 -> pool2
I0426 10:44:11.944842 12217 net.cpp:122] Setting up pool2
I0426 10:44:11.944860 12217 net.cpp:129] Top shape: 111 25 4 4 (44400)
I0426 10:44:11.944866 12217 net.cpp:137] Memory required for data: 34930812
I0426 10:44:11.944870 12217 layer_factory.hpp:77] Creating layer ip1
I0426 10:44:11.944880 12217 net.cpp:84] Creating Layer ip1
I0426 10:44:11.944886 12217 net.cpp:406] ip1 <- pool2
I0426 10:44:11.944895 12217 net.cpp:380] ip1 -> ip1
I0426 10:44:11.945050 12217 net.cpp:122] Setting up ip1
I0426 10:44:11.945056 12217 net.cpp:129] Top shape: 111 10 (1110)
I0426 10:44:11.945061 12217 net.cpp:137] Memory required for data: 34935252
I0426 10:44:11.945070 12217 layer_factory.hpp:77] Creating layer loss
I0426 10:44:11.945077 12217 net.cpp:84] Creating Layer loss
I0426 10:44:11.945082 12217 net.cpp:406] loss <- ip1
I0426 10:44:11.945089 12217 net.cpp:406] loss <- label
I0426 10:44:11.945099 12217 net.cpp:380] loss -> loss
I0426 10:44:11.945113 12217 layer_factory.hpp:77] Creating layer loss
I0426 10:44:11.945202 12217 net.cpp:122] Setting up loss
I0426 10:44:11.945210 12217 net.cpp:129] Top shape: (1)
I0426 10:44:11.945214 12217 net.cpp:132]     with loss weight 1
I0426 10:44:11.945231 12217 net.cpp:137] Memory required for data: 34935256
I0426 10:44:11.945236 12217 net.cpp:198] loss needs backward computation.
I0426 10:44:11.945246 12217 net.cpp:198] ip1 needs backward computation.
I0426 10:44:11.945253 12217 net.cpp:198] pool2 needs backward computation.
I0426 10:44:11.945257 12217 net.cpp:198] Sigmoid2 needs backward computation.
I0426 10:44:11.945262 12217 net.cpp:198] conv2 needs backward computation.
I0426 10:44:11.945267 12217 net.cpp:198] pool1 needs backward computation.
I0426 10:44:11.945271 12217 net.cpp:198] Sigmoid1 needs backward computation.
I0426 10:44:11.945276 12217 net.cpp:198] conv1 needs backward computation.
I0426 10:44:11.945281 12217 net.cpp:198] pool0 needs backward computation.
I0426 10:44:11.945289 12217 net.cpp:198] Sigmoid0 needs backward computation.
I0426 10:44:11.945296 12217 net.cpp:198] conv0 needs backward computation.
I0426 10:44:11.945300 12217 net.cpp:200] cifar does not need backward computation.
I0426 10:44:11.945303 12217 net.cpp:242] This network produces output loss
I0426 10:44:11.945318 12217 net.cpp:255] Network initialization done.
I0426 10:44:11.945514 12217 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/cifar/train_test/var_num_feature_maxiter20000/cifar_train_test_featuresize25.prototxt
I0426 10:44:11.945541 12217 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0426 10:44:11.945644 12217 net.cpp:51] Initializing net from parameters: 
name: "CIFAR"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_test_lmdb"
    batch_size: 1000
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Sigmoid0"
  type: "Sigmoid"
  bottom: "conv0"
  top: "Sigmoid0"
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "Sigmoid0"
  top: "pool0"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Sigmoid1"
  type: "Sigmoid"
  bottom: "conv1"
  top: "Sigmoid1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "Sigmoid1"
  top: "pool1"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Sigmoid2"
  type: "Sigmoid"
  bottom: "conv2"
  top: "Sigmoid2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "Sigmoid2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0426 10:44:11.945746 12217 layer_factory.hpp:77] Creating layer cifar
I0426 10:44:11.945806 12217 db_lmdb.cpp:35] Opened lmdb examples/cifar10/cifar10_test_lmdb
I0426 10:44:11.945822 12217 net.cpp:84] Creating Layer cifar
I0426 10:44:11.945828 12217 net.cpp:380] cifar -> data
I0426 10:44:11.945838 12217 net.cpp:380] cifar -> label
I0426 10:44:11.945849 12217 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I0426 10:44:11.946009 12217 data_layer.cpp:45] output data size: 1000,3,32,32
I0426 10:44:11.974577 12217 net.cpp:122] Setting up cifar
I0426 10:44:11.974604 12217 net.cpp:129] Top shape: 1000 3 32 32 (3072000)
I0426 10:44:11.974611 12217 net.cpp:129] Top shape: 1000 (1000)
I0426 10:44:11.974616 12217 net.cpp:137] Memory required for data: 12292000
I0426 10:44:11.974624 12217 layer_factory.hpp:77] Creating layer label_cifar_1_split
I0426 10:44:11.974642 12217 net.cpp:84] Creating Layer label_cifar_1_split
I0426 10:44:11.974650 12217 net.cpp:406] label_cifar_1_split <- label
I0426 10:44:11.974663 12217 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I0426 10:44:11.974679 12217 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I0426 10:44:11.974740 12217 net.cpp:122] Setting up label_cifar_1_split
I0426 10:44:11.974747 12217 net.cpp:129] Top shape: 1000 (1000)
I0426 10:44:11.974753 12217 net.cpp:129] Top shape: 1000 (1000)
I0426 10:44:11.974756 12217 net.cpp:137] Memory required for data: 12300000
I0426 10:44:11.974761 12217 layer_factory.hpp:77] Creating layer conv0
I0426 10:44:11.974778 12217 net.cpp:84] Creating Layer conv0
I0426 10:44:11.974783 12217 net.cpp:406] conv0 <- data
I0426 10:44:11.974794 12217 net.cpp:380] conv0 -> conv0
I0426 10:44:11.975052 12217 net.cpp:122] Setting up conv0
I0426 10:44:11.975062 12217 net.cpp:129] Top shape: 1000 25 32 32 (25600000)
I0426 10:44:11.975067 12217 net.cpp:137] Memory required for data: 114700000
I0426 10:44:11.975080 12217 layer_factory.hpp:77] Creating layer Sigmoid0
I0426 10:44:11.975088 12217 net.cpp:84] Creating Layer Sigmoid0
I0426 10:44:11.975095 12217 net.cpp:406] Sigmoid0 <- conv0
I0426 10:44:11.975101 12217 net.cpp:380] Sigmoid0 -> Sigmoid0
I0426 10:44:11.975128 12217 net.cpp:122] Setting up Sigmoid0
I0426 10:44:11.975136 12217 net.cpp:129] Top shape: 1000 25 32 32 (25600000)
I0426 10:44:11.975141 12217 net.cpp:137] Memory required for data: 217100000
I0426 10:44:11.975147 12217 layer_factory.hpp:77] Creating layer pool0
I0426 10:44:11.975157 12217 net.cpp:84] Creating Layer pool0
I0426 10:44:11.975162 12217 net.cpp:406] pool0 <- Sigmoid0
I0426 10:44:11.975168 12217 net.cpp:380] pool0 -> pool0
I0426 10:44:11.975196 12217 net.cpp:122] Setting up pool0
I0426 10:44:11.975203 12217 net.cpp:129] Top shape: 1000 25 16 16 (6400000)
I0426 10:44:11.975208 12217 net.cpp:137] Memory required for data: 242700000
I0426 10:44:11.975214 12217 layer_factory.hpp:77] Creating layer conv1
I0426 10:44:11.975224 12217 net.cpp:84] Creating Layer conv1
I0426 10:44:11.975241 12217 net.cpp:406] conv1 <- pool0
I0426 10:44:11.975252 12217 net.cpp:380] conv1 -> conv1
I0426 10:44:11.975652 12217 net.cpp:122] Setting up conv1
I0426 10:44:11.975661 12217 net.cpp:129] Top shape: 1000 25 16 16 (6400000)
I0426 10:44:11.975666 12217 net.cpp:137] Memory required for data: 268300000
I0426 10:44:11.975677 12217 layer_factory.hpp:77] Creating layer Sigmoid1
I0426 10:44:11.975742 12217 net.cpp:84] Creating Layer Sigmoid1
I0426 10:44:11.975747 12217 net.cpp:406] Sigmoid1 <- conv1
I0426 10:44:11.975762 12217 net.cpp:380] Sigmoid1 -> Sigmoid1
I0426 10:44:11.977671 12217 net.cpp:122] Setting up Sigmoid1
I0426 10:44:11.977680 12217 net.cpp:129] Top shape: 1000 25 16 16 (6400000)
I0426 10:44:11.977684 12217 net.cpp:137] Memory required for data: 293900000
I0426 10:44:11.977690 12217 layer_factory.hpp:77] Creating layer pool1
I0426 10:44:11.977700 12217 net.cpp:84] Creating Layer pool1
I0426 10:44:11.977705 12217 net.cpp:406] pool1 <- Sigmoid1
I0426 10:44:11.977712 12217 net.cpp:380] pool1 -> pool1
I0426 10:44:11.977742 12217 net.cpp:122] Setting up pool1
I0426 10:44:11.977751 12217 net.cpp:129] Top shape: 1000 25 8 8 (1600000)
I0426 10:44:11.977754 12217 net.cpp:137] Memory required for data: 300300000
I0426 10:44:11.977759 12217 layer_factory.hpp:77] Creating layer conv2
I0426 10:44:11.977774 12217 net.cpp:84] Creating Layer conv2
I0426 10:44:11.977779 12217 net.cpp:406] conv2 <- pool1
I0426 10:44:11.977789 12217 net.cpp:380] conv2 -> conv2
I0426 10:44:11.978183 12217 net.cpp:122] Setting up conv2
I0426 10:44:11.978191 12217 net.cpp:129] Top shape: 1000 25 8 8 (1600000)
I0426 10:44:11.978196 12217 net.cpp:137] Memory required for data: 306700000
I0426 10:44:11.978209 12217 layer_factory.hpp:77] Creating layer Sigmoid2
I0426 10:44:11.978215 12217 net.cpp:84] Creating Layer Sigmoid2
I0426 10:44:11.978221 12217 net.cpp:406] Sigmoid2 <- conv2
I0426 10:44:11.978233 12217 net.cpp:380] Sigmoid2 -> Sigmoid2
I0426 10:44:11.978258 12217 net.cpp:122] Setting up Sigmoid2
I0426 10:44:11.978268 12217 net.cpp:129] Top shape: 1000 25 8 8 (1600000)
I0426 10:44:11.978273 12217 net.cpp:137] Memory required for data: 313100000
I0426 10:44:11.978279 12217 layer_factory.hpp:77] Creating layer pool2
I0426 10:44:11.978286 12217 net.cpp:84] Creating Layer pool2
I0426 10:44:11.978291 12217 net.cpp:406] pool2 <- Sigmoid2
I0426 10:44:11.978297 12217 net.cpp:380] pool2 -> pool2
I0426 10:44:11.978324 12217 net.cpp:122] Setting up pool2
I0426 10:44:11.978332 12217 net.cpp:129] Top shape: 1000 25 4 4 (400000)
I0426 10:44:11.978335 12217 net.cpp:137] Memory required for data: 314700000
I0426 10:44:11.978341 12217 layer_factory.hpp:77] Creating layer ip1
I0426 10:44:11.978353 12217 net.cpp:84] Creating Layer ip1
I0426 10:44:11.978358 12217 net.cpp:406] ip1 <- pool2
I0426 10:44:11.978364 12217 net.cpp:380] ip1 -> ip1
I0426 10:44:11.978513 12217 net.cpp:122] Setting up ip1
I0426 10:44:11.978524 12217 net.cpp:129] Top shape: 1000 10 (10000)
I0426 10:44:11.978528 12217 net.cpp:137] Memory required for data: 314740000
I0426 10:44:11.978536 12217 layer_factory.hpp:77] Creating layer ip1_ip1_0_split
I0426 10:44:11.978546 12217 net.cpp:84] Creating Layer ip1_ip1_0_split
I0426 10:44:11.978551 12217 net.cpp:406] ip1_ip1_0_split <- ip1
I0426 10:44:11.978561 12217 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0426 10:44:11.978571 12217 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0426 10:44:11.978610 12217 net.cpp:122] Setting up ip1_ip1_0_split
I0426 10:44:11.978618 12217 net.cpp:129] Top shape: 1000 10 (10000)
I0426 10:44:11.978624 12217 net.cpp:129] Top shape: 1000 10 (10000)
I0426 10:44:11.978629 12217 net.cpp:137] Memory required for data: 314820000
I0426 10:44:11.978637 12217 layer_factory.hpp:77] Creating layer accuracy
I0426 10:44:11.978644 12217 net.cpp:84] Creating Layer accuracy
I0426 10:44:11.978652 12217 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I0426 10:44:11.978657 12217 net.cpp:406] accuracy <- label_cifar_1_split_0
I0426 10:44:11.978663 12217 net.cpp:380] accuracy -> accuracy
I0426 10:44:11.978688 12217 net.cpp:122] Setting up accuracy
I0426 10:44:11.978696 12217 net.cpp:129] Top shape: (1)
I0426 10:44:11.978700 12217 net.cpp:137] Memory required for data: 314820004
I0426 10:44:11.978703 12217 layer_factory.hpp:77] Creating layer loss
I0426 10:44:11.978710 12217 net.cpp:84] Creating Layer loss
I0426 10:44:11.978716 12217 net.cpp:406] loss <- ip1_ip1_0_split_1
I0426 10:44:11.978723 12217 net.cpp:406] loss <- label_cifar_1_split_1
I0426 10:44:11.978729 12217 net.cpp:380] loss -> loss
I0426 10:44:11.978739 12217 layer_factory.hpp:77] Creating layer loss
I0426 10:44:11.978868 12217 net.cpp:122] Setting up loss
I0426 10:44:11.978874 12217 net.cpp:129] Top shape: (1)
I0426 10:44:11.978878 12217 net.cpp:132]     with loss weight 1
I0426 10:44:11.978890 12217 net.cpp:137] Memory required for data: 314820008
I0426 10:44:11.978896 12217 net.cpp:198] loss needs backward computation.
I0426 10:44:11.978904 12217 net.cpp:200] accuracy does not need backward computation.
I0426 10:44:11.978910 12217 net.cpp:198] ip1_ip1_0_split needs backward computation.
I0426 10:44:11.978914 12217 net.cpp:198] ip1 needs backward computation.
I0426 10:44:11.978919 12217 net.cpp:198] pool2 needs backward computation.
I0426 10:44:11.978924 12217 net.cpp:198] Sigmoid2 needs backward computation.
I0426 10:44:11.978929 12217 net.cpp:198] conv2 needs backward computation.
I0426 10:44:11.978932 12217 net.cpp:198] pool1 needs backward computation.
I0426 10:44:11.978940 12217 net.cpp:198] Sigmoid1 needs backward computation.
I0426 10:44:11.978943 12217 net.cpp:198] conv1 needs backward computation.
I0426 10:44:11.978947 12217 net.cpp:198] pool0 needs backward computation.
I0426 10:44:11.978951 12217 net.cpp:198] Sigmoid0 needs backward computation.
I0426 10:44:11.978956 12217 net.cpp:198] conv0 needs backward computation.
I0426 10:44:11.978961 12217 net.cpp:200] label_cifar_1_split does not need backward computation.
I0426 10:44:11.978966 12217 net.cpp:200] cifar does not need backward computation.
I0426 10:44:11.978971 12217 net.cpp:242] This network produces output accuracy
I0426 10:44:11.978976 12217 net.cpp:242] This network produces output loss
I0426 10:44:11.978994 12217 net.cpp:255] Network initialization done.
I0426 10:44:11.979044 12217 solver.cpp:56] Solver scaffolding done.
I0426 10:44:11.979329 12217 caffe.cpp:248] Starting Optimization
I0426 10:44:11.979336 12217 solver.cpp:273] Solving CIFAR
I0426 10:44:11.979341 12217 solver.cpp:274] Learning Rate Policy: step
I0426 10:44:11.979779 12217 solver.cpp:331] Iteration 0, Testing net (#0)
I0426 10:44:11.979903 12217 blocking_queue.cpp:49] Waiting for data
I0426 10:44:13.498590 12226 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:44:14.475929 12217 solver.cpp:398]     Test net output #0: accuracy = 0.1
I0426 10:44:14.475960 12217 solver.cpp:398]     Test net output #1: loss = 2.30454 (* 1 = 2.30454 loss)
I0426 10:44:14.557417 12217 solver.cpp:219] Iteration 0 (0 iter/s, 2.5781s/100 iters), loss = 2.30792
I0426 10:44:14.557456 12217 solver.cpp:238]     Train net output #0: loss = 2.30792 (* 1 = 2.30792 loss)
I0426 10:44:14.557472 12217 sgd_solver.cpp:105] Iteration 0, lr = 0.001
I0426 10:44:21.694746 12217 solver.cpp:219] Iteration 100 (14.0107 iter/s, 7.13742s/100 iters), loss = 2.31891
I0426 10:44:21.694777 12217 solver.cpp:238]     Train net output #0: loss = 2.31891 (* 1 = 2.31891 loss)
I0426 10:44:21.694784 12217 sgd_solver.cpp:105] Iteration 100, lr = 0.001
I0426 10:44:28.819505 12217 solver.cpp:219] Iteration 200 (14.0354 iter/s, 7.12486s/100 iters), loss = 2.30462
I0426 10:44:28.819536 12217 solver.cpp:238]     Train net output #0: loss = 2.30462 (* 1 = 2.30462 loss)
I0426 10:44:28.819542 12217 sgd_solver.cpp:105] Iteration 200, lr = 0.001
I0426 10:44:35.962026 12217 solver.cpp:219] Iteration 300 (14.0005 iter/s, 7.14262s/100 iters), loss = 2.30498
I0426 10:44:35.962059 12217 solver.cpp:238]     Train net output #0: loss = 2.30498 (* 1 = 2.30498 loss)
I0426 10:44:35.962065 12217 sgd_solver.cpp:105] Iteration 300, lr = 0.001
I0426 10:44:43.102531 12217 solver.cpp:219] Iteration 400 (14.0044 iter/s, 7.14061s/100 iters), loss = 2.30281
I0426 10:44:43.102674 12217 solver.cpp:238]     Train net output #0: loss = 2.30281 (* 1 = 2.30281 loss)
I0426 10:44:43.102682 12217 sgd_solver.cpp:105] Iteration 400, lr = 0.001
I0426 10:44:46.390399 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:44:50.253209 12217 solver.cpp:219] Iteration 500 (13.9847 iter/s, 7.15067s/100 iters), loss = 2.30373
I0426 10:44:50.253244 12217 solver.cpp:238]     Train net output #0: loss = 2.30373 (* 1 = 2.30373 loss)
I0426 10:44:50.253250 12217 sgd_solver.cpp:105] Iteration 500, lr = 0.001
I0426 10:44:57.413990 12217 solver.cpp:219] Iteration 600 (13.9648 iter/s, 7.16088s/100 iters), loss = 2.30111
I0426 10:44:57.414021 12217 solver.cpp:238]     Train net output #0: loss = 2.30111 (* 1 = 2.30111 loss)
I0426 10:44:57.414028 12217 sgd_solver.cpp:105] Iteration 600, lr = 0.001
I0426 10:45:04.635673 12217 solver.cpp:219] Iteration 700 (13.847 iter/s, 7.22179s/100 iters), loss = 2.29934
I0426 10:45:04.635715 12217 solver.cpp:238]     Train net output #0: loss = 2.29934 (* 1 = 2.29934 loss)
I0426 10:45:04.635725 12217 sgd_solver.cpp:105] Iteration 700, lr = 0.001
I0426 10:45:11.782615 12217 solver.cpp:219] Iteration 800 (13.9918 iter/s, 7.14704s/100 iters), loss = 2.31146
I0426 10:45:11.782646 12217 solver.cpp:238]     Train net output #0: loss = 2.31146 (* 1 = 2.31146 loss)
I0426 10:45:11.782652 12217 sgd_solver.cpp:105] Iteration 800, lr = 0.001
I0426 10:45:18.675813 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:45:18.962430 12217 solver.cpp:219] Iteration 900 (13.9277 iter/s, 7.17992s/100 iters), loss = 2.30662
I0426 10:45:18.962465 12217 solver.cpp:238]     Train net output #0: loss = 2.30662 (* 1 = 2.30662 loss)
I0426 10:45:18.962471 12217 sgd_solver.cpp:105] Iteration 900, lr = 0.001
I0426 10:45:25.998284 12217 solver.cpp:331] Iteration 1000, Testing net (#0)
I0426 10:45:27.528663 12226 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:45:28.475404 12217 solver.cpp:398]     Test net output #0: accuracy = 0.1
I0426 10:45:28.475428 12217 solver.cpp:398]     Test net output #1: loss = 2.30488 (* 1 = 2.30488 loss)
I0426 10:45:28.547091 12217 solver.cpp:219] Iteration 1000 (10.4332 iter/s, 9.58482s/100 iters), loss = 2.30096
I0426 10:45:28.547116 12217 solver.cpp:238]     Train net output #0: loss = 2.30096 (* 1 = 2.30096 loss)
I0426 10:45:28.547124 12217 sgd_solver.cpp:105] Iteration 1000, lr = 0.001
I0426 10:45:35.677677 12217 solver.cpp:219] Iteration 1100 (14.0239 iter/s, 7.1307s/100 iters), loss = 2.30184
I0426 10:45:35.677709 12217 solver.cpp:238]     Train net output #0: loss = 2.30184 (* 1 = 2.30184 loss)
I0426 10:45:35.677716 12217 sgd_solver.cpp:105] Iteration 1100, lr = 0.001
I0426 10:45:42.806347 12217 solver.cpp:219] Iteration 1200 (14.0277 iter/s, 7.12877s/100 iters), loss = 2.31261
I0426 10:45:42.806378 12217 solver.cpp:238]     Train net output #0: loss = 2.31261 (* 1 = 2.31261 loss)
I0426 10:45:42.806385 12217 sgd_solver.cpp:105] Iteration 1200, lr = 0.001
I0426 10:45:49.926734 12217 solver.cpp:219] Iteration 1300 (14.044 iter/s, 7.12049s/100 iters), loss = 2.30695
I0426 10:45:49.926882 12217 solver.cpp:238]     Train net output #0: loss = 2.30695 (* 1 = 2.30695 loss)
I0426 10:45:49.926890 12217 sgd_solver.cpp:105] Iteration 1300, lr = 0.001
I0426 10:45:53.280266 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:45:57.049621 12217 solver.cpp:219] Iteration 1400 (14.0393 iter/s, 7.12287s/100 iters), loss = 2.29705
I0426 10:45:57.049652 12217 solver.cpp:238]     Train net output #0: loss = 2.29705 (* 1 = 2.29705 loss)
I0426 10:45:57.049657 12217 sgd_solver.cpp:105] Iteration 1400, lr = 0.001
I0426 10:46:04.166252 12217 solver.cpp:219] Iteration 1500 (14.0514 iter/s, 7.11674s/100 iters), loss = 2.31508
I0426 10:46:04.166280 12217 solver.cpp:238]     Train net output #0: loss = 2.31508 (* 1 = 2.31508 loss)
I0426 10:46:04.166285 12217 sgd_solver.cpp:105] Iteration 1500, lr = 0.001
I0426 10:46:11.281863 12217 solver.cpp:219] Iteration 1600 (14.0534 iter/s, 7.11572s/100 iters), loss = 2.30499
I0426 10:46:11.281894 12217 solver.cpp:238]     Train net output #0: loss = 2.30499 (* 1 = 2.30499 loss)
I0426 10:46:11.281898 12217 sgd_solver.cpp:105] Iteration 1600, lr = 0.001
I0426 10:46:18.404300 12217 solver.cpp:219] Iteration 1700 (14.0399 iter/s, 7.12254s/100 iters), loss = 2.30883
I0426 10:46:18.404330 12217 solver.cpp:238]     Train net output #0: loss = 2.30883 (* 1 = 2.30883 loss)
I0426 10:46:18.404335 12217 sgd_solver.cpp:105] Iteration 1700, lr = 0.001
I0426 10:46:25.305793 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:46:25.518687 12217 solver.cpp:219] Iteration 1800 (14.0558 iter/s, 7.11449s/100 iters), loss = 2.29375
I0426 10:46:25.518717 12217 solver.cpp:238]     Train net output #0: loss = 2.29375 (* 1 = 2.29375 loss)
I0426 10:46:25.518720 12217 sgd_solver.cpp:105] Iteration 1800, lr = 0.001
I0426 10:46:32.660434 12217 solver.cpp:219] Iteration 1900 (14.002 iter/s, 7.14185s/100 iters), loss = 2.29622
I0426 10:46:32.660472 12217 solver.cpp:238]     Train net output #0: loss = 2.29622 (* 1 = 2.29622 loss)
I0426 10:46:32.660478 12217 sgd_solver.cpp:105] Iteration 1900, lr = 0.001
I0426 10:46:40.029512 12217 solver.cpp:331] Iteration 2000, Testing net (#0)
I0426 10:46:41.538483 12226 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:46:42.509980 12217 solver.cpp:398]     Test net output #0: accuracy = 0.1
I0426 10:46:42.510004 12217 solver.cpp:398]     Test net output #1: loss = 2.30266 (* 1 = 2.30266 loss)
I0426 10:46:42.581199 12217 solver.cpp:219] Iteration 2000 (10.0797 iter/s, 9.92093s/100 iters), loss = 2.30426
I0426 10:46:42.581223 12217 solver.cpp:238]     Train net output #0: loss = 2.30426 (* 1 = 2.30426 loss)
I0426 10:46:42.581229 12217 sgd_solver.cpp:105] Iteration 2000, lr = 0.001
I0426 10:46:49.710078 12217 solver.cpp:219] Iteration 2100 (14.0272 iter/s, 7.12899s/100 iters), loss = 2.304
I0426 10:46:49.710106 12217 solver.cpp:238]     Train net output #0: loss = 2.304 (* 1 = 2.304 loss)
I0426 10:46:49.710111 12217 sgd_solver.cpp:105] Iteration 2100, lr = 0.001
I0426 10:46:56.829535 12217 solver.cpp:219] Iteration 2200 (14.0458 iter/s, 7.11956s/100 iters), loss = 2.30383
I0426 10:46:56.829701 12217 solver.cpp:238]     Train net output #0: loss = 2.30383 (* 1 = 2.30383 loss)
I0426 10:46:56.829708 12217 sgd_solver.cpp:105] Iteration 2200, lr = 0.001
I0426 10:47:00.249929 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:47:03.947607 12217 solver.cpp:219] Iteration 2300 (14.0488 iter/s, 7.11805s/100 iters), loss = 2.30242
I0426 10:47:03.947652 12217 solver.cpp:238]     Train net output #0: loss = 2.30242 (* 1 = 2.30242 loss)
I0426 10:47:03.947656 12217 sgd_solver.cpp:105] Iteration 2300, lr = 0.001
I0426 10:47:11.081272 12217 solver.cpp:219] Iteration 2400 (14.0179 iter/s, 7.13376s/100 iters), loss = 2.30732
I0426 10:47:11.081302 12217 solver.cpp:238]     Train net output #0: loss = 2.30732 (* 1 = 2.30732 loss)
I0426 10:47:11.081307 12217 sgd_solver.cpp:105] Iteration 2400, lr = 0.001
I0426 10:47:18.213161 12217 solver.cpp:219] Iteration 2500 (14.0213 iter/s, 7.132s/100 iters), loss = 2.30802
I0426 10:47:18.213189 12217 solver.cpp:238]     Train net output #0: loss = 2.30802 (* 1 = 2.30802 loss)
I0426 10:47:18.213194 12217 sgd_solver.cpp:105] Iteration 2500, lr = 0.001
I0426 10:47:25.345979 12217 solver.cpp:219] Iteration 2600 (14.0195 iter/s, 7.13293s/100 iters), loss = 2.30022
I0426 10:47:25.346009 12217 solver.cpp:238]     Train net output #0: loss = 2.30022 (* 1 = 2.30022 loss)
I0426 10:47:25.346014 12217 sgd_solver.cpp:105] Iteration 2600, lr = 0.001
I0426 10:47:32.333886 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:47:32.475224 12217 solver.cpp:219] Iteration 2700 (14.0265 iter/s, 7.12934s/100 iters), loss = 2.30549
I0426 10:47:32.475266 12217 solver.cpp:238]     Train net output #0: loss = 2.30549 (* 1 = 2.30549 loss)
I0426 10:47:32.475273 12217 sgd_solver.cpp:105] Iteration 2700, lr = 0.001
I0426 10:47:39.603376 12217 solver.cpp:219] Iteration 2800 (14.0287 iter/s, 7.12825s/100 iters), loss = 2.30454
I0426 10:47:39.603411 12217 solver.cpp:238]     Train net output #0: loss = 2.30454 (* 1 = 2.30454 loss)
I0426 10:47:39.603418 12217 sgd_solver.cpp:105] Iteration 2800, lr = 0.001
I0426 10:47:46.728157 12217 solver.cpp:219] Iteration 2900 (14.0353 iter/s, 7.12488s/100 iters), loss = 2.30045
I0426 10:47:46.728188 12217 solver.cpp:238]     Train net output #0: loss = 2.30045 (* 1 = 2.30045 loss)
I0426 10:47:46.728191 12217 sgd_solver.cpp:105] Iteration 2900, lr = 0.001
I0426 10:47:53.745970 12217 solver.cpp:331] Iteration 3000, Testing net (#0)
I0426 10:47:55.257123 12226 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:47:56.228854 12217 solver.cpp:398]     Test net output #0: accuracy = 0.1
I0426 10:47:56.228880 12217 solver.cpp:398]     Test net output #1: loss = 2.30123 (* 1 = 2.30123 loss)
I0426 10:47:56.300199 12217 solver.cpp:219] Iteration 3000 (10.4469 iter/s, 9.5722s/100 iters), loss = 2.29519
I0426 10:47:56.300223 12217 solver.cpp:238]     Train net output #0: loss = 2.29519 (* 1 = 2.29519 loss)
I0426 10:47:56.300230 12217 sgd_solver.cpp:105] Iteration 3000, lr = 0.001
I0426 10:48:03.421520 12217 solver.cpp:219] Iteration 3100 (14.0421 iter/s, 7.12144s/100 iters), loss = 2.3006
I0426 10:48:03.421697 12217 solver.cpp:238]     Train net output #0: loss = 2.3006 (* 1 = 2.3006 loss)
I0426 10:48:03.421705 12217 sgd_solver.cpp:105] Iteration 3100, lr = 0.001
I0426 10:48:06.920321 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:48:10.552749 12217 solver.cpp:219] Iteration 3200 (14.0229 iter/s, 7.13119s/100 iters), loss = 2.29577
I0426 10:48:10.552779 12217 solver.cpp:238]     Train net output #0: loss = 2.29577 (* 1 = 2.29577 loss)
I0426 10:48:10.552785 12217 sgd_solver.cpp:105] Iteration 3200, lr = 0.001
I0426 10:48:17.981742 12217 solver.cpp:219] Iteration 3300 (13.4606 iter/s, 7.4291s/100 iters), loss = 2.29691
I0426 10:48:17.981781 12217 solver.cpp:238]     Train net output #0: loss = 2.29691 (* 1 = 2.29691 loss)
I0426 10:48:17.981786 12217 sgd_solver.cpp:105] Iteration 3300, lr = 0.001
I0426 10:48:25.506692 12217 solver.cpp:219] Iteration 3400 (13.2889 iter/s, 7.52506s/100 iters), loss = 2.27428
I0426 10:48:25.506726 12217 solver.cpp:238]     Train net output #0: loss = 2.27428 (* 1 = 2.27428 loss)
I0426 10:48:25.506731 12217 sgd_solver.cpp:105] Iteration 3400, lr = 0.001
I0426 10:48:32.970912 12217 solver.cpp:219] Iteration 3500 (13.3971 iter/s, 7.46433s/100 iters), loss = 2.20609
I0426 10:48:32.970948 12217 solver.cpp:238]     Train net output #0: loss = 2.20609 (* 1 = 2.20609 loss)
I0426 10:48:32.970955 12217 sgd_solver.cpp:105] Iteration 3500, lr = 0.001
I0426 10:48:40.279182 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:48:40.360625 12217 solver.cpp:219] Iteration 3600 (13.5321 iter/s, 7.38982s/100 iters), loss = 2.17117
I0426 10:48:40.360657 12217 solver.cpp:238]     Train net output #0: loss = 2.17117 (* 1 = 2.17117 loss)
I0426 10:48:40.360682 12217 sgd_solver.cpp:105] Iteration 3600, lr = 0.001
I0426 10:48:47.811115 12217 solver.cpp:219] Iteration 3700 (13.4217 iter/s, 7.4506s/100 iters), loss = 2.11486
I0426 10:48:47.811144 12217 solver.cpp:238]     Train net output #0: loss = 2.11486 (* 1 = 2.11486 loss)
I0426 10:48:47.811149 12217 sgd_solver.cpp:105] Iteration 3700, lr = 0.001
I0426 10:48:55.187264 12217 solver.cpp:219] Iteration 3800 (13.557 iter/s, 7.37626s/100 iters), loss = 2.09045
I0426 10:48:55.187297 12217 solver.cpp:238]     Train net output #0: loss = 2.09045 (* 1 = 2.09045 loss)
I0426 10:48:55.187304 12217 sgd_solver.cpp:105] Iteration 3800, lr = 0.001
I0426 10:49:02.568068 12217 solver.cpp:219] Iteration 3900 (13.5485 iter/s, 7.38091s/100 iters), loss = 2.06681
I0426 10:49:02.568099 12217 solver.cpp:238]     Train net output #0: loss = 2.06681 (* 1 = 2.06681 loss)
I0426 10:49:02.568104 12217 sgd_solver.cpp:105] Iteration 3900, lr = 0.001
I0426 10:49:09.853597 12217 solver.cpp:331] Iteration 4000, Testing net (#0)
I0426 10:49:11.413743 12226 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:49:12.417729 12217 solver.cpp:398]     Test net output #0: accuracy = 0.2265
I0426 10:49:12.417753 12217 solver.cpp:398]     Test net output #1: loss = 2.05436 (* 1 = 2.05436 loss)
I0426 10:49:12.490577 12217 solver.cpp:219] Iteration 4000 (10.0779 iter/s, 9.92267s/100 iters), loss = 2.08872
I0426 10:49:12.490607 12217 solver.cpp:238]     Train net output #0: loss = 2.08872 (* 1 = 2.08872 loss)
I0426 10:49:12.490613 12217 sgd_solver.cpp:105] Iteration 4000, lr = 0.001
I0426 10:49:16.165802 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:49:19.859649 12217 solver.cpp:219] Iteration 4100 (13.57 iter/s, 7.36918s/100 iters), loss = 2.14469
I0426 10:49:19.859681 12217 solver.cpp:238]     Train net output #0: loss = 2.14469 (* 1 = 2.14469 loss)
I0426 10:49:19.859706 12217 sgd_solver.cpp:105] Iteration 4100, lr = 0.001
I0426 10:49:27.229789 12217 solver.cpp:219] Iteration 4200 (13.5681 iter/s, 7.37025s/100 iters), loss = 2.01952
I0426 10:49:27.229840 12217 solver.cpp:238]     Train net output #0: loss = 2.01952 (* 1 = 2.01952 loss)
I0426 10:49:27.229845 12217 sgd_solver.cpp:105] Iteration 4200, lr = 0.001
I0426 10:49:34.598531 12217 solver.cpp:219] Iteration 4300 (13.5707 iter/s, 7.36883s/100 iters), loss = 1.94943
I0426 10:49:34.598561 12217 solver.cpp:238]     Train net output #0: loss = 1.94943 (* 1 = 1.94943 loss)
I0426 10:49:34.598598 12217 sgd_solver.cpp:105] Iteration 4300, lr = 0.001
I0426 10:49:41.953325 12217 solver.cpp:219] Iteration 4400 (13.5964 iter/s, 7.3549s/100 iters), loss = 1.98985
I0426 10:49:41.953467 12217 solver.cpp:238]     Train net output #0: loss = 1.98985 (* 1 = 1.98985 loss)
I0426 10:49:41.953477 12217 sgd_solver.cpp:105] Iteration 4400, lr = 0.001
I0426 10:49:49.242854 12217 solver.cpp:219] Iteration 4500 (13.7183 iter/s, 7.28954s/100 iters), loss = 2.06294
I0426 10:49:49.242883 12217 solver.cpp:238]     Train net output #0: loss = 2.06294 (* 1 = 2.06294 loss)
I0426 10:49:49.242888 12217 sgd_solver.cpp:105] Iteration 4500, lr = 0.001
I0426 10:49:49.244056 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:49:56.368556 12217 solver.cpp:219] Iteration 4600 (14.0335 iter/s, 7.12581s/100 iters), loss = 1.9648
I0426 10:49:56.368583 12217 solver.cpp:238]     Train net output #0: loss = 1.9648 (* 1 = 1.9648 loss)
I0426 10:49:56.368589 12217 sgd_solver.cpp:105] Iteration 4600, lr = 0.001
I0426 10:50:03.495036 12217 solver.cpp:219] Iteration 4700 (14.032 iter/s, 7.12659s/100 iters), loss = 1.9407
I0426 10:50:03.495064 12217 solver.cpp:238]     Train net output #0: loss = 1.9407 (* 1 = 1.9407 loss)
I0426 10:50:03.495069 12217 sgd_solver.cpp:105] Iteration 4700, lr = 0.001
I0426 10:50:10.615917 12217 solver.cpp:219] Iteration 4800 (14.043 iter/s, 7.12099s/100 iters), loss = 2.08106
I0426 10:50:10.615952 12217 solver.cpp:238]     Train net output #0: loss = 2.08106 (* 1 = 2.08106 loss)
I0426 10:50:10.615957 12217 sgd_solver.cpp:105] Iteration 4800, lr = 0.001
I0426 10:50:17.729993 12217 solver.cpp:219] Iteration 4900 (14.0564 iter/s, 7.11418s/100 iters), loss = 1.91058
I0426 10:50:17.730165 12217 solver.cpp:238]     Train net output #0: loss = 1.91058 (* 1 = 1.91058 loss)
I0426 10:50:17.730170 12217 sgd_solver.cpp:105] Iteration 4900, lr = 0.001
I0426 10:50:21.291119 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:50:24.739164 12217 solver.cpp:331] Iteration 5000, Testing net (#0)
I0426 10:50:26.255208 12226 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:50:27.229501 12217 solver.cpp:398]     Test net output #0: accuracy = 0.2596
I0426 10:50:27.229521 12217 solver.cpp:398]     Test net output #1: loss = 1.98596 (* 1 = 1.98596 loss)
I0426 10:50:27.301067 12217 solver.cpp:219] Iteration 5000 (10.4481 iter/s, 9.5711s/100 iters), loss = 2.00903
I0426 10:50:27.301090 12217 solver.cpp:238]     Train net output #0: loss = 2.00903 (* 1 = 2.00903 loss)
I0426 10:50:27.301095 12217 sgd_solver.cpp:105] Iteration 5000, lr = 0.001
I0426 10:50:34.419064 12217 solver.cpp:219] Iteration 5100 (14.0487 iter/s, 7.11812s/100 iters), loss = 1.94444
I0426 10:50:34.419091 12217 solver.cpp:238]     Train net output #0: loss = 1.94444 (* 1 = 1.94444 loss)
I0426 10:50:34.419097 12217 sgd_solver.cpp:105] Iteration 5100, lr = 0.001
I0426 10:50:41.536312 12217 solver.cpp:219] Iteration 5200 (14.0502 iter/s, 7.11736s/100 iters), loss = 2.1444
I0426 10:50:41.536340 12217 solver.cpp:238]     Train net output #0: loss = 2.1444 (* 1 = 2.1444 loss)
I0426 10:50:41.536345 12217 sgd_solver.cpp:105] Iteration 5200, lr = 0.001
I0426 10:50:48.652256 12217 solver.cpp:219] Iteration 5300 (14.0527 iter/s, 7.11606s/100 iters), loss = 1.98269
I0426 10:50:48.652403 12217 solver.cpp:238]     Train net output #0: loss = 1.98269 (* 1 = 1.98269 loss)
I0426 10:50:48.652410 12217 sgd_solver.cpp:105] Iteration 5300, lr = 0.001
I0426 10:50:55.769300 12217 solver.cpp:219] Iteration 5400 (14.0508 iter/s, 7.11704s/100 iters), loss = 2.00731
I0426 10:50:55.769330 12217 solver.cpp:238]     Train net output #0: loss = 2.00731 (* 1 = 2.00731 loss)
I0426 10:50:55.769335 12217 sgd_solver.cpp:105] Iteration 5400, lr = 0.001
I0426 10:50:55.841287 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:51:02.890008 12217 solver.cpp:219] Iteration 5500 (14.0433 iter/s, 7.12082s/100 iters), loss = 2.01316
I0426 10:51:02.890038 12217 solver.cpp:238]     Train net output #0: loss = 2.01316 (* 1 = 2.01316 loss)
I0426 10:51:02.890043 12217 sgd_solver.cpp:105] Iteration 5500, lr = 0.001
I0426 10:51:10.001327 12217 solver.cpp:219] Iteration 5600 (14.0619 iter/s, 7.11143s/100 iters), loss = 1.904
I0426 10:51:10.001358 12217 solver.cpp:238]     Train net output #0: loss = 1.904 (* 1 = 1.904 loss)
I0426 10:51:10.001363 12217 sgd_solver.cpp:105] Iteration 5600, lr = 0.001
I0426 10:51:17.112792 12217 solver.cpp:219] Iteration 5700 (14.0616 iter/s, 7.11158s/100 iters), loss = 1.88989
I0426 10:51:17.112821 12217 solver.cpp:238]     Train net output #0: loss = 1.88989 (* 1 = 1.88989 loss)
I0426 10:51:17.112826 12217 sgd_solver.cpp:105] Iteration 5700, lr = 0.001
I0426 10:51:24.223654 12217 solver.cpp:219] Iteration 5800 (14.0628 iter/s, 7.11097s/100 iters), loss = 1.98643
I0426 10:51:24.223803 12217 solver.cpp:238]     Train net output #0: loss = 1.98643 (* 1 = 1.98643 loss)
I0426 10:51:24.223809 12217 sgd_solver.cpp:105] Iteration 5800, lr = 0.001
I0426 10:51:27.851969 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:51:31.333675 12217 solver.cpp:219] Iteration 5900 (14.0647 iter/s, 7.10999s/100 iters), loss = 1.87193
I0426 10:51:31.333704 12217 solver.cpp:238]     Train net output #0: loss = 1.87193 (* 1 = 1.87193 loss)
I0426 10:51:31.333709 12217 sgd_solver.cpp:105] Iteration 5900, lr = 0.001
I0426 10:51:38.341154 12217 solver.cpp:331] Iteration 6000, Testing net (#0)
I0426 10:51:39.842571 12226 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:51:40.810230 12217 solver.cpp:398]     Test net output #0: accuracy = 0.2835
I0426 10:51:40.810256 12217 solver.cpp:398]     Test net output #1: loss = 1.94349 (* 1 = 1.94349 loss)
I0426 10:51:40.881146 12217 solver.cpp:219] Iteration 6000 (10.4738 iter/s, 9.54764s/100 iters), loss = 1.88549
I0426 10:51:40.881170 12217 solver.cpp:238]     Train net output #0: loss = 1.88549 (* 1 = 1.88549 loss)
I0426 10:51:40.881176 12217 sgd_solver.cpp:105] Iteration 6000, lr = 0.001
I0426 10:51:47.995998 12217 solver.cpp:219] Iteration 6100 (14.0549 iter/s, 7.11496s/100 iters), loss = 1.89978
I0426 10:51:47.996042 12217 solver.cpp:238]     Train net output #0: loss = 1.89978 (* 1 = 1.89978 loss)
I0426 10:51:47.996049 12217 sgd_solver.cpp:105] Iteration 6100, lr = 0.001
I0426 10:51:55.119750 12217 solver.cpp:219] Iteration 6200 (14.0374 iter/s, 7.12385s/100 iters), loss = 2.02079
I0426 10:51:55.119918 12217 solver.cpp:238]     Train net output #0: loss = 2.02079 (* 1 = 2.02079 loss)
I0426 10:51:55.119925 12217 sgd_solver.cpp:105] Iteration 6200, lr = 0.001
I0426 10:52:02.241998 12217 solver.cpp:219] Iteration 6300 (14.0406 iter/s, 7.12222s/100 iters), loss = 1.90563
I0426 10:52:02.242028 12217 solver.cpp:238]     Train net output #0: loss = 1.90563 (* 1 = 1.90563 loss)
I0426 10:52:02.242033 12217 sgd_solver.cpp:105] Iteration 6300, lr = 0.001
I0426 10:52:02.385166 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:52:09.360581 12217 solver.cpp:219] Iteration 6400 (14.0475 iter/s, 7.11869s/100 iters), loss = 2.06768
I0426 10:52:09.360610 12217 solver.cpp:238]     Train net output #0: loss = 2.06768 (* 1 = 2.06768 loss)
I0426 10:52:09.360615 12217 sgd_solver.cpp:105] Iteration 6400, lr = 0.001
I0426 10:52:16.470872 12217 solver.cpp:219] Iteration 6500 (14.0639 iter/s, 7.1104s/100 iters), loss = 1.83943
I0426 10:52:16.470903 12217 solver.cpp:238]     Train net output #0: loss = 1.83943 (* 1 = 1.83943 loss)
I0426 10:52:16.470908 12217 sgd_solver.cpp:105] Iteration 6500, lr = 0.001
I0426 10:52:23.584770 12217 solver.cpp:219] Iteration 6600 (14.0568 iter/s, 7.11401s/100 iters), loss = 1.99436
I0426 10:52:23.584800 12217 solver.cpp:238]     Train net output #0: loss = 1.99436 (* 1 = 1.99436 loss)
I0426 10:52:23.584805 12217 sgd_solver.cpp:105] Iteration 6600, lr = 0.001
I0426 10:52:30.701043 12217 solver.cpp:219] Iteration 6700 (14.0521 iter/s, 7.11638s/100 iters), loss = 1.90666
I0426 10:52:30.701117 12217 solver.cpp:238]     Train net output #0: loss = 1.90666 (* 1 = 1.90666 loss)
I0426 10:52:30.701123 12217 sgd_solver.cpp:105] Iteration 6700, lr = 0.001
I0426 10:52:34.472331 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:52:37.887653 12217 solver.cpp:219] Iteration 6800 (13.9146 iter/s, 7.18668s/100 iters), loss = 1.94679
I0426 10:52:37.887683 12217 solver.cpp:238]     Train net output #0: loss = 1.94679 (* 1 = 1.94679 loss)
I0426 10:52:37.887688 12217 sgd_solver.cpp:105] Iteration 6800, lr = 0.001
I0426 10:52:45.000185 12217 solver.cpp:219] Iteration 6900 (14.0595 iter/s, 7.11264s/100 iters), loss = 2.02124
I0426 10:52:45.000216 12217 solver.cpp:238]     Train net output #0: loss = 2.02124 (* 1 = 2.02124 loss)
I0426 10:52:45.000221 12217 sgd_solver.cpp:105] Iteration 6900, lr = 0.001
I0426 10:52:52.006609 12217 solver.cpp:331] Iteration 7000, Testing net (#0)
I0426 10:52:53.520820 12226 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:52:54.482676 12217 solver.cpp:398]     Test net output #0: accuracy = 0.2894
I0426 10:52:54.482703 12217 solver.cpp:398]     Test net output #1: loss = 1.92005 (* 1 = 1.92005 loss)
I0426 10:52:54.553994 12217 solver.cpp:219] Iteration 7000 (10.4669 iter/s, 9.55397s/100 iters), loss = 2.01126
I0426 10:52:54.554023 12217 solver.cpp:238]     Train net output #0: loss = 2.01126 (* 1 = 2.01126 loss)
I0426 10:52:54.554030 12217 sgd_solver.cpp:105] Iteration 7000, lr = 0.001
I0426 10:53:01.669837 12217 solver.cpp:219] Iteration 7100 (14.0529 iter/s, 7.11596s/100 iters), loss = 1.94279
I0426 10:53:01.669988 12217 solver.cpp:238]     Train net output #0: loss = 1.94279 (* 1 = 1.94279 loss)
I0426 10:53:01.669996 12217 sgd_solver.cpp:105] Iteration 7100, lr = 0.001
I0426 10:53:08.788125 12217 solver.cpp:219] Iteration 7200 (14.0484 iter/s, 7.11826s/100 iters), loss = 1.90114
I0426 10:53:08.788153 12217 solver.cpp:238]     Train net output #0: loss = 1.90114 (* 1 = 1.90114 loss)
I0426 10:53:08.788158 12217 sgd_solver.cpp:105] Iteration 7200, lr = 0.001
I0426 10:53:09.002277 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:53:15.956501 12217 solver.cpp:219] Iteration 7300 (13.9499 iter/s, 7.16849s/100 iters), loss = 1.90939
I0426 10:53:15.956532 12217 solver.cpp:238]     Train net output #0: loss = 1.90939 (* 1 = 1.90939 loss)
I0426 10:53:15.956537 12217 sgd_solver.cpp:105] Iteration 7300, lr = 0.001
I0426 10:53:23.113553 12217 solver.cpp:219] Iteration 7400 (13.972 iter/s, 7.15716s/100 iters), loss = 1.93421
I0426 10:53:23.113590 12217 solver.cpp:238]     Train net output #0: loss = 1.93421 (* 1 = 1.93421 loss)
I0426 10:53:23.113596 12217 sgd_solver.cpp:105] Iteration 7400, lr = 0.001
I0426 10:53:30.249758 12217 solver.cpp:219] Iteration 7500 (14.0129 iter/s, 7.13631s/100 iters), loss = 1.90827
I0426 10:53:30.249795 12217 solver.cpp:238]     Train net output #0: loss = 1.90827 (* 1 = 1.90827 loss)
I0426 10:53:30.249801 12217 sgd_solver.cpp:105] Iteration 7500, lr = 0.001
I0426 10:53:37.396827 12217 solver.cpp:219] Iteration 7600 (13.9915 iter/s, 7.14717s/100 iters), loss = 1.82685
I0426 10:53:37.397008 12217 solver.cpp:238]     Train net output #0: loss = 1.82685 (* 1 = 1.82685 loss)
I0426 10:53:37.397017 12217 sgd_solver.cpp:105] Iteration 7600, lr = 0.001
I0426 10:53:41.190325 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:53:44.548739 12217 solver.cpp:219] Iteration 7700 (13.9823 iter/s, 7.15188s/100 iters), loss = 1.78742
I0426 10:53:44.548768 12217 solver.cpp:238]     Train net output #0: loss = 1.78742 (* 1 = 1.78742 loss)
I0426 10:53:44.548774 12217 sgd_solver.cpp:105] Iteration 7700, lr = 0.001
I0426 10:53:51.790462 12217 solver.cpp:219] Iteration 7800 (13.8087 iter/s, 7.24184s/100 iters), loss = 1.95762
I0426 10:53:51.790493 12217 solver.cpp:238]     Train net output #0: loss = 1.95762 (* 1 = 1.95762 loss)
I0426 10:53:51.790499 12217 sgd_solver.cpp:105] Iteration 7800, lr = 0.001
I0426 10:53:58.940814 12217 solver.cpp:219] Iteration 7900 (13.9851 iter/s, 7.15046s/100 iters), loss = 2.01052
I0426 10:53:58.940843 12217 solver.cpp:238]     Train net output #0: loss = 2.01052 (* 1 = 2.01052 loss)
I0426 10:53:58.940848 12217 sgd_solver.cpp:105] Iteration 7900, lr = 0.001
I0426 10:54:05.968971 12217 solver.cpp:331] Iteration 8000, Testing net (#0)
I0426 10:54:07.519218 12226 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:54:08.487759 12217 solver.cpp:398]     Test net output #0: accuracy = 0.2934
I0426 10:54:08.487830 12217 solver.cpp:398]     Test net output #1: loss = 1.89823 (* 1 = 1.89823 loss)
I0426 10:54:08.567471 12217 solver.cpp:219] Iteration 8000 (10.3877 iter/s, 9.6268s/100 iters), loss = 1.87663
I0426 10:54:08.567562 12217 solver.cpp:238]     Train net output #0: loss = 1.87663 (* 1 = 1.87663 loss)
I0426 10:54:08.567580 12217 sgd_solver.cpp:105] Iteration 8000, lr = 0.001
I0426 10:54:15.730322 12217 solver.cpp:219] Iteration 8100 (13.9608 iter/s, 7.16291s/100 iters), loss = 1.78709
I0426 10:54:15.730384 12217 solver.cpp:238]     Train net output #0: loss = 1.78709 (* 1 = 1.78709 loss)
I0426 10:54:15.730391 12217 sgd_solver.cpp:105] Iteration 8100, lr = 0.001
I0426 10:54:16.025367 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:54:22.890782 12217 solver.cpp:219] Iteration 8200 (13.9654 iter/s, 7.16054s/100 iters), loss = 2.02898
I0426 10:54:22.890816 12217 solver.cpp:238]     Train net output #0: loss = 2.02898 (* 1 = 2.02898 loss)
I0426 10:54:22.890821 12217 sgd_solver.cpp:105] Iteration 8200, lr = 0.001
I0426 10:54:30.037384 12217 solver.cpp:219] Iteration 8300 (13.9925 iter/s, 7.14671s/100 iters), loss = 1.90607
I0426 10:54:30.037415 12217 solver.cpp:238]     Train net output #0: loss = 1.90607 (* 1 = 1.90607 loss)
I0426 10:54:30.037420 12217 sgd_solver.cpp:105] Iteration 8300, lr = 0.001
I0426 10:54:37.193599 12217 solver.cpp:219] Iteration 8400 (13.9737 iter/s, 7.15633s/100 iters), loss = 1.82032
I0426 10:54:37.193634 12217 solver.cpp:238]     Train net output #0: loss = 1.82032 (* 1 = 1.82032 loss)
I0426 10:54:37.193639 12217 sgd_solver.cpp:105] Iteration 8400, lr = 0.001
I0426 10:54:44.336630 12217 solver.cpp:219] Iteration 8500 (13.9995 iter/s, 7.14314s/100 iters), loss = 1.92362
I0426 10:54:44.336766 12217 solver.cpp:238]     Train net output #0: loss = 1.92362 (* 1 = 1.92362 loss)
I0426 10:54:44.336776 12217 sgd_solver.cpp:105] Iteration 8500, lr = 0.001
I0426 10:54:48.198352 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:54:51.491281 12217 solver.cpp:219] Iteration 8600 (13.9769 iter/s, 7.15466s/100 iters), loss = 1.85606
I0426 10:54:51.491320 12217 solver.cpp:238]     Train net output #0: loss = 1.85606 (* 1 = 1.85606 loss)
I0426 10:54:51.491333 12217 sgd_solver.cpp:105] Iteration 8600, lr = 0.001
I0426 10:54:58.635018 12217 solver.cpp:219] Iteration 8700 (13.9981 iter/s, 7.14384s/100 iters), loss = 1.89385
I0426 10:54:58.635056 12217 solver.cpp:238]     Train net output #0: loss = 1.89385 (* 1 = 1.89385 loss)
I0426 10:54:58.635061 12217 sgd_solver.cpp:105] Iteration 8700, lr = 0.001
I0426 10:55:05.763339 12217 solver.cpp:219] Iteration 8800 (14.0283 iter/s, 7.12842s/100 iters), loss = 1.87127
I0426 10:55:05.763375 12217 solver.cpp:238]     Train net output #0: loss = 1.87127 (* 1 = 1.87127 loss)
I0426 10:55:05.763381 12217 sgd_solver.cpp:105] Iteration 8800, lr = 0.001
I0426 10:55:12.906563 12217 solver.cpp:219] Iteration 8900 (13.9991 iter/s, 7.14333s/100 iters), loss = 1.91073
I0426 10:55:12.906597 12217 solver.cpp:238]     Train net output #0: loss = 1.91073 (* 1 = 1.91073 loss)
I0426 10:55:12.906604 12217 sgd_solver.cpp:105] Iteration 8900, lr = 0.001
I0426 10:55:19.933974 12217 solver.cpp:331] Iteration 9000, Testing net (#0)
I0426 10:55:21.452086 12226 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:55:22.432752 12217 solver.cpp:398]     Test net output #0: accuracy = 0.3061
I0426 10:55:22.432782 12217 solver.cpp:398]     Test net output #1: loss = 1.86596 (* 1 = 1.86596 loss)
I0426 10:55:22.511788 12217 solver.cpp:219] Iteration 9000 (10.4108 iter/s, 9.60538s/100 iters), loss = 1.91781
I0426 10:55:22.511826 12217 solver.cpp:238]     Train net output #0: loss = 1.91781 (* 1 = 1.91781 loss)
I0426 10:55:22.511833 12217 sgd_solver.cpp:105] Iteration 9000, lr = 0.001
I0426 10:55:22.876427 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:55:29.663192 12217 solver.cpp:219] Iteration 9100 (13.9831 iter/s, 7.15151s/100 iters), loss = 2.04957
I0426 10:55:29.663223 12217 solver.cpp:238]     Train net output #0: loss = 2.04957 (* 1 = 2.04957 loss)
I0426 10:55:29.663228 12217 sgd_solver.cpp:105] Iteration 9100, lr = 0.001
I0426 10:55:36.936481 12217 solver.cpp:219] Iteration 9200 (13.7487 iter/s, 7.2734s/100 iters), loss = 1.72172
I0426 10:55:36.936509 12217 solver.cpp:238]     Train net output #0: loss = 1.72172 (* 1 = 1.72172 loss)
I0426 10:55:36.936514 12217 sgd_solver.cpp:105] Iteration 9200, lr = 0.001
I0426 10:55:44.136682 12217 solver.cpp:219] Iteration 9300 (13.8883 iter/s, 7.20031s/100 iters), loss = 1.85492
I0426 10:55:44.136713 12217 solver.cpp:238]     Train net output #0: loss = 1.85492 (* 1 = 1.85492 loss)
I0426 10:55:44.136718 12217 sgd_solver.cpp:105] Iteration 9300, lr = 0.001
I0426 10:55:51.286890 12217 solver.cpp:219] Iteration 9400 (13.9854 iter/s, 7.15031s/100 iters), loss = 1.92289
I0426 10:55:51.286990 12217 solver.cpp:238]     Train net output #0: loss = 1.92289 (* 1 = 1.92289 loss)
I0426 10:55:51.286995 12217 sgd_solver.cpp:105] Iteration 9400, lr = 0.001
I0426 10:55:55.204390 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:55:58.403123 12217 solver.cpp:219] Iteration 9500 (14.0523 iter/s, 7.11627s/100 iters), loss = 1.82892
I0426 10:55:58.403158 12217 solver.cpp:238]     Train net output #0: loss = 1.82892 (* 1 = 1.82892 loss)
I0426 10:55:58.403164 12217 sgd_solver.cpp:105] Iteration 9500, lr = 0.001
I0426 10:56:05.520705 12217 solver.cpp:219] Iteration 9600 (14.0495 iter/s, 7.11769s/100 iters), loss = 1.85761
I0426 10:56:05.520740 12217 solver.cpp:238]     Train net output #0: loss = 1.85761 (* 1 = 1.85761 loss)
I0426 10:56:05.520746 12217 sgd_solver.cpp:105] Iteration 9600, lr = 0.001
I0426 10:56:12.629158 12217 solver.cpp:219] Iteration 9700 (14.0676 iter/s, 7.10856s/100 iters), loss = 1.86827
I0426 10:56:12.629190 12217 solver.cpp:238]     Train net output #0: loss = 1.86827 (* 1 = 1.86827 loss)
I0426 10:56:12.629196 12217 sgd_solver.cpp:105] Iteration 9700, lr = 0.001
I0426 10:56:19.739174 12217 solver.cpp:219] Iteration 9800 (14.0645 iter/s, 7.11012s/100 iters), loss = 1.86887
I0426 10:56:19.739208 12217 solver.cpp:238]     Train net output #0: loss = 1.86887 (* 1 = 1.86887 loss)
I0426 10:56:19.739217 12217 sgd_solver.cpp:105] Iteration 9800, lr = 0.001
I0426 10:56:26.852082 12217 solver.cpp:219] Iteration 9900 (14.0587 iter/s, 7.11301s/100 iters), loss = 1.85564
I0426 10:56:26.852242 12217 solver.cpp:238]     Train net output #0: loss = 1.85564 (* 1 = 1.85564 loss)
I0426 10:56:26.852250 12217 sgd_solver.cpp:105] Iteration 9900, lr = 0.001
I0426 10:56:27.209908 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:56:33.857471 12217 solver.cpp:448] Snapshotting to binary proto file examples/cifar10_full_sigmoid_iter_10000.caffemodel
I0426 10:56:33.892853 12217 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_sigmoid_iter_10000.solverstate
I0426 10:56:33.893214 12217 solver.cpp:331] Iteration 10000, Testing net (#0)
I0426 10:56:35.374743 12226 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:56:36.340996 12217 solver.cpp:398]     Test net output #0: accuracy = 0.3136
I0426 10:56:36.341025 12217 solver.cpp:398]     Test net output #1: loss = 1.85715 (* 1 = 1.85715 loss)
I0426 10:56:36.411825 12217 solver.cpp:219] Iteration 10000 (10.4605 iter/s, 9.55978s/100 iters), loss = 1.82438
I0426 10:56:36.411854 12217 solver.cpp:238]     Train net output #0: loss = 1.82438 (* 1 = 1.82438 loss)
I0426 10:56:36.411860 12217 sgd_solver.cpp:105] Iteration 10000, lr = 0.001
I0426 10:56:43.519443 12217 solver.cpp:219] Iteration 10100 (14.0692 iter/s, 7.10773s/100 iters), loss = 1.85001
I0426 10:56:43.519477 12217 solver.cpp:238]     Train net output #0: loss = 1.85001 (* 1 = 1.85001 loss)
I0426 10:56:43.519484 12217 sgd_solver.cpp:105] Iteration 10100, lr = 0.001
I0426 10:56:50.631114 12217 solver.cpp:219] Iteration 10200 (14.0612 iter/s, 7.11177s/100 iters), loss = 1.95602
I0426 10:56:50.631175 12217 solver.cpp:238]     Train net output #0: loss = 1.95602 (* 1 = 1.95602 loss)
I0426 10:56:50.631181 12217 sgd_solver.cpp:105] Iteration 10200, lr = 0.001
I0426 10:56:57.739433 12217 solver.cpp:219] Iteration 10300 (14.0678 iter/s, 7.10841s/100 iters), loss = 1.79733
I0426 10:56:57.739567 12217 solver.cpp:238]     Train net output #0: loss = 1.79733 (* 1 = 1.79733 loss)
I0426 10:56:57.739575 12217 sgd_solver.cpp:105] Iteration 10300, lr = 0.001
I0426 10:57:01.724161 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:57:04.852831 12217 solver.cpp:219] Iteration 10400 (14.058 iter/s, 7.11341s/100 iters), loss = 2.00584
I0426 10:57:04.852864 12217 solver.cpp:238]     Train net output #0: loss = 2.00584 (* 1 = 2.00584 loss)
I0426 10:57:04.852870 12217 sgd_solver.cpp:105] Iteration 10400, lr = 0.001
I0426 10:57:11.967346 12217 solver.cpp:219] Iteration 10500 (14.0556 iter/s, 7.11462s/100 iters), loss = 2.00151
I0426 10:57:11.967414 12217 solver.cpp:238]     Train net output #0: loss = 2.00151 (* 1 = 2.00151 loss)
I0426 10:57:11.967420 12217 sgd_solver.cpp:105] Iteration 10500, lr = 0.001
I0426 10:57:19.083608 12217 solver.cpp:219] Iteration 10600 (14.0522 iter/s, 7.11633s/100 iters), loss = 1.77865
I0426 10:57:19.083643 12217 solver.cpp:238]     Train net output #0: loss = 1.77865 (* 1 = 1.77865 loss)
I0426 10:57:19.083649 12217 sgd_solver.cpp:105] Iteration 10600, lr = 0.001
I0426 10:57:26.190672 12217 solver.cpp:219] Iteration 10700 (14.0703 iter/s, 7.10716s/100 iters), loss = 1.97849
I0426 10:57:26.190707 12217 solver.cpp:238]     Train net output #0: loss = 1.97849 (* 1 = 1.97849 loss)
I0426 10:57:26.190713 12217 sgd_solver.cpp:105] Iteration 10700, lr = 0.001
I0426 10:57:33.311663 12217 solver.cpp:219] Iteration 10800 (14.0428 iter/s, 7.12109s/100 iters), loss = 1.84853
I0426 10:57:33.311811 12217 solver.cpp:238]     Train net output #0: loss = 1.84853 (* 1 = 1.84853 loss)
I0426 10:57:33.311817 12217 sgd_solver.cpp:105] Iteration 10800, lr = 0.001
I0426 10:57:33.740047 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:57:40.434188 12217 solver.cpp:219] Iteration 10900 (14.04 iter/s, 7.12251s/100 iters), loss = 1.83295
I0426 10:57:40.434223 12217 solver.cpp:238]     Train net output #0: loss = 1.83295 (* 1 = 1.83295 loss)
I0426 10:57:40.434228 12217 sgd_solver.cpp:105] Iteration 10900, lr = 0.001
I0426 10:57:47.449719 12217 solver.cpp:331] Iteration 11000, Testing net (#0)
I0426 10:57:48.957382 12226 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:57:49.926261 12217 solver.cpp:398]     Test net output #0: accuracy = 0.332
I0426 10:57:49.926283 12217 solver.cpp:398]     Test net output #1: loss = 1.83184 (* 1 = 1.83184 loss)
I0426 10:57:49.997637 12217 solver.cpp:219] Iteration 11000 (10.4563 iter/s, 9.5636s/100 iters), loss = 1.88745
I0426 10:57:49.997658 12217 solver.cpp:238]     Train net output #0: loss = 1.88745 (* 1 = 1.88745 loss)
I0426 10:57:49.997664 12217 sgd_solver.cpp:105] Iteration 11000, lr = 0.001
I0426 10:57:57.136338 12217 solver.cpp:219] Iteration 11100 (14.0079 iter/s, 7.13882s/100 iters), loss = 1.79958
I0426 10:57:57.136368 12217 solver.cpp:238]     Train net output #0: loss = 1.79958 (* 1 = 1.79958 loss)
I0426 10:57:57.136371 12217 sgd_solver.cpp:105] Iteration 11100, lr = 0.001
I0426 10:58:04.258075 12217 solver.cpp:219] Iteration 11200 (14.0413 iter/s, 7.12184s/100 iters), loss = 1.85532
I0426 10:58:04.258182 12217 solver.cpp:238]     Train net output #0: loss = 1.85532 (* 1 = 1.85532 loss)
I0426 10:58:04.258188 12217 sgd_solver.cpp:105] Iteration 11200, lr = 0.001
I0426 10:58:08.312583 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:58:11.369365 12217 solver.cpp:219] Iteration 11300 (14.0621 iter/s, 7.11132s/100 iters), loss = 1.81193
I0426 10:58:11.369401 12217 solver.cpp:238]     Train net output #0: loss = 1.81193 (* 1 = 1.81193 loss)
I0426 10:58:11.369407 12217 sgd_solver.cpp:105] Iteration 11300, lr = 0.001
I0426 10:58:18.483881 12217 solver.cpp:219] Iteration 11400 (14.0556 iter/s, 7.11462s/100 iters), loss = 1.8727
I0426 10:58:18.483916 12217 solver.cpp:238]     Train net output #0: loss = 1.8727 (* 1 = 1.8727 loss)
I0426 10:58:18.483921 12217 sgd_solver.cpp:105] Iteration 11400, lr = 0.001
I0426 10:58:25.596206 12217 solver.cpp:219] Iteration 11500 (14.0599 iter/s, 7.11243s/100 iters), loss = 1.84454
I0426 10:58:25.596241 12217 solver.cpp:238]     Train net output #0: loss = 1.84454 (* 1 = 1.84454 loss)
I0426 10:58:25.596247 12217 sgd_solver.cpp:105] Iteration 11500, lr = 0.001
I0426 10:58:32.716159 12217 solver.cpp:219] Iteration 11600 (14.0448 iter/s, 7.12006s/100 iters), loss = 1.87589
I0426 10:58:32.716187 12217 solver.cpp:238]     Train net output #0: loss = 1.87589 (* 1 = 1.87589 loss)
I0426 10:58:32.716192 12217 sgd_solver.cpp:105] Iteration 11600, lr = 0.001
I0426 10:58:39.841706 12217 solver.cpp:219] Iteration 11700 (14.0338 iter/s, 7.12566s/100 iters), loss = 1.89019
I0426 10:58:39.841836 12217 solver.cpp:238]     Train net output #0: loss = 1.89019 (* 1 = 1.89019 loss)
I0426 10:58:39.841843 12217 sgd_solver.cpp:105] Iteration 11700, lr = 0.001
I0426 10:58:40.342159 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:58:46.982183 12217 solver.cpp:219] Iteration 11800 (14.0046 iter/s, 7.14049s/100 iters), loss = 1.75493
I0426 10:58:46.982213 12217 solver.cpp:238]     Train net output #0: loss = 1.75493 (* 1 = 1.75493 loss)
I0426 10:58:46.982218 12217 sgd_solver.cpp:105] Iteration 11800, lr = 0.001
I0426 10:58:54.105695 12217 solver.cpp:219] Iteration 11900 (14.0378 iter/s, 7.12362s/100 iters), loss = 1.68177
I0426 10:58:54.105723 12217 solver.cpp:238]     Train net output #0: loss = 1.68177 (* 1 = 1.68177 loss)
I0426 10:58:54.105728 12217 sgd_solver.cpp:105] Iteration 11900, lr = 0.001
I0426 10:59:01.123445 12217 solver.cpp:331] Iteration 12000, Testing net (#0)
I0426 10:59:02.656841 12226 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:59:03.608757 12217 solver.cpp:398]     Test net output #0: accuracy = 0.3218
I0426 10:59:03.608780 12217 solver.cpp:398]     Test net output #1: loss = 1.83615 (* 1 = 1.83615 loss)
I0426 10:59:03.679991 12217 solver.cpp:219] Iteration 12000 (10.4445 iter/s, 9.57446s/100 iters), loss = 2.01026
I0426 10:59:03.680016 12217 solver.cpp:238]     Train net output #0: loss = 2.01026 (* 1 = 2.01026 loss)
I0426 10:59:03.680021 12217 sgd_solver.cpp:105] Iteration 12000, lr = 0.001
I0426 10:59:10.789633 12217 solver.cpp:219] Iteration 12100 (14.0652 iter/s, 7.10976s/100 iters), loss = 1.79736
I0426 10:59:10.789803 12217 solver.cpp:238]     Train net output #0: loss = 1.79736 (* 1 = 1.79736 loss)
I0426 10:59:10.789813 12217 sgd_solver.cpp:105] Iteration 12100, lr = 0.001
I0426 10:59:14.915385 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:59:17.902820 12217 solver.cpp:219] Iteration 12200 (14.0585 iter/s, 7.11314s/100 iters), loss = 1.78309
I0426 10:59:17.902855 12217 solver.cpp:238]     Train net output #0: loss = 1.78309 (* 1 = 1.78309 loss)
I0426 10:59:17.902861 12217 sgd_solver.cpp:105] Iteration 12200, lr = 0.001
I0426 10:59:25.017438 12217 solver.cpp:219] Iteration 12300 (14.0554 iter/s, 7.11472s/100 iters), loss = 1.87538
I0426 10:59:25.017472 12217 solver.cpp:238]     Train net output #0: loss = 1.87538 (* 1 = 1.87538 loss)
I0426 10:59:25.017478 12217 sgd_solver.cpp:105] Iteration 12300, lr = 0.001
I0426 10:59:32.129606 12217 solver.cpp:219] Iteration 12400 (14.0602 iter/s, 7.11227s/100 iters), loss = 1.87719
I0426 10:59:32.129642 12217 solver.cpp:238]     Train net output #0: loss = 1.87719 (* 1 = 1.87719 loss)
I0426 10:59:32.129647 12217 sgd_solver.cpp:105] Iteration 12400, lr = 0.001
I0426 10:59:39.241969 12217 solver.cpp:219] Iteration 12500 (14.0598 iter/s, 7.11247s/100 iters), loss = 1.83967
I0426 10:59:39.242003 12217 solver.cpp:238]     Train net output #0: loss = 1.83967 (* 1 = 1.83967 loss)
I0426 10:59:39.242009 12217 sgd_solver.cpp:105] Iteration 12500, lr = 0.001
I0426 10:59:46.361191 12217 solver.cpp:219] Iteration 12600 (14.0463 iter/s, 7.11932s/100 iters), loss = 1.85698
I0426 10:59:46.361349 12217 solver.cpp:238]     Train net output #0: loss = 1.85698 (* 1 = 1.85698 loss)
I0426 10:59:46.361356 12217 sgd_solver.cpp:105] Iteration 12600, lr = 0.001
I0426 10:59:46.931916 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:59:53.487573 12217 solver.cpp:219] Iteration 12700 (14.0324 iter/s, 7.12637s/100 iters), loss = 1.80487
I0426 10:59:53.487602 12217 solver.cpp:238]     Train net output #0: loss = 1.80487 (* 1 = 1.80487 loss)
I0426 10:59:53.487607 12217 sgd_solver.cpp:105] Iteration 12700, lr = 0.001
I0426 11:00:00.614277 12217 solver.cpp:219] Iteration 12800 (14.0315 iter/s, 7.12681s/100 iters), loss = 1.78096
I0426 11:00:00.614310 12217 solver.cpp:238]     Train net output #0: loss = 1.78096 (* 1 = 1.78096 loss)
I0426 11:00:00.614315 12217 sgd_solver.cpp:105] Iteration 12800, lr = 0.001
I0426 11:00:07.741821 12217 solver.cpp:219] Iteration 12900 (14.0299 iter/s, 7.12765s/100 iters), loss = 1.79568
I0426 11:00:07.741853 12217 solver.cpp:238]     Train net output #0: loss = 1.79568 (* 1 = 1.79568 loss)
I0426 11:00:07.741858 12217 sgd_solver.cpp:105] Iteration 12900, lr = 0.001
I0426 11:00:14.761665 12217 solver.cpp:331] Iteration 13000, Testing net (#0)
I0426 11:00:16.284963 12226 data_layer.cpp:73] Restarting data prefetching from start.
I0426 11:00:17.246426 12217 solver.cpp:398]     Test net output #0: accuracy = 0.3305
I0426 11:00:17.246593 12217 solver.cpp:398]     Test net output #1: loss = 1.82144 (* 1 = 1.82144 loss)
I0426 11:00:17.317883 12217 solver.cpp:219] Iteration 13000 (10.4425 iter/s, 9.57622s/100 iters), loss = 1.80662
I0426 11:00:17.317905 12217 solver.cpp:238]     Train net output #0: loss = 1.80662 (* 1 = 1.80662 loss)
I0426 11:00:17.317911 12217 sgd_solver.cpp:105] Iteration 13000, lr = 0.001
I0426 11:00:21.513557 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 11:00:24.429548 12217 solver.cpp:219] Iteration 13100 (14.0612 iter/s, 7.11178s/100 iters), loss = 1.8286
I0426 11:00:24.429581 12217 solver.cpp:238]     Train net output #0: loss = 1.8286 (* 1 = 1.8286 loss)
I0426 11:00:24.429587 12217 sgd_solver.cpp:105] Iteration 13100, lr = 0.001
I0426 11:00:31.544198 12217 solver.cpp:219] Iteration 13200 (14.0553 iter/s, 7.11475s/100 iters), loss = 1.77644
I0426 11:00:31.544234 12217 solver.cpp:238]     Train net output #0: loss = 1.77644 (* 1 = 1.77644 loss)
I0426 11:00:31.544240 12217 sgd_solver.cpp:105] Iteration 13200, lr = 0.001
I0426 11:00:38.660046 12217 solver.cpp:219] Iteration 13300 (14.0529 iter/s, 7.11595s/100 iters), loss = 1.74593
I0426 11:00:38.660080 12217 solver.cpp:238]     Train net output #0: loss = 1.74593 (* 1 = 1.74593 loss)
I0426 11:00:38.660085 12217 sgd_solver.cpp:105] Iteration 13300, lr = 0.001
I0426 11:00:45.779973 12217 solver.cpp:219] Iteration 13400 (14.0449 iter/s, 7.12003s/100 iters), loss = 1.76477
I0426 11:00:45.780010 12217 solver.cpp:238]     Train net output #0: loss = 1.76477 (* 1 = 1.76477 loss)
I0426 11:00:45.780016 12217 sgd_solver.cpp:105] Iteration 13400, lr = 0.001
I0426 11:00:52.892314 12217 solver.cpp:219] Iteration 13500 (14.0599 iter/s, 7.11244s/100 iters), loss = 1.81914
I0426 11:00:52.892488 12217 solver.cpp:238]     Train net output #0: loss = 1.81914 (* 1 = 1.81914 loss)
I0426 11:00:52.892498 12217 sgd_solver.cpp:105] Iteration 13500, lr = 0.001
I0426 11:00:53.533641 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 11:01:00.008090 12217 solver.cpp:219] Iteration 13600 (14.0533 iter/s, 7.11575s/100 iters), loss = 1.76907
I0426 11:01:00.008126 12217 solver.cpp:238]     Train net output #0: loss = 1.76907 (* 1 = 1.76907 loss)
I0426 11:01:00.008132 12217 sgd_solver.cpp:105] Iteration 13600, lr = 0.001
I0426 11:01:07.123299 12217 solver.cpp:219] Iteration 13700 (14.0542 iter/s, 7.11531s/100 iters), loss = 1.81523
I0426 11:01:07.123334 12217 solver.cpp:238]     Train net output #0: loss = 1.81523 (* 1 = 1.81523 loss)
I0426 11:01:07.123342 12217 sgd_solver.cpp:105] Iteration 13700, lr = 0.001
I0426 11:01:14.233583 12217 solver.cpp:219] Iteration 13800 (14.0639 iter/s, 7.11039s/100 iters), loss = 1.91033
I0426 11:01:14.233618 12217 solver.cpp:238]     Train net output #0: loss = 1.91033 (* 1 = 1.91033 loss)
I0426 11:01:14.233623 12217 sgd_solver.cpp:105] Iteration 13800, lr = 0.001
I0426 11:01:21.346483 12217 solver.cpp:219] Iteration 13900 (14.0588 iter/s, 7.113s/100 iters), loss = 1.84156
I0426 11:01:21.346520 12217 solver.cpp:238]     Train net output #0: loss = 1.84156 (* 1 = 1.84156 loss)
I0426 11:01:21.346526 12217 sgd_solver.cpp:105] Iteration 13900, lr = 0.001
I0426 11:01:25.543505 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 11:01:28.354382 12217 solver.cpp:331] Iteration 14000, Testing net (#0)
I0426 11:01:29.869246 12226 data_layer.cpp:73] Restarting data prefetching from start.
I0426 11:01:30.834903 12217 solver.cpp:398]     Test net output #0: accuracy = 0.3578
I0426 11:01:30.834933 12217 solver.cpp:398]     Test net output #1: loss = 1.76009 (* 1 = 1.76009 loss)
I0426 11:01:30.906175 12217 solver.cpp:219] Iteration 14000 (10.4604 iter/s, 9.55985s/100 iters), loss = 1.77065
I0426 11:01:30.906199 12217 solver.cpp:238]     Train net output #0: loss = 1.77065 (* 1 = 1.77065 loss)
I0426 11:01:30.906206 12217 sgd_solver.cpp:105] Iteration 14000, lr = 0.001
I0426 11:01:38.019234 12217 solver.cpp:219] Iteration 14100 (14.0584 iter/s, 7.11317s/100 iters), loss = 1.97344
I0426 11:01:38.019270 12217 solver.cpp:238]     Train net output #0: loss = 1.97344 (* 1 = 1.97344 loss)
I0426 11:01:38.019275 12217 sgd_solver.cpp:105] Iteration 14100, lr = 0.001
I0426 11:01:45.131718 12217 solver.cpp:219] Iteration 14200 (14.0596 iter/s, 7.11258s/100 iters), loss = 1.81725
I0426 11:01:45.131750 12217 solver.cpp:238]     Train net output #0: loss = 1.81725 (* 1 = 1.81725 loss)
I0426 11:01:45.131757 12217 sgd_solver.cpp:105] Iteration 14200, lr = 0.001
I0426 11:01:52.254531 12217 solver.cpp:219] Iteration 14300 (14.0392 iter/s, 7.12292s/100 iters), loss = 1.88929
I0426 11:01:52.254566 12217 solver.cpp:238]     Train net output #0: loss = 1.88929 (* 1 = 1.88929 loss)
I0426 11:01:52.254571 12217 sgd_solver.cpp:105] Iteration 14300, lr = 0.001
I0426 11:01:59.369299 12217 solver.cpp:219] Iteration 14400 (14.0551 iter/s, 7.11487s/100 iters), loss = 1.72148
I0426 11:01:59.369434 12217 solver.cpp:238]     Train net output #0: loss = 1.72148 (* 1 = 1.72148 loss)
I0426 11:01:59.369442 12217 sgd_solver.cpp:105] Iteration 14400, lr = 0.001
I0426 11:02:00.080313 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 11:02:06.487010 12217 solver.cpp:219] Iteration 14500 (14.0495 iter/s, 7.11771s/100 iters), loss = 1.82728
I0426 11:02:06.487043 12217 solver.cpp:238]     Train net output #0: loss = 1.82728 (* 1 = 1.82728 loss)
I0426 11:02:06.487048 12217 sgd_solver.cpp:105] Iteration 14500, lr = 0.001
I0426 11:02:13.608799 12217 solver.cpp:219] Iteration 14600 (14.0412 iter/s, 7.12189s/100 iters), loss = 1.80496
I0426 11:02:13.608846 12217 solver.cpp:238]     Train net output #0: loss = 1.80496 (* 1 = 1.80496 loss)
I0426 11:02:13.608850 12217 sgd_solver.cpp:105] Iteration 14600, lr = 0.001
I0426 11:02:20.745168 12217 solver.cpp:219] Iteration 14700 (14.0125 iter/s, 7.13646s/100 iters), loss = 1.75567
I0426 11:02:20.745198 12217 solver.cpp:238]     Train net output #0: loss = 1.75567 (* 1 = 1.75567 loss)
I0426 11:02:20.745203 12217 sgd_solver.cpp:105] Iteration 14700, lr = 0.001
I0426 11:02:27.878289 12217 solver.cpp:219] Iteration 14800 (14.0189 iter/s, 7.13323s/100 iters), loss = 1.70513
I0426 11:02:27.878319 12217 solver.cpp:238]     Train net output #0: loss = 1.70513 (* 1 = 1.70513 loss)
I0426 11:02:27.878324 12217 sgd_solver.cpp:105] Iteration 14800, lr = 0.001
I0426 11:02:32.154592 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 11:02:34.998342 12217 solver.cpp:219] Iteration 14900 (14.0446 iter/s, 7.12016s/100 iters), loss = 1.93313
I0426 11:02:34.998370 12217 solver.cpp:238]     Train net output #0: loss = 1.93313 (* 1 = 1.93313 loss)
I0426 11:02:34.998375 12217 sgd_solver.cpp:105] Iteration 14900, lr = 0.001
I0426 11:02:42.008785 12217 solver.cpp:331] Iteration 15000, Testing net (#0)
I0426 11:02:43.523226 12226 data_layer.cpp:73] Restarting data prefetching from start.
I0426 11:02:44.492280 12217 solver.cpp:398]     Test net output #0: accuracy = 0.3635
I0426 11:02:44.492302 12217 solver.cpp:398]     Test net output #1: loss = 1.74561 (* 1 = 1.74561 loss)
I0426 11:02:44.563264 12217 solver.cpp:219] Iteration 15000 (10.4547 iter/s, 9.56509s/100 iters), loss = 1.91371
I0426 11:02:44.563287 12217 solver.cpp:238]     Train net output #0: loss = 1.91371 (* 1 = 1.91371 loss)
I0426 11:02:44.563292 12217 sgd_solver.cpp:105] Iteration 15000, lr = 0.001
I0426 11:02:51.670344 12217 solver.cpp:219] Iteration 15100 (14.0702 iter/s, 7.1072s/100 iters), loss = 1.68023
I0426 11:02:51.670375 12217 solver.cpp:238]     Train net output #0: loss = 1.68023 (* 1 = 1.68023 loss)
I0426 11:02:51.670380 12217 sgd_solver.cpp:105] Iteration 15100, lr = 0.001
I0426 11:02:58.784312 12217 solver.cpp:219] Iteration 15200 (14.0566 iter/s, 7.11407s/100 iters), loss = 1.69315
I0426 11:02:58.784343 12217 solver.cpp:238]     Train net output #0: loss = 1.69315 (* 1 = 1.69315 loss)
I0426 11:02:58.784370 12217 sgd_solver.cpp:105] Iteration 15200, lr = 0.001
I0426 11:03:06.020408 12217 solver.cpp:219] Iteration 15300 (13.8194 iter/s, 7.23621s/100 iters), loss = 1.73968
I0426 11:03:06.020560 12217 solver.cpp:238]     Train net output #0: loss = 1.73968 (* 1 = 1.73968 loss)
I0426 11:03:06.020566 12217 sgd_solver.cpp:105] Iteration 15300, lr = 0.001
I0426 11:03:06.813211 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 11:03:13.167752 12217 solver.cpp:219] Iteration 15400 (13.9912 iter/s, 7.14734s/100 iters), loss = 1.83661
I0426 11:03:13.167785 12217 solver.cpp:238]     Train net output #0: loss = 1.83661 (* 1 = 1.83661 loss)
I0426 11:03:13.167791 12217 sgd_solver.cpp:105] Iteration 15400, lr = 0.001
I0426 11:03:20.303995 12217 solver.cpp:219] Iteration 15500 (14.0128 iter/s, 7.13635s/100 iters), loss = 1.8455
I0426 11:03:20.304030 12217 solver.cpp:238]     Train net output #0: loss = 1.8455 (* 1 = 1.8455 loss)
I0426 11:03:20.304036 12217 sgd_solver.cpp:105] Iteration 15500, lr = 0.001
I0426 11:03:27.446282 12217 solver.cpp:219] Iteration 15600 (14.0009 iter/s, 7.14239s/100 iters), loss = 1.76365
I0426 11:03:27.446318 12217 solver.cpp:238]     Train net output #0: loss = 1.76365 (* 1 = 1.76365 loss)
I0426 11:03:27.446324 12217 sgd_solver.cpp:105] Iteration 15600, lr = 0.001
I0426 11:03:34.577879 12217 solver.cpp:219] Iteration 15700 (14.0219 iter/s, 7.1317s/100 iters), loss = 1.82508
I0426 11:03:34.577914 12217 solver.cpp:238]     Train net output #0: loss = 1.82508 (* 1 = 1.82508 loss)
I0426 11:03:34.577921 12217 sgd_solver.cpp:105] Iteration 15700, lr = 0.001
I0426 11:03:38.938652 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 11:03:41.727591 12217 solver.cpp:219] Iteration 15800 (13.9864 iter/s, 7.14982s/100 iters), loss = 1.66904
I0426 11:03:41.727625 12217 solver.cpp:238]     Train net output #0: loss = 1.66904 (* 1 = 1.66904 loss)
I0426 11:03:41.727632 12217 sgd_solver.cpp:105] Iteration 15800, lr = 0.001
I0426 11:03:48.862560 12217 solver.cpp:219] Iteration 15900 (14.0153 iter/s, 7.13508s/100 iters), loss = 1.82252
I0426 11:03:48.862593 12217 solver.cpp:238]     Train net output #0: loss = 1.82252 (* 1 = 1.82252 loss)
I0426 11:03:48.862599 12217 sgd_solver.cpp:105] Iteration 15900, lr = 0.001
I0426 11:03:55.903926 12217 solver.cpp:331] Iteration 16000, Testing net (#0)
I0426 11:03:57.420269 12226 data_layer.cpp:73] Restarting data prefetching from start.
I0426 11:03:58.392561 12217 solver.cpp:398]     Test net output #0: accuracy = 0.3756
I0426 11:03:58.392591 12217 solver.cpp:398]     Test net output #1: loss = 1.71727 (* 1 = 1.71727 loss)
I0426 11:03:58.472100 12217 solver.cpp:219] Iteration 16000 (10.4062 iter/s, 9.6097s/100 iters), loss = 1.50989
I0426 11:03:58.472136 12217 solver.cpp:238]     Train net output #0: loss = 1.50989 (* 1 = 1.50989 loss)
I0426 11:03:58.472142 12217 sgd_solver.cpp:105] Iteration 16000, lr = 0.001
I0426 11:04:05.597497 12217 solver.cpp:219] Iteration 16100 (14.0341 iter/s, 7.1255s/100 iters), loss = 1.72495
I0426 11:04:05.597533 12217 solver.cpp:238]     Train net output #0: loss = 1.72495 (* 1 = 1.72495 loss)
I0426 11:04:05.597539 12217 sgd_solver.cpp:105] Iteration 16100, lr = 0.001
I0426 11:04:12.741958 12217 solver.cpp:219] Iteration 16200 (13.9967 iter/s, 7.14456s/100 iters), loss = 1.60223
I0426 11:04:12.742099 12217 solver.cpp:238]     Train net output #0: loss = 1.60223 (* 1 = 1.60223 loss)
I0426 11:04:12.742108 12217 sgd_solver.cpp:105] Iteration 16200, lr = 0.001
I0426 11:04:13.607116 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 11:04:19.887532 12217 solver.cpp:219] Iteration 16300 (13.9947 iter/s, 7.14558s/100 iters), loss = 1.71304
I0426 11:04:19.887567 12217 solver.cpp:238]     Train net output #0: loss = 1.71304 (* 1 = 1.71304 loss)
I0426 11:04:19.887574 12217 sgd_solver.cpp:105] Iteration 16300, lr = 0.001
I0426 11:04:27.030607 12217 solver.cpp:219] Iteration 16400 (13.9994 iter/s, 7.14318s/100 iters), loss = 1.69001
I0426 11:04:27.030642 12217 solver.cpp:238]     Train net output #0: loss = 1.69001 (* 1 = 1.69001 loss)
I0426 11:04:27.030648 12217 sgd_solver.cpp:105] Iteration 16400, lr = 0.001
I0426 11:04:34.177564 12217 solver.cpp:219] Iteration 16500 (13.9918 iter/s, 7.14706s/100 iters), loss = 1.75391
I0426 11:04:34.177610 12217 solver.cpp:238]     Train net output #0: loss = 1.75391 (* 1 = 1.75391 loss)
I0426 11:04:34.177615 12217 sgd_solver.cpp:105] Iteration 16500, lr = 0.001
I0426 11:04:41.342103 12217 solver.cpp:219] Iteration 16600 (13.9574 iter/s, 7.16465s/100 iters), loss = 1.56244
I0426 11:04:41.342149 12217 solver.cpp:238]     Train net output #0: loss = 1.56244 (* 1 = 1.56244 loss)
I0426 11:04:41.342152 12217 sgd_solver.cpp:105] Iteration 16600, lr = 0.001
I0426 11:04:45.783766 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 11:04:48.508263 12217 solver.cpp:219] Iteration 16700 (13.9543 iter/s, 7.16625s/100 iters), loss = 1.5219
I0426 11:04:48.508291 12217 solver.cpp:238]     Train net output #0: loss = 1.5219 (* 1 = 1.5219 loss)
I0426 11:04:48.508296 12217 sgd_solver.cpp:105] Iteration 16700, lr = 0.001
I0426 11:04:55.662466 12217 solver.cpp:219] Iteration 16800 (13.9776 iter/s, 7.15431s/100 iters), loss = 1.66577
I0426 11:04:55.662497 12217 solver.cpp:238]     Train net output #0: loss = 1.66577 (* 1 = 1.66577 loss)
I0426 11:04:55.662502 12217 sgd_solver.cpp:105] Iteration 16800, lr = 0.001
I0426 11:05:02.787678 12217 solver.cpp:219] Iteration 16900 (14.0345 iter/s, 7.12532s/100 iters), loss = 1.72734
I0426 11:05:02.787708 12217 solver.cpp:238]     Train net output #0: loss = 1.72734 (* 1 = 1.72734 loss)
I0426 11:05:02.787713 12217 sgd_solver.cpp:105] Iteration 16900, lr = 0.001
I0426 11:05:09.818769 12217 solver.cpp:331] Iteration 17000, Testing net (#0)
I0426 11:05:11.341444 12226 data_layer.cpp:73] Restarting data prefetching from start.
I0426 11:05:12.318411 12217 solver.cpp:398]     Test net output #0: accuracy = 0.3861
I0426 11:05:12.318439 12217 solver.cpp:398]     Test net output #1: loss = 1.70524 (* 1 = 1.70524 loss)
I0426 11:05:12.397442 12217 solver.cpp:219] Iteration 17000 (10.4059 iter/s, 9.60992s/100 iters), loss = 1.59638
I0426 11:05:12.397478 12217 solver.cpp:238]     Train net output #0: loss = 1.59638 (* 1 = 1.59638 loss)
I0426 11:05:12.397486 12217 sgd_solver.cpp:105] Iteration 17000, lr = 0.001
I0426 11:05:19.521708 12217 solver.cpp:219] Iteration 17100 (14.0363 iter/s, 7.12437s/100 iters), loss = 1.6516
I0426 11:05:19.521831 12217 solver.cpp:238]     Train net output #0: loss = 1.6516 (* 1 = 1.6516 loss)
I0426 11:05:19.521842 12217 sgd_solver.cpp:105] Iteration 17100, lr = 0.001
I0426 11:05:20.457547 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 11:05:26.671531 12217 solver.cpp:219] Iteration 17200 (13.9863 iter/s, 7.14984s/100 iters), loss = 1.73994
I0426 11:05:26.671569 12217 solver.cpp:238]     Train net output #0: loss = 1.73994 (* 1 = 1.73994 loss)
I0426 11:05:26.671577 12217 sgd_solver.cpp:105] Iteration 17200, lr = 0.001
I0426 11:05:33.805515 12217 solver.cpp:219] Iteration 17300 (14.0172 iter/s, 7.13409s/100 iters), loss = 1.69539
I0426 11:05:33.805552 12217 solver.cpp:238]     Train net output #0: loss = 1.69539 (* 1 = 1.69539 loss)
I0426 11:05:33.805560 12217 sgd_solver.cpp:105] Iteration 17300, lr = 0.001
I0426 11:05:40.945559 12217 solver.cpp:219] Iteration 17400 (14.0053 iter/s, 7.14015s/100 iters), loss = 1.73628
I0426 11:05:40.945592 12217 solver.cpp:238]     Train net output #0: loss = 1.73628 (* 1 = 1.73628 loss)
I0426 11:05:40.945598 12217 sgd_solver.cpp:105] Iteration 17400, lr = 0.001
I0426 11:05:48.080528 12217 solver.cpp:219] Iteration 17500 (14.0153 iter/s, 7.13508s/100 iters), loss = 1.74812
I0426 11:05:48.080564 12217 solver.cpp:238]     Train net output #0: loss = 1.74812 (* 1 = 1.74812 loss)
I0426 11:05:48.080570 12217 sgd_solver.cpp:105] Iteration 17500, lr = 0.001
I0426 11:05:52.590344 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 11:05:55.241377 12217 solver.cpp:219] Iteration 17600 (13.9646 iter/s, 7.16095s/100 iters), loss = 1.736
I0426 11:05:55.241413 12217 solver.cpp:238]     Train net output #0: loss = 1.736 (* 1 = 1.736 loss)
I0426 11:05:55.241420 12217 sgd_solver.cpp:105] Iteration 17600, lr = 0.001
I0426 11:06:02.375974 12217 solver.cpp:219] Iteration 17700 (14.016 iter/s, 7.1347s/100 iters), loss = 1.77633
I0426 11:06:02.376011 12217 solver.cpp:238]     Train net output #0: loss = 1.77633 (* 1 = 1.77633 loss)
I0426 11:06:02.376019 12217 sgd_solver.cpp:105] Iteration 17700, lr = 0.001
I0426 11:06:09.517349 12217 solver.cpp:219] Iteration 17800 (14.0027 iter/s, 7.14148s/100 iters), loss = 1.68519
I0426 11:06:09.517385 12217 solver.cpp:238]     Train net output #0: loss = 1.68519 (* 1 = 1.68519 loss)
I0426 11:06:09.517390 12217 sgd_solver.cpp:105] Iteration 17800, lr = 0.001
I0426 11:06:16.650035 12217 solver.cpp:219] Iteration 17900 (14.0198 iter/s, 7.13279s/100 iters), loss = 1.73869
I0426 11:06:16.650069 12217 solver.cpp:238]     Train net output #0: loss = 1.73869 (* 1 = 1.73869 loss)
I0426 11:06:16.650075 12217 sgd_solver.cpp:105] Iteration 17900, lr = 0.001
I0426 11:06:23.686960 12217 solver.cpp:331] Iteration 18000, Testing net (#0)
I0426 11:06:25.211496 12226 data_layer.cpp:73] Restarting data prefetching from start.
I0426 11:06:26.189962 12217 solver.cpp:398]     Test net output #0: accuracy = 0.395
I0426 11:06:26.189991 12217 solver.cpp:398]     Test net output #1: loss = 1.67098 (* 1 = 1.67098 loss)
I0426 11:06:26.269142 12217 solver.cpp:219] Iteration 18000 (10.3958 iter/s, 9.61926s/100 iters), loss = 1.9006
I0426 11:06:26.269181 12217 solver.cpp:238]     Train net output #0: loss = 1.9006 (* 1 = 1.9006 loss)
I0426 11:06:26.269187 12217 sgd_solver.cpp:105] Iteration 18000, lr = 0.001
I0426 11:06:27.273726 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 11:06:33.402992 12217 solver.cpp:219] Iteration 18100 (14.0175 iter/s, 7.13395s/100 iters), loss = 1.58411
I0426 11:06:33.403026 12217 solver.cpp:238]     Train net output #0: loss = 1.58411 (* 1 = 1.58411 loss)
I0426 11:06:33.403033 12217 sgd_solver.cpp:105] Iteration 18100, lr = 0.001
I0426 11:06:40.545248 12217 solver.cpp:219] Iteration 18200 (14.001 iter/s, 7.14236s/100 iters), loss = 1.70315
I0426 11:06:40.545284 12217 solver.cpp:238]     Train net output #0: loss = 1.70315 (* 1 = 1.70315 loss)
I0426 11:06:40.545290 12217 sgd_solver.cpp:105] Iteration 18200, lr = 0.001
I0426 11:06:47.680294 12217 solver.cpp:219] Iteration 18300 (14.0151 iter/s, 7.13515s/100 iters), loss = 1.66733
I0426 11:06:47.680332 12217 solver.cpp:238]     Train net output #0: loss = 1.66733 (* 1 = 1.66733 loss)
I0426 11:06:47.680341 12217 sgd_solver.cpp:105] Iteration 18300, lr = 0.001
I0426 11:06:54.822103 12217 solver.cpp:219] Iteration 18400 (14.0019 iter/s, 7.14191s/100 iters), loss = 1.55499
I0426 11:06:54.822288 12217 solver.cpp:238]     Train net output #0: loss = 1.55499 (* 1 = 1.55499 loss)
I0426 11:06:54.822300 12217 sgd_solver.cpp:105] Iteration 18400, lr = 0.001
I0426 11:06:59.393992 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 11:07:01.975370 12217 solver.cpp:219] Iteration 18500 (13.9797 iter/s, 7.15323s/100 iters), loss = 1.67376
I0426 11:07:01.975409 12217 solver.cpp:238]     Train net output #0: loss = 1.67376 (* 1 = 1.67376 loss)
I0426 11:07:01.975417 12217 sgd_solver.cpp:105] Iteration 18500, lr = 0.001
I0426 11:07:09.118988 12217 solver.cpp:219] Iteration 18600 (13.9983 iter/s, 7.14372s/100 iters), loss = 1.66175
I0426 11:07:09.119060 12217 solver.cpp:238]     Train net output #0: loss = 1.66175 (* 1 = 1.66175 loss)
I0426 11:07:09.119067 12217 sgd_solver.cpp:105] Iteration 18600, lr = 0.001
I0426 11:07:16.244848 12217 solver.cpp:219] Iteration 18700 (14.0333 iter/s, 7.12593s/100 iters), loss = 1.64878
I0426 11:07:16.244886 12217 solver.cpp:238]     Train net output #0: loss = 1.64878 (* 1 = 1.64878 loss)
I0426 11:07:16.244895 12217 sgd_solver.cpp:105] Iteration 18700, lr = 0.001
I0426 11:07:23.384696 12217 solver.cpp:219] Iteration 18800 (14.0057 iter/s, 7.13995s/100 iters), loss = 1.6884
I0426 11:07:23.384735 12217 solver.cpp:238]     Train net output #0: loss = 1.6884 (* 1 = 1.6884 loss)
I0426 11:07:23.384744 12217 sgd_solver.cpp:105] Iteration 18800, lr = 0.001
I0426 11:07:30.517928 12217 solver.cpp:219] Iteration 18900 (14.0187 iter/s, 7.13333s/100 iters), loss = 1.63279
I0426 11:07:30.518128 12217 solver.cpp:238]     Train net output #0: loss = 1.63279 (* 1 = 1.63279 loss)
I0426 11:07:30.518141 12217 sgd_solver.cpp:105] Iteration 18900, lr = 0.001
I0426 11:07:31.524613 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 11:07:37.563395 12217 solver.cpp:331] Iteration 19000, Testing net (#0)
I0426 11:07:39.085091 12226 data_layer.cpp:73] Restarting data prefetching from start.
I0426 11:07:40.058202 12217 solver.cpp:398]     Test net output #0: accuracy = 0.3966
I0426 11:07:40.058233 12217 solver.cpp:398]     Test net output #1: loss = 1.65744 (* 1 = 1.65744 loss)
I0426 11:07:40.137112 12217 solver.cpp:219] Iteration 19000 (10.3959 iter/s, 9.61918s/100 iters), loss = 1.79217
I0426 11:07:40.137148 12217 solver.cpp:238]     Train net output #0: loss = 1.79217 (* 1 = 1.79217 loss)
I0426 11:07:40.137156 12217 sgd_solver.cpp:105] Iteration 19000, lr = 0.001
I0426 11:07:47.260568 12217 solver.cpp:219] Iteration 19100 (14.0379 iter/s, 7.12356s/100 iters), loss = 1.68944
I0426 11:07:47.260607 12217 solver.cpp:238]     Train net output #0: loss = 1.68944 (* 1 = 1.68944 loss)
I0426 11:07:47.260615 12217 sgd_solver.cpp:105] Iteration 19100, lr = 0.001
I0426 11:07:54.408872 12217 solver.cpp:219] Iteration 19200 (13.9891 iter/s, 7.1484s/100 iters), loss = 1.59854
I0426 11:07:54.408915 12217 solver.cpp:238]     Train net output #0: loss = 1.59854 (* 1 = 1.59854 loss)
I0426 11:07:54.408926 12217 sgd_solver.cpp:105] Iteration 19200, lr = 0.001
I0426 11:08:01.548969 12217 solver.cpp:219] Iteration 19300 (14.0052 iter/s, 7.14019s/100 iters), loss = 1.58825
I0426 11:08:01.549062 12217 solver.cpp:238]     Train net output #0: loss = 1.58825 (* 1 = 1.58825 loss)
I0426 11:08:01.549072 12217 sgd_solver.cpp:105] Iteration 19300, lr = 0.001
I0426 11:08:06.192764 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 11:08:08.694792 12217 solver.cpp:219] Iteration 19400 (13.9941 iter/s, 7.14587s/100 iters), loss = 1.84236
I0426 11:08:08.694830 12217 solver.cpp:238]     Train net output #0: loss = 1.84236 (* 1 = 1.84236 loss)
I0426 11:08:08.694839 12217 sgd_solver.cpp:105] Iteration 19400, lr = 0.001
I0426 11:08:15.834166 12217 solver.cpp:219] Iteration 19500 (14.0066 iter/s, 7.13947s/100 iters), loss = 1.45997
I0426 11:08:15.834203 12217 solver.cpp:238]     Train net output #0: loss = 1.45997 (* 1 = 1.45997 loss)
I0426 11:08:15.834211 12217 sgd_solver.cpp:105] Iteration 19500, lr = 0.001
I0426 11:08:22.976434 12217 solver.cpp:219] Iteration 19600 (14.001 iter/s, 7.14237s/100 iters), loss = 1.68042
I0426 11:08:22.976474 12217 solver.cpp:238]     Train net output #0: loss = 1.68042 (* 1 = 1.68042 loss)
I0426 11:08:22.976482 12217 sgd_solver.cpp:105] Iteration 19600, lr = 0.001
I0426 11:08:30.115075 12217 solver.cpp:219] Iteration 19700 (14.0081 iter/s, 7.13874s/100 iters), loss = 1.61552
I0426 11:08:30.115113 12217 solver.cpp:238]     Train net output #0: loss = 1.61552 (* 1 = 1.61552 loss)
I0426 11:08:30.115121 12217 sgd_solver.cpp:105] Iteration 19700, lr = 0.001
I0426 11:08:37.260325 12217 solver.cpp:219] Iteration 19800 (13.9951 iter/s, 7.14535s/100 iters), loss = 1.93485
I0426 11:08:37.260525 12217 solver.cpp:238]     Train net output #0: loss = 1.93485 (* 1 = 1.93485 loss)
I0426 11:08:37.260538 12217 sgd_solver.cpp:105] Iteration 19800, lr = 0.001
I0426 11:08:38.339427 12225 data_layer.cpp:73] Restarting data prefetching from start.
I0426 11:08:44.407790 12217 solver.cpp:219] Iteration 19900 (13.9911 iter/s, 7.14741s/100 iters), loss = 1.91085
I0426 11:08:44.407829 12217 solver.cpp:238]     Train net output #0: loss = 1.91085 (* 1 = 1.91085 loss)
I0426 11:08:44.407836 12217 sgd_solver.cpp:105] Iteration 19900, lr = 0.001
I0426 11:08:51.446866 12217 solver.cpp:448] Snapshotting to binary proto file examples/cifar10_full_sigmoid_iter_20000.caffemodel
I0426 11:08:51.490836 12217 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_sigmoid_iter_20000.solverstate
I0426 11:08:51.525317 12217 solver.cpp:311] Iteration 20000, loss = 1.65859
I0426 11:08:51.525338 12217 solver.cpp:331] Iteration 20000, Testing net (#0)
I0426 11:08:53.023862 12226 data_layer.cpp:73] Restarting data prefetching from start.
I0426 11:08:54.004281 12217 solver.cpp:398]     Test net output #0: accuracy = 0.4046
I0426 11:08:54.004305 12217 solver.cpp:398]     Test net output #1: loss = 1.6463 (* 1 = 1.6463 loss)
I0426 11:08:54.004310 12217 solver.cpp:316] Optimization Done.
I0426 11:08:54.004313 12217 caffe.cpp:259] Optimization Done.
