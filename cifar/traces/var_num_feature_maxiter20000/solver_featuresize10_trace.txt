I0426 10:32:15.483786 12028 caffe.cpp:218] Using GPUs 0
I0426 10:32:15.595124 12028 caffe.cpp:223] GPU 0: GeForce GTX 950M
I0426 10:32:15.794939 12028 solver.cpp:44] Initializing solver from parameters: 
test_iter: 10
test_interval: 1000
base_lr: 0.001
display: 100
max_iter: 20000
lr_policy: "step"
gamma: 1
momentum: 0.9
stepsize: 5000
snapshot: 10000
snapshot_prefix: "examples/cifar10_full_sigmoid"
solver_mode: GPU
device_id: 0
net: "ECE595/cifar/train_test/var_num_feature_maxiter20000/cifar_train_test_featuresize10.prototxt"
train_state {
  level: 0
  stage: ""
}
I0426 10:32:15.795138 12028 solver.cpp:87] Creating training net from net file: ECE595/cifar/train_test/var_num_feature_maxiter20000/cifar_train_test_featuresize10.prototxt
I0426 10:32:15.795426 12028 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0426 10:32:15.795454 12028 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0426 10:32:15.795605 12028 net.cpp:51] Initializing net from parameters: 
name: "CIFAR"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_train_lmdb"
    batch_size: 111
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 10
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Sigmoid0"
  type: "Sigmoid"
  bottom: "conv0"
  top: "Sigmoid0"
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "Sigmoid0"
  top: "pool0"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 10
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Sigmoid1"
  type: "Sigmoid"
  bottom: "conv1"
  top: "Sigmoid1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "Sigmoid1"
  top: "pool1"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 10
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Sigmoid2"
  type: "Sigmoid"
  bottom: "conv2"
  top: "Sigmoid2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "Sigmoid2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0426 10:32:15.795683 12028 layer_factory.hpp:77] Creating layer cifar
I0426 10:32:15.795831 12028 db_lmdb.cpp:35] Opened lmdb examples/cifar10/cifar10_train_lmdb
I0426 10:32:15.795892 12028 net.cpp:84] Creating Layer cifar
I0426 10:32:15.795900 12028 net.cpp:380] cifar -> data
I0426 10:32:15.795953 12028 net.cpp:380] cifar -> label
I0426 10:32:15.795963 12028 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I0426 10:32:15.796746 12028 data_layer.cpp:45] output data size: 111,3,32,32
I0426 10:32:15.800565 12028 net.cpp:122] Setting up cifar
I0426 10:32:15.800598 12028 net.cpp:129] Top shape: 111 3 32 32 (340992)
I0426 10:32:15.800637 12028 net.cpp:129] Top shape: 111 (111)
I0426 10:32:15.800639 12028 net.cpp:137] Memory required for data: 1364412
I0426 10:32:15.800664 12028 layer_factory.hpp:77] Creating layer conv0
I0426 10:32:15.800724 12028 net.cpp:84] Creating Layer conv0
I0426 10:32:15.800757 12028 net.cpp:406] conv0 <- data
I0426 10:32:15.800768 12028 net.cpp:380] conv0 -> conv0
I0426 10:32:15.801290 12028 net.cpp:122] Setting up conv0
I0426 10:32:15.801319 12028 net.cpp:129] Top shape: 111 10 32 32 (1136640)
I0426 10:32:15.801321 12028 net.cpp:137] Memory required for data: 5910972
I0426 10:32:15.801369 12028 layer_factory.hpp:77] Creating layer Sigmoid0
I0426 10:32:15.801376 12028 net.cpp:84] Creating Layer Sigmoid0
I0426 10:32:15.801395 12028 net.cpp:406] Sigmoid0 <- conv0
I0426 10:32:15.801399 12028 net.cpp:380] Sigmoid0 -> Sigmoid0
I0426 10:32:15.801486 12028 net.cpp:122] Setting up Sigmoid0
I0426 10:32:15.801507 12028 net.cpp:129] Top shape: 111 10 32 32 (1136640)
I0426 10:32:15.801509 12028 net.cpp:137] Memory required for data: 10457532
I0426 10:32:15.801512 12028 layer_factory.hpp:77] Creating layer pool0
I0426 10:32:15.801535 12028 net.cpp:84] Creating Layer pool0
I0426 10:32:15.801537 12028 net.cpp:406] pool0 <- Sigmoid0
I0426 10:32:15.801561 12028 net.cpp:380] pool0 -> pool0
I0426 10:32:15.801666 12028 net.cpp:122] Setting up pool0
I0426 10:32:15.801671 12028 net.cpp:129] Top shape: 111 10 16 16 (284160)
I0426 10:32:15.801672 12028 net.cpp:137] Memory required for data: 11594172
I0426 10:32:15.801693 12028 layer_factory.hpp:77] Creating layer conv1
I0426 10:32:15.801700 12028 net.cpp:84] Creating Layer conv1
I0426 10:32:15.801703 12028 net.cpp:406] conv1 <- pool0
I0426 10:32:15.801728 12028 net.cpp:380] conv1 -> conv1
I0426 10:32:15.802199 12028 net.cpp:122] Setting up conv1
I0426 10:32:15.802227 12028 net.cpp:129] Top shape: 111 10 16 16 (284160)
I0426 10:32:15.802229 12028 net.cpp:137] Memory required for data: 12730812
I0426 10:32:15.802237 12028 layer_factory.hpp:77] Creating layer Sigmoid1
I0426 10:32:15.802242 12028 net.cpp:84] Creating Layer Sigmoid1
I0426 10:32:15.802244 12028 net.cpp:406] Sigmoid1 <- conv1
I0426 10:32:15.802248 12028 net.cpp:380] Sigmoid1 -> Sigmoid1
I0426 10:32:15.802281 12028 net.cpp:122] Setting up Sigmoid1
I0426 10:32:15.802301 12028 net.cpp:129] Top shape: 111 10 16 16 (284160)
I0426 10:32:15.802304 12028 net.cpp:137] Memory required for data: 13867452
I0426 10:32:15.802305 12028 layer_factory.hpp:77] Creating layer pool1
I0426 10:32:15.802323 12028 net.cpp:84] Creating Layer pool1
I0426 10:32:15.802325 12028 net.cpp:406] pool1 <- Sigmoid1
I0426 10:32:15.802330 12028 net.cpp:380] pool1 -> pool1
I0426 10:32:15.802376 12028 net.cpp:122] Setting up pool1
I0426 10:32:15.802395 12028 net.cpp:129] Top shape: 111 10 8 8 (71040)
I0426 10:32:15.802398 12028 net.cpp:137] Memory required for data: 14151612
I0426 10:32:15.802400 12028 layer_factory.hpp:77] Creating layer conv2
I0426 10:32:15.802409 12028 net.cpp:84] Creating Layer conv2
I0426 10:32:15.802413 12028 net.cpp:406] conv2 <- pool1
I0426 10:32:15.802434 12028 net.cpp:380] conv2 -> conv2
I0426 10:32:15.802726 12028 net.cpp:122] Setting up conv2
I0426 10:32:15.802732 12028 net.cpp:129] Top shape: 111 10 8 8 (71040)
I0426 10:32:15.802752 12028 net.cpp:137] Memory required for data: 14435772
I0426 10:32:15.802758 12028 layer_factory.hpp:77] Creating layer Sigmoid2
I0426 10:32:15.802763 12028 net.cpp:84] Creating Layer Sigmoid2
I0426 10:32:15.802783 12028 net.cpp:406] Sigmoid2 <- conv2
I0426 10:32:15.802791 12028 net.cpp:380] Sigmoid2 -> Sigmoid2
I0426 10:32:15.802826 12028 net.cpp:122] Setting up Sigmoid2
I0426 10:32:15.802831 12028 net.cpp:129] Top shape: 111 10 8 8 (71040)
I0426 10:32:15.802852 12028 net.cpp:137] Memory required for data: 14719932
I0426 10:32:15.802855 12028 layer_factory.hpp:77] Creating layer pool2
I0426 10:32:15.802857 12028 net.cpp:84] Creating Layer pool2
I0426 10:32:15.802878 12028 net.cpp:406] pool2 <- Sigmoid2
I0426 10:32:15.802881 12028 net.cpp:380] pool2 -> pool2
I0426 10:32:15.802934 12028 net.cpp:122] Setting up pool2
I0426 10:32:15.802964 12028 net.cpp:129] Top shape: 111 10 4 4 (17760)
I0426 10:32:15.802966 12028 net.cpp:137] Memory required for data: 14790972
I0426 10:32:15.802968 12028 layer_factory.hpp:77] Creating layer ip1
I0426 10:32:15.802994 12028 net.cpp:84] Creating Layer ip1
I0426 10:32:15.802997 12028 net.cpp:406] ip1 <- pool2
I0426 10:32:15.803014 12028 net.cpp:380] ip1 -> ip1
I0426 10:32:15.803146 12028 net.cpp:122] Setting up ip1
I0426 10:32:15.803151 12028 net.cpp:129] Top shape: 111 10 (1110)
I0426 10:32:15.803154 12028 net.cpp:137] Memory required for data: 14795412
I0426 10:32:15.803161 12028 layer_factory.hpp:77] Creating layer loss
I0426 10:32:15.803169 12028 net.cpp:84] Creating Layer loss
I0426 10:32:15.803185 12028 net.cpp:406] loss <- ip1
I0426 10:32:15.803189 12028 net.cpp:406] loss <- label
I0426 10:32:15.803210 12028 net.cpp:380] loss -> loss
I0426 10:32:15.803220 12028 layer_factory.hpp:77] Creating layer loss
I0426 10:32:15.803303 12028 net.cpp:122] Setting up loss
I0426 10:32:15.803306 12028 net.cpp:129] Top shape: (1)
I0426 10:32:15.803308 12028 net.cpp:132]     with loss weight 1
I0426 10:32:15.803406 12028 net.cpp:137] Memory required for data: 14795416
I0426 10:32:15.803409 12028 net.cpp:198] loss needs backward computation.
I0426 10:32:15.803414 12028 net.cpp:198] ip1 needs backward computation.
I0426 10:32:15.803417 12028 net.cpp:198] pool2 needs backward computation.
I0426 10:32:15.803421 12028 net.cpp:198] Sigmoid2 needs backward computation.
I0426 10:32:15.803423 12028 net.cpp:198] conv2 needs backward computation.
I0426 10:32:15.803426 12028 net.cpp:198] pool1 needs backward computation.
I0426 10:32:15.803428 12028 net.cpp:198] Sigmoid1 needs backward computation.
I0426 10:32:15.803431 12028 net.cpp:198] conv1 needs backward computation.
I0426 10:32:15.803447 12028 net.cpp:198] pool0 needs backward computation.
I0426 10:32:15.803449 12028 net.cpp:198] Sigmoid0 needs backward computation.
I0426 10:32:15.803452 12028 net.cpp:198] conv0 needs backward computation.
I0426 10:32:15.803472 12028 net.cpp:200] cifar does not need backward computation.
I0426 10:32:15.803475 12028 net.cpp:242] This network produces output loss
I0426 10:32:15.803485 12028 net.cpp:255] Network initialization done.
I0426 10:32:15.803686 12028 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/cifar/train_test/var_num_feature_maxiter20000/cifar_train_test_featuresize10.prototxt
I0426 10:32:15.803704 12028 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0426 10:32:15.803818 12028 net.cpp:51] Initializing net from parameters: 
name: "CIFAR"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_test_lmdb"
    batch_size: 1000
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 10
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Sigmoid0"
  type: "Sigmoid"
  bottom: "conv0"
  top: "Sigmoid0"
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "Sigmoid0"
  top: "pool0"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 10
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Sigmoid1"
  type: "Sigmoid"
  bottom: "conv1"
  top: "Sigmoid1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "Sigmoid1"
  top: "pool1"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 10
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Sigmoid2"
  type: "Sigmoid"
  bottom: "conv2"
  top: "Sigmoid2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "Sigmoid2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0426 10:32:15.803923 12028 layer_factory.hpp:77] Creating layer cifar
I0426 10:32:15.803970 12028 db_lmdb.cpp:35] Opened lmdb examples/cifar10/cifar10_test_lmdb
I0426 10:32:15.803982 12028 net.cpp:84] Creating Layer cifar
I0426 10:32:15.804002 12028 net.cpp:380] cifar -> data
I0426 10:32:15.804023 12028 net.cpp:380] cifar -> label
I0426 10:32:15.804028 12028 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I0426 10:32:15.804352 12028 data_layer.cpp:45] output data size: 1000,3,32,32
I0426 10:32:15.831221 12028 net.cpp:122] Setting up cifar
I0426 10:32:15.831243 12028 net.cpp:129] Top shape: 1000 3 32 32 (3072000)
I0426 10:32:15.831245 12028 net.cpp:129] Top shape: 1000 (1000)
I0426 10:32:15.831248 12028 net.cpp:137] Memory required for data: 12292000
I0426 10:32:15.831270 12028 layer_factory.hpp:77] Creating layer label_cifar_1_split
I0426 10:32:15.831282 12028 net.cpp:84] Creating Layer label_cifar_1_split
I0426 10:32:15.831285 12028 net.cpp:406] label_cifar_1_split <- label
I0426 10:32:15.831291 12028 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I0426 10:32:15.831336 12028 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I0426 10:32:15.831466 12028 net.cpp:122] Setting up label_cifar_1_split
I0426 10:32:15.831471 12028 net.cpp:129] Top shape: 1000 (1000)
I0426 10:32:15.831492 12028 net.cpp:129] Top shape: 1000 (1000)
I0426 10:32:15.831495 12028 net.cpp:137] Memory required for data: 12300000
I0426 10:32:15.831497 12028 layer_factory.hpp:77] Creating layer conv0
I0426 10:32:15.831508 12028 net.cpp:84] Creating Layer conv0
I0426 10:32:15.831511 12028 net.cpp:406] conv0 <- data
I0426 10:32:15.831535 12028 net.cpp:380] conv0 -> conv0
I0426 10:32:15.831784 12028 net.cpp:122] Setting up conv0
I0426 10:32:15.831789 12028 net.cpp:129] Top shape: 1000 10 32 32 (10240000)
I0426 10:32:15.831809 12028 net.cpp:137] Memory required for data: 53260000
I0426 10:32:15.831817 12028 layer_factory.hpp:77] Creating layer Sigmoid0
I0426 10:32:15.831821 12028 net.cpp:84] Creating Layer Sigmoid0
I0426 10:32:15.831823 12028 net.cpp:406] Sigmoid0 <- conv0
I0426 10:32:15.831827 12028 net.cpp:380] Sigmoid0 -> Sigmoid0
I0426 10:32:15.831879 12028 net.cpp:122] Setting up Sigmoid0
I0426 10:32:15.831883 12028 net.cpp:129] Top shape: 1000 10 32 32 (10240000)
I0426 10:32:15.831885 12028 net.cpp:137] Memory required for data: 94220000
I0426 10:32:15.831887 12028 layer_factory.hpp:77] Creating layer pool0
I0426 10:32:15.831892 12028 net.cpp:84] Creating Layer pool0
I0426 10:32:15.831894 12028 net.cpp:406] pool0 <- Sigmoid0
I0426 10:32:15.831917 12028 net.cpp:380] pool0 -> pool0
I0426 10:32:15.831964 12028 net.cpp:122] Setting up pool0
I0426 10:32:15.831969 12028 net.cpp:129] Top shape: 1000 10 16 16 (2560000)
I0426 10:32:15.831969 12028 net.cpp:137] Memory required for data: 104460000
I0426 10:32:15.831971 12028 layer_factory.hpp:77] Creating layer conv1
I0426 10:32:15.831996 12028 net.cpp:84] Creating Layer conv1
I0426 10:32:15.832025 12028 net.cpp:406] conv1 <- pool0
I0426 10:32:15.832029 12028 net.cpp:380] conv1 -> conv1
I0426 10:32:15.832228 12028 net.cpp:122] Setting up conv1
I0426 10:32:15.832233 12028 net.cpp:129] Top shape: 1000 10 16 16 (2560000)
I0426 10:32:15.832237 12028 net.cpp:137] Memory required for data: 114700000
I0426 10:32:15.832254 12028 layer_factory.hpp:77] Creating layer Sigmoid1
I0426 10:32:15.832278 12028 net.cpp:84] Creating Layer Sigmoid1
I0426 10:32:15.832281 12028 net.cpp:406] Sigmoid1 <- conv1
I0426 10:32:15.832285 12028 net.cpp:380] Sigmoid1 -> Sigmoid1
I0426 10:32:15.832316 12028 net.cpp:122] Setting up Sigmoid1
I0426 10:32:15.832336 12028 net.cpp:129] Top shape: 1000 10 16 16 (2560000)
I0426 10:32:15.832339 12028 net.cpp:137] Memory required for data: 124940000
I0426 10:32:15.832341 12028 layer_factory.hpp:77] Creating layer pool1
I0426 10:32:15.832362 12028 net.cpp:84] Creating Layer pool1
I0426 10:32:15.832365 12028 net.cpp:406] pool1 <- Sigmoid1
I0426 10:32:15.832368 12028 net.cpp:380] pool1 -> pool1
I0426 10:32:15.832398 12028 net.cpp:122] Setting up pool1
I0426 10:32:15.832419 12028 net.cpp:129] Top shape: 1000 10 8 8 (640000)
I0426 10:32:15.832420 12028 net.cpp:137] Memory required for data: 127500000
I0426 10:32:15.832422 12028 layer_factory.hpp:77] Creating layer conv2
I0426 10:32:15.832448 12028 net.cpp:84] Creating Layer conv2
I0426 10:32:15.832469 12028 net.cpp:406] conv2 <- pool1
I0426 10:32:15.832473 12028 net.cpp:380] conv2 -> conv2
I0426 10:32:15.834636 12028 net.cpp:122] Setting up conv2
I0426 10:32:15.834642 12028 net.cpp:129] Top shape: 1000 10 8 8 (640000)
I0426 10:32:15.834645 12028 net.cpp:137] Memory required for data: 130060000
I0426 10:32:15.834651 12028 layer_factory.hpp:77] Creating layer Sigmoid2
I0426 10:32:15.834656 12028 net.cpp:84] Creating Layer Sigmoid2
I0426 10:32:15.834659 12028 net.cpp:406] Sigmoid2 <- conv2
I0426 10:32:15.834681 12028 net.cpp:380] Sigmoid2 -> Sigmoid2
I0426 10:32:15.834695 12028 net.cpp:122] Setting up Sigmoid2
I0426 10:32:15.834700 12028 net.cpp:129] Top shape: 1000 10 8 8 (640000)
I0426 10:32:15.834703 12028 net.cpp:137] Memory required for data: 132620000
I0426 10:32:15.834704 12028 layer_factory.hpp:77] Creating layer pool2
I0426 10:32:15.834708 12028 net.cpp:84] Creating Layer pool2
I0426 10:32:15.834710 12028 net.cpp:406] pool2 <- Sigmoid2
I0426 10:32:15.834729 12028 net.cpp:380] pool2 -> pool2
I0426 10:32:15.834744 12028 net.cpp:122] Setting up pool2
I0426 10:32:15.834749 12028 net.cpp:129] Top shape: 1000 10 4 4 (160000)
I0426 10:32:15.834751 12028 net.cpp:137] Memory required for data: 133260000
I0426 10:32:15.834753 12028 layer_factory.hpp:77] Creating layer ip1
I0426 10:32:15.834758 12028 net.cpp:84] Creating Layer ip1
I0426 10:32:15.834760 12028 net.cpp:406] ip1 <- pool2
I0426 10:32:15.834764 12028 net.cpp:380] ip1 -> ip1
I0426 10:32:15.834868 12028 net.cpp:122] Setting up ip1
I0426 10:32:15.834873 12028 net.cpp:129] Top shape: 1000 10 (10000)
I0426 10:32:15.834875 12028 net.cpp:137] Memory required for data: 133300000
I0426 10:32:15.834878 12028 layer_factory.hpp:77] Creating layer ip1_ip1_0_split
I0426 10:32:15.834884 12028 net.cpp:84] Creating Layer ip1_ip1_0_split
I0426 10:32:15.834887 12028 net.cpp:406] ip1_ip1_0_split <- ip1
I0426 10:32:15.834890 12028 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0426 10:32:15.834895 12028 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0426 10:32:15.834959 12028 net.cpp:122] Setting up ip1_ip1_0_split
I0426 10:32:15.834961 12028 net.cpp:129] Top shape: 1000 10 (10000)
I0426 10:32:15.834964 12028 net.cpp:129] Top shape: 1000 10 (10000)
I0426 10:32:15.834966 12028 net.cpp:137] Memory required for data: 133380000
I0426 10:32:15.834969 12028 layer_factory.hpp:77] Creating layer accuracy
I0426 10:32:15.834974 12028 net.cpp:84] Creating Layer accuracy
I0426 10:32:15.834975 12028 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I0426 10:32:15.834978 12028 net.cpp:406] accuracy <- label_cifar_1_split_0
I0426 10:32:15.834996 12028 net.cpp:380] accuracy -> accuracy
I0426 10:32:15.835013 12028 net.cpp:122] Setting up accuracy
I0426 10:32:15.835018 12028 net.cpp:129] Top shape: (1)
I0426 10:32:15.835021 12028 net.cpp:137] Memory required for data: 133380004
I0426 10:32:15.835023 12028 layer_factory.hpp:77] Creating layer loss
I0426 10:32:15.835027 12028 net.cpp:84] Creating Layer loss
I0426 10:32:15.835029 12028 net.cpp:406] loss <- ip1_ip1_0_split_1
I0426 10:32:15.835032 12028 net.cpp:406] loss <- label_cifar_1_split_1
I0426 10:32:15.835036 12028 net.cpp:380] loss -> loss
I0426 10:32:15.835042 12028 layer_factory.hpp:77] Creating layer loss
I0426 10:32:15.835511 12028 net.cpp:122] Setting up loss
I0426 10:32:15.835520 12028 net.cpp:129] Top shape: (1)
I0426 10:32:15.835525 12028 net.cpp:132]     with loss weight 1
I0426 10:32:15.835547 12028 net.cpp:137] Memory required for data: 133380008
I0426 10:32:15.835551 12028 net.cpp:198] loss needs backward computation.
I0426 10:32:15.835567 12028 net.cpp:200] accuracy does not need backward computation.
I0426 10:32:15.835572 12028 net.cpp:198] ip1_ip1_0_split needs backward computation.
I0426 10:32:15.835573 12028 net.cpp:198] ip1 needs backward computation.
I0426 10:32:15.835575 12028 net.cpp:198] pool2 needs backward computation.
I0426 10:32:15.835577 12028 net.cpp:198] Sigmoid2 needs backward computation.
I0426 10:32:15.835580 12028 net.cpp:198] conv2 needs backward computation.
I0426 10:32:15.835582 12028 net.cpp:198] pool1 needs backward computation.
I0426 10:32:15.835584 12028 net.cpp:198] Sigmoid1 needs backward computation.
I0426 10:32:15.835587 12028 net.cpp:198] conv1 needs backward computation.
I0426 10:32:15.835589 12028 net.cpp:198] pool0 needs backward computation.
I0426 10:32:15.835592 12028 net.cpp:198] Sigmoid0 needs backward computation.
I0426 10:32:15.835593 12028 net.cpp:198] conv0 needs backward computation.
I0426 10:32:15.835595 12028 net.cpp:200] label_cifar_1_split does not need backward computation.
I0426 10:32:15.835602 12028 net.cpp:200] cifar does not need backward computation.
I0426 10:32:15.835604 12028 net.cpp:242] This network produces output accuracy
I0426 10:32:15.835608 12028 net.cpp:242] This network produces output loss
I0426 10:32:15.835631 12028 net.cpp:255] Network initialization done.
I0426 10:32:15.835671 12028 solver.cpp:56] Solver scaffolding done.
I0426 10:32:15.835918 12028 caffe.cpp:248] Starting Optimization
I0426 10:32:15.835922 12028 solver.cpp:273] Solving CIFAR
I0426 10:32:15.835924 12028 solver.cpp:274] Learning Rate Policy: step
I0426 10:32:15.836311 12028 solver.cpp:331] Iteration 0, Testing net (#0)
I0426 10:32:15.836997 12028 blocking_queue.cpp:49] Waiting for data
I0426 10:32:16.501636 12036 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:32:16.909796 12028 solver.cpp:398]     Test net output #0: accuracy = 0.1
I0426 10:32:16.909821 12028 solver.cpp:398]     Test net output #1: loss = 2.30404 (* 1 = 2.30404 loss)
I0426 10:32:16.953935 12028 solver.cpp:219] Iteration 0 (-3.78416e-07 iter/s, 1.11799s/100 iters), loss = 2.30245
I0426 10:32:16.953982 12028 solver.cpp:238]     Train net output #0: loss = 2.30245 (* 1 = 2.30245 loss)
I0426 10:32:16.953995 12028 sgd_solver.cpp:105] Iteration 0, lr = 0.001
I0426 10:32:20.453292 12028 solver.cpp:219] Iteration 100 (28.5766 iter/s, 3.49936s/100 iters), loss = 2.31279
I0426 10:32:20.453320 12028 solver.cpp:238]     Train net output #0: loss = 2.31279 (* 1 = 2.31279 loss)
I0426 10:32:20.453325 12028 sgd_solver.cpp:105] Iteration 100, lr = 0.001
I0426 10:32:23.953025 12028 solver.cpp:219] Iteration 200 (28.5734 iter/s, 3.49976s/100 iters), loss = 2.30396
I0426 10:32:23.953070 12028 solver.cpp:238]     Train net output #0: loss = 2.30396 (* 1 = 2.30396 loss)
I0426 10:32:23.953089 12028 sgd_solver.cpp:105] Iteration 200, lr = 0.001
I0426 10:32:27.612779 12028 solver.cpp:219] Iteration 300 (27.3242 iter/s, 3.65977s/100 iters), loss = 2.304
I0426 10:32:27.612807 12028 solver.cpp:238]     Train net output #0: loss = 2.304 (* 1 = 2.304 loss)
I0426 10:32:27.612812 12028 sgd_solver.cpp:105] Iteration 300, lr = 0.001
I0426 10:32:31.877002 12028 solver.cpp:219] Iteration 400 (23.4508 iter/s, 4.26425s/100 iters), loss = 2.30283
I0426 10:32:31.877073 12028 solver.cpp:238]     Train net output #0: loss = 2.30283 (* 1 = 2.30283 loss)
I0426 10:32:31.877079 12028 sgd_solver.cpp:105] Iteration 400, lr = 0.001
I0426 10:32:33.873816 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:32:36.220578 12028 solver.cpp:219] Iteration 500 (23.0225 iter/s, 4.34358s/100 iters), loss = 2.3036
I0426 10:32:36.220623 12028 solver.cpp:238]     Train net output #0: loss = 2.3036 (* 1 = 2.3036 loss)
I0426 10:32:36.220628 12028 sgd_solver.cpp:105] Iteration 500, lr = 0.001
I0426 10:32:40.106452 12028 solver.cpp:219] Iteration 600 (25.7341 iter/s, 3.8859s/100 iters), loss = 2.30223
I0426 10:32:40.106495 12028 solver.cpp:238]     Train net output #0: loss = 2.30223 (* 1 = 2.30223 loss)
I0426 10:32:40.106500 12028 sgd_solver.cpp:105] Iteration 600, lr = 0.001
I0426 10:32:43.556499 12028 solver.cpp:219] Iteration 700 (28.985 iter/s, 3.45006s/100 iters), loss = 2.3002
I0426 10:32:43.556526 12028 solver.cpp:238]     Train net output #0: loss = 2.3002 (* 1 = 2.3002 loss)
I0426 10:32:43.556530 12028 sgd_solver.cpp:105] Iteration 700, lr = 0.001
I0426 10:32:47.020989 12028 solver.cpp:219] Iteration 800 (28.8641 iter/s, 3.46452s/100 iters), loss = 2.30742
I0426 10:32:47.021209 12028 solver.cpp:238]     Train net output #0: loss = 2.30742 (* 1 = 2.30742 loss)
I0426 10:32:47.021216 12028 sgd_solver.cpp:105] Iteration 800, lr = 0.001
I0426 10:32:50.331143 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:32:50.472256 12028 solver.cpp:219] Iteration 900 (28.9761 iter/s, 3.45112s/100 iters), loss = 2.3068
I0426 10:32:50.472301 12028 solver.cpp:238]     Train net output #0: loss = 2.3068 (* 1 = 2.3068 loss)
I0426 10:32:50.472318 12028 sgd_solver.cpp:105] Iteration 900, lr = 0.001
I0426 10:32:53.868532 12028 solver.cpp:331] Iteration 1000, Testing net (#0)
I0426 10:32:54.502387 12036 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:32:54.900115 12028 solver.cpp:398]     Test net output #0: accuracy = 0.1
I0426 10:32:54.900138 12028 solver.cpp:398]     Test net output #1: loss = 2.30382 (* 1 = 2.30382 loss)
I0426 10:32:54.938679 12028 solver.cpp:219] Iteration 1000 (22.3891 iter/s, 4.46645s/100 iters), loss = 2.30031
I0426 10:32:54.938719 12028 solver.cpp:238]     Train net output #0: loss = 2.30031 (* 1 = 2.30031 loss)
I0426 10:32:54.938742 12028 sgd_solver.cpp:105] Iteration 1000, lr = 0.001
I0426 10:32:58.389235 12028 solver.cpp:219] Iteration 1100 (28.9807 iter/s, 3.45057s/100 iters), loss = 2.30115
I0426 10:32:58.389261 12028 solver.cpp:238]     Train net output #0: loss = 2.30115 (* 1 = 2.30115 loss)
I0426 10:32:58.389266 12028 sgd_solver.cpp:105] Iteration 1100, lr = 0.001
I0426 10:33:01.848027 12028 solver.cpp:219] Iteration 1200 (28.9116 iter/s, 3.45882s/100 iters), loss = 2.30316
I0426 10:33:01.848055 12028 solver.cpp:238]     Train net output #0: loss = 2.30316 (* 1 = 2.30316 loss)
I0426 10:33:01.848059 12028 sgd_solver.cpp:105] Iteration 1200, lr = 0.001
I0426 10:33:05.298034 12028 solver.cpp:219] Iteration 1300 (28.9852 iter/s, 3.45003s/100 iters), loss = 2.30654
I0426 10:33:05.298061 12028 solver.cpp:238]     Train net output #0: loss = 2.30654 (* 1 = 2.30654 loss)
I0426 10:33:05.298066 12028 sgd_solver.cpp:105] Iteration 1300, lr = 0.001
I0426 10:33:06.922057 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:33:08.751255 12028 solver.cpp:219] Iteration 1400 (28.9582 iter/s, 3.45325s/100 iters), loss = 2.29969
I0426 10:33:08.751281 12028 solver.cpp:238]     Train net output #0: loss = 2.29969 (* 1 = 2.29969 loss)
I0426 10:33:08.751286 12028 sgd_solver.cpp:105] Iteration 1400, lr = 0.001
I0426 10:33:12.200043 12028 solver.cpp:219] Iteration 1500 (28.9954 iter/s, 3.44882s/100 iters), loss = 2.30837
I0426 10:33:12.200070 12028 solver.cpp:238]     Train net output #0: loss = 2.30837 (* 1 = 2.30837 loss)
I0426 10:33:12.200074 12028 sgd_solver.cpp:105] Iteration 1500, lr = 0.001
I0426 10:33:15.650022 12028 solver.cpp:219] Iteration 1600 (28.9854 iter/s, 3.45001s/100 iters), loss = 2.30318
I0426 10:33:15.650048 12028 solver.cpp:238]     Train net output #0: loss = 2.30318 (* 1 = 2.30318 loss)
I0426 10:33:15.650071 12028 sgd_solver.cpp:105] Iteration 1600, lr = 0.001
I0426 10:33:19.098330 12028 solver.cpp:219] Iteration 1700 (28.9995 iter/s, 3.44834s/100 iters), loss = 2.30459
I0426 10:33:19.098500 12028 solver.cpp:238]     Train net output #0: loss = 2.30459 (* 1 = 2.30459 loss)
I0426 10:33:19.098505 12028 sgd_solver.cpp:105] Iteration 1700, lr = 0.001
I0426 10:33:22.444609 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:33:22.551524 12028 solver.cpp:219] Iteration 1800 (28.9597 iter/s, 3.45308s/100 iters), loss = 2.29958
I0426 10:33:22.551551 12028 solver.cpp:238]     Train net output #0: loss = 2.29958 (* 1 = 2.29958 loss)
I0426 10:33:22.551575 12028 sgd_solver.cpp:105] Iteration 1800, lr = 0.001
I0426 10:33:26.004016 12028 solver.cpp:219] Iteration 1900 (28.9643 iter/s, 3.45252s/100 iters), loss = 2.29792
I0426 10:33:26.004043 12028 solver.cpp:238]     Train net output #0: loss = 2.29792 (* 1 = 2.29792 loss)
I0426 10:33:26.004047 12028 sgd_solver.cpp:105] Iteration 1900, lr = 0.001
I0426 10:33:29.402101 12028 solver.cpp:331] Iteration 2000, Testing net (#0)
I0426 10:33:30.035670 12036 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:33:30.434242 12028 solver.cpp:398]     Test net output #0: accuracy = 0.1
I0426 10:33:30.434283 12028 solver.cpp:398]     Test net output #1: loss = 2.30268 (* 1 = 2.30268 loss)
I0426 10:33:30.473076 12028 solver.cpp:219] Iteration 2000 (22.3758 iter/s, 4.4691s/100 iters), loss = 2.30348
I0426 10:33:30.473098 12028 solver.cpp:238]     Train net output #0: loss = 2.30348 (* 1 = 2.30348 loss)
I0426 10:33:30.473103 12028 sgd_solver.cpp:105] Iteration 2000, lr = 0.001
I0426 10:33:33.921762 12028 solver.cpp:219] Iteration 2100 (28.9963 iter/s, 3.44872s/100 iters), loss = 2.30166
I0426 10:33:33.921790 12028 solver.cpp:238]     Train net output #0: loss = 2.30166 (* 1 = 2.30166 loss)
I0426 10:33:33.921794 12028 sgd_solver.cpp:105] Iteration 2100, lr = 0.001
I0426 10:33:37.372133 12028 solver.cpp:219] Iteration 2200 (28.9822 iter/s, 3.45039s/100 iters), loss = 2.30591
I0426 10:33:37.372159 12028 solver.cpp:238]     Train net output #0: loss = 2.30591 (* 1 = 2.30591 loss)
I0426 10:33:37.372164 12028 sgd_solver.cpp:105] Iteration 2200, lr = 0.001
I0426 10:33:39.030128 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:33:40.825662 12028 solver.cpp:219] Iteration 2300 (28.9556 iter/s, 3.45356s/100 iters), loss = 2.30175
I0426 10:33:40.825691 12028 solver.cpp:238]     Train net output #0: loss = 2.30175 (* 1 = 2.30175 loss)
I0426 10:33:40.825714 12028 sgd_solver.cpp:105] Iteration 2300, lr = 0.001
I0426 10:33:44.276958 12028 solver.cpp:219] Iteration 2400 (28.9744 iter/s, 3.45132s/100 iters), loss = 2.30507
I0426 10:33:44.276986 12028 solver.cpp:238]     Train net output #0: loss = 2.30507 (* 1 = 2.30507 loss)
I0426 10:33:44.276991 12028 sgd_solver.cpp:105] Iteration 2400, lr = 0.001
I0426 10:33:47.726267 12028 solver.cpp:219] Iteration 2500 (28.9911 iter/s, 3.44934s/100 iters), loss = 2.30652
I0426 10:33:47.726294 12028 solver.cpp:238]     Train net output #0: loss = 2.30652 (* 1 = 2.30652 loss)
I0426 10:33:47.726316 12028 sgd_solver.cpp:105] Iteration 2500, lr = 0.001
I0426 10:33:51.176652 12028 solver.cpp:219] Iteration 2600 (28.982 iter/s, 3.45041s/100 iters), loss = 2.30253
I0426 10:33:51.176748 12028 solver.cpp:238]     Train net output #0: loss = 2.30253 (* 1 = 2.30253 loss)
I0426 10:33:51.176753 12028 sgd_solver.cpp:105] Iteration 2600, lr = 0.001
I0426 10:33:54.558845 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:33:54.631042 12028 solver.cpp:219] Iteration 2700 (28.949 iter/s, 3.45435s/100 iters), loss = 2.30502
I0426 10:33:54.631068 12028 solver.cpp:238]     Train net output #0: loss = 2.30502 (* 1 = 2.30502 loss)
I0426 10:33:54.631073 12028 sgd_solver.cpp:105] Iteration 2700, lr = 0.001
I0426 10:33:58.081049 12028 solver.cpp:219] Iteration 2800 (28.9852 iter/s, 3.45004s/100 iters), loss = 2.30519
I0426 10:33:58.081077 12028 solver.cpp:238]     Train net output #0: loss = 2.30519 (* 1 = 2.30519 loss)
I0426 10:33:58.081082 12028 sgd_solver.cpp:105] Iteration 2800, lr = 0.001
I0426 10:34:01.538656 12028 solver.cpp:219] Iteration 2900 (28.9215 iter/s, 3.45763s/100 iters), loss = 2.30262
I0426 10:34:01.538683 12028 solver.cpp:238]     Train net output #0: loss = 2.30262 (* 1 = 2.30262 loss)
I0426 10:34:01.538705 12028 sgd_solver.cpp:105] Iteration 2900, lr = 0.001
I0426 10:34:04.938269 12028 solver.cpp:331] Iteration 3000, Testing net (#0)
I0426 10:34:05.571948 12036 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:34:05.969166 12028 solver.cpp:398]     Test net output #0: accuracy = 0.1
I0426 10:34:05.969187 12028 solver.cpp:398]     Test net output #1: loss = 2.30347 (* 1 = 2.30347 loss)
I0426 10:34:06.007694 12028 solver.cpp:219] Iteration 3000 (22.3759 iter/s, 4.46908s/100 iters), loss = 2.29944
I0426 10:34:06.007716 12028 solver.cpp:238]     Train net output #0: loss = 2.29944 (* 1 = 2.29944 loss)
I0426 10:34:06.007721 12028 sgd_solver.cpp:105] Iteration 3000, lr = 0.001
I0426 10:34:09.479595 12028 solver.cpp:219] Iteration 3100 (28.8024 iter/s, 3.47193s/100 iters), loss = 2.30501
I0426 10:34:09.479624 12028 solver.cpp:238]     Train net output #0: loss = 2.30501 (* 1 = 2.30501 loss)
I0426 10:34:09.479645 12028 sgd_solver.cpp:105] Iteration 3100, lr = 0.001
I0426 10:34:11.173617 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:34:12.943022 12028 solver.cpp:219] Iteration 3200 (28.8729 iter/s, 3.46346s/100 iters), loss = 2.3012
I0426 10:34:12.943051 12028 solver.cpp:238]     Train net output #0: loss = 2.3012 (* 1 = 2.3012 loss)
I0426 10:34:12.943055 12028 sgd_solver.cpp:105] Iteration 3200, lr = 0.001
I0426 10:34:16.391490 12028 solver.cpp:219] Iteration 3300 (28.9982 iter/s, 3.44849s/100 iters), loss = 2.30365
I0426 10:34:16.391517 12028 solver.cpp:238]     Train net output #0: loss = 2.30365 (* 1 = 2.30365 loss)
I0426 10:34:16.391541 12028 sgd_solver.cpp:105] Iteration 3300, lr = 0.001
I0426 10:34:19.840823 12028 solver.cpp:219] Iteration 3400 (28.9909 iter/s, 3.44936s/100 iters), loss = 2.30757
I0426 10:34:19.840850 12028 solver.cpp:238]     Train net output #0: loss = 2.30757 (* 1 = 2.30757 loss)
I0426 10:34:19.840855 12028 sgd_solver.cpp:105] Iteration 3400, lr = 0.001
I0426 10:34:23.291551 12028 solver.cpp:219] Iteration 3500 (28.9792 iter/s, 3.45076s/100 iters), loss = 2.30132
I0426 10:34:23.291759 12028 solver.cpp:238]     Train net output #0: loss = 2.30132 (* 1 = 2.30132 loss)
I0426 10:34:23.291766 12028 sgd_solver.cpp:105] Iteration 3500, lr = 0.001
I0426 10:34:26.707085 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:34:26.744693 12028 solver.cpp:219] Iteration 3600 (28.9602 iter/s, 3.45301s/100 iters), loss = 2.30366
I0426 10:34:26.744719 12028 solver.cpp:238]     Train net output #0: loss = 2.30366 (* 1 = 2.30366 loss)
I0426 10:34:26.744741 12028 sgd_solver.cpp:105] Iteration 3600, lr = 0.001
I0426 10:34:30.196604 12028 solver.cpp:219] Iteration 3700 (28.9692 iter/s, 3.45194s/100 iters), loss = 2.3106
I0426 10:34:30.196631 12028 solver.cpp:238]     Train net output #0: loss = 2.3106 (* 1 = 2.3106 loss)
I0426 10:34:30.196636 12028 sgd_solver.cpp:105] Iteration 3700, lr = 0.001
I0426 10:34:33.650432 12028 solver.cpp:219] Iteration 3800 (28.9532 iter/s, 3.45385s/100 iters), loss = 2.30348
I0426 10:34:33.650478 12028 solver.cpp:238]     Train net output #0: loss = 2.30348 (* 1 = 2.30348 loss)
I0426 10:34:33.650501 12028 sgd_solver.cpp:105] Iteration 3800, lr = 0.001
I0426 10:34:37.105448 12028 solver.cpp:219] Iteration 3900 (28.9434 iter/s, 3.45502s/100 iters), loss = 2.30398
I0426 10:34:37.105485 12028 solver.cpp:238]     Train net output #0: loss = 2.30398 (* 1 = 2.30398 loss)
I0426 10:34:37.105491 12028 sgd_solver.cpp:105] Iteration 3900, lr = 0.001
I0426 10:34:40.509397 12028 solver.cpp:331] Iteration 4000, Testing net (#0)
I0426 10:34:41.143102 12036 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:34:41.541213 12028 solver.cpp:398]     Test net output #0: accuracy = 0.1
I0426 10:34:41.541254 12028 solver.cpp:398]     Test net output #1: loss = 2.30281 (* 1 = 2.30281 loss)
I0426 10:34:41.579854 12028 solver.cpp:219] Iteration 4000 (22.3492 iter/s, 4.47444s/100 iters), loss = 2.30263
I0426 10:34:41.579892 12028 solver.cpp:238]     Train net output #0: loss = 2.30263 (* 1 = 2.30263 loss)
I0426 10:34:41.579898 12028 sgd_solver.cpp:105] Iteration 4000, lr = 0.001
I0426 10:34:43.307970 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:34:45.034703 12028 solver.cpp:219] Iteration 4100 (28.9447 iter/s, 3.45486s/100 iters), loss = 2.30855
I0426 10:34:45.034731 12028 solver.cpp:238]     Train net output #0: loss = 2.30855 (* 1 = 2.30855 loss)
I0426 10:34:45.034754 12028 sgd_solver.cpp:105] Iteration 4100, lr = 0.001
I0426 10:34:48.484954 12028 solver.cpp:219] Iteration 4200 (28.9832 iter/s, 3.45028s/100 iters), loss = 2.30077
I0426 10:34:48.484983 12028 solver.cpp:238]     Train net output #0: loss = 2.30077 (* 1 = 2.30077 loss)
I0426 10:34:48.484987 12028 sgd_solver.cpp:105] Iteration 4200, lr = 0.001
I0426 10:34:51.934617 12028 solver.cpp:219] Iteration 4300 (28.9881 iter/s, 3.44969s/100 iters), loss = 2.3058
I0426 10:34:51.934643 12028 solver.cpp:238]     Train net output #0: loss = 2.3058 (* 1 = 2.3058 loss)
I0426 10:34:51.934648 12028 sgd_solver.cpp:105] Iteration 4300, lr = 0.001
I0426 10:34:55.386307 12028 solver.cpp:219] Iteration 4400 (28.9711 iter/s, 3.45172s/100 iters), loss = 2.30381
I0426 10:34:55.386518 12028 solver.cpp:238]     Train net output #0: loss = 2.30381 (* 1 = 2.30381 loss)
I0426 10:34:55.386524 12028 sgd_solver.cpp:105] Iteration 4400, lr = 0.001
I0426 10:34:58.836308 12028 solver.cpp:219] Iteration 4500 (28.9868 iter/s, 3.44985s/100 iters), loss = 2.30211
I0426 10:34:58.836336 12028 solver.cpp:238]     Train net output #0: loss = 2.30211 (* 1 = 2.30211 loss)
I0426 10:34:58.836359 12028 sgd_solver.cpp:105] Iteration 4500, lr = 0.001
I0426 10:34:58.837182 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:35:02.294657 12028 solver.cpp:219] Iteration 4600 (28.9153 iter/s, 3.45837s/100 iters), loss = 2.30354
I0426 10:35:02.294689 12028 solver.cpp:238]     Train net output #0: loss = 2.30354 (* 1 = 2.30354 loss)
I0426 10:35:02.294694 12028 sgd_solver.cpp:105] Iteration 4600, lr = 0.001
I0426 10:35:05.747469 12028 solver.cpp:219] Iteration 4700 (28.9617 iter/s, 3.45283s/100 iters), loss = 2.30237
I0426 10:35:05.747498 12028 solver.cpp:238]     Train net output #0: loss = 2.30237 (* 1 = 2.30237 loss)
I0426 10:35:05.747521 12028 sgd_solver.cpp:105] Iteration 4700, lr = 0.001
I0426 10:35:09.196743 12028 solver.cpp:219] Iteration 4800 (28.9914 iter/s, 3.4493s/100 iters), loss = 2.29877
I0426 10:35:09.196770 12028 solver.cpp:238]     Train net output #0: loss = 2.29877 (* 1 = 2.29877 loss)
I0426 10:35:09.196792 12028 sgd_solver.cpp:105] Iteration 4800, lr = 0.001
I0426 10:35:12.645473 12028 solver.cpp:219] Iteration 4900 (28.9959 iter/s, 3.44876s/100 iters), loss = 2.29972
I0426 10:35:12.645501 12028 solver.cpp:238]     Train net output #0: loss = 2.29972 (* 1 = 2.29972 loss)
I0426 10:35:12.645524 12028 sgd_solver.cpp:105] Iteration 4900, lr = 0.001
I0426 10:35:14.373029 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:35:16.047508 12028 solver.cpp:331] Iteration 5000, Testing net (#0)
I0426 10:35:16.680668 12036 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:35:17.077879 12028 solver.cpp:398]     Test net output #0: accuracy = 0.1
I0426 10:35:17.077903 12028 solver.cpp:398]     Test net output #1: loss = 2.30312 (* 1 = 2.30312 loss)
I0426 10:35:17.116441 12028 solver.cpp:219] Iteration 5000 (22.3663 iter/s, 4.47101s/100 iters), loss = 2.30341
I0426 10:35:17.116480 12028 solver.cpp:238]     Train net output #0: loss = 2.30341 (* 1 = 2.30341 loss)
I0426 10:35:17.116485 12028 sgd_solver.cpp:105] Iteration 5000, lr = 0.001
I0426 10:35:20.566691 12028 solver.cpp:219] Iteration 5100 (28.9833 iter/s, 3.45026s/100 iters), loss = 2.30557
I0426 10:35:20.566718 12028 solver.cpp:238]     Train net output #0: loss = 2.30557 (* 1 = 2.30557 loss)
I0426 10:35:20.566740 12028 sgd_solver.cpp:105] Iteration 5100, lr = 0.001
I0426 10:35:24.015954 12028 solver.cpp:219] Iteration 5200 (28.9915 iter/s, 3.44929s/100 iters), loss = 2.30557
I0426 10:35:24.015981 12028 solver.cpp:238]     Train net output #0: loss = 2.30557 (* 1 = 2.30557 loss)
I0426 10:35:24.015985 12028 sgd_solver.cpp:105] Iteration 5200, lr = 0.001
I0426 10:35:27.465777 12028 solver.cpp:219] Iteration 5300 (28.9867 iter/s, 3.44985s/100 iters), loss = 2.30146
I0426 10:35:27.465981 12028 solver.cpp:238]     Train net output #0: loss = 2.30146 (* 1 = 2.30146 loss)
I0426 10:35:27.465988 12028 sgd_solver.cpp:105] Iteration 5300, lr = 0.001
I0426 10:35:30.915269 12028 solver.cpp:219] Iteration 5400 (28.9909 iter/s, 3.44936s/100 iters), loss = 2.30207
I0426 10:35:30.915300 12028 solver.cpp:238]     Train net output #0: loss = 2.30207 (* 1 = 2.30207 loss)
I0426 10:35:30.915325 12028 sgd_solver.cpp:105] Iteration 5400, lr = 0.001
I0426 10:35:30.954757 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:35:34.372737 12028 solver.cpp:219] Iteration 5500 (28.9227 iter/s, 3.45749s/100 iters), loss = 2.30529
I0426 10:35:34.372766 12028 solver.cpp:238]     Train net output #0: loss = 2.30529 (* 1 = 2.30529 loss)
I0426 10:35:34.372769 12028 sgd_solver.cpp:105] Iteration 5500, lr = 0.001
I0426 10:35:37.824813 12028 solver.cpp:219] Iteration 5600 (28.9679 iter/s, 3.4521s/100 iters), loss = 2.30152
I0426 10:35:37.824839 12028 solver.cpp:238]     Train net output #0: loss = 2.30152 (* 1 = 2.30152 loss)
I0426 10:35:37.824863 12028 sgd_solver.cpp:105] Iteration 5600, lr = 0.001
I0426 10:35:41.275486 12028 solver.cpp:219] Iteration 5700 (28.9796 iter/s, 3.4507s/100 iters), loss = 2.29692
I0426 10:35:41.275514 12028 solver.cpp:238]     Train net output #0: loss = 2.29692 (* 1 = 2.29692 loss)
I0426 10:35:41.275518 12028 sgd_solver.cpp:105] Iteration 5700, lr = 0.001
I0426 10:35:44.726902 12028 solver.cpp:219] Iteration 5800 (28.9734 iter/s, 3.45144s/100 iters), loss = 2.30244
I0426 10:35:44.726929 12028 solver.cpp:238]     Train net output #0: loss = 2.30244 (* 1 = 2.30244 loss)
I0426 10:35:44.726934 12028 sgd_solver.cpp:105] Iteration 5800, lr = 0.001
I0426 10:35:46.490392 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:35:48.181679 12028 solver.cpp:219] Iteration 5900 (28.9452 iter/s, 3.45481s/100 iters), loss = 2.30533
I0426 10:35:48.181704 12028 solver.cpp:238]     Train net output #0: loss = 2.30533 (* 1 = 2.30533 loss)
I0426 10:35:48.181709 12028 sgd_solver.cpp:105] Iteration 5900, lr = 0.001
I0426 10:35:51.600347 12028 solver.cpp:331] Iteration 6000, Testing net (#0)
I0426 10:35:52.233795 12036 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:35:52.631003 12028 solver.cpp:398]     Test net output #0: accuracy = 0.1
I0426 10:35:52.631024 12028 solver.cpp:398]     Test net output #1: loss = 2.30305 (* 1 = 2.30305 loss)
I0426 10:35:52.669349 12028 solver.cpp:219] Iteration 6000 (22.283 iter/s, 4.48772s/100 iters), loss = 2.2986
I0426 10:35:52.669368 12028 solver.cpp:238]     Train net output #0: loss = 2.2986 (* 1 = 2.2986 loss)
I0426 10:35:52.669373 12028 sgd_solver.cpp:105] Iteration 6000, lr = 0.001
I0426 10:35:56.132061 12028 solver.cpp:219] Iteration 6100 (28.8788 iter/s, 3.46275s/100 iters), loss = 2.30578
I0426 10:35:56.132087 12028 solver.cpp:238]     Train net output #0: loss = 2.30578 (* 1 = 2.30578 loss)
I0426 10:35:56.132110 12028 sgd_solver.cpp:105] Iteration 6100, lr = 0.001
I0426 10:35:59.585053 12028 solver.cpp:219] Iteration 6200 (28.9601 iter/s, 3.45302s/100 iters), loss = 2.30856
I0426 10:35:59.585149 12028 solver.cpp:238]     Train net output #0: loss = 2.30856 (* 1 = 2.30856 loss)
I0426 10:35:59.585153 12028 sgd_solver.cpp:105] Iteration 6200, lr = 0.001
I0426 10:36:03.045897 12028 solver.cpp:219] Iteration 6300 (28.895 iter/s, 3.46081s/100 iters), loss = 2.30559
I0426 10:36:03.045925 12028 solver.cpp:238]     Train net output #0: loss = 2.30559 (* 1 = 2.30559 loss)
I0426 10:36:03.045929 12028 sgd_solver.cpp:105] Iteration 6300, lr = 0.001
I0426 10:36:03.120474 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:36:06.503042 12028 solver.cpp:219] Iteration 6400 (28.9254 iter/s, 3.45717s/100 iters), loss = 2.30174
I0426 10:36:06.503068 12028 solver.cpp:238]     Train net output #0: loss = 2.30174 (* 1 = 2.30174 loss)
I0426 10:36:06.503072 12028 sgd_solver.cpp:105] Iteration 6400, lr = 0.001
I0426 10:36:09.954736 12028 solver.cpp:219] Iteration 6500 (28.971 iter/s, 3.45173s/100 iters), loss = 2.30306
I0426 10:36:09.954764 12028 solver.cpp:238]     Train net output #0: loss = 2.30306 (* 1 = 2.30306 loss)
I0426 10:36:09.954768 12028 sgd_solver.cpp:105] Iteration 6500, lr = 0.001
I0426 10:36:13.407598 12028 solver.cpp:219] Iteration 6600 (28.9612 iter/s, 3.45289s/100 iters), loss = 2.30907
I0426 10:36:13.407625 12028 solver.cpp:238]     Train net output #0: loss = 2.30907 (* 1 = 2.30907 loss)
I0426 10:36:13.407629 12028 sgd_solver.cpp:105] Iteration 6600, lr = 0.001
I0426 10:36:16.860553 12028 solver.cpp:219] Iteration 6700 (28.9604 iter/s, 3.45299s/100 iters), loss = 2.30191
I0426 10:36:16.860581 12028 solver.cpp:238]     Train net output #0: loss = 2.30191 (* 1 = 2.30191 loss)
I0426 10:36:16.860585 12028 sgd_solver.cpp:105] Iteration 6700, lr = 0.001
I0426 10:36:18.658046 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:36:20.315663 12028 solver.cpp:219] Iteration 6800 (28.9424 iter/s, 3.45514s/100 iters), loss = 2.29759
I0426 10:36:20.315691 12028 solver.cpp:238]     Train net output #0: loss = 2.29759 (* 1 = 2.29759 loss)
I0426 10:36:20.315696 12028 sgd_solver.cpp:105] Iteration 6800, lr = 0.001
I0426 10:36:23.766281 12028 solver.cpp:219] Iteration 6900 (28.9801 iter/s, 3.45065s/100 iters), loss = 2.3011
I0426 10:36:23.766312 12028 solver.cpp:238]     Train net output #0: loss = 2.3011 (* 1 = 2.3011 loss)
I0426 10:36:23.766319 12028 sgd_solver.cpp:105] Iteration 6900, lr = 0.001
I0426 10:36:27.167095 12028 solver.cpp:331] Iteration 7000, Testing net (#0)
I0426 10:36:27.802238 12036 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:36:28.196709 12028 solver.cpp:398]     Test net output #0: accuracy = 0.1
I0426 10:36:28.196748 12028 solver.cpp:398]     Test net output #1: loss = 2.30285 (* 1 = 2.30285 loss)
I0426 10:36:28.235548 12028 solver.cpp:219] Iteration 7000 (22.3748 iter/s, 4.46931s/100 iters), loss = 2.30501
I0426 10:36:28.235570 12028 solver.cpp:238]     Train net output #0: loss = 2.30501 (* 1 = 2.30501 loss)
I0426 10:36:28.235575 12028 sgd_solver.cpp:105] Iteration 7000, lr = 0.001
I0426 10:36:31.688302 12028 solver.cpp:219] Iteration 7100 (28.9621 iter/s, 3.45279s/100 iters), loss = 2.30883
I0426 10:36:31.688441 12028 solver.cpp:238]     Train net output #0: loss = 2.30883 (* 1 = 2.30883 loss)
I0426 10:36:31.688447 12028 sgd_solver.cpp:105] Iteration 7100, lr = 0.001
I0426 10:36:35.142441 12028 solver.cpp:219] Iteration 7200 (28.9514 iter/s, 3.45406s/100 iters), loss = 2.3051
I0426 10:36:35.142469 12028 solver.cpp:238]     Train net output #0: loss = 2.3051 (* 1 = 2.3051 loss)
I0426 10:36:35.142473 12028 sgd_solver.cpp:105] Iteration 7200, lr = 0.001
I0426 10:36:35.250725 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:36:38.598439 12028 solver.cpp:219] Iteration 7300 (28.935 iter/s, 3.45603s/100 iters), loss = 2.30134
I0426 10:36:38.598466 12028 solver.cpp:238]     Train net output #0: loss = 2.30134 (* 1 = 2.30134 loss)
I0426 10:36:38.598471 12028 sgd_solver.cpp:105] Iteration 7300, lr = 0.001
I0426 10:36:42.049137 12028 solver.cpp:219] Iteration 7400 (28.9794 iter/s, 3.45073s/100 iters), loss = 2.30391
I0426 10:36:42.049165 12028 solver.cpp:238]     Train net output #0: loss = 2.30391 (* 1 = 2.30391 loss)
I0426 10:36:42.049170 12028 sgd_solver.cpp:105] Iteration 7400, lr = 0.001
I0426 10:36:45.501209 12028 solver.cpp:219] Iteration 7500 (28.9679 iter/s, 3.4521s/100 iters), loss = 2.30503
I0426 10:36:45.501237 12028 solver.cpp:238]     Train net output #0: loss = 2.30503 (* 1 = 2.30503 loss)
I0426 10:36:45.501241 12028 sgd_solver.cpp:105] Iteration 7500, lr = 0.001
I0426 10:36:48.951712 12028 solver.cpp:219] Iteration 7600 (28.9811 iter/s, 3.45053s/100 iters), loss = 2.29935
I0426 10:36:48.951740 12028 solver.cpp:238]     Train net output #0: loss = 2.29935 (* 1 = 2.29935 loss)
I0426 10:36:48.951745 12028 sgd_solver.cpp:105] Iteration 7600, lr = 0.001
I0426 10:36:50.783125 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:36:52.406533 12028 solver.cpp:219] Iteration 7700 (28.9448 iter/s, 3.45485s/100 iters), loss = 2.29754
I0426 10:36:52.406561 12028 solver.cpp:238]     Train net output #0: loss = 2.29754 (* 1 = 2.29754 loss)
I0426 10:36:52.406566 12028 sgd_solver.cpp:105] Iteration 7700, lr = 0.001
I0426 10:36:55.857928 12028 solver.cpp:219] Iteration 7800 (28.9736 iter/s, 3.45142s/100 iters), loss = 2.29962
I0426 10:36:55.857954 12028 solver.cpp:238]     Train net output #0: loss = 2.29962 (* 1 = 2.29962 loss)
I0426 10:36:55.857976 12028 sgd_solver.cpp:105] Iteration 7800, lr = 0.001
I0426 10:36:59.309434 12028 solver.cpp:219] Iteration 7900 (28.9726 iter/s, 3.45154s/100 iters), loss = 2.3074
I0426 10:36:59.309464 12028 solver.cpp:238]     Train net output #0: loss = 2.3074 (* 1 = 2.3074 loss)
I0426 10:36:59.309487 12028 sgd_solver.cpp:105] Iteration 7900, lr = 0.001
I0426 10:37:02.717459 12028 solver.cpp:331] Iteration 8000, Testing net (#0)
I0426 10:37:03.351440 12036 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:37:03.748352 12028 solver.cpp:398]     Test net output #0: accuracy = 0.1
I0426 10:37:03.748376 12028 solver.cpp:398]     Test net output #1: loss = 2.3024 (* 1 = 2.3024 loss)
I0426 10:37:03.786809 12028 solver.cpp:219] Iteration 8000 (22.3343 iter/s, 4.47742s/100 iters), loss = 2.29784
I0426 10:37:03.786830 12028 solver.cpp:238]     Train net output #0: loss = 2.29784 (* 1 = 2.29784 loss)
I0426 10:37:03.786836 12028 sgd_solver.cpp:105] Iteration 8000, lr = 0.001
I0426 10:37:07.236855 12028 solver.cpp:219] Iteration 8100 (28.9848 iter/s, 3.45008s/100 iters), loss = 2.30292
I0426 10:37:07.236884 12028 solver.cpp:238]     Train net output #0: loss = 2.30292 (* 1 = 2.30292 loss)
I0426 10:37:07.236891 12028 sgd_solver.cpp:105] Iteration 8100, lr = 0.001
I0426 10:37:07.379137 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:37:10.690188 12028 solver.cpp:219] Iteration 8200 (28.9573 iter/s, 3.45336s/100 iters), loss = 2.30346
I0426 10:37:10.690217 12028 solver.cpp:238]     Train net output #0: loss = 2.30346 (* 1 = 2.30346 loss)
I0426 10:37:10.690222 12028 sgd_solver.cpp:105] Iteration 8200, lr = 0.001
I0426 10:37:14.140302 12028 solver.cpp:219] Iteration 8300 (28.9843 iter/s, 3.45014s/100 iters), loss = 2.30094
I0426 10:37:14.140329 12028 solver.cpp:238]     Train net output #0: loss = 2.30094 (* 1 = 2.30094 loss)
I0426 10:37:14.140334 12028 sgd_solver.cpp:105] Iteration 8300, lr = 0.001
I0426 10:37:17.593005 12028 solver.cpp:219] Iteration 8400 (28.9626 iter/s, 3.45273s/100 iters), loss = 2.30504
I0426 10:37:17.593034 12028 solver.cpp:238]     Train net output #0: loss = 2.30504 (* 1 = 2.30504 loss)
I0426 10:37:17.593037 12028 sgd_solver.cpp:105] Iteration 8400, lr = 0.001
I0426 10:37:21.043413 12028 solver.cpp:219] Iteration 8500 (28.9818 iter/s, 3.45044s/100 iters), loss = 2.30137
I0426 10:37:21.043442 12028 solver.cpp:238]     Train net output #0: loss = 2.30137 (* 1 = 2.30137 loss)
I0426 10:37:21.043445 12028 sgd_solver.cpp:105] Iteration 8500, lr = 0.001
I0426 10:37:22.909852 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:37:24.498571 12028 solver.cpp:219] Iteration 8600 (28.942 iter/s, 3.45519s/100 iters), loss = 2.30123
I0426 10:37:24.498600 12028 solver.cpp:238]     Train net output #0: loss = 2.30123 (* 1 = 2.30123 loss)
I0426 10:37:24.498621 12028 sgd_solver.cpp:105] Iteration 8600, lr = 0.001
I0426 10:37:27.950100 12028 solver.cpp:219] Iteration 8700 (28.9724 iter/s, 3.45156s/100 iters), loss = 2.30166
I0426 10:37:27.950129 12028 solver.cpp:238]     Train net output #0: loss = 2.30166 (* 1 = 2.30166 loss)
I0426 10:37:27.950151 12028 sgd_solver.cpp:105] Iteration 8700, lr = 0.001
I0426 10:37:31.402091 12028 solver.cpp:219] Iteration 8800 (28.9685 iter/s, 3.45202s/100 iters), loss = 2.30504
I0426 10:37:31.402117 12028 solver.cpp:238]     Train net output #0: loss = 2.30504 (* 1 = 2.30504 loss)
I0426 10:37:31.402122 12028 sgd_solver.cpp:105] Iteration 8800, lr = 0.001
I0426 10:37:34.853101 12028 solver.cpp:219] Iteration 8900 (28.9767 iter/s, 3.45104s/100 iters), loss = 2.29748
I0426 10:37:34.853271 12028 solver.cpp:238]     Train net output #0: loss = 2.29748 (* 1 = 2.29748 loss)
I0426 10:37:34.853278 12028 sgd_solver.cpp:105] Iteration 8900, lr = 0.001
I0426 10:37:38.252917 12028 solver.cpp:331] Iteration 9000, Testing net (#0)
I0426 10:37:38.886373 12036 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:37:39.283668 12028 solver.cpp:398]     Test net output #0: accuracy = 0.1248
I0426 10:37:39.283689 12028 solver.cpp:398]     Test net output #1: loss = 2.2958 (* 1 = 2.2958 loss)
I0426 10:37:39.322058 12028 solver.cpp:219] Iteration 9000 (22.3769 iter/s, 4.46889s/100 iters), loss = 2.30073
I0426 10:37:39.322077 12028 solver.cpp:238]     Train net output #0: loss = 2.30073 (* 1 = 2.30073 loss)
I0426 10:37:39.322082 12028 sgd_solver.cpp:105] Iteration 9000, lr = 0.001
I0426 10:37:39.499660 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:37:42.778636 12028 solver.cpp:219] Iteration 9100 (28.93 iter/s, 3.45662s/100 iters), loss = 2.2937
I0426 10:37:42.778664 12028 solver.cpp:238]     Train net output #0: loss = 2.2937 (* 1 = 2.2937 loss)
I0426 10:37:42.778668 12028 sgd_solver.cpp:105] Iteration 9100, lr = 0.001
I0426 10:37:46.230201 12028 solver.cpp:219] Iteration 9200 (28.9721 iter/s, 3.45159s/100 iters), loss = 2.28372
I0426 10:37:46.230228 12028 solver.cpp:238]     Train net output #0: loss = 2.28372 (* 1 = 2.28372 loss)
I0426 10:37:46.230250 12028 sgd_solver.cpp:105] Iteration 9200, lr = 0.001
I0426 10:37:49.682077 12028 solver.cpp:219] Iteration 9300 (28.9695 iter/s, 3.45191s/100 iters), loss = 2.27478
I0426 10:37:49.682106 12028 solver.cpp:238]     Train net output #0: loss = 2.27478 (* 1 = 2.27478 loss)
I0426 10:37:49.682109 12028 sgd_solver.cpp:105] Iteration 9300, lr = 0.001
I0426 10:37:53.156572 12028 solver.cpp:219] Iteration 9400 (28.7809 iter/s, 3.47452s/100 iters), loss = 2.24568
I0426 10:37:53.156599 12028 solver.cpp:238]     Train net output #0: loss = 2.24568 (* 1 = 2.24568 loss)
I0426 10:37:53.156605 12028 sgd_solver.cpp:105] Iteration 9400, lr = 0.001
I0426 10:37:55.065793 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:37:56.621284 12028 solver.cpp:219] Iteration 9500 (28.8622 iter/s, 3.46474s/100 iters), loss = 2.20596
I0426 10:37:56.621310 12028 solver.cpp:238]     Train net output #0: loss = 2.20596 (* 1 = 2.20596 loss)
I0426 10:37:56.621315 12028 sgd_solver.cpp:105] Iteration 9500, lr = 0.001
I0426 10:38:00.073632 12028 solver.cpp:219] Iteration 9600 (28.9655 iter/s, 3.45238s/100 iters), loss = 2.12569
I0426 10:38:00.073662 12028 solver.cpp:238]     Train net output #0: loss = 2.12569 (* 1 = 2.12569 loss)
I0426 10:38:00.073686 12028 sgd_solver.cpp:105] Iteration 9600, lr = 0.001
I0426 10:38:03.534173 12028 solver.cpp:219] Iteration 9700 (28.897 iter/s, 3.46057s/100 iters), loss = 2.12271
I0426 10:38:03.534201 12028 solver.cpp:238]     Train net output #0: loss = 2.12271 (* 1 = 2.12271 loss)
I0426 10:38:03.534224 12028 sgd_solver.cpp:105] Iteration 9700, lr = 0.001
I0426 10:38:06.995144 12028 solver.cpp:219] Iteration 9800 (28.8934 iter/s, 3.461s/100 iters), loss = 2.1032
I0426 10:38:06.995235 12028 solver.cpp:238]     Train net output #0: loss = 2.1032 (* 1 = 2.1032 loss)
I0426 10:38:06.995240 12028 sgd_solver.cpp:105] Iteration 9800, lr = 0.001
I0426 10:38:10.468636 12028 solver.cpp:219] Iteration 9900 (28.7898 iter/s, 3.47346s/100 iters), loss = 2.06789
I0426 10:38:10.468663 12028 solver.cpp:238]     Train net output #0: loss = 2.06789 (* 1 = 2.06789 loss)
I0426 10:38:10.468686 12028 sgd_solver.cpp:105] Iteration 9900, lr = 0.001
I0426 10:38:10.646586 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:38:13.883184 12028 solver.cpp:448] Snapshotting to binary proto file examples/cifar10_full_sigmoid_iter_10000.caffemodel
I0426 10:38:13.901075 12028 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_sigmoid_iter_10000.solverstate
I0426 10:38:13.901304 12028 solver.cpp:331] Iteration 10000, Testing net (#0)
I0426 10:38:14.520817 12036 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:38:14.920398 12028 solver.cpp:398]     Test net output #0: accuracy = 0.2254
I0426 10:38:14.920436 12028 solver.cpp:398]     Test net output #1: loss = 2.06993 (* 1 = 2.06993 loss)
I0426 10:38:14.959249 12028 solver.cpp:219] Iteration 10000 (22.2684 iter/s, 4.49067s/100 iters), loss = 2.06771
I0426 10:38:14.959285 12028 solver.cpp:238]     Train net output #0: loss = 2.06771 (* 1 = 2.06771 loss)
I0426 10:38:14.959291 12028 sgd_solver.cpp:105] Iteration 10000, lr = 0.001
I0426 10:38:18.434092 12028 solver.cpp:219] Iteration 10100 (28.7781 iter/s, 3.47486s/100 iters), loss = 2.08304
I0426 10:38:18.434118 12028 solver.cpp:238]     Train net output #0: loss = 2.08304 (* 1 = 2.08304 loss)
I0426 10:38:18.434123 12028 sgd_solver.cpp:105] Iteration 10100, lr = 0.001
I0426 10:38:21.890713 12028 solver.cpp:219] Iteration 10200 (28.9297 iter/s, 3.45665s/100 iters), loss = 2.06162
I0426 10:38:21.890740 12028 solver.cpp:238]     Train net output #0: loss = 2.06162 (* 1 = 2.06162 loss)
I0426 10:38:21.890744 12028 sgd_solver.cpp:105] Iteration 10200, lr = 0.001
I0426 10:38:25.344163 12028 solver.cpp:219] Iteration 10300 (28.9563 iter/s, 3.45348s/100 iters), loss = 2.0062
I0426 10:38:25.344192 12028 solver.cpp:238]     Train net output #0: loss = 2.0062 (* 1 = 2.0062 loss)
I0426 10:38:25.344195 12028 sgd_solver.cpp:105] Iteration 10300, lr = 0.001
I0426 10:38:27.281534 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:38:28.802661 12028 solver.cpp:219] Iteration 10400 (28.9141 iter/s, 3.45853s/100 iters), loss = 2.06462
I0426 10:38:28.802690 12028 solver.cpp:238]     Train net output #0: loss = 2.06462 (* 1 = 2.06462 loss)
I0426 10:38:28.802693 12028 sgd_solver.cpp:105] Iteration 10400, lr = 0.001
I0426 10:38:32.255424 12028 solver.cpp:219] Iteration 10500 (28.9621 iter/s, 3.45279s/100 iters), loss = 2.05236
I0426 10:38:32.255450 12028 solver.cpp:238]     Train net output #0: loss = 2.05236 (* 1 = 2.05236 loss)
I0426 10:38:32.255455 12028 sgd_solver.cpp:105] Iteration 10500, lr = 0.001
I0426 10:38:35.706725 12028 solver.cpp:219] Iteration 10600 (28.9743 iter/s, 3.45133s/100 iters), loss = 1.92523
I0426 10:38:35.706753 12028 solver.cpp:238]     Train net output #0: loss = 1.92523 (* 1 = 1.92523 loss)
I0426 10:38:35.706758 12028 sgd_solver.cpp:105] Iteration 10600, lr = 0.001
I0426 10:38:39.158929 12028 solver.cpp:219] Iteration 10700 (28.9667 iter/s, 3.45224s/100 iters), loss = 2.08129
I0426 10:38:39.159124 12028 solver.cpp:238]     Train net output #0: loss = 2.08129 (* 1 = 2.08129 loss)
I0426 10:38:39.159131 12028 sgd_solver.cpp:105] Iteration 10700, lr = 0.001
I0426 10:38:42.611706 12028 solver.cpp:219] Iteration 10800 (28.9633 iter/s, 3.45264s/100 iters), loss = 1.99401
I0426 10:38:42.611733 12028 solver.cpp:238]     Train net output #0: loss = 1.99401 (* 1 = 1.99401 loss)
I0426 10:38:42.611737 12028 sgd_solver.cpp:105] Iteration 10800, lr = 0.001
I0426 10:38:42.823941 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:38:46.071449 12028 solver.cpp:219] Iteration 10900 (28.9036 iter/s, 3.45977s/100 iters), loss = 1.97594
I0426 10:38:46.071477 12028 solver.cpp:238]     Train net output #0: loss = 1.97594 (* 1 = 1.97594 loss)
I0426 10:38:46.071482 12028 sgd_solver.cpp:105] Iteration 10900, lr = 0.001
I0426 10:38:49.473093 12028 solver.cpp:331] Iteration 11000, Testing net (#0)
I0426 10:38:50.109067 12036 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:38:50.508682 12028 solver.cpp:398]     Test net output #0: accuracy = 0.2557
I0426 10:38:50.508703 12028 solver.cpp:398]     Test net output #1: loss = 2.00434 (* 1 = 2.00434 loss)
I0426 10:38:50.547587 12028 solver.cpp:219] Iteration 11000 (22.3404 iter/s, 4.47619s/100 iters), loss = 2.05063
I0426 10:38:50.547628 12028 solver.cpp:238]     Train net output #0: loss = 2.05063 (* 1 = 2.05063 loss)
I0426 10:38:50.547647 12028 sgd_solver.cpp:105] Iteration 11000, lr = 0.001
I0426 10:38:54.007797 12028 solver.cpp:219] Iteration 11100 (28.8999 iter/s, 3.46023s/100 iters), loss = 1.99045
I0426 10:38:54.007841 12028 solver.cpp:238]     Train net output #0: loss = 1.99045 (* 1 = 1.99045 loss)
I0426 10:38:54.007845 12028 sgd_solver.cpp:105] Iteration 11100, lr = 0.001
I0426 10:38:57.461066 12028 solver.cpp:219] Iteration 11200 (28.958 iter/s, 3.45328s/100 iters), loss = 1.97163
I0426 10:38:57.461112 12028 solver.cpp:238]     Train net output #0: loss = 1.97163 (* 1 = 1.97163 loss)
I0426 10:38:57.461117 12028 sgd_solver.cpp:105] Iteration 11200, lr = 0.001
I0426 10:38:59.433559 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:39:00.928076 12028 solver.cpp:219] Iteration 11300 (28.8431 iter/s, 3.46704s/100 iters), loss = 1.96299
I0426 10:39:00.928104 12028 solver.cpp:238]     Train net output #0: loss = 1.96299 (* 1 = 1.96299 loss)
I0426 10:39:00.928108 12028 sgd_solver.cpp:105] Iteration 11300, lr = 0.001
I0426 10:39:04.381011 12028 solver.cpp:219] Iteration 11400 (28.9606 iter/s, 3.45296s/100 iters), loss = 1.99831
I0426 10:39:04.381055 12028 solver.cpp:238]     Train net output #0: loss = 1.99831 (* 1 = 1.99831 loss)
I0426 10:39:04.381059 12028 sgd_solver.cpp:105] Iteration 11400, lr = 0.001
I0426 10:39:07.849905 12028 solver.cpp:219] Iteration 11500 (28.8275 iter/s, 3.46891s/100 iters), loss = 1.96323
I0426 10:39:07.849951 12028 solver.cpp:238]     Train net output #0: loss = 1.96323 (* 1 = 1.96323 loss)
I0426 10:39:07.849956 12028 sgd_solver.cpp:105] Iteration 11500, lr = 0.001
I0426 10:39:11.313491 12028 solver.cpp:219] Iteration 11600 (28.8717 iter/s, 3.4636s/100 iters), loss = 1.9641
I0426 10:39:11.313643 12028 solver.cpp:238]     Train net output #0: loss = 1.9641 (* 1 = 1.9641 loss)
I0426 10:39:11.313649 12028 sgd_solver.cpp:105] Iteration 11600, lr = 0.001
I0426 10:39:14.766130 12028 solver.cpp:219] Iteration 11700 (28.9641 iter/s, 3.45255s/100 iters), loss = 2.03298
I0426 10:39:14.766158 12028 solver.cpp:238]     Train net output #0: loss = 2.03298 (* 1 = 2.03298 loss)
I0426 10:39:14.766162 12028 sgd_solver.cpp:105] Iteration 11700, lr = 0.001
I0426 10:39:15.013227 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:39:18.222993 12028 solver.cpp:219] Iteration 11800 (28.9277 iter/s, 3.45689s/100 iters), loss = 1.94506
I0426 10:39:18.223022 12028 solver.cpp:238]     Train net output #0: loss = 1.94506 (* 1 = 1.94506 loss)
I0426 10:39:18.223026 12028 sgd_solver.cpp:105] Iteration 11800, lr = 0.001
I0426 10:39:21.698693 12028 solver.cpp:219] Iteration 11900 (28.771 iter/s, 3.47573s/100 iters), loss = 1.86412
I0426 10:39:21.698740 12028 solver.cpp:238]     Train net output #0: loss = 1.86412 (* 1 = 1.86412 loss)
I0426 10:39:21.698743 12028 sgd_solver.cpp:105] Iteration 11900, lr = 0.001
I0426 10:39:25.104017 12028 solver.cpp:331] Iteration 12000, Testing net (#0)
I0426 10:39:25.740543 12036 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:39:26.139320 12028 solver.cpp:398]     Test net output #0: accuracy = 0.2695
I0426 10:39:26.139363 12028 solver.cpp:398]     Test net output #1: loss = 1.96142 (* 1 = 1.96142 loss)
I0426 10:39:26.178402 12028 solver.cpp:219] Iteration 12000 (22.3227 iter/s, 4.47974s/100 iters), loss = 2.07409
I0426 10:39:26.178443 12028 solver.cpp:238]     Train net output #0: loss = 2.07409 (* 1 = 2.07409 loss)
I0426 10:39:26.178448 12028 sgd_solver.cpp:105] Iteration 12000, lr = 0.001
I0426 10:39:29.650377 12028 solver.cpp:219] Iteration 12100 (28.8019 iter/s, 3.47199s/100 iters), loss = 1.90637
I0426 10:39:29.650421 12028 solver.cpp:238]     Train net output #0: loss = 1.90637 (* 1 = 1.90637 loss)
I0426 10:39:29.650425 12028 sgd_solver.cpp:105] Iteration 12100, lr = 0.001
I0426 10:39:31.660181 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:39:33.113414 12028 solver.cpp:219] Iteration 12200 (28.8763 iter/s, 3.46305s/100 iters), loss = 1.84692
I0426 10:39:33.113440 12028 solver.cpp:238]     Train net output #0: loss = 1.84692 (* 1 = 1.84692 loss)
I0426 10:39:33.113463 12028 sgd_solver.cpp:105] Iteration 12200, lr = 0.001
I0426 10:39:36.568532 12028 solver.cpp:219] Iteration 12300 (28.9423 iter/s, 3.45515s/100 iters), loss = 2.00165
I0426 10:39:36.568578 12028 solver.cpp:238]     Train net output #0: loss = 2.00165 (* 1 = 2.00165 loss)
I0426 10:39:36.568583 12028 sgd_solver.cpp:105] Iteration 12300, lr = 0.001
I0426 10:39:40.025163 12028 solver.cpp:219] Iteration 12400 (28.9298 iter/s, 3.45664s/100 iters), loss = 2.0305
I0426 10:39:40.025192 12028 solver.cpp:238]     Train net output #0: loss = 2.0305 (* 1 = 2.0305 loss)
I0426 10:39:40.025197 12028 sgd_solver.cpp:105] Iteration 12400, lr = 0.001
I0426 10:39:43.482188 12028 solver.cpp:219] Iteration 12500 (28.9263 iter/s, 3.45706s/100 iters), loss = 1.99337
I0426 10:39:43.482412 12028 solver.cpp:238]     Train net output #0: loss = 1.99337 (* 1 = 1.99337 loss)
I0426 10:39:43.482419 12028 sgd_solver.cpp:105] Iteration 12500, lr = 0.001
I0426 10:39:46.938184 12028 solver.cpp:219] Iteration 12600 (28.9364 iter/s, 3.45585s/100 iters), loss = 1.96921
I0426 10:39:46.938210 12028 solver.cpp:238]     Train net output #0: loss = 1.96921 (* 1 = 1.96921 loss)
I0426 10:39:46.938213 12028 sgd_solver.cpp:105] Iteration 12600, lr = 0.001
I0426 10:39:47.219239 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:39:50.398228 12028 solver.cpp:219] Iteration 12700 (28.9011 iter/s, 3.46008s/100 iters), loss = 1.93001
I0426 10:39:50.398257 12028 solver.cpp:238]     Train net output #0: loss = 1.93001 (* 1 = 1.93001 loss)
I0426 10:39:50.398262 12028 sgd_solver.cpp:105] Iteration 12700, lr = 0.001
I0426 10:39:53.866058 12028 solver.cpp:219] Iteration 12800 (28.8362 iter/s, 3.46786s/100 iters), loss = 1.88828
I0426 10:39:53.866101 12028 solver.cpp:238]     Train net output #0: loss = 1.88828 (* 1 = 1.88828 loss)
I0426 10:39:53.866104 12028 sgd_solver.cpp:105] Iteration 12800, lr = 0.001
I0426 10:39:57.319286 12028 solver.cpp:219] Iteration 12900 (28.9583 iter/s, 3.45325s/100 iters), loss = 1.96777
I0426 10:39:57.319334 12028 solver.cpp:238]     Train net output #0: loss = 1.96777 (* 1 = 1.96777 loss)
I0426 10:39:57.319353 12028 sgd_solver.cpp:105] Iteration 12900, lr = 0.001
I0426 10:40:00.729778 12028 solver.cpp:331] Iteration 13000, Testing net (#0)
I0426 10:40:01.363894 12036 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:40:01.761415 12028 solver.cpp:398]     Test net output #0: accuracy = 0.2793
I0426 10:40:01.761437 12028 solver.cpp:398]     Test net output #1: loss = 1.9368 (* 1 = 1.9368 loss)
I0426 10:40:01.800087 12028 solver.cpp:219] Iteration 13000 (22.3173 iter/s, 4.48083s/100 iters), loss = 1.89257
I0426 10:40:01.800109 12028 solver.cpp:238]     Train net output #0: loss = 1.89257 (* 1 = 1.89257 loss)
I0426 10:40:01.800115 12028 sgd_solver.cpp:105] Iteration 13000, lr = 0.001
I0426 10:40:03.838696 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:40:05.255940 12028 solver.cpp:219] Iteration 13100 (28.9361 iter/s, 3.45589s/100 iters), loss = 1.92745
I0426 10:40:05.255967 12028 solver.cpp:238]     Train net output #0: loss = 1.92745 (* 1 = 1.92745 loss)
I0426 10:40:05.255972 12028 sgd_solver.cpp:105] Iteration 13100, lr = 0.001
I0426 10:40:08.715142 12028 solver.cpp:219] Iteration 13200 (28.9082 iter/s, 3.45923s/100 iters), loss = 1.94409
I0426 10:40:08.715170 12028 solver.cpp:238]     Train net output #0: loss = 1.94409 (* 1 = 1.94409 loss)
I0426 10:40:08.715174 12028 sgd_solver.cpp:105] Iteration 13200, lr = 0.001
I0426 10:40:12.168226 12028 solver.cpp:219] Iteration 13300 (28.9594 iter/s, 3.45311s/100 iters), loss = 1.94492
I0426 10:40:12.168256 12028 solver.cpp:238]     Train net output #0: loss = 1.94492 (* 1 = 1.94492 loss)
I0426 10:40:12.168261 12028 sgd_solver.cpp:105] Iteration 13300, lr = 0.001
I0426 10:40:15.622772 12028 solver.cpp:219] Iteration 13400 (28.9471 iter/s, 3.45457s/100 iters), loss = 1.92288
I0426 10:40:15.622982 12028 solver.cpp:238]     Train net output #0: loss = 1.92288 (* 1 = 1.92288 loss)
I0426 10:40:15.622988 12028 sgd_solver.cpp:105] Iteration 13400, lr = 0.001
I0426 10:40:19.078713 12028 solver.cpp:219] Iteration 13500 (28.9369 iter/s, 3.45579s/100 iters), loss = 1.91486
I0426 10:40:19.078740 12028 solver.cpp:238]     Train net output #0: loss = 1.91486 (* 1 = 1.91486 loss)
I0426 10:40:19.078745 12028 sgd_solver.cpp:105] Iteration 13500, lr = 0.001
I0426 10:40:19.395264 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:40:22.539245 12028 solver.cpp:219] Iteration 13600 (28.897 iter/s, 3.46056s/100 iters), loss = 1.86589
I0426 10:40:22.539295 12028 solver.cpp:238]     Train net output #0: loss = 1.86589 (* 1 = 1.86589 loss)
I0426 10:40:22.539301 12028 sgd_solver.cpp:105] Iteration 13600, lr = 0.001
I0426 10:40:25.995514 12028 solver.cpp:219] Iteration 13700 (28.9329 iter/s, 3.45628s/100 iters), loss = 1.97069
I0426 10:40:25.995559 12028 solver.cpp:238]     Train net output #0: loss = 1.97069 (* 1 = 1.97069 loss)
I0426 10:40:25.995564 12028 sgd_solver.cpp:105] Iteration 13700, lr = 0.001
I0426 10:40:29.452215 12028 solver.cpp:219] Iteration 13800 (28.9292 iter/s, 3.45671s/100 iters), loss = 2.07103
I0426 10:40:29.452242 12028 solver.cpp:238]     Train net output #0: loss = 2.07103 (* 1 = 2.07103 loss)
I0426 10:40:29.452247 12028 sgd_solver.cpp:105] Iteration 13800, lr = 0.001
I0426 10:40:32.907869 12028 solver.cpp:219] Iteration 13900 (28.9378 iter/s, 3.45569s/100 iters), loss = 1.96203
I0426 10:40:32.907897 12028 solver.cpp:238]     Train net output #0: loss = 1.96203 (* 1 = 1.96203 loss)
I0426 10:40:32.907902 12028 sgd_solver.cpp:105] Iteration 13900, lr = 0.001
I0426 10:40:34.951969 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:40:36.319216 12028 solver.cpp:331] Iteration 14000, Testing net (#0)
I0426 10:40:36.954941 12036 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:40:37.352946 12028 solver.cpp:398]     Test net output #0: accuracy = 0.2782
I0426 10:40:37.352967 12028 solver.cpp:398]     Test net output #1: loss = 1.93079 (* 1 = 1.93079 loss)
I0426 10:40:37.391453 12028 solver.cpp:219] Iteration 14000 (22.3033 iter/s, 4.48364s/100 iters), loss = 1.95338
I0426 10:40:37.391477 12028 solver.cpp:238]     Train net output #0: loss = 1.95338 (* 1 = 1.95338 loss)
I0426 10:40:37.391482 12028 sgd_solver.cpp:105] Iteration 14000, lr = 0.001
I0426 10:40:40.847290 12028 solver.cpp:219] Iteration 14100 (28.9362 iter/s, 3.45587s/100 iters), loss = 2.04951
I0426 10:40:40.847337 12028 solver.cpp:238]     Train net output #0: loss = 2.04951 (* 1 = 2.04951 loss)
I0426 10:40:40.847342 12028 sgd_solver.cpp:105] Iteration 14100, lr = 0.001
I0426 10:40:44.304714 12028 solver.cpp:219] Iteration 14200 (28.9231 iter/s, 3.45744s/100 iters), loss = 2.02582
I0426 10:40:44.304741 12028 solver.cpp:238]     Train net output #0: loss = 2.02582 (* 1 = 2.02582 loss)
I0426 10:40:44.304746 12028 sgd_solver.cpp:105] Iteration 14200, lr = 0.001
I0426 10:40:47.760637 12028 solver.cpp:219] Iteration 14300 (28.9356 iter/s, 3.45595s/100 iters), loss = 2.05102
I0426 10:40:47.760812 12028 solver.cpp:238]     Train net output #0: loss = 2.05102 (* 1 = 2.05102 loss)
I0426 10:40:47.760819 12028 sgd_solver.cpp:105] Iteration 14300, lr = 0.001
I0426 10:40:51.217178 12028 solver.cpp:219] Iteration 14400 (28.9315 iter/s, 3.45644s/100 iters), loss = 1.81346
I0426 10:40:51.217209 12028 solver.cpp:238]     Train net output #0: loss = 1.81346 (* 1 = 1.81346 loss)
I0426 10:40:51.217214 12028 sgd_solver.cpp:105] Iteration 14400, lr = 0.001
I0426 10:40:51.567669 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:40:54.676442 12028 solver.cpp:219] Iteration 14500 (28.9077 iter/s, 3.45929s/100 iters), loss = 1.9914
I0426 10:40:54.676471 12028 solver.cpp:238]     Train net output #0: loss = 1.9914 (* 1 = 1.9914 loss)
I0426 10:40:54.676494 12028 sgd_solver.cpp:105] Iteration 14500, lr = 0.001
I0426 10:40:58.129484 12028 solver.cpp:219] Iteration 14600 (28.9597 iter/s, 3.45307s/100 iters), loss = 1.9309
I0426 10:40:58.129513 12028 solver.cpp:238]     Train net output #0: loss = 1.9309 (* 1 = 1.9309 loss)
I0426 10:40:58.129518 12028 sgd_solver.cpp:105] Iteration 14600, lr = 0.001
I0426 10:41:01.590898 12028 solver.cpp:219] Iteration 14700 (28.8897 iter/s, 3.46145s/100 iters), loss = 1.87719
I0426 10:41:01.590924 12028 solver.cpp:238]     Train net output #0: loss = 1.87719 (* 1 = 1.87719 loss)
I0426 10:41:01.590929 12028 sgd_solver.cpp:105] Iteration 14700, lr = 0.001
I0426 10:41:05.045784 12028 solver.cpp:219] Iteration 14800 (28.9442 iter/s, 3.45492s/100 iters), loss = 1.84273
I0426 10:41:05.045811 12028 solver.cpp:238]     Train net output #0: loss = 1.84273 (* 1 = 1.84273 loss)
I0426 10:41:05.045815 12028 sgd_solver.cpp:105] Iteration 14800, lr = 0.001
I0426 10:41:07.120826 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:41:08.504736 12028 solver.cpp:219] Iteration 14900 (28.9102 iter/s, 3.45898s/100 iters), loss = 1.95634
I0426 10:41:08.504765 12028 solver.cpp:238]     Train net output #0: loss = 1.95634 (* 1 = 1.95634 loss)
I0426 10:41:08.504768 12028 sgd_solver.cpp:105] Iteration 14900, lr = 0.001
I0426 10:41:11.906910 12028 solver.cpp:331] Iteration 15000, Testing net (#0)
I0426 10:41:12.543632 12036 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:41:12.943842 12028 solver.cpp:398]     Test net output #0: accuracy = 0.3012
I0426 10:41:12.943883 12028 solver.cpp:398]     Test net output #1: loss = 1.89744 (* 1 = 1.89744 loss)
I0426 10:41:12.982316 12028 solver.cpp:219] Iteration 15000 (22.3332 iter/s, 4.47763s/100 iters), loss = 2.00174
I0426 10:41:12.982338 12028 solver.cpp:238]     Train net output #0: loss = 2.00174 (* 1 = 2.00174 loss)
I0426 10:41:12.982362 12028 sgd_solver.cpp:105] Iteration 15000, lr = 0.001
I0426 10:41:16.438843 12028 solver.cpp:219] Iteration 15100 (28.9305 iter/s, 3.45657s/100 iters), loss = 1.79654
I0426 10:41:16.438870 12028 solver.cpp:238]     Train net output #0: loss = 1.79654 (* 1 = 1.79654 loss)
I0426 10:41:16.438875 12028 sgd_solver.cpp:105] Iteration 15100, lr = 0.001
I0426 10:41:19.892330 12028 solver.cpp:219] Iteration 15200 (28.9559 iter/s, 3.45352s/100 iters), loss = 1.88411
I0426 10:41:19.892504 12028 solver.cpp:238]     Train net output #0: loss = 1.88411 (* 1 = 1.88411 loss)
I0426 10:41:19.892509 12028 sgd_solver.cpp:105] Iteration 15200, lr = 0.001
I0426 10:41:23.350940 12028 solver.cpp:219] Iteration 15300 (28.9143 iter/s, 3.4585s/100 iters), loss = 1.89495
I0426 10:41:23.350971 12028 solver.cpp:238]     Train net output #0: loss = 1.89495 (* 1 = 1.89495 loss)
I0426 10:41:23.350993 12028 sgd_solver.cpp:105] Iteration 15300, lr = 0.001
I0426 10:41:23.734870 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:41:26.808707 12028 solver.cpp:219] Iteration 15400 (28.9202 iter/s, 3.45779s/100 iters), loss = 1.99584
I0426 10:41:26.808735 12028 solver.cpp:238]     Train net output #0: loss = 1.99584 (* 1 = 1.99584 loss)
I0426 10:41:26.808739 12028 sgd_solver.cpp:105] Iteration 15400, lr = 0.001
I0426 10:41:30.262331 12028 solver.cpp:219] Iteration 15500 (28.9549 iter/s, 3.45365s/100 iters), loss = 1.91808
I0426 10:41:30.262358 12028 solver.cpp:238]     Train net output #0: loss = 1.91808 (* 1 = 1.91808 loss)
I0426 10:41:30.262363 12028 sgd_solver.cpp:105] Iteration 15500, lr = 0.001
I0426 10:41:33.716213 12028 solver.cpp:219] Iteration 15600 (28.9527 iter/s, 3.45391s/100 iters), loss = 1.94689
I0426 10:41:33.716240 12028 solver.cpp:238]     Train net output #0: loss = 1.94689 (* 1 = 1.94689 loss)
I0426 10:41:33.716245 12028 sgd_solver.cpp:105] Iteration 15600, lr = 0.001
I0426 10:41:37.171205 12028 solver.cpp:219] Iteration 15700 (28.9434 iter/s, 3.45502s/100 iters), loss = 1.94522
I0426 10:41:37.171232 12028 solver.cpp:238]     Train net output #0: loss = 1.94522 (* 1 = 1.94522 loss)
I0426 10:41:37.171237 12028 sgd_solver.cpp:105] Iteration 15700, lr = 0.001
I0426 10:41:39.289441 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:41:40.640386 12028 solver.cpp:219] Iteration 15800 (28.825 iter/s, 3.46922s/100 iters), loss = 1.8763
I0426 10:41:40.640414 12028 solver.cpp:238]     Train net output #0: loss = 1.8763 (* 1 = 1.8763 loss)
I0426 10:41:40.640419 12028 sgd_solver.cpp:105] Iteration 15800, lr = 0.001
I0426 10:41:44.100600 12028 solver.cpp:219] Iteration 15900 (28.8997 iter/s, 3.46024s/100 iters), loss = 2.04124
I0426 10:41:44.100648 12028 solver.cpp:238]     Train net output #0: loss = 2.04124 (* 1 = 2.04124 loss)
I0426 10:41:44.100653 12028 sgd_solver.cpp:105] Iteration 15900, lr = 0.001
I0426 10:41:47.514322 12028 solver.cpp:331] Iteration 16000, Testing net (#0)
I0426 10:41:48.150377 12036 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:41:48.555909 12028 solver.cpp:398]     Test net output #0: accuracy = 0.3051
I0426 10:41:48.555949 12028 solver.cpp:398]     Test net output #1: loss = 1.88119 (* 1 = 1.88119 loss)
I0426 10:41:48.594640 12028 solver.cpp:219] Iteration 16000 (22.2514 iter/s, 4.49409s/100 iters), loss = 1.67818
I0426 10:41:48.594696 12028 solver.cpp:238]     Train net output #0: loss = 1.67818 (* 1 = 1.67818 loss)
I0426 10:41:48.594715 12028 sgd_solver.cpp:105] Iteration 16000, lr = 0.001
I0426 10:41:52.066220 12028 solver.cpp:219] Iteration 16100 (28.8053 iter/s, 3.47158s/100 iters), loss = 1.89966
I0426 10:41:52.066318 12028 solver.cpp:238]     Train net output #0: loss = 1.89966 (* 1 = 1.89966 loss)
I0426 10:41:52.066340 12028 sgd_solver.cpp:105] Iteration 16100, lr = 0.001
I0426 10:41:55.536614 12028 solver.cpp:219] Iteration 16200 (28.8155 iter/s, 3.47036s/100 iters), loss = 1.76489
I0426 10:41:55.536640 12028 solver.cpp:238]     Train net output #0: loss = 1.76489 (* 1 = 1.76489 loss)
I0426 10:41:55.536645 12028 sgd_solver.cpp:105] Iteration 16200, lr = 0.001
I0426 10:41:55.957223 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:41:58.997349 12028 solver.cpp:219] Iteration 16300 (28.8953 iter/s, 3.46077s/100 iters), loss = 1.8613
I0426 10:41:58.997381 12028 solver.cpp:238]     Train net output #0: loss = 1.8613 (* 1 = 1.8613 loss)
I0426 10:41:58.997404 12028 sgd_solver.cpp:105] Iteration 16300, lr = 0.001
I0426 10:42:02.465960 12028 solver.cpp:219] Iteration 16400 (28.8298 iter/s, 3.46864s/100 iters), loss = 1.87494
I0426 10:42:02.465988 12028 solver.cpp:238]     Train net output #0: loss = 1.87494 (* 1 = 1.87494 loss)
I0426 10:42:02.465993 12028 sgd_solver.cpp:105] Iteration 16400, lr = 0.001
I0426 10:42:05.929028 12028 solver.cpp:219] Iteration 16500 (28.8759 iter/s, 3.4631s/100 iters), loss = 1.94397
I0426 10:42:05.929055 12028 solver.cpp:238]     Train net output #0: loss = 1.94397 (* 1 = 1.94397 loss)
I0426 10:42:05.929059 12028 sgd_solver.cpp:105] Iteration 16500, lr = 0.001
I0426 10:42:09.396402 12028 solver.cpp:219] Iteration 16600 (28.84 iter/s, 3.46741s/100 iters), loss = 1.7941
I0426 10:42:09.396447 12028 solver.cpp:238]     Train net output #0: loss = 1.7941 (* 1 = 1.7941 loss)
I0426 10:42:09.396452 12028 sgd_solver.cpp:105] Iteration 16600, lr = 0.001
I0426 10:42:11.541328 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:42:12.855492 12028 solver.cpp:219] Iteration 16700 (28.9092 iter/s, 3.4591s/100 iters), loss = 1.69911
I0426 10:42:12.855520 12028 solver.cpp:238]     Train net output #0: loss = 1.69911 (* 1 = 1.69911 loss)
I0426 10:42:12.855523 12028 sgd_solver.cpp:105] Iteration 16700, lr = 0.001
I0426 10:42:16.316704 12028 solver.cpp:219] Iteration 16800 (28.8913 iter/s, 3.46125s/100 iters), loss = 1.8871
I0426 10:42:16.316750 12028 solver.cpp:238]     Train net output #0: loss = 1.8871 (* 1 = 1.8871 loss)
I0426 10:42:16.316753 12028 sgd_solver.cpp:105] Iteration 16800, lr = 0.001
I0426 10:42:19.770262 12028 solver.cpp:219] Iteration 16900 (28.9555 iter/s, 3.45357s/100 iters), loss = 1.84837
I0426 10:42:19.770292 12028 solver.cpp:238]     Train net output #0: loss = 1.84837 (* 1 = 1.84837 loss)
I0426 10:42:19.770315 12028 sgd_solver.cpp:105] Iteration 16900, lr = 0.001
I0426 10:42:23.181655 12028 solver.cpp:331] Iteration 17000, Testing net (#0)
I0426 10:42:23.817203 12036 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:42:24.216078 12028 solver.cpp:398]     Test net output #0: accuracy = 0.2982
I0426 10:42:24.216099 12028 solver.cpp:398]     Test net output #1: loss = 1.90119 (* 1 = 1.90119 loss)
I0426 10:42:24.255175 12028 solver.cpp:219] Iteration 17000 (22.2967 iter/s, 4.48497s/100 iters), loss = 1.83329
I0426 10:42:24.255216 12028 solver.cpp:238]     Train net output #0: loss = 1.83329 (* 1 = 1.83329 loss)
I0426 10:42:24.255223 12028 sgd_solver.cpp:105] Iteration 17000, lr = 0.001
I0426 10:42:27.718657 12028 solver.cpp:219] Iteration 17100 (28.8725 iter/s, 3.4635s/100 iters), loss = 1.82768
I0426 10:42:27.718684 12028 solver.cpp:238]     Train net output #0: loss = 1.82768 (* 1 = 1.82768 loss)
I0426 10:42:27.718688 12028 sgd_solver.cpp:105] Iteration 17100, lr = 0.001
I0426 10:42:28.172181 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:42:31.179101 12028 solver.cpp:219] Iteration 17200 (28.8977 iter/s, 3.46048s/100 iters), loss = 1.88339
I0426 10:42:31.179131 12028 solver.cpp:238]     Train net output #0: loss = 1.88339 (* 1 = 1.88339 loss)
I0426 10:42:31.179153 12028 sgd_solver.cpp:105] Iteration 17200, lr = 0.001
I0426 10:42:34.639869 12028 solver.cpp:219] Iteration 17300 (28.895 iter/s, 3.4608s/100 iters), loss = 1.85117
I0426 10:42:34.639916 12028 solver.cpp:238]     Train net output #0: loss = 1.85117 (* 1 = 1.85117 loss)
I0426 10:42:34.639920 12028 sgd_solver.cpp:105] Iteration 17300, lr = 0.001
I0426 10:42:38.108788 12028 solver.cpp:219] Iteration 17400 (28.8273 iter/s, 3.46893s/100 iters), loss = 1.90421
I0426 10:42:38.108814 12028 solver.cpp:238]     Train net output #0: loss = 1.90421 (* 1 = 1.90421 loss)
I0426 10:42:38.108837 12028 sgd_solver.cpp:105] Iteration 17400, lr = 0.001
I0426 10:42:41.576699 12028 solver.cpp:219] Iteration 17500 (28.8355 iter/s, 3.46795s/100 iters), loss = 1.87678
I0426 10:42:41.576725 12028 solver.cpp:238]     Train net output #0: loss = 1.87678 (* 1 = 1.87678 loss)
I0426 10:42:41.576730 12028 sgd_solver.cpp:105] Iteration 17500, lr = 0.001
I0426 10:42:43.755973 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:42:45.040761 12028 solver.cpp:219] Iteration 17600 (28.8675 iter/s, 3.4641s/100 iters), loss = 1.91272
I0426 10:42:45.040807 12028 solver.cpp:238]     Train net output #0: loss = 1.91272 (* 1 = 1.91272 loss)
I0426 10:42:45.040812 12028 sgd_solver.cpp:105] Iteration 17600, lr = 0.001
I0426 10:42:48.507943 12028 solver.cpp:219] Iteration 17700 (28.8416 iter/s, 3.46722s/100 iters), loss = 1.91415
I0426 10:42:48.507992 12028 solver.cpp:238]     Train net output #0: loss = 1.91415 (* 1 = 1.91415 loss)
I0426 10:42:48.507997 12028 sgd_solver.cpp:105] Iteration 17700, lr = 0.001
I0426 10:42:51.976289 12028 solver.cpp:219] Iteration 17800 (28.8321 iter/s, 3.46836s/100 iters), loss = 1.90855
I0426 10:42:51.976338 12028 solver.cpp:238]     Train net output #0: loss = 1.90855 (* 1 = 1.90855 loss)
I0426 10:42:51.976343 12028 sgd_solver.cpp:105] Iteration 17800, lr = 0.001
I0426 10:42:55.442447 12028 solver.cpp:219] Iteration 17900 (28.8503 iter/s, 3.46617s/100 iters), loss = 1.87696
I0426 10:42:55.442574 12028 solver.cpp:238]     Train net output #0: loss = 1.87696 (* 1 = 1.87696 loss)
I0426 10:42:55.442579 12028 sgd_solver.cpp:105] Iteration 17900, lr = 0.001
I0426 10:42:58.843753 12028 solver.cpp:331] Iteration 18000, Testing net (#0)
I0426 10:42:59.480571 12036 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:42:59.879699 12028 solver.cpp:398]     Test net output #0: accuracy = 0.307
I0426 10:42:59.879721 12028 solver.cpp:398]     Test net output #1: loss = 1.85657 (* 1 = 1.85657 loss)
I0426 10:42:59.918479 12028 solver.cpp:219] Iteration 18000 (22.3414 iter/s, 4.47599s/100 iters), loss = 2.0605
I0426 10:42:59.918499 12028 solver.cpp:238]     Train net output #0: loss = 2.0605 (* 1 = 2.0605 loss)
I0426 10:42:59.918522 12028 sgd_solver.cpp:105] Iteration 18000, lr = 0.001
I0426 10:43:00.415769 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:43:03.398231 12028 solver.cpp:219] Iteration 18100 (28.7373 iter/s, 3.47979s/100 iters), loss = 1.77077
I0426 10:43:03.398262 12028 solver.cpp:238]     Train net output #0: loss = 1.77077 (* 1 = 1.77077 loss)
I0426 10:43:03.398267 12028 sgd_solver.cpp:105] Iteration 18100, lr = 0.001
I0426 10:43:06.851781 12028 solver.cpp:219] Iteration 18200 (28.9555 iter/s, 3.45358s/100 iters), loss = 1.8457
I0426 10:43:06.851810 12028 solver.cpp:238]     Train net output #0: loss = 1.8457 (* 1 = 1.8457 loss)
I0426 10:43:06.851814 12028 sgd_solver.cpp:105] Iteration 18200, lr = 0.001
I0426 10:43:10.305734 12028 solver.cpp:219] Iteration 18300 (28.9521 iter/s, 3.45398s/100 iters), loss = 1.84261
I0426 10:43:10.305763 12028 solver.cpp:238]     Train net output #0: loss = 1.84261 (* 1 = 1.84261 loss)
I0426 10:43:10.305768 12028 sgd_solver.cpp:105] Iteration 18300, lr = 0.001
I0426 10:43:13.768102 12028 solver.cpp:219] Iteration 18400 (28.8817 iter/s, 3.4624s/100 iters), loss = 1.70557
I0426 10:43:13.768129 12028 solver.cpp:238]     Train net output #0: loss = 1.70557 (* 1 = 1.70557 loss)
I0426 10:43:13.768134 12028 sgd_solver.cpp:105] Iteration 18400, lr = 0.001
I0426 10:43:15.984977 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:43:17.230535 12028 solver.cpp:219] Iteration 18500 (28.8811 iter/s, 3.46247s/100 iters), loss = 1.85332
I0426 10:43:17.230563 12028 solver.cpp:238]     Train net output #0: loss = 1.85332 (* 1 = 1.85332 loss)
I0426 10:43:17.230568 12028 sgd_solver.cpp:105] Iteration 18500, lr = 0.001
I0426 10:43:20.702726 12028 solver.cpp:219] Iteration 18600 (28.8 iter/s, 3.47223s/100 iters), loss = 1.8831
I0426 10:43:20.702754 12028 solver.cpp:238]     Train net output #0: loss = 1.8831 (* 1 = 1.8831 loss)
I0426 10:43:20.702771 12028 sgd_solver.cpp:105] Iteration 18600, lr = 0.001
I0426 10:43:24.168524 12028 solver.cpp:219] Iteration 18700 (28.8531 iter/s, 3.46583s/100 iters), loss = 1.89401
I0426 10:43:24.168567 12028 solver.cpp:238]     Train net output #0: loss = 1.89401 (* 1 = 1.89401 loss)
I0426 10:43:24.168572 12028 sgd_solver.cpp:105] Iteration 18700, lr = 0.001
I0426 10:43:27.635087 12028 solver.cpp:219] Iteration 18800 (28.8469 iter/s, 3.46658s/100 iters), loss = 1.75352
I0426 10:43:27.635218 12028 solver.cpp:238]     Train net output #0: loss = 1.75352 (* 1 = 1.75352 loss)
I0426 10:43:27.635224 12028 sgd_solver.cpp:105] Iteration 18800, lr = 0.001
I0426 10:43:31.092685 12028 solver.cpp:219] Iteration 18900 (28.9224 iter/s, 3.45753s/100 iters), loss = 1.86248
I0426 10:43:31.092730 12028 solver.cpp:238]     Train net output #0: loss = 1.86248 (* 1 = 1.86248 loss)
I0426 10:43:31.092749 12028 sgd_solver.cpp:105] Iteration 18900, lr = 0.001
I0426 10:43:31.579831 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:43:34.492234 12028 solver.cpp:331] Iteration 19000, Testing net (#0)
I0426 10:43:35.124502 12036 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:43:35.523000 12028 solver.cpp:398]     Test net output #0: accuracy = 0.3183
I0426 10:43:35.523023 12028 solver.cpp:398]     Test net output #1: loss = 1.84748 (* 1 = 1.84748 loss)
I0426 10:43:35.561574 12028 solver.cpp:219] Iteration 19000 (22.3767 iter/s, 4.46893s/100 iters), loss = 1.88992
I0426 10:43:35.561595 12028 solver.cpp:238]     Train net output #0: loss = 1.88992 (* 1 = 1.88992 loss)
I0426 10:43:35.561620 12028 sgd_solver.cpp:105] Iteration 19000, lr = 0.001
I0426 10:43:39.026892 12028 solver.cpp:219] Iteration 19100 (28.857 iter/s, 3.46536s/100 iters), loss = 1.88392
I0426 10:43:39.026921 12028 solver.cpp:238]     Train net output #0: loss = 1.88392 (* 1 = 1.88392 loss)
I0426 10:43:39.026943 12028 sgd_solver.cpp:105] Iteration 19100, lr = 0.001
I0426 10:43:42.473459 12028 solver.cpp:219] Iteration 19200 (29.0141 iter/s, 3.4466s/100 iters), loss = 1.90856
I0426 10:43:42.473487 12028 solver.cpp:238]     Train net output #0: loss = 1.90856 (* 1 = 1.90856 loss)
I0426 10:43:42.473492 12028 sgd_solver.cpp:105] Iteration 19200, lr = 0.001
I0426 10:43:45.933192 12028 solver.cpp:219] Iteration 19300 (28.9037 iter/s, 3.45976s/100 iters), loss = 1.7698
I0426 10:43:45.933219 12028 solver.cpp:238]     Train net output #0: loss = 1.7698 (* 1 = 1.7698 loss)
I0426 10:43:45.933223 12028 sgd_solver.cpp:105] Iteration 19300, lr = 0.001
I0426 10:43:48.182873 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:43:49.397742 12028 solver.cpp:219] Iteration 19400 (28.8635 iter/s, 3.46459s/100 iters), loss = 1.9211
I0426 10:43:49.397771 12028 solver.cpp:238]     Train net output #0: loss = 1.9211 (* 1 = 1.9211 loss)
I0426 10:43:49.397776 12028 sgd_solver.cpp:105] Iteration 19400, lr = 0.001
I0426 10:43:52.860965 12028 solver.cpp:219] Iteration 19500 (28.8746 iter/s, 3.46325s/100 iters), loss = 1.72969
I0426 10:43:52.861013 12028 solver.cpp:238]     Train net output #0: loss = 1.72969 (* 1 = 1.72969 loss)
I0426 10:43:52.861019 12028 sgd_solver.cpp:105] Iteration 19500, lr = 0.001
I0426 10:43:56.323158 12028 solver.cpp:219] Iteration 19600 (28.8832 iter/s, 3.46222s/100 iters), loss = 1.9036
I0426 10:43:56.323204 12028 solver.cpp:238]     Train net output #0: loss = 1.9036 (* 1 = 1.9036 loss)
I0426 10:43:56.323207 12028 sgd_solver.cpp:105] Iteration 19600, lr = 0.001
I0426 10:43:59.932302 12028 solver.cpp:219] Iteration 19700 (27.7073 iter/s, 3.60916s/100 iters), loss = 1.7327
I0426 10:43:59.932457 12028 solver.cpp:238]     Train net output #0: loss = 1.7327 (* 1 = 1.7327 loss)
I0426 10:43:59.932464 12028 sgd_solver.cpp:105] Iteration 19700, lr = 0.001
I0426 10:44:03.528921 12028 solver.cpp:219] Iteration 19800 (27.8046 iter/s, 3.59653s/100 iters), loss = 2.03997
I0426 10:44:03.528947 12028 solver.cpp:238]     Train net output #0: loss = 2.03997 (* 1 = 2.03997 loss)
I0426 10:44:03.528952 12028 sgd_solver.cpp:105] Iteration 19800, lr = 0.001
I0426 10:44:04.065181 12035 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:44:07.054471 12028 solver.cpp:219] Iteration 19900 (28.3641 iter/s, 3.52559s/100 iters), loss = 2.063
I0426 10:44:07.054517 12028 solver.cpp:238]     Train net output #0: loss = 2.063 (* 1 = 2.063 loss)
I0426 10:44:07.054520 12028 sgd_solver.cpp:105] Iteration 19900, lr = 0.001
I0426 10:44:10.498361 12028 solver.cpp:448] Snapshotting to binary proto file examples/cifar10_full_sigmoid_iter_20000.caffemodel
I0426 10:44:10.516603 12028 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_sigmoid_iter_20000.solverstate
I0426 10:44:10.533342 12028 solver.cpp:311] Iteration 20000, loss = 1.83824
I0426 10:44:10.533361 12028 solver.cpp:331] Iteration 20000, Testing net (#0)
I0426 10:44:11.162945 12036 data_layer.cpp:73] Restarting data prefetching from start.
I0426 10:44:11.568341 12028 solver.cpp:398]     Test net output #0: accuracy = 0.3185
I0426 10:44:11.568374 12028 solver.cpp:398]     Test net output #1: loss = 1.83808 (* 1 = 1.83808 loss)
I0426 10:44:11.568379 12028 solver.cpp:316] Optimization Done.
I0426 10:44:11.568382 12028 caffe.cpp:259] Optimization Done.
