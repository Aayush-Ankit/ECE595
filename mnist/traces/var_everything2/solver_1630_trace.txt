I0428 20:36:01.454726  4734 caffe.cpp:218] Using GPUs 0
I0428 20:36:01.492043  4734 caffe.cpp:223] GPU 0: TITAN X (Pascal)
I0428 20:36:02.003682  4734 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 1000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_everything2/lenet_train_test1630.prototxt"
train_state {
  level: 0
  stage: ""
}
I0428 20:36:02.003829  4734 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1630.prototxt
I0428 20:36:02.004245  4734 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0428 20:36:02.004263  4734 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0428 20:36:02.004367  4734 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:36:02.004452  4734 layer_factory.hpp:77] Creating layer mnist
I0428 20:36:02.004559  4734 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0428 20:36:02.004583  4734 net.cpp:86] Creating Layer mnist
I0428 20:36:02.004591  4734 net.cpp:382] mnist -> data
I0428 20:36:02.004613  4734 net.cpp:382] mnist -> label
I0428 20:36:02.005759  4734 data_layer.cpp:45] output data size: 64,1,28,28
I0428 20:36:02.008221  4734 net.cpp:124] Setting up mnist
I0428 20:36:02.008239  4734 net.cpp:131] Top shape: 64 1 28 28 (50176)
I0428 20:36:02.008246  4734 net.cpp:131] Top shape: 64 (64)
I0428 20:36:02.008250  4734 net.cpp:139] Memory required for data: 200960
I0428 20:36:02.008257  4734 layer_factory.hpp:77] Creating layer conv0
I0428 20:36:02.008273  4734 net.cpp:86] Creating Layer conv0
I0428 20:36:02.008294  4734 net.cpp:408] conv0 <- data
I0428 20:36:02.008308  4734 net.cpp:382] conv0 -> conv0
I0428 20:36:02.291463  4734 net.cpp:124] Setting up conv0
I0428 20:36:02.291491  4734 net.cpp:131] Top shape: 64 100 24 24 (3686400)
I0428 20:36:02.291494  4734 net.cpp:139] Memory required for data: 14946560
I0428 20:36:02.291510  4734 layer_factory.hpp:77] Creating layer pool0
I0428 20:36:02.291523  4734 net.cpp:86] Creating Layer pool0
I0428 20:36:02.291527  4734 net.cpp:408] pool0 <- conv0
I0428 20:36:02.291533  4734 net.cpp:382] pool0 -> pool0
I0428 20:36:02.291592  4734 net.cpp:124] Setting up pool0
I0428 20:36:02.291600  4734 net.cpp:131] Top shape: 64 100 12 12 (921600)
I0428 20:36:02.291604  4734 net.cpp:139] Memory required for data: 18632960
I0428 20:36:02.291606  4734 layer_factory.hpp:77] Creating layer conv1
I0428 20:36:02.291617  4734 net.cpp:86] Creating Layer conv1
I0428 20:36:02.291622  4734 net.cpp:408] conv1 <- pool0
I0428 20:36:02.291627  4734 net.cpp:382] conv1 -> conv1
I0428 20:36:02.295104  4734 net.cpp:124] Setting up conv1
I0428 20:36:02.295120  4734 net.cpp:131] Top shape: 64 50 8 8 (204800)
I0428 20:36:02.295122  4734 net.cpp:139] Memory required for data: 19452160
I0428 20:36:02.295131  4734 layer_factory.hpp:77] Creating layer pool1
I0428 20:36:02.295140  4734 net.cpp:86] Creating Layer pool1
I0428 20:36:02.295143  4734 net.cpp:408] pool1 <- conv1
I0428 20:36:02.295148  4734 net.cpp:382] pool1 -> pool1
I0428 20:36:02.295186  4734 net.cpp:124] Setting up pool1
I0428 20:36:02.295197  4734 net.cpp:131] Top shape: 64 50 4 4 (51200)
I0428 20:36:02.295200  4734 net.cpp:139] Memory required for data: 19656960
I0428 20:36:02.295203  4734 layer_factory.hpp:77] Creating layer ip1
I0428 20:36:02.295212  4734 net.cpp:86] Creating Layer ip1
I0428 20:36:02.295217  4734 net.cpp:408] ip1 <- pool1
I0428 20:36:02.295222  4734 net.cpp:382] ip1 -> ip1
I0428 20:36:02.295552  4734 net.cpp:124] Setting up ip1
I0428 20:36:02.295560  4734 net.cpp:131] Top shape: 64 50 (3200)
I0428 20:36:02.295563  4734 net.cpp:139] Memory required for data: 19669760
I0428 20:36:02.295572  4734 layer_factory.hpp:77] Creating layer relu1
I0428 20:36:02.295577  4734 net.cpp:86] Creating Layer relu1
I0428 20:36:02.295580  4734 net.cpp:408] relu1 <- ip1
I0428 20:36:02.295584  4734 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:36:02.295756  4734 net.cpp:124] Setting up relu1
I0428 20:36:02.295765  4734 net.cpp:131] Top shape: 64 50 (3200)
I0428 20:36:02.295768  4734 net.cpp:139] Memory required for data: 19682560
I0428 20:36:02.295773  4734 layer_factory.hpp:77] Creating layer ip2
I0428 20:36:02.295778  4734 net.cpp:86] Creating Layer ip2
I0428 20:36:02.295781  4734 net.cpp:408] ip2 <- ip1
I0428 20:36:02.295786  4734 net.cpp:382] ip2 -> ip2
I0428 20:36:02.295886  4734 net.cpp:124] Setting up ip2
I0428 20:36:02.295892  4734 net.cpp:131] Top shape: 64 10 (640)
I0428 20:36:02.295895  4734 net.cpp:139] Memory required for data: 19685120
I0428 20:36:02.295902  4734 layer_factory.hpp:77] Creating layer relu2
I0428 20:36:02.295907  4734 net.cpp:86] Creating Layer relu2
I0428 20:36:02.295912  4734 net.cpp:408] relu2 <- ip2
I0428 20:36:02.295915  4734 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:36:02.296670  4734 net.cpp:124] Setting up relu2
I0428 20:36:02.296684  4734 net.cpp:131] Top shape: 64 10 (640)
I0428 20:36:02.296686  4734 net.cpp:139] Memory required for data: 19687680
I0428 20:36:02.296690  4734 layer_factory.hpp:77] Creating layer ip3
I0428 20:36:02.296697  4734 net.cpp:86] Creating Layer ip3
I0428 20:36:02.296700  4734 net.cpp:408] ip3 <- ip2
I0428 20:36:02.296707  4734 net.cpp:382] ip3 -> ip3
I0428 20:36:02.296820  4734 net.cpp:124] Setting up ip3
I0428 20:36:02.296828  4734 net.cpp:131] Top shape: 64 10 (640)
I0428 20:36:02.296831  4734 net.cpp:139] Memory required for data: 19690240
I0428 20:36:02.296856  4734 layer_factory.hpp:77] Creating layer relu3
I0428 20:36:02.296864  4734 net.cpp:86] Creating Layer relu3
I0428 20:36:02.296867  4734 net.cpp:408] relu3 <- ip3
I0428 20:36:02.296872  4734 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:36:02.297081  4734 net.cpp:124] Setting up relu3
I0428 20:36:02.297091  4734 net.cpp:131] Top shape: 64 10 (640)
I0428 20:36:02.297094  4734 net.cpp:139] Memory required for data: 19692800
I0428 20:36:02.297098  4734 layer_factory.hpp:77] Creating layer loss
I0428 20:36:02.297104  4734 net.cpp:86] Creating Layer loss
I0428 20:36:02.297107  4734 net.cpp:408] loss <- ip3
I0428 20:36:02.297111  4734 net.cpp:408] loss <- label
I0428 20:36:02.297118  4734 net.cpp:382] loss -> loss
I0428 20:36:02.297138  4734 layer_factory.hpp:77] Creating layer loss
I0428 20:36:02.297469  4734 net.cpp:124] Setting up loss
I0428 20:36:02.297479  4734 net.cpp:131] Top shape: (1)
I0428 20:36:02.297482  4734 net.cpp:134]     with loss weight 1
I0428 20:36:02.297498  4734 net.cpp:139] Memory required for data: 19692804
I0428 20:36:02.297502  4734 net.cpp:200] loss needs backward computation.
I0428 20:36:02.297507  4734 net.cpp:200] relu3 needs backward computation.
I0428 20:36:02.297509  4734 net.cpp:200] ip3 needs backward computation.
I0428 20:36:02.297513  4734 net.cpp:200] relu2 needs backward computation.
I0428 20:36:02.297515  4734 net.cpp:200] ip2 needs backward computation.
I0428 20:36:02.297519  4734 net.cpp:200] relu1 needs backward computation.
I0428 20:36:02.297521  4734 net.cpp:200] ip1 needs backward computation.
I0428 20:36:02.297525  4734 net.cpp:200] pool1 needs backward computation.
I0428 20:36:02.297528  4734 net.cpp:200] conv1 needs backward computation.
I0428 20:36:02.297531  4734 net.cpp:200] pool0 needs backward computation.
I0428 20:36:02.297534  4734 net.cpp:200] conv0 needs backward computation.
I0428 20:36:02.297538  4734 net.cpp:202] mnist does not need backward computation.
I0428 20:36:02.297541  4734 net.cpp:244] This network produces output loss
I0428 20:36:02.297552  4734 net.cpp:257] Network initialization done.
I0428 20:36:02.297930  4734 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1630.prototxt
I0428 20:36:02.297973  4734 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0428 20:36:02.298089  4734 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:36:02.298187  4734 layer_factory.hpp:77] Creating layer mnist
I0428 20:36:02.298230  4734 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0428 20:36:02.298243  4734 net.cpp:86] Creating Layer mnist
I0428 20:36:02.298249  4734 net.cpp:382] mnist -> data
I0428 20:36:02.298256  4734 net.cpp:382] mnist -> label
I0428 20:36:02.298377  4734 data_layer.cpp:45] output data size: 100,1,28,28
I0428 20:36:02.299705  4734 net.cpp:124] Setting up mnist
I0428 20:36:02.299717  4734 net.cpp:131] Top shape: 100 1 28 28 (78400)
I0428 20:36:02.299741  4734 net.cpp:131] Top shape: 100 (100)
I0428 20:36:02.299743  4734 net.cpp:139] Memory required for data: 314000
I0428 20:36:02.299747  4734 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0428 20:36:02.299770  4734 net.cpp:86] Creating Layer label_mnist_1_split
I0428 20:36:02.299773  4734 net.cpp:408] label_mnist_1_split <- label
I0428 20:36:02.299778  4734 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_0
I0428 20:36:02.299785  4734 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_1
I0428 20:36:02.299831  4734 net.cpp:124] Setting up label_mnist_1_split
I0428 20:36:02.299839  4734 net.cpp:131] Top shape: 100 (100)
I0428 20:36:02.299842  4734 net.cpp:131] Top shape: 100 (100)
I0428 20:36:02.299845  4734 net.cpp:139] Memory required for data: 314800
I0428 20:36:02.299849  4734 layer_factory.hpp:77] Creating layer conv0
I0428 20:36:02.299859  4734 net.cpp:86] Creating Layer conv0
I0428 20:36:02.299862  4734 net.cpp:408] conv0 <- data
I0428 20:36:02.299870  4734 net.cpp:382] conv0 -> conv0
I0428 20:36:02.301579  4734 net.cpp:124] Setting up conv0
I0428 20:36:02.301594  4734 net.cpp:131] Top shape: 100 100 24 24 (5760000)
I0428 20:36:02.301614  4734 net.cpp:139] Memory required for data: 23354800
I0428 20:36:02.301638  4734 layer_factory.hpp:77] Creating layer pool0
I0428 20:36:02.301646  4734 net.cpp:86] Creating Layer pool0
I0428 20:36:02.301650  4734 net.cpp:408] pool0 <- conv0
I0428 20:36:02.301669  4734 net.cpp:382] pool0 -> pool0
I0428 20:36:02.301725  4734 net.cpp:124] Setting up pool0
I0428 20:36:02.301733  4734 net.cpp:131] Top shape: 100 100 12 12 (1440000)
I0428 20:36:02.301736  4734 net.cpp:139] Memory required for data: 29114800
I0428 20:36:02.301739  4734 layer_factory.hpp:77] Creating layer conv1
I0428 20:36:02.301749  4734 net.cpp:86] Creating Layer conv1
I0428 20:36:02.301754  4734 net.cpp:408] conv1 <- pool0
I0428 20:36:02.301760  4734 net.cpp:382] conv1 -> conv1
I0428 20:36:02.304962  4734 net.cpp:124] Setting up conv1
I0428 20:36:02.304976  4734 net.cpp:131] Top shape: 100 50 8 8 (320000)
I0428 20:36:02.304980  4734 net.cpp:139] Memory required for data: 30394800
I0428 20:36:02.304987  4734 layer_factory.hpp:77] Creating layer pool1
I0428 20:36:02.304994  4734 net.cpp:86] Creating Layer pool1
I0428 20:36:02.304997  4734 net.cpp:408] pool1 <- conv1
I0428 20:36:02.305004  4734 net.cpp:382] pool1 -> pool1
I0428 20:36:02.305058  4734 net.cpp:124] Setting up pool1
I0428 20:36:02.305066  4734 net.cpp:131] Top shape: 100 50 4 4 (80000)
I0428 20:36:02.305070  4734 net.cpp:139] Memory required for data: 30714800
I0428 20:36:02.305073  4734 layer_factory.hpp:77] Creating layer ip1
I0428 20:36:02.305078  4734 net.cpp:86] Creating Layer ip1
I0428 20:36:02.305083  4734 net.cpp:408] ip1 <- pool1
I0428 20:36:02.305088  4734 net.cpp:382] ip1 -> ip1
I0428 20:36:02.305434  4734 net.cpp:124] Setting up ip1
I0428 20:36:02.305452  4734 net.cpp:131] Top shape: 100 50 (5000)
I0428 20:36:02.305456  4734 net.cpp:139] Memory required for data: 30734800
I0428 20:36:02.305464  4734 layer_factory.hpp:77] Creating layer relu1
I0428 20:36:02.305469  4734 net.cpp:86] Creating Layer relu1
I0428 20:36:02.305472  4734 net.cpp:408] relu1 <- ip1
I0428 20:36:02.305480  4734 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:36:02.305645  4734 net.cpp:124] Setting up relu1
I0428 20:36:02.305654  4734 net.cpp:131] Top shape: 100 50 (5000)
I0428 20:36:02.305656  4734 net.cpp:139] Memory required for data: 30754800
I0428 20:36:02.305660  4734 layer_factory.hpp:77] Creating layer ip2
I0428 20:36:02.305683  4734 net.cpp:86] Creating Layer ip2
I0428 20:36:02.305688  4734 net.cpp:408] ip2 <- ip1
I0428 20:36:02.305694  4734 net.cpp:382] ip2 -> ip2
I0428 20:36:02.305830  4734 net.cpp:124] Setting up ip2
I0428 20:36:02.305837  4734 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:36:02.305840  4734 net.cpp:139] Memory required for data: 30758800
I0428 20:36:02.305846  4734 layer_factory.hpp:77] Creating layer relu2
I0428 20:36:02.305851  4734 net.cpp:86] Creating Layer relu2
I0428 20:36:02.305855  4734 net.cpp:408] relu2 <- ip2
I0428 20:36:02.305860  4734 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:36:02.306107  4734 net.cpp:124] Setting up relu2
I0428 20:36:02.306116  4734 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:36:02.306119  4734 net.cpp:139] Memory required for data: 30762800
I0428 20:36:02.306123  4734 layer_factory.hpp:77] Creating layer ip3
I0428 20:36:02.306129  4734 net.cpp:86] Creating Layer ip3
I0428 20:36:02.306133  4734 net.cpp:408] ip3 <- ip2
I0428 20:36:02.306138  4734 net.cpp:382] ip3 -> ip3
I0428 20:36:02.306268  4734 net.cpp:124] Setting up ip3
I0428 20:36:02.306275  4734 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:36:02.306278  4734 net.cpp:139] Memory required for data: 30766800
I0428 20:36:02.306288  4734 layer_factory.hpp:77] Creating layer relu3
I0428 20:36:02.306294  4734 net.cpp:86] Creating Layer relu3
I0428 20:36:02.306298  4734 net.cpp:408] relu3 <- ip3
I0428 20:36:02.306303  4734 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:36:02.307106  4734 net.cpp:124] Setting up relu3
I0428 20:36:02.307117  4734 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:36:02.307137  4734 net.cpp:139] Memory required for data: 30770800
I0428 20:36:02.307142  4734 layer_factory.hpp:77] Creating layer ip3_relu3_0_split
I0428 20:36:02.307163  4734 net.cpp:86] Creating Layer ip3_relu3_0_split
I0428 20:36:02.307183  4734 net.cpp:408] ip3_relu3_0_split <- ip3
I0428 20:36:02.307188  4734 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_0
I0428 20:36:02.307209  4734 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_1
I0428 20:36:02.307271  4734 net.cpp:124] Setting up ip3_relu3_0_split
I0428 20:36:02.307279  4734 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:36:02.307283  4734 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:36:02.307292  4734 net.cpp:139] Memory required for data: 30778800
I0428 20:36:02.307296  4734 layer_factory.hpp:77] Creating layer accuracy
I0428 20:36:02.307302  4734 net.cpp:86] Creating Layer accuracy
I0428 20:36:02.307306  4734 net.cpp:408] accuracy <- ip3_relu3_0_split_0
I0428 20:36:02.307310  4734 net.cpp:408] accuracy <- label_mnist_1_split_0
I0428 20:36:02.307315  4734 net.cpp:382] accuracy -> accuracy
I0428 20:36:02.307322  4734 net.cpp:124] Setting up accuracy
I0428 20:36:02.307328  4734 net.cpp:131] Top shape: (1)
I0428 20:36:02.307332  4734 net.cpp:139] Memory required for data: 30778804
I0428 20:36:02.307340  4734 layer_factory.hpp:77] Creating layer loss
I0428 20:36:02.307345  4734 net.cpp:86] Creating Layer loss
I0428 20:36:02.307348  4734 net.cpp:408] loss <- ip3_relu3_0_split_1
I0428 20:36:02.307353  4734 net.cpp:408] loss <- label_mnist_1_split_1
I0428 20:36:02.307358  4734 net.cpp:382] loss -> loss
I0428 20:36:02.307364  4734 layer_factory.hpp:77] Creating layer loss
I0428 20:36:02.307628  4734 net.cpp:124] Setting up loss
I0428 20:36:02.307652  4734 net.cpp:131] Top shape: (1)
I0428 20:36:02.307656  4734 net.cpp:134]     with loss weight 1
I0428 20:36:02.307687  4734 net.cpp:139] Memory required for data: 30778808
I0428 20:36:02.307692  4734 net.cpp:200] loss needs backward computation.
I0428 20:36:02.307695  4734 net.cpp:202] accuracy does not need backward computation.
I0428 20:36:02.307700  4734 net.cpp:200] ip3_relu3_0_split needs backward computation.
I0428 20:36:02.307703  4734 net.cpp:200] relu3 needs backward computation.
I0428 20:36:02.307706  4734 net.cpp:200] ip3 needs backward computation.
I0428 20:36:02.307709  4734 net.cpp:200] relu2 needs backward computation.
I0428 20:36:02.307713  4734 net.cpp:200] ip2 needs backward computation.
I0428 20:36:02.307715  4734 net.cpp:200] relu1 needs backward computation.
I0428 20:36:02.307718  4734 net.cpp:200] ip1 needs backward computation.
I0428 20:36:02.307721  4734 net.cpp:200] pool1 needs backward computation.
I0428 20:36:02.307724  4734 net.cpp:200] conv1 needs backward computation.
I0428 20:36:02.307729  4734 net.cpp:200] pool0 needs backward computation.
I0428 20:36:02.307731  4734 net.cpp:200] conv0 needs backward computation.
I0428 20:36:02.307735  4734 net.cpp:202] label_mnist_1_split does not need backward computation.
I0428 20:36:02.307739  4734 net.cpp:202] mnist does not need backward computation.
I0428 20:36:02.307742  4734 net.cpp:244] This network produces output accuracy
I0428 20:36:02.307745  4734 net.cpp:244] This network produces output loss
I0428 20:36:02.307757  4734 net.cpp:257] Network initialization done.
I0428 20:36:02.307801  4734 solver.cpp:56] Solver scaffolding done.
I0428 20:36:02.308192  4734 caffe.cpp:248] Starting Optimization
I0428 20:36:02.308197  4734 solver.cpp:273] Solving LeNet
I0428 20:36:02.308200  4734 solver.cpp:274] Learning Rate Policy: inv
I0428 20:36:02.309057  4734 solver.cpp:331] Iteration 0, Testing net (#0)
I0428 20:36:02.435583  4741 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:36:02.440079  4734 solver.cpp:398]     Test net output #0: accuracy = 0.1205
I0428 20:36:02.440121  4734 solver.cpp:398]     Test net output #1: loss = 2.30454 (* 1 = 2.30454 loss)
I0428 20:36:02.447021  4734 solver.cpp:219] Iteration 0 (0 iter/s, 0.13878s/100 iters), loss = 2.26249
I0428 20:36:02.447064  4734 solver.cpp:238]     Train net output #0: loss = 2.26249 (* 1 = 2.26249 loss)
I0428 20:36:02.447082  4734 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0428 20:36:02.700698  4734 solver.cpp:219] Iteration 100 (394.306 iter/s, 0.25361s/100 iters), loss = 0.74892
I0428 20:36:02.700752  4734 solver.cpp:238]     Train net output #0: loss = 0.74892 (* 1 = 0.74892 loss)
I0428 20:36:02.700767  4734 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0428 20:36:02.949439  4734 solver.cpp:219] Iteration 200 (402.142 iter/s, 0.248668s/100 iters), loss = 0.55951
I0428 20:36:02.949487  4734 solver.cpp:238]     Train net output #0: loss = 0.55951 (* 1 = 0.55951 loss)
I0428 20:36:02.949499  4734 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0428 20:36:03.195165  4734 solver.cpp:219] Iteration 300 (407.062 iter/s, 0.245663s/100 iters), loss = 0.218154
I0428 20:36:03.195209  4734 solver.cpp:238]     Train net output #0: loss = 0.218154 (* 1 = 0.218154 loss)
I0428 20:36:03.195219  4734 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0428 20:36:03.443578  4734 solver.cpp:219] Iteration 400 (402.655 iter/s, 0.248352s/100 iters), loss = 0.0790974
I0428 20:36:03.443625  4734 solver.cpp:238]     Train net output #0: loss = 0.0790974 (* 1 = 0.0790974 loss)
I0428 20:36:03.443637  4734 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0428 20:36:03.685775  4734 solver.cpp:331] Iteration 500, Testing net (#0)
I0428 20:36:03.799783  4741 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:36:03.803817  4734 solver.cpp:398]     Test net output #0: accuracy = 0.9623
I0428 20:36:03.803844  4734 solver.cpp:398]     Test net output #1: loss = 0.127862 (* 1 = 0.127862 loss)
I0428 20:36:03.806107  4734 solver.cpp:219] Iteration 500 (275.891 iter/s, 0.362462s/100 iters), loss = 0.14571
I0428 20:36:03.806136  4734 solver.cpp:238]     Train net output #0: loss = 0.14571 (* 1 = 0.14571 loss)
I0428 20:36:03.806165  4734 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0428 20:36:04.047291  4734 solver.cpp:219] Iteration 600 (414.703 iter/s, 0.241136s/100 iters), loss = 0.0491555
I0428 20:36:04.047332  4734 solver.cpp:238]     Train net output #0: loss = 0.0491555 (* 1 = 0.0491555 loss)
I0428 20:36:04.047341  4734 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0428 20:36:04.291127  4734 solver.cpp:219] Iteration 700 (410.208 iter/s, 0.243779s/100 iters), loss = 0.130336
I0428 20:36:04.291169  4734 solver.cpp:238]     Train net output #0: loss = 0.130336 (* 1 = 0.130336 loss)
I0428 20:36:04.291180  4734 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0428 20:36:04.537729  4734 solver.cpp:219] Iteration 800 (405.61 iter/s, 0.246542s/100 iters), loss = 0.285336
I0428 20:36:04.537772  4734 solver.cpp:238]     Train net output #0: loss = 0.285336 (* 1 = 0.285336 loss)
I0428 20:36:04.537783  4734 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0428 20:36:04.784862  4734 solver.cpp:219] Iteration 900 (404.739 iter/s, 0.247073s/100 iters), loss = 0.1209
I0428 20:36:04.784903  4734 solver.cpp:238]     Train net output #0: loss = 0.1209 (* 1 = 0.1209 loss)
I0428 20:36:04.784912  4734 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0428 20:36:04.867543  4740 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:36:05.030455  4734 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_1000.caffemodel
I0428 20:36:05.037124  4734 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_1000.solverstate
I0428 20:36:05.040279  4734 solver.cpp:311] Iteration 1000, loss = 0.0807922
I0428 20:36:05.040307  4734 solver.cpp:331] Iteration 1000, Testing net (#0)
I0428 20:36:05.152562  4741 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:36:05.156666  4734 solver.cpp:398]     Test net output #0: accuracy = 0.9725
I0428 20:36:05.156689  4734 solver.cpp:398]     Test net output #1: loss = 0.084912 (* 1 = 0.084912 loss)
I0428 20:36:05.156704  4734 solver.cpp:316] Optimization Done.
I0428 20:36:05.156708  4734 caffe.cpp:259] Optimization Done.
