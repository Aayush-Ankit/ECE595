I0428 20:05:09.669102 30551 caffe.cpp:218] Using GPUs 0
I0428 20:05:09.706131 30551 caffe.cpp:223] GPU 0: TITAN X (Pascal)
I0428 20:05:10.164676 30551 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 1000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_everything2/lenet_train_test992.prototxt"
train_state {
  level: 0
  stage: ""
}
I0428 20:05:10.164866 30551 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_everything2/lenet_train_test992.prototxt
I0428 20:05:10.165241 30551 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0428 20:05:10.165271 30551 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0428 20:05:10.165352 30551 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:05:10.165419 30551 layer_factory.hpp:77] Creating layer mnist
I0428 20:05:10.165499 30551 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0428 20:05:10.165520 30551 net.cpp:86] Creating Layer mnist
I0428 20:05:10.165526 30551 net.cpp:382] mnist -> data
I0428 20:05:10.165545 30551 net.cpp:382] mnist -> label
I0428 20:05:10.166472 30551 data_layer.cpp:45] output data size: 64,1,28,28
I0428 20:05:10.168753 30551 net.cpp:124] Setting up mnist
I0428 20:05:10.168782 30551 net.cpp:131] Top shape: 64 1 28 28 (50176)
I0428 20:05:10.168789 30551 net.cpp:131] Top shape: 64 (64)
I0428 20:05:10.168792 30551 net.cpp:139] Memory required for data: 200960
I0428 20:05:10.168798 30551 layer_factory.hpp:77] Creating layer conv0
I0428 20:05:10.168833 30551 net.cpp:86] Creating Layer conv0
I0428 20:05:10.168884 30551 net.cpp:408] conv0 <- data
I0428 20:05:10.168896 30551 net.cpp:382] conv0 -> conv0
I0428 20:05:10.403122 30551 net.cpp:124] Setting up conv0
I0428 20:05:10.403148 30551 net.cpp:131] Top shape: 64 25 24 24 (921600)
I0428 20:05:10.403152 30551 net.cpp:139] Memory required for data: 3887360
I0428 20:05:10.403167 30551 layer_factory.hpp:77] Creating layer pool0
I0428 20:05:10.403179 30551 net.cpp:86] Creating Layer pool0
I0428 20:05:10.403183 30551 net.cpp:408] pool0 <- conv0
I0428 20:05:10.403188 30551 net.cpp:382] pool0 -> pool0
I0428 20:05:10.403246 30551 net.cpp:124] Setting up pool0
I0428 20:05:10.403251 30551 net.cpp:131] Top shape: 64 25 12 12 (230400)
I0428 20:05:10.403254 30551 net.cpp:139] Memory required for data: 4808960
I0428 20:05:10.403257 30551 layer_factory.hpp:77] Creating layer conv1
I0428 20:05:10.403267 30551 net.cpp:86] Creating Layer conv1
I0428 20:05:10.403270 30551 net.cpp:408] conv1 <- pool0
I0428 20:05:10.403275 30551 net.cpp:382] conv1 -> conv1
I0428 20:05:10.405946 30551 net.cpp:124] Setting up conv1
I0428 20:05:10.405977 30551 net.cpp:131] Top shape: 64 2 8 8 (8192)
I0428 20:05:10.405979 30551 net.cpp:139] Memory required for data: 4841728
I0428 20:05:10.405988 30551 layer_factory.hpp:77] Creating layer pool1
I0428 20:05:10.405997 30551 net.cpp:86] Creating Layer pool1
I0428 20:05:10.405999 30551 net.cpp:408] pool1 <- conv1
I0428 20:05:10.406004 30551 net.cpp:382] pool1 -> pool1
I0428 20:05:10.406056 30551 net.cpp:124] Setting up pool1
I0428 20:05:10.406061 30551 net.cpp:131] Top shape: 64 2 4 4 (2048)
I0428 20:05:10.406064 30551 net.cpp:139] Memory required for data: 4849920
I0428 20:05:10.406067 30551 layer_factory.hpp:77] Creating layer ip1
I0428 20:05:10.406075 30551 net.cpp:86] Creating Layer ip1
I0428 20:05:10.406077 30551 net.cpp:408] ip1 <- pool1
I0428 20:05:10.406082 30551 net.cpp:382] ip1 -> ip1
I0428 20:05:10.406174 30551 net.cpp:124] Setting up ip1
I0428 20:05:10.406182 30551 net.cpp:131] Top shape: 64 10 (640)
I0428 20:05:10.406184 30551 net.cpp:139] Memory required for data: 4852480
I0428 20:05:10.406191 30551 layer_factory.hpp:77] Creating layer relu1
I0428 20:05:10.406198 30551 net.cpp:86] Creating Layer relu1
I0428 20:05:10.406200 30551 net.cpp:408] relu1 <- ip1
I0428 20:05:10.406204 30551 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:05:10.406365 30551 net.cpp:124] Setting up relu1
I0428 20:05:10.406374 30551 net.cpp:131] Top shape: 64 10 (640)
I0428 20:05:10.406378 30551 net.cpp:139] Memory required for data: 4855040
I0428 20:05:10.406380 30551 layer_factory.hpp:77] Creating layer ip2
I0428 20:05:10.406386 30551 net.cpp:86] Creating Layer ip2
I0428 20:05:10.406389 30551 net.cpp:408] ip2 <- ip1
I0428 20:05:10.406394 30551 net.cpp:382] ip2 -> ip2
I0428 20:05:10.406486 30551 net.cpp:124] Setting up ip2
I0428 20:05:10.406491 30551 net.cpp:131] Top shape: 64 25 (1600)
I0428 20:05:10.406494 30551 net.cpp:139] Memory required for data: 4861440
I0428 20:05:10.406500 30551 layer_factory.hpp:77] Creating layer relu2
I0428 20:05:10.406505 30551 net.cpp:86] Creating Layer relu2
I0428 20:05:10.406508 30551 net.cpp:408] relu2 <- ip2
I0428 20:05:10.406512 30551 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:05:10.407256 30551 net.cpp:124] Setting up relu2
I0428 20:05:10.407269 30551 net.cpp:131] Top shape: 64 25 (1600)
I0428 20:05:10.407287 30551 net.cpp:139] Memory required for data: 4867840
I0428 20:05:10.407290 30551 layer_factory.hpp:77] Creating layer ip3
I0428 20:05:10.407297 30551 net.cpp:86] Creating Layer ip3
I0428 20:05:10.407302 30551 net.cpp:408] ip3 <- ip2
I0428 20:05:10.407307 30551 net.cpp:382] ip3 -> ip3
I0428 20:05:10.407418 30551 net.cpp:124] Setting up ip3
I0428 20:05:10.407425 30551 net.cpp:131] Top shape: 64 10 (640)
I0428 20:05:10.407428 30551 net.cpp:139] Memory required for data: 4870400
I0428 20:05:10.407436 30551 layer_factory.hpp:77] Creating layer relu3
I0428 20:05:10.407441 30551 net.cpp:86] Creating Layer relu3
I0428 20:05:10.407444 30551 net.cpp:408] relu3 <- ip3
I0428 20:05:10.407447 30551 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:05:10.407606 30551 net.cpp:124] Setting up relu3
I0428 20:05:10.407614 30551 net.cpp:131] Top shape: 64 10 (640)
I0428 20:05:10.407618 30551 net.cpp:139] Memory required for data: 4872960
I0428 20:05:10.407620 30551 layer_factory.hpp:77] Creating layer loss
I0428 20:05:10.407626 30551 net.cpp:86] Creating Layer loss
I0428 20:05:10.407629 30551 net.cpp:408] loss <- ip3
I0428 20:05:10.407634 30551 net.cpp:408] loss <- label
I0428 20:05:10.407639 30551 net.cpp:382] loss -> loss
I0428 20:05:10.407655 30551 layer_factory.hpp:77] Creating layer loss
I0428 20:05:10.407883 30551 net.cpp:124] Setting up loss
I0428 20:05:10.407892 30551 net.cpp:131] Top shape: (1)
I0428 20:05:10.407896 30551 net.cpp:134]     with loss weight 1
I0428 20:05:10.407909 30551 net.cpp:139] Memory required for data: 4872964
I0428 20:05:10.407914 30551 net.cpp:200] loss needs backward computation.
I0428 20:05:10.407917 30551 net.cpp:200] relu3 needs backward computation.
I0428 20:05:10.407920 30551 net.cpp:200] ip3 needs backward computation.
I0428 20:05:10.407924 30551 net.cpp:200] relu2 needs backward computation.
I0428 20:05:10.407927 30551 net.cpp:200] ip2 needs backward computation.
I0428 20:05:10.407930 30551 net.cpp:200] relu1 needs backward computation.
I0428 20:05:10.407933 30551 net.cpp:200] ip1 needs backward computation.
I0428 20:05:10.407937 30551 net.cpp:200] pool1 needs backward computation.
I0428 20:05:10.407939 30551 net.cpp:200] conv1 needs backward computation.
I0428 20:05:10.407943 30551 net.cpp:200] pool0 needs backward computation.
I0428 20:05:10.407945 30551 net.cpp:200] conv0 needs backward computation.
I0428 20:05:10.407949 30551 net.cpp:202] mnist does not need backward computation.
I0428 20:05:10.407953 30551 net.cpp:244] This network produces output loss
I0428 20:05:10.407961 30551 net.cpp:257] Network initialization done.
I0428 20:05:10.408329 30551 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_everything2/lenet_train_test992.prototxt
I0428 20:05:10.408376 30551 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0428 20:05:10.408469 30551 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:05:10.408550 30551 layer_factory.hpp:77] Creating layer mnist
I0428 20:05:10.408605 30551 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0428 20:05:10.408617 30551 net.cpp:86] Creating Layer mnist
I0428 20:05:10.408622 30551 net.cpp:382] mnist -> data
I0428 20:05:10.408629 30551 net.cpp:382] mnist -> label
I0428 20:05:10.408725 30551 data_layer.cpp:45] output data size: 100,1,28,28
I0428 20:05:10.410949 30551 net.cpp:124] Setting up mnist
I0428 20:05:10.410979 30551 net.cpp:131] Top shape: 100 1 28 28 (78400)
I0428 20:05:10.410984 30551 net.cpp:131] Top shape: 100 (100)
I0428 20:05:10.410986 30551 net.cpp:139] Memory required for data: 314000
I0428 20:05:10.410990 30551 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0428 20:05:10.411022 30551 net.cpp:86] Creating Layer label_mnist_1_split
I0428 20:05:10.411026 30551 net.cpp:408] label_mnist_1_split <- label
I0428 20:05:10.411031 30551 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_0
I0428 20:05:10.411038 30551 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_1
I0428 20:05:10.411088 30551 net.cpp:124] Setting up label_mnist_1_split
I0428 20:05:10.411094 30551 net.cpp:131] Top shape: 100 (100)
I0428 20:05:10.411098 30551 net.cpp:131] Top shape: 100 (100)
I0428 20:05:10.411100 30551 net.cpp:139] Memory required for data: 314800
I0428 20:05:10.411103 30551 layer_factory.hpp:77] Creating layer conv0
I0428 20:05:10.411111 30551 net.cpp:86] Creating Layer conv0
I0428 20:05:10.411114 30551 net.cpp:408] conv0 <- data
I0428 20:05:10.411118 30551 net.cpp:382] conv0 -> conv0
I0428 20:05:10.412853 30551 net.cpp:124] Setting up conv0
I0428 20:05:10.412868 30551 net.cpp:131] Top shape: 100 25 24 24 (1440000)
I0428 20:05:10.412871 30551 net.cpp:139] Memory required for data: 6074800
I0428 20:05:10.412880 30551 layer_factory.hpp:77] Creating layer pool0
I0428 20:05:10.412886 30551 net.cpp:86] Creating Layer pool0
I0428 20:05:10.412905 30551 net.cpp:408] pool0 <- conv0
I0428 20:05:10.412910 30551 net.cpp:382] pool0 -> pool0
I0428 20:05:10.412946 30551 net.cpp:124] Setting up pool0
I0428 20:05:10.412951 30551 net.cpp:131] Top shape: 100 25 12 12 (360000)
I0428 20:05:10.412955 30551 net.cpp:139] Memory required for data: 7514800
I0428 20:05:10.412957 30551 layer_factory.hpp:77] Creating layer conv1
I0428 20:05:10.412966 30551 net.cpp:86] Creating Layer conv1
I0428 20:05:10.412968 30551 net.cpp:408] conv1 <- pool0
I0428 20:05:10.412973 30551 net.cpp:382] conv1 -> conv1
I0428 20:05:10.414983 30551 net.cpp:124] Setting up conv1
I0428 20:05:10.414997 30551 net.cpp:131] Top shape: 100 2 8 8 (12800)
I0428 20:05:10.415001 30551 net.cpp:139] Memory required for data: 7566000
I0428 20:05:10.415011 30551 layer_factory.hpp:77] Creating layer pool1
I0428 20:05:10.415032 30551 net.cpp:86] Creating Layer pool1
I0428 20:05:10.415036 30551 net.cpp:408] pool1 <- conv1
I0428 20:05:10.415058 30551 net.cpp:382] pool1 -> pool1
I0428 20:05:10.415112 30551 net.cpp:124] Setting up pool1
I0428 20:05:10.415117 30551 net.cpp:131] Top shape: 100 2 4 4 (3200)
I0428 20:05:10.415120 30551 net.cpp:139] Memory required for data: 7578800
I0428 20:05:10.415122 30551 layer_factory.hpp:77] Creating layer ip1
I0428 20:05:10.415129 30551 net.cpp:86] Creating Layer ip1
I0428 20:05:10.415132 30551 net.cpp:408] ip1 <- pool1
I0428 20:05:10.415138 30551 net.cpp:382] ip1 -> ip1
I0428 20:05:10.415235 30551 net.cpp:124] Setting up ip1
I0428 20:05:10.415242 30551 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:05:10.415254 30551 net.cpp:139] Memory required for data: 7582800
I0428 20:05:10.415261 30551 layer_factory.hpp:77] Creating layer relu1
I0428 20:05:10.415267 30551 net.cpp:86] Creating Layer relu1
I0428 20:05:10.415271 30551 net.cpp:408] relu1 <- ip1
I0428 20:05:10.415274 30551 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:05:10.415550 30551 net.cpp:124] Setting up relu1
I0428 20:05:10.415560 30551 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:05:10.415563 30551 net.cpp:139] Memory required for data: 7586800
I0428 20:05:10.415566 30551 layer_factory.hpp:77] Creating layer ip2
I0428 20:05:10.415575 30551 net.cpp:86] Creating Layer ip2
I0428 20:05:10.415578 30551 net.cpp:408] ip2 <- ip1
I0428 20:05:10.415585 30551 net.cpp:382] ip2 -> ip2
I0428 20:05:10.415684 30551 net.cpp:124] Setting up ip2
I0428 20:05:10.415693 30551 net.cpp:131] Top shape: 100 25 (2500)
I0428 20:05:10.415695 30551 net.cpp:139] Memory required for data: 7596800
I0428 20:05:10.415700 30551 layer_factory.hpp:77] Creating layer relu2
I0428 20:05:10.415705 30551 net.cpp:86] Creating Layer relu2
I0428 20:05:10.415709 30551 net.cpp:408] relu2 <- ip2
I0428 20:05:10.415712 30551 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:05:10.415881 30551 net.cpp:124] Setting up relu2
I0428 20:05:10.415889 30551 net.cpp:131] Top shape: 100 25 (2500)
I0428 20:05:10.415892 30551 net.cpp:139] Memory required for data: 7606800
I0428 20:05:10.415895 30551 layer_factory.hpp:77] Creating layer ip3
I0428 20:05:10.415900 30551 net.cpp:86] Creating Layer ip3
I0428 20:05:10.415904 30551 net.cpp:408] ip3 <- ip2
I0428 20:05:10.415908 30551 net.cpp:382] ip3 -> ip3
I0428 20:05:10.416018 30551 net.cpp:124] Setting up ip3
I0428 20:05:10.416024 30551 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:05:10.416028 30551 net.cpp:139] Memory required for data: 7610800
I0428 20:05:10.416035 30551 layer_factory.hpp:77] Creating layer relu3
I0428 20:05:10.416046 30551 net.cpp:86] Creating Layer relu3
I0428 20:05:10.416051 30551 net.cpp:408] relu3 <- ip3
I0428 20:05:10.416055 30551 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:05:10.416863 30551 net.cpp:124] Setting up relu3
I0428 20:05:10.416896 30551 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:05:10.416899 30551 net.cpp:139] Memory required for data: 7614800
I0428 20:05:10.416903 30551 layer_factory.hpp:77] Creating layer ip3_relu3_0_split
I0428 20:05:10.416908 30551 net.cpp:86] Creating Layer ip3_relu3_0_split
I0428 20:05:10.416913 30551 net.cpp:408] ip3_relu3_0_split <- ip3
I0428 20:05:10.416929 30551 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_0
I0428 20:05:10.416936 30551 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_1
I0428 20:05:10.416993 30551 net.cpp:124] Setting up ip3_relu3_0_split
I0428 20:05:10.417003 30551 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:05:10.417007 30551 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:05:10.417011 30551 net.cpp:139] Memory required for data: 7622800
I0428 20:05:10.417019 30551 layer_factory.hpp:77] Creating layer accuracy
I0428 20:05:10.417031 30551 net.cpp:86] Creating Layer accuracy
I0428 20:05:10.417033 30551 net.cpp:408] accuracy <- ip3_relu3_0_split_0
I0428 20:05:10.417038 30551 net.cpp:408] accuracy <- label_mnist_1_split_0
I0428 20:05:10.417047 30551 net.cpp:382] accuracy -> accuracy
I0428 20:05:10.417053 30551 net.cpp:124] Setting up accuracy
I0428 20:05:10.417057 30551 net.cpp:131] Top shape: (1)
I0428 20:05:10.417060 30551 net.cpp:139] Memory required for data: 7622804
I0428 20:05:10.417063 30551 layer_factory.hpp:77] Creating layer loss
I0428 20:05:10.417068 30551 net.cpp:86] Creating Layer loss
I0428 20:05:10.417071 30551 net.cpp:408] loss <- ip3_relu3_0_split_1
I0428 20:05:10.417075 30551 net.cpp:408] loss <- label_mnist_1_split_1
I0428 20:05:10.417080 30551 net.cpp:382] loss -> loss
I0428 20:05:10.417086 30551 layer_factory.hpp:77] Creating layer loss
I0428 20:05:10.417371 30551 net.cpp:124] Setting up loss
I0428 20:05:10.417381 30551 net.cpp:131] Top shape: (1)
I0428 20:05:10.417383 30551 net.cpp:134]     with loss weight 1
I0428 20:05:10.417388 30551 net.cpp:139] Memory required for data: 7622808
I0428 20:05:10.417402 30551 net.cpp:200] loss needs backward computation.
I0428 20:05:10.417405 30551 net.cpp:202] accuracy does not need backward computation.
I0428 20:05:10.417409 30551 net.cpp:200] ip3_relu3_0_split needs backward computation.
I0428 20:05:10.417412 30551 net.cpp:200] relu3 needs backward computation.
I0428 20:05:10.417414 30551 net.cpp:200] ip3 needs backward computation.
I0428 20:05:10.417424 30551 net.cpp:200] relu2 needs backward computation.
I0428 20:05:10.417426 30551 net.cpp:200] ip2 needs backward computation.
I0428 20:05:10.417429 30551 net.cpp:200] relu1 needs backward computation.
I0428 20:05:10.417433 30551 net.cpp:200] ip1 needs backward computation.
I0428 20:05:10.417434 30551 net.cpp:200] pool1 needs backward computation.
I0428 20:05:10.417438 30551 net.cpp:200] conv1 needs backward computation.
I0428 20:05:10.417446 30551 net.cpp:200] pool0 needs backward computation.
I0428 20:05:10.417449 30551 net.cpp:200] conv0 needs backward computation.
I0428 20:05:10.417453 30551 net.cpp:202] label_mnist_1_split does not need backward computation.
I0428 20:05:10.417460 30551 net.cpp:202] mnist does not need backward computation.
I0428 20:05:10.417464 30551 net.cpp:244] This network produces output accuracy
I0428 20:05:10.417466 30551 net.cpp:244] This network produces output loss
I0428 20:05:10.417477 30551 net.cpp:257] Network initialization done.
I0428 20:05:10.417515 30551 solver.cpp:56] Solver scaffolding done.
I0428 20:05:10.417907 30551 caffe.cpp:248] Starting Optimization
I0428 20:05:10.417934 30551 solver.cpp:273] Solving LeNet
I0428 20:05:10.417938 30551 solver.cpp:274] Learning Rate Policy: inv
I0428 20:05:10.418835 30551 solver.cpp:331] Iteration 0, Testing net (#0)
I0428 20:05:10.423836 30551 blocking_queue.cpp:49] Waiting for data
I0428 20:05:10.495199 30558 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:05:10.495828 30551 solver.cpp:398]     Test net output #0: accuracy = 0.0818
I0428 20:05:10.495863 30551 solver.cpp:398]     Test net output #1: loss = 2.30392 (* 1 = 2.30392 loss)
I0428 20:05:10.499029 30551 solver.cpp:219] Iteration 0 (0 iter/s, 0.0810629s/100 iters), loss = 2.29979
I0428 20:05:10.499063 30551 solver.cpp:238]     Train net output #0: loss = 2.29979 (* 1 = 2.29979 loss)
I0428 20:05:10.499073 30551 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0428 20:05:10.589658 30551 solver.cpp:219] Iteration 100 (1103.96 iter/s, 0.090583s/100 iters), loss = 1.26917
I0428 20:05:10.589682 30551 solver.cpp:238]     Train net output #0: loss = 1.26917 (* 1 = 1.26917 loss)
I0428 20:05:10.589689 30551 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0428 20:05:10.678575 30551 solver.cpp:219] Iteration 200 (1125.08 iter/s, 0.0888822s/100 iters), loss = 0.539804
I0428 20:05:10.678597 30551 solver.cpp:238]     Train net output #0: loss = 0.539804 (* 1 = 0.539804 loss)
I0428 20:05:10.678603 30551 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0428 20:05:10.768990 30551 solver.cpp:219] Iteration 300 (1106.41 iter/s, 0.0903823s/100 iters), loss = 0.460313
I0428 20:05:10.769013 30551 solver.cpp:238]     Train net output #0: loss = 0.460313 (* 1 = 0.460313 loss)
I0428 20:05:10.769019 30551 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0428 20:05:10.856421 30551 solver.cpp:219] Iteration 400 (1144.19 iter/s, 0.0873984s/100 iters), loss = 0.384999
I0428 20:05:10.856446 30551 solver.cpp:238]     Train net output #0: loss = 0.384999 (* 1 = 0.384999 loss)
I0428 20:05:10.856451 30551 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0428 20:05:10.943603 30551 solver.cpp:331] Iteration 500, Testing net (#0)
I0428 20:05:10.998152 30558 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:05:10.998731 30551 solver.cpp:398]     Test net output #0: accuracy = 0.903
I0428 20:05:10.998749 30551 solver.cpp:398]     Test net output #1: loss = 0.305884 (* 1 = 0.305884 loss)
I0428 20:05:10.999661 30551 solver.cpp:219] Iteration 500 (698.303 iter/s, 0.143204s/100 iters), loss = 0.194048
I0428 20:05:10.999708 30551 solver.cpp:238]     Train net output #0: loss = 0.194048 (* 1 = 0.194048 loss)
I0428 20:05:10.999744 30551 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0428 20:05:11.094866 30551 solver.cpp:219] Iteration 600 (1050.97 iter/s, 0.0951503s/100 iters), loss = 0.166101
I0428 20:05:11.094889 30551 solver.cpp:238]     Train net output #0: loss = 0.166101 (* 1 = 0.166101 loss)
I0428 20:05:11.094895 30551 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0428 20:05:11.184301 30551 solver.cpp:219] Iteration 700 (1118.74 iter/s, 0.089386s/100 iters), loss = 0.388367
I0428 20:05:11.184325 30551 solver.cpp:238]     Train net output #0: loss = 0.388367 (* 1 = 0.388367 loss)
I0428 20:05:11.184331 30551 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0428 20:05:11.272495 30551 solver.cpp:219] Iteration 800 (1134.31 iter/s, 0.0881592s/100 iters), loss = 0.426568
I0428 20:05:11.272518 30551 solver.cpp:238]     Train net output #0: loss = 0.426568 (* 1 = 0.426568 loss)
I0428 20:05:11.272524 30551 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0428 20:05:11.359781 30551 solver.cpp:219] Iteration 900 (1146.11 iter/s, 0.087252s/100 iters), loss = 0.317642
I0428 20:05:11.359804 30551 solver.cpp:238]     Train net output #0: loss = 0.317642 (* 1 = 0.317642 loss)
I0428 20:05:11.359810 30551 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0428 20:05:11.388381 30557 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:05:11.444792 30551 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_1000.caffemodel
I0428 20:05:11.445582 30551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_1000.solverstate
I0428 20:05:11.446106 30551 solver.cpp:311] Iteration 1000, loss = 0.186382
I0428 20:05:11.446121 30551 solver.cpp:331] Iteration 1000, Testing net (#0)
I0428 20:05:11.522372 30558 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:05:11.522966 30551 solver.cpp:398]     Test net output #0: accuracy = 0.9258
I0428 20:05:11.522984 30551 solver.cpp:398]     Test net output #1: loss = 0.248751 (* 1 = 0.248751 loss)
I0428 20:05:11.522989 30551 solver.cpp:316] Optimization Done.
I0428 20:05:11.522992 30551 caffe.cpp:259] Optimization Done.
