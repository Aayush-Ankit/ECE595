I0428 20:22:06.938400  1890 caffe.cpp:218] Using GPUs 0
I0428 20:22:06.975304  1890 caffe.cpp:223] GPU 0: TITAN X (Pascal)
I0428 20:22:07.495023  1890 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 1000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_everything2/lenet_train_test1398.prototxt"
train_state {
  level: 0
  stage: ""
}
I0428 20:22:07.495165  1890 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1398.prototxt
I0428 20:22:07.495581  1890 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0428 20:22:07.495600  1890 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0428 20:22:07.495712  1890 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:22:07.495791  1890 layer_factory.hpp:77] Creating layer mnist
I0428 20:22:07.495889  1890 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0428 20:22:07.495921  1890 net.cpp:86] Creating Layer mnist
I0428 20:22:07.495930  1890 net.cpp:382] mnist -> data
I0428 20:22:07.495951  1890 net.cpp:382] mnist -> label
I0428 20:22:07.497092  1890 data_layer.cpp:45] output data size: 64,1,28,28
I0428 20:22:07.499557  1890 net.cpp:124] Setting up mnist
I0428 20:22:07.499574  1890 net.cpp:131] Top shape: 64 1 28 28 (50176)
I0428 20:22:07.499580  1890 net.cpp:131] Top shape: 64 (64)
I0428 20:22:07.499583  1890 net.cpp:139] Memory required for data: 200960
I0428 20:22:07.499590  1890 layer_factory.hpp:77] Creating layer conv0
I0428 20:22:07.499616  1890 net.cpp:86] Creating Layer conv0
I0428 20:22:07.499637  1890 net.cpp:408] conv0 <- data
I0428 20:22:07.499651  1890 net.cpp:382] conv0 -> conv0
I0428 20:22:07.793473  1890 net.cpp:124] Setting up conv0
I0428 20:22:07.793505  1890 net.cpp:131] Top shape: 64 50 24 24 (1843200)
I0428 20:22:07.793510  1890 net.cpp:139] Memory required for data: 7573760
I0428 20:22:07.793529  1890 layer_factory.hpp:77] Creating layer pool0
I0428 20:22:07.793543  1890 net.cpp:86] Creating Layer pool0
I0428 20:22:07.793550  1890 net.cpp:408] pool0 <- conv0
I0428 20:22:07.793556  1890 net.cpp:382] pool0 -> pool0
I0428 20:22:07.793611  1890 net.cpp:124] Setting up pool0
I0428 20:22:07.793617  1890 net.cpp:131] Top shape: 64 50 12 12 (460800)
I0428 20:22:07.793622  1890 net.cpp:139] Memory required for data: 9416960
I0428 20:22:07.793624  1890 layer_factory.hpp:77] Creating layer conv1
I0428 20:22:07.793637  1890 net.cpp:86] Creating Layer conv1
I0428 20:22:07.793642  1890 net.cpp:408] conv1 <- pool0
I0428 20:22:07.793648  1890 net.cpp:382] conv1 -> conv1
I0428 20:22:07.796222  1890 net.cpp:124] Setting up conv1
I0428 20:22:07.796239  1890 net.cpp:131] Top shape: 64 50 8 8 (204800)
I0428 20:22:07.796244  1890 net.cpp:139] Memory required for data: 10236160
I0428 20:22:07.796254  1890 layer_factory.hpp:77] Creating layer pool1
I0428 20:22:07.796263  1890 net.cpp:86] Creating Layer pool1
I0428 20:22:07.796268  1890 net.cpp:408] pool1 <- conv1
I0428 20:22:07.796275  1890 net.cpp:382] pool1 -> pool1
I0428 20:22:07.796319  1890 net.cpp:124] Setting up pool1
I0428 20:22:07.796326  1890 net.cpp:131] Top shape: 64 50 4 4 (51200)
I0428 20:22:07.796330  1890 net.cpp:139] Memory required for data: 10440960
I0428 20:22:07.796334  1890 layer_factory.hpp:77] Creating layer ip1
I0428 20:22:07.796342  1890 net.cpp:86] Creating Layer ip1
I0428 20:22:07.796347  1890 net.cpp:408] ip1 <- pool1
I0428 20:22:07.796353  1890 net.cpp:382] ip1 -> ip1
I0428 20:22:07.796744  1890 net.cpp:124] Setting up ip1
I0428 20:22:07.796753  1890 net.cpp:131] Top shape: 64 50 (3200)
I0428 20:22:07.796757  1890 net.cpp:139] Memory required for data: 10453760
I0428 20:22:07.796766  1890 layer_factory.hpp:77] Creating layer relu1
I0428 20:22:07.796772  1890 net.cpp:86] Creating Layer relu1
I0428 20:22:07.796777  1890 net.cpp:408] relu1 <- ip1
I0428 20:22:07.796782  1890 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:22:07.796995  1890 net.cpp:124] Setting up relu1
I0428 20:22:07.797006  1890 net.cpp:131] Top shape: 64 50 (3200)
I0428 20:22:07.797010  1890 net.cpp:139] Memory required for data: 10466560
I0428 20:22:07.797015  1890 layer_factory.hpp:77] Creating layer ip2
I0428 20:22:07.797022  1890 net.cpp:86] Creating Layer ip2
I0428 20:22:07.797026  1890 net.cpp:408] ip2 <- ip1
I0428 20:22:07.797032  1890 net.cpp:382] ip2 -> ip2
I0428 20:22:07.797171  1890 net.cpp:124] Setting up ip2
I0428 20:22:07.797180  1890 net.cpp:131] Top shape: 64 25 (1600)
I0428 20:22:07.797183  1890 net.cpp:139] Memory required for data: 10472960
I0428 20:22:07.797190  1890 layer_factory.hpp:77] Creating layer relu2
I0428 20:22:07.797197  1890 net.cpp:86] Creating Layer relu2
I0428 20:22:07.797201  1890 net.cpp:408] relu2 <- ip2
I0428 20:22:07.797206  1890 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:22:07.798050  1890 net.cpp:124] Setting up relu2
I0428 20:22:07.798065  1890 net.cpp:131] Top shape: 64 25 (1600)
I0428 20:22:07.798070  1890 net.cpp:139] Memory required for data: 10479360
I0428 20:22:07.798074  1890 layer_factory.hpp:77] Creating layer ip3
I0428 20:22:07.798082  1890 net.cpp:86] Creating Layer ip3
I0428 20:22:07.798086  1890 net.cpp:408] ip3 <- ip2
I0428 20:22:07.798094  1890 net.cpp:382] ip3 -> ip3
I0428 20:22:07.798213  1890 net.cpp:124] Setting up ip3
I0428 20:22:07.798221  1890 net.cpp:131] Top shape: 64 10 (640)
I0428 20:22:07.798225  1890 net.cpp:139] Memory required for data: 10481920
I0428 20:22:07.798235  1890 layer_factory.hpp:77] Creating layer relu3
I0428 20:22:07.798241  1890 net.cpp:86] Creating Layer relu3
I0428 20:22:07.798244  1890 net.cpp:408] relu3 <- ip3
I0428 20:22:07.798250  1890 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:22:07.798450  1890 net.cpp:124] Setting up relu3
I0428 20:22:07.798462  1890 net.cpp:131] Top shape: 64 10 (640)
I0428 20:22:07.798466  1890 net.cpp:139] Memory required for data: 10484480
I0428 20:22:07.798470  1890 layer_factory.hpp:77] Creating layer loss
I0428 20:22:07.798482  1890 net.cpp:86] Creating Layer loss
I0428 20:22:07.798486  1890 net.cpp:408] loss <- ip3
I0428 20:22:07.798491  1890 net.cpp:408] loss <- label
I0428 20:22:07.798497  1890 net.cpp:382] loss -> loss
I0428 20:22:07.798512  1890 layer_factory.hpp:77] Creating layer loss
I0428 20:22:07.798801  1890 net.cpp:124] Setting up loss
I0428 20:22:07.798811  1890 net.cpp:131] Top shape: (1)
I0428 20:22:07.798815  1890 net.cpp:134]     with loss weight 1
I0428 20:22:07.798830  1890 net.cpp:139] Memory required for data: 10484484
I0428 20:22:07.798835  1890 net.cpp:200] loss needs backward computation.
I0428 20:22:07.798838  1890 net.cpp:200] relu3 needs backward computation.
I0428 20:22:07.798843  1890 net.cpp:200] ip3 needs backward computation.
I0428 20:22:07.798847  1890 net.cpp:200] relu2 needs backward computation.
I0428 20:22:07.798851  1890 net.cpp:200] ip2 needs backward computation.
I0428 20:22:07.798854  1890 net.cpp:200] relu1 needs backward computation.
I0428 20:22:07.798857  1890 net.cpp:200] ip1 needs backward computation.
I0428 20:22:07.798861  1890 net.cpp:200] pool1 needs backward computation.
I0428 20:22:07.798864  1890 net.cpp:200] conv1 needs backward computation.
I0428 20:22:07.798867  1890 net.cpp:200] pool0 needs backward computation.
I0428 20:22:07.798871  1890 net.cpp:200] conv0 needs backward computation.
I0428 20:22:07.798876  1890 net.cpp:202] mnist does not need backward computation.
I0428 20:22:07.798878  1890 net.cpp:244] This network produces output loss
I0428 20:22:07.798888  1890 net.cpp:257] Network initialization done.
I0428 20:22:07.799273  1890 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1398.prototxt
I0428 20:22:07.799305  1890 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0428 20:22:07.799414  1890 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:22:07.799512  1890 layer_factory.hpp:77] Creating layer mnist
I0428 20:22:07.799566  1890 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0428 20:22:07.799579  1890 net.cpp:86] Creating Layer mnist
I0428 20:22:07.799587  1890 net.cpp:382] mnist -> data
I0428 20:22:07.799595  1890 net.cpp:382] mnist -> label
I0428 20:22:07.799697  1890 data_layer.cpp:45] output data size: 100,1,28,28
I0428 20:22:07.801897  1890 net.cpp:124] Setting up mnist
I0428 20:22:07.801913  1890 net.cpp:131] Top shape: 100 1 28 28 (78400)
I0428 20:22:07.801918  1890 net.cpp:131] Top shape: 100 (100)
I0428 20:22:07.801921  1890 net.cpp:139] Memory required for data: 314000
I0428 20:22:07.801925  1890 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0428 20:22:07.801934  1890 net.cpp:86] Creating Layer label_mnist_1_split
I0428 20:22:07.801956  1890 net.cpp:408] label_mnist_1_split <- label
I0428 20:22:07.801962  1890 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_0
I0428 20:22:07.801970  1890 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_1
I0428 20:22:07.802027  1890 net.cpp:124] Setting up label_mnist_1_split
I0428 20:22:07.802037  1890 net.cpp:131] Top shape: 100 (100)
I0428 20:22:07.802040  1890 net.cpp:131] Top shape: 100 (100)
I0428 20:22:07.802044  1890 net.cpp:139] Memory required for data: 314800
I0428 20:22:07.802047  1890 layer_factory.hpp:77] Creating layer conv0
I0428 20:22:07.802058  1890 net.cpp:86] Creating Layer conv0
I0428 20:22:07.802062  1890 net.cpp:408] conv0 <- data
I0428 20:22:07.802069  1890 net.cpp:382] conv0 -> conv0
I0428 20:22:07.804003  1890 net.cpp:124] Setting up conv0
I0428 20:22:07.804020  1890 net.cpp:131] Top shape: 100 50 24 24 (2880000)
I0428 20:22:07.804024  1890 net.cpp:139] Memory required for data: 11834800
I0428 20:22:07.804036  1890 layer_factory.hpp:77] Creating layer pool0
I0428 20:22:07.804044  1890 net.cpp:86] Creating Layer pool0
I0428 20:22:07.804047  1890 net.cpp:408] pool0 <- conv0
I0428 20:22:07.804054  1890 net.cpp:382] pool0 -> pool0
I0428 20:22:07.804096  1890 net.cpp:124] Setting up pool0
I0428 20:22:07.804102  1890 net.cpp:131] Top shape: 100 50 12 12 (720000)
I0428 20:22:07.804106  1890 net.cpp:139] Memory required for data: 14714800
I0428 20:22:07.804110  1890 layer_factory.hpp:77] Creating layer conv1
I0428 20:22:07.804124  1890 net.cpp:86] Creating Layer conv1
I0428 20:22:07.804128  1890 net.cpp:408] conv1 <- pool0
I0428 20:22:07.804134  1890 net.cpp:382] conv1 -> conv1
I0428 20:22:07.806313  1890 net.cpp:124] Setting up conv1
I0428 20:22:07.806330  1890 net.cpp:131] Top shape: 100 50 8 8 (320000)
I0428 20:22:07.806334  1890 net.cpp:139] Memory required for data: 15994800
I0428 20:22:07.806345  1890 layer_factory.hpp:77] Creating layer pool1
I0428 20:22:07.806354  1890 net.cpp:86] Creating Layer pool1
I0428 20:22:07.806357  1890 net.cpp:408] pool1 <- conv1
I0428 20:22:07.806365  1890 net.cpp:382] pool1 -> pool1
I0428 20:22:07.806411  1890 net.cpp:124] Setting up pool1
I0428 20:22:07.806417  1890 net.cpp:131] Top shape: 100 50 4 4 (80000)
I0428 20:22:07.806421  1890 net.cpp:139] Memory required for data: 16314800
I0428 20:22:07.806424  1890 layer_factory.hpp:77] Creating layer ip1
I0428 20:22:07.806432  1890 net.cpp:86] Creating Layer ip1
I0428 20:22:07.806437  1890 net.cpp:408] ip1 <- pool1
I0428 20:22:07.806443  1890 net.cpp:382] ip1 -> ip1
I0428 20:22:07.806840  1890 net.cpp:124] Setting up ip1
I0428 20:22:07.806851  1890 net.cpp:131] Top shape: 100 50 (5000)
I0428 20:22:07.806866  1890 net.cpp:139] Memory required for data: 16334800
I0428 20:22:07.806876  1890 layer_factory.hpp:77] Creating layer relu1
I0428 20:22:07.806884  1890 net.cpp:86] Creating Layer relu1
I0428 20:22:07.806888  1890 net.cpp:408] relu1 <- ip1
I0428 20:22:07.806893  1890 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:22:07.807157  1890 net.cpp:124] Setting up relu1
I0428 20:22:07.807169  1890 net.cpp:131] Top shape: 100 50 (5000)
I0428 20:22:07.807173  1890 net.cpp:139] Memory required for data: 16354800
I0428 20:22:07.807176  1890 layer_factory.hpp:77] Creating layer ip2
I0428 20:22:07.807185  1890 net.cpp:86] Creating Layer ip2
I0428 20:22:07.807188  1890 net.cpp:408] ip2 <- ip1
I0428 20:22:07.807195  1890 net.cpp:382] ip2 -> ip2
I0428 20:22:07.807341  1890 net.cpp:124] Setting up ip2
I0428 20:22:07.807350  1890 net.cpp:131] Top shape: 100 25 (2500)
I0428 20:22:07.807353  1890 net.cpp:139] Memory required for data: 16364800
I0428 20:22:07.807360  1890 layer_factory.hpp:77] Creating layer relu2
I0428 20:22:07.807368  1890 net.cpp:86] Creating Layer relu2
I0428 20:22:07.807371  1890 net.cpp:408] relu2 <- ip2
I0428 20:22:07.807377  1890 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:22:07.807569  1890 net.cpp:124] Setting up relu2
I0428 20:22:07.807579  1890 net.cpp:131] Top shape: 100 25 (2500)
I0428 20:22:07.807582  1890 net.cpp:139] Memory required for data: 16374800
I0428 20:22:07.807586  1890 layer_factory.hpp:77] Creating layer ip3
I0428 20:22:07.807593  1890 net.cpp:86] Creating Layer ip3
I0428 20:22:07.807596  1890 net.cpp:408] ip3 <- ip2
I0428 20:22:07.807603  1890 net.cpp:382] ip3 -> ip3
I0428 20:22:07.807724  1890 net.cpp:124] Setting up ip3
I0428 20:22:07.807732  1890 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:22:07.807735  1890 net.cpp:139] Memory required for data: 16378800
I0428 20:22:07.807744  1890 layer_factory.hpp:77] Creating layer relu3
I0428 20:22:07.807751  1890 net.cpp:86] Creating Layer relu3
I0428 20:22:07.807755  1890 net.cpp:408] relu3 <- ip3
I0428 20:22:07.807761  1890 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:22:07.808737  1890 net.cpp:124] Setting up relu3
I0428 20:22:07.808750  1890 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:22:07.808754  1890 net.cpp:139] Memory required for data: 16382800
I0428 20:22:07.808758  1890 layer_factory.hpp:77] Creating layer ip3_relu3_0_split
I0428 20:22:07.808766  1890 net.cpp:86] Creating Layer ip3_relu3_0_split
I0428 20:22:07.808771  1890 net.cpp:408] ip3_relu3_0_split <- ip3
I0428 20:22:07.808776  1890 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_0
I0428 20:22:07.808784  1890 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_1
I0428 20:22:07.808840  1890 net.cpp:124] Setting up ip3_relu3_0_split
I0428 20:22:07.808846  1890 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:22:07.808851  1890 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:22:07.808854  1890 net.cpp:139] Memory required for data: 16390800
I0428 20:22:07.808858  1890 layer_factory.hpp:77] Creating layer accuracy
I0428 20:22:07.808864  1890 net.cpp:86] Creating Layer accuracy
I0428 20:22:07.808868  1890 net.cpp:408] accuracy <- ip3_relu3_0_split_0
I0428 20:22:07.808873  1890 net.cpp:408] accuracy <- label_mnist_1_split_0
I0428 20:22:07.808881  1890 net.cpp:382] accuracy -> accuracy
I0428 20:22:07.808888  1890 net.cpp:124] Setting up accuracy
I0428 20:22:07.808893  1890 net.cpp:131] Top shape: (1)
I0428 20:22:07.808897  1890 net.cpp:139] Memory required for data: 16390804
I0428 20:22:07.808900  1890 layer_factory.hpp:77] Creating layer loss
I0428 20:22:07.808907  1890 net.cpp:86] Creating Layer loss
I0428 20:22:07.808910  1890 net.cpp:408] loss <- ip3_relu3_0_split_1
I0428 20:22:07.808914  1890 net.cpp:408] loss <- label_mnist_1_split_1
I0428 20:22:07.808919  1890 net.cpp:382] loss -> loss
I0428 20:22:07.808928  1890 layer_factory.hpp:77] Creating layer loss
I0428 20:22:07.809213  1890 net.cpp:124] Setting up loss
I0428 20:22:07.809223  1890 net.cpp:131] Top shape: (1)
I0428 20:22:07.809227  1890 net.cpp:134]     with loss weight 1
I0428 20:22:07.809247  1890 net.cpp:139] Memory required for data: 16390808
I0428 20:22:07.809250  1890 net.cpp:200] loss needs backward computation.
I0428 20:22:07.809255  1890 net.cpp:202] accuracy does not need backward computation.
I0428 20:22:07.809259  1890 net.cpp:200] ip3_relu3_0_split needs backward computation.
I0428 20:22:07.809264  1890 net.cpp:200] relu3 needs backward computation.
I0428 20:22:07.809268  1890 net.cpp:200] ip3 needs backward computation.
I0428 20:22:07.809272  1890 net.cpp:200] relu2 needs backward computation.
I0428 20:22:07.809275  1890 net.cpp:200] ip2 needs backward computation.
I0428 20:22:07.809279  1890 net.cpp:200] relu1 needs backward computation.
I0428 20:22:07.809283  1890 net.cpp:200] ip1 needs backward computation.
I0428 20:22:07.809286  1890 net.cpp:200] pool1 needs backward computation.
I0428 20:22:07.809290  1890 net.cpp:200] conv1 needs backward computation.
I0428 20:22:07.809299  1890 net.cpp:200] pool0 needs backward computation.
I0428 20:22:07.809303  1890 net.cpp:200] conv0 needs backward computation.
I0428 20:22:07.809309  1890 net.cpp:202] label_mnist_1_split does not need backward computation.
I0428 20:22:07.809312  1890 net.cpp:202] mnist does not need backward computation.
I0428 20:22:07.809315  1890 net.cpp:244] This network produces output accuracy
I0428 20:22:07.809319  1890 net.cpp:244] This network produces output loss
I0428 20:22:07.809332  1890 net.cpp:257] Network initialization done.
I0428 20:22:07.809382  1890 solver.cpp:56] Solver scaffolding done.
I0428 20:22:07.809826  1890 caffe.cpp:248] Starting Optimization
I0428 20:22:07.809834  1890 solver.cpp:273] Solving LeNet
I0428 20:22:07.809837  1890 solver.cpp:274] Learning Rate Policy: inv
I0428 20:22:07.810047  1890 solver.cpp:331] Iteration 0, Testing net (#0)
I0428 20:22:07.819488  1890 blocking_queue.cpp:49] Waiting for data
I0428 20:22:07.892170  1906 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:22:07.893379  1890 solver.cpp:398]     Test net output #0: accuracy = 0.1247
I0428 20:22:07.893402  1890 solver.cpp:398]     Test net output #1: loss = 2.30682 (* 1 = 2.30682 loss)
I0428 20:22:07.898835  1890 solver.cpp:219] Iteration 0 (0 iter/s, 0.0889621s/100 iters), loss = 2.29705
I0428 20:22:07.898864  1890 solver.cpp:238]     Train net output #0: loss = 2.29705 (* 1 = 2.29705 loss)
I0428 20:22:07.898877  1890 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0428 20:22:08.073007  1890 solver.cpp:219] Iteration 100 (574.3 iter/s, 0.174125s/100 iters), loss = 0.441572
I0428 20:22:08.073040  1890 solver.cpp:238]     Train net output #0: loss = 0.441572 (* 1 = 0.441572 loss)
I0428 20:22:08.073047  1890 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0428 20:22:08.242154  1890 solver.cpp:219] Iteration 200 (591.365 iter/s, 0.1691s/100 iters), loss = 0.286899
I0428 20:22:08.242187  1890 solver.cpp:238]     Train net output #0: loss = 0.286899 (* 1 = 0.286899 loss)
I0428 20:22:08.242195  1890 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0428 20:22:08.417261  1890 solver.cpp:219] Iteration 300 (571.24 iter/s, 0.175058s/100 iters), loss = 0.462527
I0428 20:22:08.417299  1890 solver.cpp:238]     Train net output #0: loss = 0.462527 (* 1 = 0.462527 loss)
I0428 20:22:08.417309  1890 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0428 20:22:08.603669  1890 solver.cpp:219] Iteration 400 (536.62 iter/s, 0.186352s/100 iters), loss = 0.308581
I0428 20:22:08.603723  1890 solver.cpp:238]     Train net output #0: loss = 0.308581 (* 1 = 0.308581 loss)
I0428 20:22:08.603735  1890 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0428 20:22:08.774890  1890 solver.cpp:331] Iteration 500, Testing net (#0)
I0428 20:22:08.854578  1906 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:22:08.857136  1890 solver.cpp:398]     Test net output #0: accuracy = 0.8742
I0428 20:22:08.857180  1890 solver.cpp:398]     Test net output #1: loss = 0.327212 (* 1 = 0.327212 loss)
I0428 20:22:08.858981  1890 solver.cpp:219] Iteration 500 (391.788 iter/s, 0.25524s/100 iters), loss = 0.354339
I0428 20:22:08.859056  1890 solver.cpp:238]     Train net output #0: loss = 0.354339 (* 1 = 0.354339 loss)
I0428 20:22:08.859071  1890 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0428 20:22:09.049732  1890 solver.cpp:219] Iteration 600 (524.492 iter/s, 0.190661s/100 iters), loss = 0.381733
I0428 20:22:09.049788  1890 solver.cpp:238]     Train net output #0: loss = 0.381733 (* 1 = 0.381733 loss)
I0428 20:22:09.049803  1890 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0428 20:22:09.231422  1890 solver.cpp:219] Iteration 700 (550.61 iter/s, 0.181617s/100 iters), loss = 0.351162
I0428 20:22:09.231474  1890 solver.cpp:238]     Train net output #0: loss = 0.351162 (* 1 = 0.351162 loss)
I0428 20:22:09.231487  1890 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0428 20:22:09.404206  1890 solver.cpp:219] Iteration 800 (578.971 iter/s, 0.17272s/100 iters), loss = 0.484912
I0428 20:22:09.404243  1890 solver.cpp:238]     Train net output #0: loss = 0.484912 (* 1 = 0.484912 loss)
I0428 20:22:09.404253  1890 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0428 20:22:09.569932  1890 solver.cpp:219] Iteration 900 (603.603 iter/s, 0.165672s/100 iters), loss = 0.432566
I0428 20:22:09.569974  1890 solver.cpp:238]     Train net output #0: loss = 0.432566 (* 1 = 0.432566 loss)
I0428 20:22:09.569984  1890 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0428 20:22:09.623929  1905 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:22:09.729691  1890 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_1000.caffemodel
I0428 20:22:09.732542  1890 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_1000.solverstate
I0428 20:22:09.734134  1890 solver.cpp:311] Iteration 1000, loss = 0.366203
I0428 20:22:09.734156  1890 solver.cpp:331] Iteration 1000, Testing net (#0)
I0428 20:22:09.810824  1906 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:22:09.813474  1890 solver.cpp:398]     Test net output #0: accuracy = 0.8846
I0428 20:22:09.813498  1890 solver.cpp:398]     Test net output #1: loss = 0.293515 (* 1 = 0.293515 loss)
I0428 20:22:09.813503  1890 solver.cpp:316] Optimization Done.
I0428 20:22:09.813508  1890 caffe.cpp:259] Optimization Done.
