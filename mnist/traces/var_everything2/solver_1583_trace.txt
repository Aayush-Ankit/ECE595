I0428 20:33:07.658092  4245 caffe.cpp:218] Using GPUs 0
I0428 20:33:07.693708  4245 caffe.cpp:223] GPU 0: TITAN X (Pascal)
I0428 20:33:08.147279  4245 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 1000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_everything2/lenet_train_test1583.prototxt"
train_state {
  level: 0
  stage: ""
}
I0428 20:33:08.147411  4245 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1583.prototxt
I0428 20:33:08.147739  4245 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0428 20:33:08.147755  4245 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0428 20:33:08.147833  4245 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:33:08.147896  4245 layer_factory.hpp:77] Creating layer mnist
I0428 20:33:08.147974  4245 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0428 20:33:08.147994  4245 net.cpp:86] Creating Layer mnist
I0428 20:33:08.148000  4245 net.cpp:382] mnist -> data
I0428 20:33:08.148033  4245 net.cpp:382] mnist -> label
I0428 20:33:08.149047  4245 data_layer.cpp:45] output data size: 64,1,28,28
I0428 20:33:08.151252  4245 net.cpp:124] Setting up mnist
I0428 20:33:08.151281  4245 net.cpp:131] Top shape: 64 1 28 28 (50176)
I0428 20:33:08.151302  4245 net.cpp:131] Top shape: 64 (64)
I0428 20:33:08.151305  4245 net.cpp:139] Memory required for data: 200960
I0428 20:33:08.151311  4245 layer_factory.hpp:77] Creating layer conv0
I0428 20:33:08.151324  4245 net.cpp:86] Creating Layer conv0
I0428 20:33:08.151340  4245 net.cpp:408] conv0 <- data
I0428 20:33:08.151351  4245 net.cpp:382] conv0 -> conv0
I0428 20:33:08.380843  4245 net.cpp:124] Setting up conv0
I0428 20:33:08.380884  4245 net.cpp:131] Top shape: 64 100 24 24 (3686400)
I0428 20:33:08.380888  4245 net.cpp:139] Memory required for data: 14946560
I0428 20:33:08.380918  4245 layer_factory.hpp:77] Creating layer pool0
I0428 20:33:08.380930  4245 net.cpp:86] Creating Layer pool0
I0428 20:33:08.380934  4245 net.cpp:408] pool0 <- conv0
I0428 20:33:08.380939  4245 net.cpp:382] pool0 -> pool0
I0428 20:33:08.381000  4245 net.cpp:124] Setting up pool0
I0428 20:33:08.381006  4245 net.cpp:131] Top shape: 64 100 12 12 (921600)
I0428 20:33:08.381009  4245 net.cpp:139] Memory required for data: 18632960
I0428 20:33:08.381012  4245 layer_factory.hpp:77] Creating layer conv1
I0428 20:33:08.381022  4245 net.cpp:86] Creating Layer conv1
I0428 20:33:08.381026  4245 net.cpp:408] conv1 <- pool0
I0428 20:33:08.381029  4245 net.cpp:382] conv1 -> conv1
I0428 20:33:08.383158  4245 net.cpp:124] Setting up conv1
I0428 20:33:08.383188  4245 net.cpp:131] Top shape: 64 25 8 8 (102400)
I0428 20:33:08.383191  4245 net.cpp:139] Memory required for data: 19042560
I0428 20:33:08.383201  4245 layer_factory.hpp:77] Creating layer pool1
I0428 20:33:08.383209  4245 net.cpp:86] Creating Layer pool1
I0428 20:33:08.383213  4245 net.cpp:408] pool1 <- conv1
I0428 20:33:08.383218  4245 net.cpp:382] pool1 -> pool1
I0428 20:33:08.383283  4245 net.cpp:124] Setting up pool1
I0428 20:33:08.383288  4245 net.cpp:131] Top shape: 64 25 4 4 (25600)
I0428 20:33:08.383291  4245 net.cpp:139] Memory required for data: 19144960
I0428 20:33:08.383294  4245 layer_factory.hpp:77] Creating layer ip1
I0428 20:33:08.383301  4245 net.cpp:86] Creating Layer ip1
I0428 20:33:08.383303  4245 net.cpp:408] ip1 <- pool1
I0428 20:33:08.383308  4245 net.cpp:382] ip1 -> ip1
I0428 20:33:08.384330  4245 net.cpp:124] Setting up ip1
I0428 20:33:08.384342  4245 net.cpp:131] Top shape: 64 25 (1600)
I0428 20:33:08.384361  4245 net.cpp:139] Memory required for data: 19151360
I0428 20:33:08.384369  4245 layer_factory.hpp:77] Creating layer relu1
I0428 20:33:08.384377  4245 net.cpp:86] Creating Layer relu1
I0428 20:33:08.384379  4245 net.cpp:408] relu1 <- ip1
I0428 20:33:08.384385  4245 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:33:08.384584  4245 net.cpp:124] Setting up relu1
I0428 20:33:08.384593  4245 net.cpp:131] Top shape: 64 25 (1600)
I0428 20:33:08.384596  4245 net.cpp:139] Memory required for data: 19157760
I0428 20:33:08.384599  4245 layer_factory.hpp:77] Creating layer ip2
I0428 20:33:08.384606  4245 net.cpp:86] Creating Layer ip2
I0428 20:33:08.384609  4245 net.cpp:408] ip2 <- ip1
I0428 20:33:08.384613  4245 net.cpp:382] ip2 -> ip2
I0428 20:33:08.384707  4245 net.cpp:124] Setting up ip2
I0428 20:33:08.384714  4245 net.cpp:131] Top shape: 64 10 (640)
I0428 20:33:08.384717  4245 net.cpp:139] Memory required for data: 19160320
I0428 20:33:08.384722  4245 layer_factory.hpp:77] Creating layer relu2
I0428 20:33:08.384728  4245 net.cpp:86] Creating Layer relu2
I0428 20:33:08.384732  4245 net.cpp:408] relu2 <- ip2
I0428 20:33:08.384735  4245 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:33:08.385622  4245 net.cpp:124] Setting up relu2
I0428 20:33:08.385633  4245 net.cpp:131] Top shape: 64 10 (640)
I0428 20:33:08.385653  4245 net.cpp:139] Memory required for data: 19162880
I0428 20:33:08.385655  4245 layer_factory.hpp:77] Creating layer ip3
I0428 20:33:08.385663  4245 net.cpp:86] Creating Layer ip3
I0428 20:33:08.385668  4245 net.cpp:408] ip3 <- ip2
I0428 20:33:08.385673  4245 net.cpp:382] ip3 -> ip3
I0428 20:33:08.385787  4245 net.cpp:124] Setting up ip3
I0428 20:33:08.385793  4245 net.cpp:131] Top shape: 64 10 (640)
I0428 20:33:08.385797  4245 net.cpp:139] Memory required for data: 19165440
I0428 20:33:08.385819  4245 layer_factory.hpp:77] Creating layer relu3
I0428 20:33:08.385825  4245 net.cpp:86] Creating Layer relu3
I0428 20:33:08.385828  4245 net.cpp:408] relu3 <- ip3
I0428 20:33:08.385831  4245 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:33:08.386003  4245 net.cpp:124] Setting up relu3
I0428 20:33:08.386013  4245 net.cpp:131] Top shape: 64 10 (640)
I0428 20:33:08.386015  4245 net.cpp:139] Memory required for data: 19168000
I0428 20:33:08.386019  4245 layer_factory.hpp:77] Creating layer loss
I0428 20:33:08.386024  4245 net.cpp:86] Creating Layer loss
I0428 20:33:08.386028  4245 net.cpp:408] loss <- ip3
I0428 20:33:08.386031  4245 net.cpp:408] loss <- label
I0428 20:33:08.386037  4245 net.cpp:382] loss -> loss
I0428 20:33:08.386050  4245 layer_factory.hpp:77] Creating layer loss
I0428 20:33:08.386291  4245 net.cpp:124] Setting up loss
I0428 20:33:08.386301  4245 net.cpp:131] Top shape: (1)
I0428 20:33:08.386302  4245 net.cpp:134]     with loss weight 1
I0428 20:33:08.386333  4245 net.cpp:139] Memory required for data: 19168004
I0428 20:33:08.386337  4245 net.cpp:200] loss needs backward computation.
I0428 20:33:08.386339  4245 net.cpp:200] relu3 needs backward computation.
I0428 20:33:08.386343  4245 net.cpp:200] ip3 needs backward computation.
I0428 20:33:08.386345  4245 net.cpp:200] relu2 needs backward computation.
I0428 20:33:08.386348  4245 net.cpp:200] ip2 needs backward computation.
I0428 20:33:08.386350  4245 net.cpp:200] relu1 needs backward computation.
I0428 20:33:08.386353  4245 net.cpp:200] ip1 needs backward computation.
I0428 20:33:08.386356  4245 net.cpp:200] pool1 needs backward computation.
I0428 20:33:08.386358  4245 net.cpp:200] conv1 needs backward computation.
I0428 20:33:08.386361  4245 net.cpp:200] pool0 needs backward computation.
I0428 20:33:08.386364  4245 net.cpp:200] conv0 needs backward computation.
I0428 20:33:08.386368  4245 net.cpp:202] mnist does not need backward computation.
I0428 20:33:08.386370  4245 net.cpp:244] This network produces output loss
I0428 20:33:08.386379  4245 net.cpp:257] Network initialization done.
I0428 20:33:08.386699  4245 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1583.prototxt
I0428 20:33:08.386754  4245 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0428 20:33:08.386857  4245 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:33:08.386941  4245 layer_factory.hpp:77] Creating layer mnist
I0428 20:33:08.386984  4245 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0428 20:33:08.386996  4245 net.cpp:86] Creating Layer mnist
I0428 20:33:08.387001  4245 net.cpp:382] mnist -> data
I0428 20:33:08.387008  4245 net.cpp:382] mnist -> label
I0428 20:33:08.387105  4245 data_layer.cpp:45] output data size: 100,1,28,28
I0428 20:33:08.389295  4245 net.cpp:124] Setting up mnist
I0428 20:33:08.389308  4245 net.cpp:131] Top shape: 100 1 28 28 (78400)
I0428 20:33:08.389313  4245 net.cpp:131] Top shape: 100 (100)
I0428 20:33:08.389317  4245 net.cpp:139] Memory required for data: 314000
I0428 20:33:08.389320  4245 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0428 20:33:08.389327  4245 net.cpp:86] Creating Layer label_mnist_1_split
I0428 20:33:08.389329  4245 net.cpp:408] label_mnist_1_split <- label
I0428 20:33:08.389360  4245 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_0
I0428 20:33:08.389369  4245 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_1
I0428 20:33:08.389407  4245 net.cpp:124] Setting up label_mnist_1_split
I0428 20:33:08.389412  4245 net.cpp:131] Top shape: 100 (100)
I0428 20:33:08.389416  4245 net.cpp:131] Top shape: 100 (100)
I0428 20:33:08.389418  4245 net.cpp:139] Memory required for data: 314800
I0428 20:33:08.389421  4245 layer_factory.hpp:77] Creating layer conv0
I0428 20:33:08.389430  4245 net.cpp:86] Creating Layer conv0
I0428 20:33:08.389433  4245 net.cpp:408] conv0 <- data
I0428 20:33:08.389438  4245 net.cpp:382] conv0 -> conv0
I0428 20:33:08.391296  4245 net.cpp:124] Setting up conv0
I0428 20:33:08.391309  4245 net.cpp:131] Top shape: 100 100 24 24 (5760000)
I0428 20:33:08.391312  4245 net.cpp:139] Memory required for data: 23354800
I0428 20:33:08.391320  4245 layer_factory.hpp:77] Creating layer pool0
I0428 20:33:08.391327  4245 net.cpp:86] Creating Layer pool0
I0428 20:33:08.391330  4245 net.cpp:408] pool0 <- conv0
I0428 20:33:08.391335  4245 net.cpp:382] pool0 -> pool0
I0428 20:33:08.391369  4245 net.cpp:124] Setting up pool0
I0428 20:33:08.391374  4245 net.cpp:131] Top shape: 100 100 12 12 (1440000)
I0428 20:33:08.391377  4245 net.cpp:139] Memory required for data: 29114800
I0428 20:33:08.391379  4245 layer_factory.hpp:77] Creating layer conv1
I0428 20:33:08.391388  4245 net.cpp:86] Creating Layer conv1
I0428 20:33:08.391391  4245 net.cpp:408] conv1 <- pool0
I0428 20:33:08.391396  4245 net.cpp:382] conv1 -> conv1
I0428 20:33:08.393523  4245 net.cpp:124] Setting up conv1
I0428 20:33:08.393535  4245 net.cpp:131] Top shape: 100 25 8 8 (160000)
I0428 20:33:08.393538  4245 net.cpp:139] Memory required for data: 29754800
I0428 20:33:08.393546  4245 layer_factory.hpp:77] Creating layer pool1
I0428 20:33:08.393569  4245 net.cpp:86] Creating Layer pool1
I0428 20:33:08.393573  4245 net.cpp:408] pool1 <- conv1
I0428 20:33:08.393577  4245 net.cpp:382] pool1 -> pool1
I0428 20:33:08.393625  4245 net.cpp:124] Setting up pool1
I0428 20:33:08.393630  4245 net.cpp:131] Top shape: 100 25 4 4 (40000)
I0428 20:33:08.393633  4245 net.cpp:139] Memory required for data: 29914800
I0428 20:33:08.393635  4245 layer_factory.hpp:77] Creating layer ip1
I0428 20:33:08.393642  4245 net.cpp:86] Creating Layer ip1
I0428 20:33:08.393646  4245 net.cpp:408] ip1 <- pool1
I0428 20:33:08.393651  4245 net.cpp:382] ip1 -> ip1
I0428 20:33:08.393801  4245 net.cpp:124] Setting up ip1
I0428 20:33:08.393821  4245 net.cpp:131] Top shape: 100 25 (2500)
I0428 20:33:08.393849  4245 net.cpp:139] Memory required for data: 29924800
I0428 20:33:08.393860  4245 layer_factory.hpp:77] Creating layer relu1
I0428 20:33:08.393884  4245 net.cpp:86] Creating Layer relu1
I0428 20:33:08.393890  4245 net.cpp:408] relu1 <- ip1
I0428 20:33:08.393898  4245 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:33:08.394074  4245 net.cpp:124] Setting up relu1
I0428 20:33:08.394083  4245 net.cpp:131] Top shape: 100 25 (2500)
I0428 20:33:08.394088  4245 net.cpp:139] Memory required for data: 29934800
I0428 20:33:08.394096  4245 layer_factory.hpp:77] Creating layer ip2
I0428 20:33:08.394104  4245 net.cpp:86] Creating Layer ip2
I0428 20:33:08.394107  4245 net.cpp:408] ip2 <- ip1
I0428 20:33:08.394112  4245 net.cpp:382] ip2 -> ip2
I0428 20:33:08.394208  4245 net.cpp:124] Setting up ip2
I0428 20:33:08.394215  4245 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:33:08.394218  4245 net.cpp:139] Memory required for data: 29938800
I0428 20:33:08.394223  4245 layer_factory.hpp:77] Creating layer relu2
I0428 20:33:08.394228  4245 net.cpp:86] Creating Layer relu2
I0428 20:33:08.394230  4245 net.cpp:408] relu2 <- ip2
I0428 20:33:08.394234  4245 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:33:08.394471  4245 net.cpp:124] Setting up relu2
I0428 20:33:08.394479  4245 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:33:08.394498  4245 net.cpp:139] Memory required for data: 29942800
I0428 20:33:08.394501  4245 layer_factory.hpp:77] Creating layer ip3
I0428 20:33:08.394506  4245 net.cpp:86] Creating Layer ip3
I0428 20:33:08.394510  4245 net.cpp:408] ip3 <- ip2
I0428 20:33:08.394515  4245 net.cpp:382] ip3 -> ip3
I0428 20:33:08.394659  4245 net.cpp:124] Setting up ip3
I0428 20:33:08.394665  4245 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:33:08.394668  4245 net.cpp:139] Memory required for data: 29946800
I0428 20:33:08.394676  4245 layer_factory.hpp:77] Creating layer relu3
I0428 20:33:08.394681  4245 net.cpp:86] Creating Layer relu3
I0428 20:33:08.394685  4245 net.cpp:408] relu3 <- ip3
I0428 20:33:08.394690  4245 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:33:08.395522  4245 net.cpp:124] Setting up relu3
I0428 20:33:08.395534  4245 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:33:08.395539  4245 net.cpp:139] Memory required for data: 29950800
I0428 20:33:08.395542  4245 layer_factory.hpp:77] Creating layer ip3_relu3_0_split
I0428 20:33:08.395547  4245 net.cpp:86] Creating Layer ip3_relu3_0_split
I0428 20:33:08.395550  4245 net.cpp:408] ip3_relu3_0_split <- ip3
I0428 20:33:08.395556  4245 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_0
I0428 20:33:08.395562  4245 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_1
I0428 20:33:08.395611  4245 net.cpp:124] Setting up ip3_relu3_0_split
I0428 20:33:08.395630  4245 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:33:08.395639  4245 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:33:08.395642  4245 net.cpp:139] Memory required for data: 29958800
I0428 20:33:08.395645  4245 layer_factory.hpp:77] Creating layer accuracy
I0428 20:33:08.395651  4245 net.cpp:86] Creating Layer accuracy
I0428 20:33:08.395654  4245 net.cpp:408] accuracy <- ip3_relu3_0_split_0
I0428 20:33:08.395658  4245 net.cpp:408] accuracy <- label_mnist_1_split_0
I0428 20:33:08.395663  4245 net.cpp:382] accuracy -> accuracy
I0428 20:33:08.395669  4245 net.cpp:124] Setting up accuracy
I0428 20:33:08.395673  4245 net.cpp:131] Top shape: (1)
I0428 20:33:08.395676  4245 net.cpp:139] Memory required for data: 29958804
I0428 20:33:08.395678  4245 layer_factory.hpp:77] Creating layer loss
I0428 20:33:08.395683  4245 net.cpp:86] Creating Layer loss
I0428 20:33:08.395685  4245 net.cpp:408] loss <- ip3_relu3_0_split_1
I0428 20:33:08.395689  4245 net.cpp:408] loss <- label_mnist_1_split_1
I0428 20:33:08.395692  4245 net.cpp:382] loss -> loss
I0428 20:33:08.395697  4245 layer_factory.hpp:77] Creating layer loss
I0428 20:33:08.395959  4245 net.cpp:124] Setting up loss
I0428 20:33:08.395970  4245 net.cpp:131] Top shape: (1)
I0428 20:33:08.395989  4245 net.cpp:134]     with loss weight 1
I0428 20:33:08.396005  4245 net.cpp:139] Memory required for data: 29958808
I0428 20:33:08.396009  4245 net.cpp:200] loss needs backward computation.
I0428 20:33:08.396013  4245 net.cpp:202] accuracy does not need backward computation.
I0428 20:33:08.396016  4245 net.cpp:200] ip3_relu3_0_split needs backward computation.
I0428 20:33:08.396019  4245 net.cpp:200] relu3 needs backward computation.
I0428 20:33:08.396023  4245 net.cpp:200] ip3 needs backward computation.
I0428 20:33:08.396025  4245 net.cpp:200] relu2 needs backward computation.
I0428 20:33:08.396028  4245 net.cpp:200] ip2 needs backward computation.
I0428 20:33:08.396039  4245 net.cpp:200] relu1 needs backward computation.
I0428 20:33:08.396041  4245 net.cpp:200] ip1 needs backward computation.
I0428 20:33:08.396044  4245 net.cpp:200] pool1 needs backward computation.
I0428 20:33:08.396071  4245 net.cpp:200] conv1 needs backward computation.
I0428 20:33:08.396075  4245 net.cpp:200] pool0 needs backward computation.
I0428 20:33:08.396078  4245 net.cpp:200] conv0 needs backward computation.
I0428 20:33:08.396081  4245 net.cpp:202] label_mnist_1_split does not need backward computation.
I0428 20:33:08.396085  4245 net.cpp:202] mnist does not need backward computation.
I0428 20:33:08.396088  4245 net.cpp:244] This network produces output accuracy
I0428 20:33:08.396092  4245 net.cpp:244] This network produces output loss
I0428 20:33:08.396105  4245 net.cpp:257] Network initialization done.
I0428 20:33:08.396170  4245 solver.cpp:56] Solver scaffolding done.
I0428 20:33:08.396519  4245 caffe.cpp:248] Starting Optimization
I0428 20:33:08.396525  4245 solver.cpp:273] Solving LeNet
I0428 20:33:08.396528  4245 solver.cpp:274] Learning Rate Policy: inv
I0428 20:33:08.396688  4245 solver.cpp:331] Iteration 0, Testing net (#0)
I0428 20:33:08.494519  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:33:08.497108  4245 solver.cpp:398]     Test net output #0: accuracy = 0.1381
I0428 20:33:08.497126  4245 solver.cpp:398]     Test net output #1: loss = 2.3015 (* 1 = 2.3015 loss)
I0428 20:33:08.503023  4245 solver.cpp:219] Iteration 0 (0 iter/s, 0.106469s/100 iters), loss = 2.31243
I0428 20:33:08.503046  4245 solver.cpp:238]     Train net output #0: loss = 2.31243 (* 1 = 2.31243 loss)
I0428 20:33:08.503072  4245 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0428 20:33:08.720831  4245 solver.cpp:219] Iteration 100 (459.237 iter/s, 0.217753s/100 iters), loss = 0.451679
I0428 20:33:08.720866  4245 solver.cpp:238]     Train net output #0: loss = 0.451679 (* 1 = 0.451679 loss)
I0428 20:33:08.720875  4245 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0428 20:33:08.933676  4245 solver.cpp:219] Iteration 200 (469.937 iter/s, 0.212794s/100 iters), loss = 0.178235
I0428 20:33:08.933706  4245 solver.cpp:238]     Train net output #0: loss = 0.178235 (* 1 = 0.178235 loss)
I0428 20:33:08.933713  4245 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0428 20:33:09.155036  4245 solver.cpp:219] Iteration 300 (451.85 iter/s, 0.221312s/100 iters), loss = 0.344451
I0428 20:33:09.155076  4245 solver.cpp:238]     Train net output #0: loss = 0.344451 (* 1 = 0.344451 loss)
I0428 20:33:09.155086  4245 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0428 20:33:09.365331  4245 solver.cpp:219] Iteration 400 (475.648 iter/s, 0.21024s/100 iters), loss = 0.169419
I0428 20:33:09.365367  4245 solver.cpp:238]     Train net output #0: loss = 0.16942 (* 1 = 0.16942 loss)
I0428 20:33:09.365376  4245 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0428 20:33:09.575253  4245 solver.cpp:331] Iteration 500, Testing net (#0)
I0428 20:33:09.675494  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:33:09.679052  4245 solver.cpp:398]     Test net output #0: accuracy = 0.9661
I0428 20:33:09.679080  4245 solver.cpp:398]     Test net output #1: loss = 0.109596 (* 1 = 0.109596 loss)
I0428 20:33:09.681047  4245 solver.cpp:219] Iteration 500 (316.796 iter/s, 0.31566s/100 iters), loss = 0.101892
I0428 20:33:09.681076  4245 solver.cpp:238]     Train net output #0: loss = 0.101892 (* 1 = 0.101892 loss)
I0428 20:33:09.681118  4245 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0428 20:33:09.895567  4245 solver.cpp:219] Iteration 600 (466.253 iter/s, 0.214476s/100 iters), loss = 0.131674
I0428 20:33:09.895599  4245 solver.cpp:238]     Train net output #0: loss = 0.131674 (* 1 = 0.131674 loss)
I0428 20:33:09.895608  4245 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0428 20:33:10.114375  4245 solver.cpp:219] Iteration 700 (457.122 iter/s, 0.21876s/100 iters), loss = 0.109929
I0428 20:33:10.114408  4245 solver.cpp:238]     Train net output #0: loss = 0.109929 (* 1 = 0.109929 loss)
I0428 20:33:10.114428  4245 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0428 20:33:10.337726  4245 solver.cpp:219] Iteration 800 (447.823 iter/s, 0.223303s/100 iters), loss = 0.30535
I0428 20:33:10.337759  4245 solver.cpp:238]     Train net output #0: loss = 0.30535 (* 1 = 0.30535 loss)
I0428 20:33:10.337766  4245 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0428 20:33:10.563019  4245 solver.cpp:219] Iteration 900 (443.965 iter/s, 0.225243s/100 iters), loss = 0.0813653
I0428 20:33:10.563055  4245 solver.cpp:238]     Train net output #0: loss = 0.0813653 (* 1 = 0.0813653 loss)
I0428 20:33:10.563066  4245 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0428 20:33:10.635013  4251 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:33:10.774511  4245 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_1000.caffemodel
I0428 20:33:10.777180  4245 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_1000.solverstate
I0428 20:33:10.778699  4245 solver.cpp:311] Iteration 1000, loss = 0.0603453
I0428 20:33:10.778726  4245 solver.cpp:331] Iteration 1000, Testing net (#0)
I0428 20:33:10.877923  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:33:10.881464  4245 solver.cpp:398]     Test net output #0: accuracy = 0.9748
I0428 20:33:10.881486  4245 solver.cpp:398]     Test net output #1: loss = 0.0764511 (* 1 = 0.0764511 loss)
I0428 20:33:10.881491  4245 solver.cpp:316] Optimization Done.
I0428 20:33:10.881495  4245 caffe.cpp:259] Optimization Done.
