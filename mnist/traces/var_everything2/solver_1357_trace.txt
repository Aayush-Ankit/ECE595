I0428 20:20:10.073865  1498 caffe.cpp:218] Using GPUs 0
I0428 20:20:10.103668  1498 caffe.cpp:223] GPU 0: TITAN X (Pascal)
I0428 20:20:10.549422  1498 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 1000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_everything2/lenet_train_test1357.prototxt"
train_state {
  level: 0
  stage: ""
}
I0428 20:20:10.549561  1498 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1357.prototxt
I0428 20:20:10.549901  1498 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0428 20:20:10.549931  1498 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0428 20:20:10.550009  1498 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:20:10.550071  1498 layer_factory.hpp:77] Creating layer mnist
I0428 20:20:10.550168  1498 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0428 20:20:10.550186  1498 net.cpp:86] Creating Layer mnist
I0428 20:20:10.550192  1498 net.cpp:382] mnist -> data
I0428 20:20:10.550211  1498 net.cpp:382] mnist -> label
I0428 20:20:10.551108  1498 data_layer.cpp:45] output data size: 64,1,28,28
I0428 20:20:10.553366  1498 net.cpp:124] Setting up mnist
I0428 20:20:10.553414  1498 net.cpp:131] Top shape: 64 1 28 28 (50176)
I0428 20:20:10.553436  1498 net.cpp:131] Top shape: 64 (64)
I0428 20:20:10.553438  1498 net.cpp:139] Memory required for data: 200960
I0428 20:20:10.553444  1498 layer_factory.hpp:77] Creating layer conv0
I0428 20:20:10.553459  1498 net.cpp:86] Creating Layer conv0
I0428 20:20:10.553478  1498 net.cpp:408] conv0 <- data
I0428 20:20:10.553488  1498 net.cpp:382] conv0 -> conv0
I0428 20:20:10.778936  1498 net.cpp:124] Setting up conv0
I0428 20:20:10.778978  1498 net.cpp:131] Top shape: 64 50 24 24 (1843200)
I0428 20:20:10.778982  1498 net.cpp:139] Memory required for data: 7573760
I0428 20:20:10.778997  1498 layer_factory.hpp:77] Creating layer pool0
I0428 20:20:10.779009  1498 net.cpp:86] Creating Layer pool0
I0428 20:20:10.779013  1498 net.cpp:408] pool0 <- conv0
I0428 20:20:10.779033  1498 net.cpp:382] pool0 -> pool0
I0428 20:20:10.779078  1498 net.cpp:124] Setting up pool0
I0428 20:20:10.779093  1498 net.cpp:131] Top shape: 64 50 12 12 (460800)
I0428 20:20:10.779095  1498 net.cpp:139] Memory required for data: 9416960
I0428 20:20:10.779098  1498 layer_factory.hpp:77] Creating layer conv1
I0428 20:20:10.779109  1498 net.cpp:86] Creating Layer conv1
I0428 20:20:10.779112  1498 net.cpp:408] conv1 <- pool0
I0428 20:20:10.779116  1498 net.cpp:382] conv1 -> conv1
I0428 20:20:10.781250  1498 net.cpp:124] Setting up conv1
I0428 20:20:10.781280  1498 net.cpp:131] Top shape: 64 25 8 8 (102400)
I0428 20:20:10.781283  1498 net.cpp:139] Memory required for data: 9826560
I0428 20:20:10.781306  1498 layer_factory.hpp:77] Creating layer pool1
I0428 20:20:10.781313  1498 net.cpp:86] Creating Layer pool1
I0428 20:20:10.781317  1498 net.cpp:408] pool1 <- conv1
I0428 20:20:10.781322  1498 net.cpp:382] pool1 -> pool1
I0428 20:20:10.781373  1498 net.cpp:124] Setting up pool1
I0428 20:20:10.781379  1498 net.cpp:131] Top shape: 64 25 4 4 (25600)
I0428 20:20:10.781383  1498 net.cpp:139] Memory required for data: 9928960
I0428 20:20:10.781385  1498 layer_factory.hpp:77] Creating layer ip1
I0428 20:20:10.781393  1498 net.cpp:86] Creating Layer ip1
I0428 20:20:10.781395  1498 net.cpp:408] ip1 <- pool1
I0428 20:20:10.781399  1498 net.cpp:382] ip1 -> ip1
I0428 20:20:10.781612  1498 net.cpp:124] Setting up ip1
I0428 20:20:10.781620  1498 net.cpp:131] Top shape: 64 50 (3200)
I0428 20:20:10.781625  1498 net.cpp:139] Memory required for data: 9941760
I0428 20:20:10.781631  1498 layer_factory.hpp:77] Creating layer relu1
I0428 20:20:10.781637  1498 net.cpp:86] Creating Layer relu1
I0428 20:20:10.781641  1498 net.cpp:408] relu1 <- ip1
I0428 20:20:10.781644  1498 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:20:10.781841  1498 net.cpp:124] Setting up relu1
I0428 20:20:10.781849  1498 net.cpp:131] Top shape: 64 50 (3200)
I0428 20:20:10.781852  1498 net.cpp:139] Memory required for data: 9954560
I0428 20:20:10.781855  1498 layer_factory.hpp:77] Creating layer ip2
I0428 20:20:10.781862  1498 net.cpp:86] Creating Layer ip2
I0428 20:20:10.781867  1498 net.cpp:408] ip2 <- ip1
I0428 20:20:10.781870  1498 net.cpp:382] ip2 -> ip2
I0428 20:20:10.781980  1498 net.cpp:124] Setting up ip2
I0428 20:20:10.781987  1498 net.cpp:131] Top shape: 64 10 (640)
I0428 20:20:10.781991  1498 net.cpp:139] Memory required for data: 9957120
I0428 20:20:10.781996  1498 layer_factory.hpp:77] Creating layer relu2
I0428 20:20:10.782002  1498 net.cpp:86] Creating Layer relu2
I0428 20:20:10.782004  1498 net.cpp:408] relu2 <- ip2
I0428 20:20:10.782008  1498 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:20:10.782791  1498 net.cpp:124] Setting up relu2
I0428 20:20:10.782804  1498 net.cpp:131] Top shape: 64 10 (640)
I0428 20:20:10.782822  1498 net.cpp:139] Memory required for data: 9959680
I0428 20:20:10.782826  1498 layer_factory.hpp:77] Creating layer ip3
I0428 20:20:10.782833  1498 net.cpp:86] Creating Layer ip3
I0428 20:20:10.782836  1498 net.cpp:408] ip3 <- ip2
I0428 20:20:10.782841  1498 net.cpp:382] ip3 -> ip3
I0428 20:20:10.782939  1498 net.cpp:124] Setting up ip3
I0428 20:20:10.782946  1498 net.cpp:131] Top shape: 64 10 (640)
I0428 20:20:10.782949  1498 net.cpp:139] Memory required for data: 9962240
I0428 20:20:10.782958  1498 layer_factory.hpp:77] Creating layer relu3
I0428 20:20:10.782979  1498 net.cpp:86] Creating Layer relu3
I0428 20:20:10.782981  1498 net.cpp:408] relu3 <- ip3
I0428 20:20:10.782985  1498 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:20:10.783154  1498 net.cpp:124] Setting up relu3
I0428 20:20:10.783164  1498 net.cpp:131] Top shape: 64 10 (640)
I0428 20:20:10.783166  1498 net.cpp:139] Memory required for data: 9964800
I0428 20:20:10.783170  1498 layer_factory.hpp:77] Creating layer loss
I0428 20:20:10.783181  1498 net.cpp:86] Creating Layer loss
I0428 20:20:10.783185  1498 net.cpp:408] loss <- ip3
I0428 20:20:10.783188  1498 net.cpp:408] loss <- label
I0428 20:20:10.783195  1498 net.cpp:382] loss -> loss
I0428 20:20:10.783207  1498 layer_factory.hpp:77] Creating layer loss
I0428 20:20:10.783447  1498 net.cpp:124] Setting up loss
I0428 20:20:10.783455  1498 net.cpp:131] Top shape: (1)
I0428 20:20:10.783459  1498 net.cpp:134]     with loss weight 1
I0428 20:20:10.783475  1498 net.cpp:139] Memory required for data: 9964804
I0428 20:20:10.783478  1498 net.cpp:200] loss needs backward computation.
I0428 20:20:10.783483  1498 net.cpp:200] relu3 needs backward computation.
I0428 20:20:10.783485  1498 net.cpp:200] ip3 needs backward computation.
I0428 20:20:10.783488  1498 net.cpp:200] relu2 needs backward computation.
I0428 20:20:10.783491  1498 net.cpp:200] ip2 needs backward computation.
I0428 20:20:10.783493  1498 net.cpp:200] relu1 needs backward computation.
I0428 20:20:10.783496  1498 net.cpp:200] ip1 needs backward computation.
I0428 20:20:10.783499  1498 net.cpp:200] pool1 needs backward computation.
I0428 20:20:10.783502  1498 net.cpp:200] conv1 needs backward computation.
I0428 20:20:10.783505  1498 net.cpp:200] pool0 needs backward computation.
I0428 20:20:10.783509  1498 net.cpp:200] conv0 needs backward computation.
I0428 20:20:10.783512  1498 net.cpp:202] mnist does not need backward computation.
I0428 20:20:10.783515  1498 net.cpp:244] This network produces output loss
I0428 20:20:10.783524  1498 net.cpp:257] Network initialization done.
I0428 20:20:10.783875  1498 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1357.prototxt
I0428 20:20:10.783917  1498 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0428 20:20:10.784005  1498 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:20:10.784096  1498 layer_factory.hpp:77] Creating layer mnist
I0428 20:20:10.784139  1498 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0428 20:20:10.784152  1498 net.cpp:86] Creating Layer mnist
I0428 20:20:10.784155  1498 net.cpp:382] mnist -> data
I0428 20:20:10.784162  1498 net.cpp:382] mnist -> label
I0428 20:20:10.784242  1498 data_layer.cpp:45] output data size: 100,1,28,28
I0428 20:20:10.786499  1498 net.cpp:124] Setting up mnist
I0428 20:20:10.786542  1498 net.cpp:131] Top shape: 100 1 28 28 (78400)
I0428 20:20:10.786547  1498 net.cpp:131] Top shape: 100 (100)
I0428 20:20:10.786566  1498 net.cpp:139] Memory required for data: 314000
I0428 20:20:10.786571  1498 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0428 20:20:10.786576  1498 net.cpp:86] Creating Layer label_mnist_1_split
I0428 20:20:10.786579  1498 net.cpp:408] label_mnist_1_split <- label
I0428 20:20:10.786584  1498 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_0
I0428 20:20:10.786592  1498 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_1
I0428 20:20:10.786638  1498 net.cpp:124] Setting up label_mnist_1_split
I0428 20:20:10.786643  1498 net.cpp:131] Top shape: 100 (100)
I0428 20:20:10.786646  1498 net.cpp:131] Top shape: 100 (100)
I0428 20:20:10.786649  1498 net.cpp:139] Memory required for data: 314800
I0428 20:20:10.786653  1498 layer_factory.hpp:77] Creating layer conv0
I0428 20:20:10.786660  1498 net.cpp:86] Creating Layer conv0
I0428 20:20:10.786664  1498 net.cpp:408] conv0 <- data
I0428 20:20:10.786667  1498 net.cpp:382] conv0 -> conv0
I0428 20:20:10.788497  1498 net.cpp:124] Setting up conv0
I0428 20:20:10.788527  1498 net.cpp:131] Top shape: 100 50 24 24 (2880000)
I0428 20:20:10.788530  1498 net.cpp:139] Memory required for data: 11834800
I0428 20:20:10.788539  1498 layer_factory.hpp:77] Creating layer pool0
I0428 20:20:10.788545  1498 net.cpp:86] Creating Layer pool0
I0428 20:20:10.788549  1498 net.cpp:408] pool0 <- conv0
I0428 20:20:10.788553  1498 net.cpp:382] pool0 -> pool0
I0428 20:20:10.788588  1498 net.cpp:124] Setting up pool0
I0428 20:20:10.788592  1498 net.cpp:131] Top shape: 100 50 12 12 (720000)
I0428 20:20:10.788594  1498 net.cpp:139] Memory required for data: 14714800
I0428 20:20:10.788597  1498 layer_factory.hpp:77] Creating layer conv1
I0428 20:20:10.788605  1498 net.cpp:86] Creating Layer conv1
I0428 20:20:10.788609  1498 net.cpp:408] conv1 <- pool0
I0428 20:20:10.788612  1498 net.cpp:382] conv1 -> conv1
I0428 20:20:10.790455  1498 net.cpp:124] Setting up conv1
I0428 20:20:10.790487  1498 net.cpp:131] Top shape: 100 25 8 8 (160000)
I0428 20:20:10.790490  1498 net.cpp:139] Memory required for data: 15354800
I0428 20:20:10.790500  1498 layer_factory.hpp:77] Creating layer pool1
I0428 20:20:10.790508  1498 net.cpp:86] Creating Layer pool1
I0428 20:20:10.790511  1498 net.cpp:408] pool1 <- conv1
I0428 20:20:10.790518  1498 net.cpp:382] pool1 -> pool1
I0428 20:20:10.790585  1498 net.cpp:124] Setting up pool1
I0428 20:20:10.790602  1498 net.cpp:131] Top shape: 100 25 4 4 (40000)
I0428 20:20:10.790606  1498 net.cpp:139] Memory required for data: 15514800
I0428 20:20:10.790609  1498 layer_factory.hpp:77] Creating layer ip1
I0428 20:20:10.790616  1498 net.cpp:86] Creating Layer ip1
I0428 20:20:10.790642  1498 net.cpp:408] ip1 <- pool1
I0428 20:20:10.790647  1498 net.cpp:382] ip1 -> ip1
I0428 20:20:10.790855  1498 net.cpp:124] Setting up ip1
I0428 20:20:10.790863  1498 net.cpp:131] Top shape: 100 50 (5000)
I0428 20:20:10.790877  1498 net.cpp:139] Memory required for data: 15534800
I0428 20:20:10.790885  1498 layer_factory.hpp:77] Creating layer relu1
I0428 20:20:10.790890  1498 net.cpp:86] Creating Layer relu1
I0428 20:20:10.790894  1498 net.cpp:408] relu1 <- ip1
I0428 20:20:10.790899  1498 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:20:10.791070  1498 net.cpp:124] Setting up relu1
I0428 20:20:10.791079  1498 net.cpp:131] Top shape: 100 50 (5000)
I0428 20:20:10.791084  1498 net.cpp:139] Memory required for data: 15554800
I0428 20:20:10.791086  1498 layer_factory.hpp:77] Creating layer ip2
I0428 20:20:10.791095  1498 net.cpp:86] Creating Layer ip2
I0428 20:20:10.791097  1498 net.cpp:408] ip2 <- ip1
I0428 20:20:10.791103  1498 net.cpp:382] ip2 -> ip2
I0428 20:20:10.791225  1498 net.cpp:124] Setting up ip2
I0428 20:20:10.791232  1498 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:20:10.791235  1498 net.cpp:139] Memory required for data: 15558800
I0428 20:20:10.791240  1498 layer_factory.hpp:77] Creating layer relu2
I0428 20:20:10.791244  1498 net.cpp:86] Creating Layer relu2
I0428 20:20:10.791247  1498 net.cpp:408] relu2 <- ip2
I0428 20:20:10.791251  1498 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:20:10.791527  1498 net.cpp:124] Setting up relu2
I0428 20:20:10.791538  1498 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:20:10.791540  1498 net.cpp:139] Memory required for data: 15562800
I0428 20:20:10.791543  1498 layer_factory.hpp:77] Creating layer ip3
I0428 20:20:10.791550  1498 net.cpp:86] Creating Layer ip3
I0428 20:20:10.791563  1498 net.cpp:408] ip3 <- ip2
I0428 20:20:10.791569  1498 net.cpp:382] ip3 -> ip3
I0428 20:20:10.791688  1498 net.cpp:124] Setting up ip3
I0428 20:20:10.791710  1498 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:20:10.791713  1498 net.cpp:139] Memory required for data: 15566800
I0428 20:20:10.791723  1498 layer_factory.hpp:77] Creating layer relu3
I0428 20:20:10.791726  1498 net.cpp:86] Creating Layer relu3
I0428 20:20:10.791729  1498 net.cpp:408] relu3 <- ip3
I0428 20:20:10.791740  1498 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:20:10.792577  1498 net.cpp:124] Setting up relu3
I0428 20:20:10.792588  1498 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:20:10.792608  1498 net.cpp:139] Memory required for data: 15570800
I0428 20:20:10.792610  1498 layer_factory.hpp:77] Creating layer ip3_relu3_0_split
I0428 20:20:10.792616  1498 net.cpp:86] Creating Layer ip3_relu3_0_split
I0428 20:20:10.792619  1498 net.cpp:408] ip3_relu3_0_split <- ip3
I0428 20:20:10.792625  1498 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_0
I0428 20:20:10.792631  1498 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_1
I0428 20:20:10.792671  1498 net.cpp:124] Setting up ip3_relu3_0_split
I0428 20:20:10.792676  1498 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:20:10.792680  1498 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:20:10.792683  1498 net.cpp:139] Memory required for data: 15578800
I0428 20:20:10.792686  1498 layer_factory.hpp:77] Creating layer accuracy
I0428 20:20:10.792691  1498 net.cpp:86] Creating Layer accuracy
I0428 20:20:10.792695  1498 net.cpp:408] accuracy <- ip3_relu3_0_split_0
I0428 20:20:10.792699  1498 net.cpp:408] accuracy <- label_mnist_1_split_0
I0428 20:20:10.792704  1498 net.cpp:382] accuracy -> accuracy
I0428 20:20:10.792711  1498 net.cpp:124] Setting up accuracy
I0428 20:20:10.792716  1498 net.cpp:131] Top shape: (1)
I0428 20:20:10.792717  1498 net.cpp:139] Memory required for data: 15578804
I0428 20:20:10.792721  1498 layer_factory.hpp:77] Creating layer loss
I0428 20:20:10.792726  1498 net.cpp:86] Creating Layer loss
I0428 20:20:10.792743  1498 net.cpp:408] loss <- ip3_relu3_0_split_1
I0428 20:20:10.792747  1498 net.cpp:408] loss <- label_mnist_1_split_1
I0428 20:20:10.792752  1498 net.cpp:382] loss -> loss
I0428 20:20:10.792757  1498 layer_factory.hpp:77] Creating layer loss
I0428 20:20:10.793015  1498 net.cpp:124] Setting up loss
I0428 20:20:10.793025  1498 net.cpp:131] Top shape: (1)
I0428 20:20:10.793028  1498 net.cpp:134]     with loss weight 1
I0428 20:20:10.793061  1498 net.cpp:139] Memory required for data: 15578808
I0428 20:20:10.793064  1498 net.cpp:200] loss needs backward computation.
I0428 20:20:10.793068  1498 net.cpp:202] accuracy does not need backward computation.
I0428 20:20:10.793072  1498 net.cpp:200] ip3_relu3_0_split needs backward computation.
I0428 20:20:10.793076  1498 net.cpp:200] relu3 needs backward computation.
I0428 20:20:10.793079  1498 net.cpp:200] ip3 needs backward computation.
I0428 20:20:10.793083  1498 net.cpp:200] relu2 needs backward computation.
I0428 20:20:10.793102  1498 net.cpp:200] ip2 needs backward computation.
I0428 20:20:10.793105  1498 net.cpp:200] relu1 needs backward computation.
I0428 20:20:10.793108  1498 net.cpp:200] ip1 needs backward computation.
I0428 20:20:10.793112  1498 net.cpp:200] pool1 needs backward computation.
I0428 20:20:10.793121  1498 net.cpp:200] conv1 needs backward computation.
I0428 20:20:10.793139  1498 net.cpp:200] pool0 needs backward computation.
I0428 20:20:10.793143  1498 net.cpp:200] conv0 needs backward computation.
I0428 20:20:10.793148  1498 net.cpp:202] label_mnist_1_split does not need backward computation.
I0428 20:20:10.793151  1498 net.cpp:202] mnist does not need backward computation.
I0428 20:20:10.793154  1498 net.cpp:244] This network produces output accuracy
I0428 20:20:10.793157  1498 net.cpp:244] This network produces output loss
I0428 20:20:10.793169  1498 net.cpp:257] Network initialization done.
I0428 20:20:10.793226  1498 solver.cpp:56] Solver scaffolding done.
I0428 20:20:10.793632  1498 caffe.cpp:248] Starting Optimization
I0428 20:20:10.793638  1498 solver.cpp:273] Solving LeNet
I0428 20:20:10.793642  1498 solver.cpp:274] Learning Rate Policy: inv
I0428 20:20:10.794510  1498 solver.cpp:331] Iteration 0, Testing net (#0)
I0428 20:20:10.801134  1498 blocking_queue.cpp:49] Waiting for data
I0428 20:20:10.871980  1505 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:20:10.872773  1498 solver.cpp:398]     Test net output #0: accuracy = 0.0821
I0428 20:20:10.872807  1498 solver.cpp:398]     Test net output #1: loss = 2.32348 (* 1 = 2.32348 loss)
I0428 20:20:10.877053  1498 solver.cpp:219] Iteration 0 (2.73115 iter/s, 0.0833526s/100 iters), loss = 2.32901
I0428 20:20:10.877090  1498 solver.cpp:238]     Train net output #0: loss = 2.32901 (* 1 = 2.32901 loss)
I0428 20:20:10.877101  1498 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0428 20:20:11.010977  1498 solver.cpp:219] Iteration 100 (746.882 iter/s, 0.13389s/100 iters), loss = 0.936335
I0428 20:20:11.011016  1498 solver.cpp:238]     Train net output #0: loss = 0.936335 (* 1 = 0.936335 loss)
I0428 20:20:11.011023  1498 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0428 20:20:11.151469  1498 solver.cpp:219] Iteration 200 (712.045 iter/s, 0.140441s/100 iters), loss = 1.07341
I0428 20:20:11.151509  1498 solver.cpp:238]     Train net output #0: loss = 1.07341 (* 1 = 1.07341 loss)
I0428 20:20:11.151515  1498 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0428 20:20:11.289860  1498 solver.cpp:219] Iteration 300 (722.861 iter/s, 0.138339s/100 iters), loss = 0.495242
I0428 20:20:11.289898  1498 solver.cpp:238]     Train net output #0: loss = 0.495242 (* 1 = 0.495242 loss)
I0428 20:20:11.289904  1498 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0428 20:20:11.428398  1498 solver.cpp:219] Iteration 400 (722.101 iter/s, 0.138485s/100 iters), loss = 0.591101
I0428 20:20:11.428439  1498 solver.cpp:238]     Train net output #0: loss = 0.591101 (* 1 = 0.591101 loss)
I0428 20:20:11.428450  1498 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0428 20:20:11.569114  1498 solver.cpp:331] Iteration 500, Testing net (#0)
I0428 20:20:11.638471  1505 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:20:11.640677  1498 solver.cpp:398]     Test net output #0: accuracy = 0.7825
I0428 20:20:11.640698  1498 solver.cpp:398]     Test net output #1: loss = 0.563285 (* 1 = 0.563285 loss)
I0428 20:20:11.641973  1498 solver.cpp:219] Iteration 500 (468.335 iter/s, 0.213522s/100 iters), loss = 0.658253
I0428 20:20:11.642014  1498 solver.cpp:238]     Train net output #0: loss = 0.658253 (* 1 = 0.658253 loss)
I0428 20:20:11.642020  1498 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0428 20:20:11.781997  1498 solver.cpp:219] Iteration 600 (714.499 iter/s, 0.139958s/100 iters), loss = 0.285989
I0428 20:20:11.782037  1498 solver.cpp:238]     Train net output #0: loss = 0.285989 (* 1 = 0.285989 loss)
I0428 20:20:11.782043  1498 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0428 20:20:11.924049  1498 solver.cpp:219] Iteration 700 (704.149 iter/s, 0.142015s/100 iters), loss = 0.61769
I0428 20:20:11.924088  1498 solver.cpp:238]     Train net output #0: loss = 0.61769 (* 1 = 0.61769 loss)
I0428 20:20:11.924094  1498 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0428 20:20:12.060858  1498 solver.cpp:219] Iteration 800 (731.142 iter/s, 0.136772s/100 iters), loss = 0.524935
I0428 20:20:12.060897  1498 solver.cpp:238]     Train net output #0: loss = 0.524935 (* 1 = 0.524935 loss)
I0428 20:20:12.060904  1498 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0428 20:20:12.208004  1498 solver.cpp:219] Iteration 900 (679.769 iter/s, 0.147109s/100 iters), loss = 0.25749
I0428 20:20:12.208039  1498 solver.cpp:238]     Train net output #0: loss = 0.25749 (* 1 = 0.25749 loss)
I0428 20:20:12.208047  1498 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0428 20:20:12.256642  1504 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:20:12.345995  1498 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_1000.caffemodel
I0428 20:20:12.347578  1498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_1000.solverstate
I0428 20:20:12.348564  1498 solver.cpp:311] Iteration 1000, loss = 0.435917
I0428 20:20:12.348580  1498 solver.cpp:331] Iteration 1000, Testing net (#0)
I0428 20:20:12.413952  1505 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:20:12.415747  1498 solver.cpp:398]     Test net output #0: accuracy = 0.8901
I0428 20:20:12.415766  1498 solver.cpp:398]     Test net output #1: loss = 0.283925 (* 1 = 0.283925 loss)
I0428 20:20:12.415773  1498 solver.cpp:316] Optimization Done.
I0428 20:20:12.415776  1498 caffe.cpp:259] Optimization Done.
