I0428 20:19:50.230031  1433 caffe.cpp:218] Using GPUs 0
I0428 20:19:50.265698  1433 caffe.cpp:223] GPU 0: TITAN X (Pascal)
I0428 20:19:50.785280  1433 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 1000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_everything2/lenet_train_test1350.prototxt"
train_state {
  level: 0
  stage: ""
}
I0428 20:19:50.785424  1433 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1350.prototxt
I0428 20:19:50.785835  1433 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0428 20:19:50.785853  1433 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0428 20:19:50.785957  1433 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:19:50.786041  1433 layer_factory.hpp:77] Creating layer mnist
I0428 20:19:50.786140  1433 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0428 20:19:50.786164  1433 net.cpp:86] Creating Layer mnist
I0428 20:19:50.786172  1433 net.cpp:382] mnist -> data
I0428 20:19:50.786195  1433 net.cpp:382] mnist -> label
I0428 20:19:50.787279  1433 data_layer.cpp:45] output data size: 64,1,28,28
I0428 20:19:50.789752  1433 net.cpp:124] Setting up mnist
I0428 20:19:50.789769  1433 net.cpp:131] Top shape: 64 1 28 28 (50176)
I0428 20:19:50.789775  1433 net.cpp:131] Top shape: 64 (64)
I0428 20:19:50.789778  1433 net.cpp:139] Memory required for data: 200960
I0428 20:19:50.789785  1433 layer_factory.hpp:77] Creating layer conv0
I0428 20:19:50.789824  1433 net.cpp:86] Creating Layer conv0
I0428 20:19:50.789847  1433 net.cpp:408] conv0 <- data
I0428 20:19:50.789860  1433 net.cpp:382] conv0 -> conv0
I0428 20:19:51.082350  1433 net.cpp:124] Setting up conv0
I0428 20:19:51.082383  1433 net.cpp:131] Top shape: 64 50 24 24 (1843200)
I0428 20:19:51.082388  1433 net.cpp:139] Memory required for data: 7573760
I0428 20:19:51.082406  1433 layer_factory.hpp:77] Creating layer pool0
I0428 20:19:51.082422  1433 net.cpp:86] Creating Layer pool0
I0428 20:19:51.082427  1433 net.cpp:408] pool0 <- conv0
I0428 20:19:51.082432  1433 net.cpp:382] pool0 -> pool0
I0428 20:19:51.082489  1433 net.cpp:124] Setting up pool0
I0428 20:19:51.082494  1433 net.cpp:131] Top shape: 64 50 12 12 (460800)
I0428 20:19:51.082499  1433 net.cpp:139] Memory required for data: 9416960
I0428 20:19:51.082501  1433 layer_factory.hpp:77] Creating layer conv1
I0428 20:19:51.082520  1433 net.cpp:86] Creating Layer conv1
I0428 20:19:51.082523  1433 net.cpp:408] conv1 <- pool0
I0428 20:19:51.082530  1433 net.cpp:382] conv1 -> conv1
I0428 20:19:51.084883  1433 net.cpp:124] Setting up conv1
I0428 20:19:51.084902  1433 net.cpp:131] Top shape: 64 25 8 8 (102400)
I0428 20:19:51.084906  1433 net.cpp:139] Memory required for data: 9826560
I0428 20:19:51.084916  1433 layer_factory.hpp:77] Creating layer pool1
I0428 20:19:51.084925  1433 net.cpp:86] Creating Layer pool1
I0428 20:19:51.084930  1433 net.cpp:408] pool1 <- conv1
I0428 20:19:51.084936  1433 net.cpp:382] pool1 -> pool1
I0428 20:19:51.084981  1433 net.cpp:124] Setting up pool1
I0428 20:19:51.084988  1433 net.cpp:131] Top shape: 64 25 4 4 (25600)
I0428 20:19:51.084991  1433 net.cpp:139] Memory required for data: 9928960
I0428 20:19:51.084995  1433 layer_factory.hpp:77] Creating layer ip1
I0428 20:19:51.085003  1433 net.cpp:86] Creating Layer ip1
I0428 20:19:51.085007  1433 net.cpp:408] ip1 <- pool1
I0428 20:19:51.085012  1433 net.cpp:382] ip1 -> ip1
I0428 20:19:51.086164  1433 net.cpp:124] Setting up ip1
I0428 20:19:51.086179  1433 net.cpp:131] Top shape: 64 25 (1600)
I0428 20:19:51.086184  1433 net.cpp:139] Memory required for data: 9935360
I0428 20:19:51.086194  1433 layer_factory.hpp:77] Creating layer relu1
I0428 20:19:51.086201  1433 net.cpp:86] Creating Layer relu1
I0428 20:19:51.086205  1433 net.cpp:408] relu1 <- ip1
I0428 20:19:51.086212  1433 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:19:51.086421  1433 net.cpp:124] Setting up relu1
I0428 20:19:51.086431  1433 net.cpp:131] Top shape: 64 25 (1600)
I0428 20:19:51.086436  1433 net.cpp:139] Memory required for data: 9941760
I0428 20:19:51.086439  1433 layer_factory.hpp:77] Creating layer ip2
I0428 20:19:51.086448  1433 net.cpp:86] Creating Layer ip2
I0428 20:19:51.086452  1433 net.cpp:408] ip2 <- ip1
I0428 20:19:51.086458  1433 net.cpp:382] ip2 -> ip2
I0428 20:19:51.086575  1433 net.cpp:124] Setting up ip2
I0428 20:19:51.086582  1433 net.cpp:131] Top shape: 64 25 (1600)
I0428 20:19:51.086586  1433 net.cpp:139] Memory required for data: 9948160
I0428 20:19:51.086592  1433 layer_factory.hpp:77] Creating layer relu2
I0428 20:19:51.086599  1433 net.cpp:86] Creating Layer relu2
I0428 20:19:51.086603  1433 net.cpp:408] relu2 <- ip2
I0428 20:19:51.086608  1433 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:19:51.087457  1433 net.cpp:124] Setting up relu2
I0428 20:19:51.087473  1433 net.cpp:131] Top shape: 64 25 (1600)
I0428 20:19:51.087477  1433 net.cpp:139] Memory required for data: 9954560
I0428 20:19:51.087481  1433 layer_factory.hpp:77] Creating layer ip3
I0428 20:19:51.087491  1433 net.cpp:86] Creating Layer ip3
I0428 20:19:51.087494  1433 net.cpp:408] ip3 <- ip2
I0428 20:19:51.087501  1433 net.cpp:382] ip3 -> ip3
I0428 20:19:51.087620  1433 net.cpp:124] Setting up ip3
I0428 20:19:51.087630  1433 net.cpp:131] Top shape: 64 10 (640)
I0428 20:19:51.087633  1433 net.cpp:139] Memory required for data: 9957120
I0428 20:19:51.087642  1433 layer_factory.hpp:77] Creating layer relu3
I0428 20:19:51.087648  1433 net.cpp:86] Creating Layer relu3
I0428 20:19:51.087652  1433 net.cpp:408] relu3 <- ip3
I0428 20:19:51.087657  1433 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:19:51.087863  1433 net.cpp:124] Setting up relu3
I0428 20:19:51.087874  1433 net.cpp:131] Top shape: 64 10 (640)
I0428 20:19:51.087878  1433 net.cpp:139] Memory required for data: 9959680
I0428 20:19:51.087882  1433 layer_factory.hpp:77] Creating layer loss
I0428 20:19:51.087888  1433 net.cpp:86] Creating Layer loss
I0428 20:19:51.087893  1433 net.cpp:408] loss <- ip3
I0428 20:19:51.087898  1433 net.cpp:408] loss <- label
I0428 20:19:51.087903  1433 net.cpp:382] loss -> loss
I0428 20:19:51.087920  1433 layer_factory.hpp:77] Creating layer loss
I0428 20:19:51.088205  1433 net.cpp:124] Setting up loss
I0428 20:19:51.088217  1433 net.cpp:131] Top shape: (1)
I0428 20:19:51.088220  1433 net.cpp:134]     with loss weight 1
I0428 20:19:51.088238  1433 net.cpp:139] Memory required for data: 9959684
I0428 20:19:51.088241  1433 net.cpp:200] loss needs backward computation.
I0428 20:19:51.088246  1433 net.cpp:200] relu3 needs backward computation.
I0428 20:19:51.088250  1433 net.cpp:200] ip3 needs backward computation.
I0428 20:19:51.088253  1433 net.cpp:200] relu2 needs backward computation.
I0428 20:19:51.088256  1433 net.cpp:200] ip2 needs backward computation.
I0428 20:19:51.088260  1433 net.cpp:200] relu1 needs backward computation.
I0428 20:19:51.088263  1433 net.cpp:200] ip1 needs backward computation.
I0428 20:19:51.088266  1433 net.cpp:200] pool1 needs backward computation.
I0428 20:19:51.088270  1433 net.cpp:200] conv1 needs backward computation.
I0428 20:19:51.088274  1433 net.cpp:200] pool0 needs backward computation.
I0428 20:19:51.088277  1433 net.cpp:200] conv0 needs backward computation.
I0428 20:19:51.088281  1433 net.cpp:202] mnist does not need backward computation.
I0428 20:19:51.088284  1433 net.cpp:244] This network produces output loss
I0428 20:19:51.088296  1433 net.cpp:257] Network initialization done.
I0428 20:19:51.088681  1433 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1350.prototxt
I0428 20:19:51.088716  1433 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0428 20:19:51.088837  1433 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:19:51.088943  1433 layer_factory.hpp:77] Creating layer mnist
I0428 20:19:51.088994  1433 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0428 20:19:51.089012  1433 net.cpp:86] Creating Layer mnist
I0428 20:19:51.089017  1433 net.cpp:382] mnist -> data
I0428 20:19:51.089026  1433 net.cpp:382] mnist -> label
I0428 20:19:51.089130  1433 data_layer.cpp:45] output data size: 100,1,28,28
I0428 20:19:51.091269  1433 net.cpp:124] Setting up mnist
I0428 20:19:51.091289  1433 net.cpp:131] Top shape: 100 1 28 28 (78400)
I0428 20:19:51.091295  1433 net.cpp:131] Top shape: 100 (100)
I0428 20:19:51.091297  1433 net.cpp:139] Memory required for data: 314000
I0428 20:19:51.091301  1433 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0428 20:19:51.091308  1433 net.cpp:86] Creating Layer label_mnist_1_split
I0428 20:19:51.091312  1433 net.cpp:408] label_mnist_1_split <- label
I0428 20:19:51.091317  1433 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_0
I0428 20:19:51.091325  1433 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_1
I0428 20:19:51.091431  1433 net.cpp:124] Setting up label_mnist_1_split
I0428 20:19:51.091439  1433 net.cpp:131] Top shape: 100 (100)
I0428 20:19:51.091444  1433 net.cpp:131] Top shape: 100 (100)
I0428 20:19:51.091447  1433 net.cpp:139] Memory required for data: 314800
I0428 20:19:51.091450  1433 layer_factory.hpp:77] Creating layer conv0
I0428 20:19:51.091461  1433 net.cpp:86] Creating Layer conv0
I0428 20:19:51.091465  1433 net.cpp:408] conv0 <- data
I0428 20:19:51.091472  1433 net.cpp:382] conv0 -> conv0
I0428 20:19:51.093327  1433 net.cpp:124] Setting up conv0
I0428 20:19:51.093343  1433 net.cpp:131] Top shape: 100 50 24 24 (2880000)
I0428 20:19:51.093358  1433 net.cpp:139] Memory required for data: 11834800
I0428 20:19:51.093367  1433 layer_factory.hpp:77] Creating layer pool0
I0428 20:19:51.093376  1433 net.cpp:86] Creating Layer pool0
I0428 20:19:51.093380  1433 net.cpp:408] pool0 <- conv0
I0428 20:19:51.093386  1433 net.cpp:382] pool0 -> pool0
I0428 20:19:51.093436  1433 net.cpp:124] Setting up pool0
I0428 20:19:51.093442  1433 net.cpp:131] Top shape: 100 50 12 12 (720000)
I0428 20:19:51.093446  1433 net.cpp:139] Memory required for data: 14714800
I0428 20:19:51.093449  1433 layer_factory.hpp:77] Creating layer conv1
I0428 20:19:51.093461  1433 net.cpp:86] Creating Layer conv1
I0428 20:19:51.093464  1433 net.cpp:408] conv1 <- pool0
I0428 20:19:51.093473  1433 net.cpp:382] conv1 -> conv1
I0428 20:19:51.095394  1433 net.cpp:124] Setting up conv1
I0428 20:19:51.095410  1433 net.cpp:131] Top shape: 100 25 8 8 (160000)
I0428 20:19:51.095414  1433 net.cpp:139] Memory required for data: 15354800
I0428 20:19:51.095425  1433 layer_factory.hpp:77] Creating layer pool1
I0428 20:19:51.095432  1433 net.cpp:86] Creating Layer pool1
I0428 20:19:51.095437  1433 net.cpp:408] pool1 <- conv1
I0428 20:19:51.095445  1433 net.cpp:382] pool1 -> pool1
I0428 20:19:51.095487  1433 net.cpp:124] Setting up pool1
I0428 20:19:51.095494  1433 net.cpp:131] Top shape: 100 25 4 4 (40000)
I0428 20:19:51.095497  1433 net.cpp:139] Memory required for data: 15514800
I0428 20:19:51.095501  1433 layer_factory.hpp:77] Creating layer ip1
I0428 20:19:51.095510  1433 net.cpp:86] Creating Layer ip1
I0428 20:19:51.095513  1433 net.cpp:408] ip1 <- pool1
I0428 20:19:51.095520  1433 net.cpp:382] ip1 -> ip1
I0428 20:19:51.095695  1433 net.cpp:124] Setting up ip1
I0428 20:19:51.095705  1433 net.cpp:131] Top shape: 100 25 (2500)
I0428 20:19:51.095721  1433 net.cpp:139] Memory required for data: 15524800
I0428 20:19:51.095737  1433 layer_factory.hpp:77] Creating layer relu1
I0428 20:19:51.095743  1433 net.cpp:86] Creating Layer relu1
I0428 20:19:51.095747  1433 net.cpp:408] relu1 <- ip1
I0428 20:19:51.095752  1433 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:19:51.096000  1433 net.cpp:124] Setting up relu1
I0428 20:19:51.096010  1433 net.cpp:131] Top shape: 100 25 (2500)
I0428 20:19:51.096014  1433 net.cpp:139] Memory required for data: 15534800
I0428 20:19:51.096019  1433 layer_factory.hpp:77] Creating layer ip2
I0428 20:19:51.096026  1433 net.cpp:86] Creating Layer ip2
I0428 20:19:51.096029  1433 net.cpp:408] ip2 <- ip1
I0428 20:19:51.096036  1433 net.cpp:382] ip2 -> ip2
I0428 20:19:51.096179  1433 net.cpp:124] Setting up ip2
I0428 20:19:51.096189  1433 net.cpp:131] Top shape: 100 25 (2500)
I0428 20:19:51.096192  1433 net.cpp:139] Memory required for data: 15544800
I0428 20:19:51.096199  1433 layer_factory.hpp:77] Creating layer relu2
I0428 20:19:51.096204  1433 net.cpp:86] Creating Layer relu2
I0428 20:19:51.096207  1433 net.cpp:408] relu2 <- ip2
I0428 20:19:51.096215  1433 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:19:51.096395  1433 net.cpp:124] Setting up relu2
I0428 20:19:51.096405  1433 net.cpp:131] Top shape: 100 25 (2500)
I0428 20:19:51.096408  1433 net.cpp:139] Memory required for data: 15554800
I0428 20:19:51.096412  1433 layer_factory.hpp:77] Creating layer ip3
I0428 20:19:51.096421  1433 net.cpp:86] Creating Layer ip3
I0428 20:19:51.096424  1433 net.cpp:408] ip3 <- ip2
I0428 20:19:51.096429  1433 net.cpp:382] ip3 -> ip3
I0428 20:19:51.096545  1433 net.cpp:124] Setting up ip3
I0428 20:19:51.096554  1433 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:19:51.096556  1433 net.cpp:139] Memory required for data: 15558800
I0428 20:19:51.096566  1433 layer_factory.hpp:77] Creating layer relu3
I0428 20:19:51.096571  1433 net.cpp:86] Creating Layer relu3
I0428 20:19:51.096575  1433 net.cpp:408] relu3 <- ip3
I0428 20:19:51.096580  1433 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:19:51.097540  1433 net.cpp:124] Setting up relu3
I0428 20:19:51.097555  1433 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:19:51.097559  1433 net.cpp:139] Memory required for data: 15562800
I0428 20:19:51.097563  1433 layer_factory.hpp:77] Creating layer ip3_relu3_0_split
I0428 20:19:51.097573  1433 net.cpp:86] Creating Layer ip3_relu3_0_split
I0428 20:19:51.097576  1433 net.cpp:408] ip3_relu3_0_split <- ip3
I0428 20:19:51.097582  1433 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_0
I0428 20:19:51.097589  1433 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_1
I0428 20:19:51.097635  1433 net.cpp:124] Setting up ip3_relu3_0_split
I0428 20:19:51.097641  1433 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:19:51.097645  1433 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:19:51.097648  1433 net.cpp:139] Memory required for data: 15570800
I0428 20:19:51.097652  1433 layer_factory.hpp:77] Creating layer accuracy
I0428 20:19:51.097657  1433 net.cpp:86] Creating Layer accuracy
I0428 20:19:51.097661  1433 net.cpp:408] accuracy <- ip3_relu3_0_split_0
I0428 20:19:51.097667  1433 net.cpp:408] accuracy <- label_mnist_1_split_0
I0428 20:19:51.097673  1433 net.cpp:382] accuracy -> accuracy
I0428 20:19:51.097681  1433 net.cpp:124] Setting up accuracy
I0428 20:19:51.097685  1433 net.cpp:131] Top shape: (1)
I0428 20:19:51.097689  1433 net.cpp:139] Memory required for data: 15570804
I0428 20:19:51.097692  1433 layer_factory.hpp:77] Creating layer loss
I0428 20:19:51.097697  1433 net.cpp:86] Creating Layer loss
I0428 20:19:51.097700  1433 net.cpp:408] loss <- ip3_relu3_0_split_1
I0428 20:19:51.097705  1433 net.cpp:408] loss <- label_mnist_1_split_1
I0428 20:19:51.097712  1433 net.cpp:382] loss -> loss
I0428 20:19:51.097719  1433 layer_factory.hpp:77] Creating layer loss
I0428 20:19:51.097995  1433 net.cpp:124] Setting up loss
I0428 20:19:51.098006  1433 net.cpp:131] Top shape: (1)
I0428 20:19:51.098011  1433 net.cpp:134]     with loss weight 1
I0428 20:19:51.098028  1433 net.cpp:139] Memory required for data: 15570808
I0428 20:19:51.098034  1433 net.cpp:200] loss needs backward computation.
I0428 20:19:51.098040  1433 net.cpp:202] accuracy does not need backward computation.
I0428 20:19:51.098044  1433 net.cpp:200] ip3_relu3_0_split needs backward computation.
I0428 20:19:51.098048  1433 net.cpp:200] relu3 needs backward computation.
I0428 20:19:51.098052  1433 net.cpp:200] ip3 needs backward computation.
I0428 20:19:51.098057  1433 net.cpp:200] relu2 needs backward computation.
I0428 20:19:51.098059  1433 net.cpp:200] ip2 needs backward computation.
I0428 20:19:51.098062  1433 net.cpp:200] relu1 needs backward computation.
I0428 20:19:51.098067  1433 net.cpp:200] ip1 needs backward computation.
I0428 20:19:51.098069  1433 net.cpp:200] pool1 needs backward computation.
I0428 20:19:51.098073  1433 net.cpp:200] conv1 needs backward computation.
I0428 20:19:51.098076  1433 net.cpp:200] pool0 needs backward computation.
I0428 20:19:51.098080  1433 net.cpp:200] conv0 needs backward computation.
I0428 20:19:51.098085  1433 net.cpp:202] label_mnist_1_split does not need backward computation.
I0428 20:19:51.098096  1433 net.cpp:202] mnist does not need backward computation.
I0428 20:19:51.098099  1433 net.cpp:244] This network produces output accuracy
I0428 20:19:51.098104  1433 net.cpp:244] This network produces output loss
I0428 20:19:51.098116  1433 net.cpp:257] Network initialization done.
I0428 20:19:51.098165  1433 solver.cpp:56] Solver scaffolding done.
I0428 20:19:51.098577  1433 caffe.cpp:248] Starting Optimization
I0428 20:19:51.098583  1433 solver.cpp:273] Solving LeNet
I0428 20:19:51.098587  1433 solver.cpp:274] Learning Rate Policy: inv
I0428 20:19:51.099575  1433 solver.cpp:331] Iteration 0, Testing net (#0)
I0428 20:19:51.106223  1433 blocking_queue.cpp:49] Waiting for data
I0428 20:19:51.175654  1440 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:19:51.176530  1433 solver.cpp:398]     Test net output #0: accuracy = 0.12
I0428 20:19:51.176551  1433 solver.cpp:398]     Test net output #1: loss = 2.31954 (* 1 = 2.31954 loss)
I0428 20:19:51.180898  1433 solver.cpp:219] Iteration 0 (0 iter/s, 0.0822794s/100 iters), loss = 2.31999
I0428 20:19:51.180940  1433 solver.cpp:238]     Train net output #0: loss = 2.31999 (* 1 = 2.31999 loss)
I0428 20:19:51.180969  1433 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0428 20:19:51.327600  1433 solver.cpp:219] Iteration 100 (681.867 iter/s, 0.146656s/100 iters), loss = 0.694433
I0428 20:19:51.327647  1433 solver.cpp:238]     Train net output #0: loss = 0.694433 (* 1 = 0.694433 loss)
I0428 20:19:51.327661  1433 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0428 20:19:51.477843  1433 solver.cpp:219] Iteration 200 (665.851 iter/s, 0.150184s/100 iters), loss = 0.332312
I0428 20:19:51.477887  1433 solver.cpp:238]     Train net output #0: loss = 0.332312 (* 1 = 0.332312 loss)
I0428 20:19:51.477900  1433 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0428 20:19:51.628806  1433 solver.cpp:219] Iteration 300 (662.67 iter/s, 0.150905s/100 iters), loss = 0.385843
I0428 20:19:51.628865  1433 solver.cpp:238]     Train net output #0: loss = 0.385843 (* 1 = 0.385843 loss)
I0428 20:19:51.628877  1433 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0428 20:19:51.783100  1433 solver.cpp:219] Iteration 400 (648.418 iter/s, 0.154222s/100 iters), loss = 0.555811
I0428 20:19:51.783149  1433 solver.cpp:238]     Train net output #0: loss = 0.555811 (* 1 = 0.555811 loss)
I0428 20:19:51.783164  1433 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0428 20:19:51.932504  1433 solver.cpp:331] Iteration 500, Testing net (#0)
I0428 20:19:52.007217  1440 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:19:52.009204  1433 solver.cpp:398]     Test net output #0: accuracy = 0.8702
I0428 20:19:52.009233  1433 solver.cpp:398]     Test net output #1: loss = 0.348418 (* 1 = 0.348418 loss)
I0428 20:19:52.010587  1433 solver.cpp:219] Iteration 500 (439.705 iter/s, 0.227425s/100 iters), loss = 0.446255
I0428 20:19:52.010635  1433 solver.cpp:238]     Train net output #0: loss = 0.446255 (* 1 = 0.446255 loss)
I0428 20:19:52.010645  1433 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0428 20:19:52.152289  1433 solver.cpp:219] Iteration 600 (706.011 iter/s, 0.141641s/100 iters), loss = 0.181254
I0428 20:19:52.152329  1433 solver.cpp:238]     Train net output #0: loss = 0.181254 (* 1 = 0.181254 loss)
I0428 20:19:52.152340  1433 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0428 20:19:52.294114  1433 solver.cpp:219] Iteration 700 (705.349 iter/s, 0.141774s/100 iters), loss = 0.286106
I0428 20:19:52.294150  1433 solver.cpp:238]     Train net output #0: loss = 0.286106 (* 1 = 0.286106 loss)
I0428 20:19:52.294160  1433 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0428 20:19:52.433192  1433 solver.cpp:219] Iteration 800 (719.272 iter/s, 0.13903s/100 iters), loss = 0.367962
I0428 20:19:52.433228  1433 solver.cpp:238]     Train net output #0: loss = 0.367962 (* 1 = 0.367962 loss)
I0428 20:19:52.433238  1433 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0428 20:19:52.578922  1433 solver.cpp:219] Iteration 900 (686.429 iter/s, 0.145681s/100 iters), loss = 0.214935
I0428 20:19:52.578963  1433 solver.cpp:238]     Train net output #0: loss = 0.214935 (* 1 = 0.214935 loss)
I0428 20:19:52.578974  1433 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0428 20:19:52.630337  1439 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:19:52.733937  1433 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_1000.caffemodel
I0428 20:19:52.736093  1433 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_1000.solverstate
I0428 20:19:52.737499  1433 solver.cpp:311] Iteration 1000, loss = 0.242334
I0428 20:19:52.737535  1433 solver.cpp:331] Iteration 1000, Testing net (#0)
I0428 20:19:52.848317  1440 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:19:52.849256  1433 solver.cpp:398]     Test net output #0: accuracy = 0.879
I0428 20:19:52.849292  1433 solver.cpp:398]     Test net output #1: loss = 0.307908 (* 1 = 0.307908 loss)
I0428 20:19:52.849301  1433 solver.cpp:316] Optimization Done.
I0428 20:19:52.849308  1433 caffe.cpp:259] Optimization Done.
