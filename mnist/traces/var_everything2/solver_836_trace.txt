I0428 19:59:02.322367 29145 caffe.cpp:218] Using GPUs 0
I0428 19:59:02.365473 29145 caffe.cpp:223] GPU 0: TITAN X (Pascal)
I0428 19:59:02.882066 29145 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 1000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_everything2/lenet_train_test836.prototxt"
train_state {
  level: 0
  stage: ""
}
I0428 19:59:02.882202 29145 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_everything2/lenet_train_test836.prototxt
I0428 19:59:02.882612 29145 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0428 19:59:02.882632 29145 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0428 19:59:02.882733 29145 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 10
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 10
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 19:59:02.882809 29145 layer_factory.hpp:77] Creating layer mnist
I0428 19:59:02.882903 29145 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0428 19:59:02.882926 29145 net.cpp:86] Creating Layer mnist
I0428 19:59:02.882936 29145 net.cpp:382] mnist -> data
I0428 19:59:02.882957 29145 net.cpp:382] mnist -> label
I0428 19:59:02.884064 29145 data_layer.cpp:45] output data size: 64,1,28,28
I0428 19:59:02.886533 29145 net.cpp:124] Setting up mnist
I0428 19:59:02.886549 29145 net.cpp:131] Top shape: 64 1 28 28 (50176)
I0428 19:59:02.886557 29145 net.cpp:131] Top shape: 64 (64)
I0428 19:59:02.886561 29145 net.cpp:139] Memory required for data: 200960
I0428 19:59:02.886569 29145 layer_factory.hpp:77] Creating layer conv0
I0428 19:59:02.886584 29145 net.cpp:86] Creating Layer conv0
I0428 19:59:02.886608 29145 net.cpp:408] conv0 <- data
I0428 19:59:02.886626 29145 net.cpp:382] conv0 -> conv0
I0428 19:59:03.174165 29145 net.cpp:124] Setting up conv0
I0428 19:59:03.174191 29145 net.cpp:131] Top shape: 64 10 24 24 (368640)
I0428 19:59:03.174196 29145 net.cpp:139] Memory required for data: 1675520
I0428 19:59:03.174217 29145 layer_factory.hpp:77] Creating layer pool0
I0428 19:59:03.174230 29145 net.cpp:86] Creating Layer pool0
I0428 19:59:03.174234 29145 net.cpp:408] pool0 <- conv0
I0428 19:59:03.174240 29145 net.cpp:382] pool0 -> pool0
I0428 19:59:03.174290 29145 net.cpp:124] Setting up pool0
I0428 19:59:03.174299 29145 net.cpp:131] Top shape: 64 10 12 12 (92160)
I0428 19:59:03.174301 29145 net.cpp:139] Memory required for data: 2044160
I0428 19:59:03.174304 29145 layer_factory.hpp:77] Creating layer conv1
I0428 19:59:03.174315 29145 net.cpp:86] Creating Layer conv1
I0428 19:59:03.174320 29145 net.cpp:408] conv1 <- pool0
I0428 19:59:03.174325 29145 net.cpp:382] conv1 -> conv1
I0428 19:59:03.177052 29145 net.cpp:124] Setting up conv1
I0428 19:59:03.177067 29145 net.cpp:131] Top shape: 64 10 8 8 (40960)
I0428 19:59:03.177070 29145 net.cpp:139] Memory required for data: 2208000
I0428 19:59:03.177079 29145 layer_factory.hpp:77] Creating layer pool1
I0428 19:59:03.177090 29145 net.cpp:86] Creating Layer pool1
I0428 19:59:03.177104 29145 net.cpp:408] pool1 <- conv1
I0428 19:59:03.177109 29145 net.cpp:382] pool1 -> pool1
I0428 19:59:03.177155 29145 net.cpp:124] Setting up pool1
I0428 19:59:03.177171 29145 net.cpp:131] Top shape: 64 10 4 4 (10240)
I0428 19:59:03.177175 29145 net.cpp:139] Memory required for data: 2248960
I0428 19:59:03.177177 29145 layer_factory.hpp:77] Creating layer ip1
I0428 19:59:03.177186 29145 net.cpp:86] Creating Layer ip1
I0428 19:59:03.177191 29145 net.cpp:408] ip1 <- pool1
I0428 19:59:03.177197 29145 net.cpp:382] ip1 -> ip1
I0428 19:59:03.177310 29145 net.cpp:124] Setting up ip1
I0428 19:59:03.177317 29145 net.cpp:131] Top shape: 64 10 (640)
I0428 19:59:03.177320 29145 net.cpp:139] Memory required for data: 2251520
I0428 19:59:03.177327 29145 layer_factory.hpp:77] Creating layer relu1
I0428 19:59:03.177333 29145 net.cpp:86] Creating Layer relu1
I0428 19:59:03.177340 29145 net.cpp:408] relu1 <- ip1
I0428 19:59:03.177347 29145 net.cpp:369] relu1 -> ip1 (in-place)
I0428 19:59:03.177520 29145 net.cpp:124] Setting up relu1
I0428 19:59:03.177531 29145 net.cpp:131] Top shape: 64 10 (640)
I0428 19:59:03.177533 29145 net.cpp:139] Memory required for data: 2254080
I0428 19:59:03.177546 29145 layer_factory.hpp:77] Creating layer ip2
I0428 19:59:03.177556 29145 net.cpp:86] Creating Layer ip2
I0428 19:59:03.177561 29145 net.cpp:408] ip2 <- ip1
I0428 19:59:03.177566 29145 net.cpp:382] ip2 -> ip2
I0428 19:59:03.177669 29145 net.cpp:124] Setting up ip2
I0428 19:59:03.177675 29145 net.cpp:131] Top shape: 64 25 (1600)
I0428 19:59:03.177678 29145 net.cpp:139] Memory required for data: 2260480
I0428 19:59:03.177683 29145 layer_factory.hpp:77] Creating layer relu2
I0428 19:59:03.177690 29145 net.cpp:86] Creating Layer relu2
I0428 19:59:03.177695 29145 net.cpp:408] relu2 <- ip2
I0428 19:59:03.177700 29145 net.cpp:369] relu2 -> ip2 (in-place)
I0428 19:59:03.178438 29145 net.cpp:124] Setting up relu2
I0428 19:59:03.178452 29145 net.cpp:131] Top shape: 64 25 (1600)
I0428 19:59:03.178454 29145 net.cpp:139] Memory required for data: 2266880
I0428 19:59:03.178458 29145 layer_factory.hpp:77] Creating layer ip3
I0428 19:59:03.178467 29145 net.cpp:86] Creating Layer ip3
I0428 19:59:03.178470 29145 net.cpp:408] ip3 <- ip2
I0428 19:59:03.178475 29145 net.cpp:382] ip3 -> ip3
I0428 19:59:03.178577 29145 net.cpp:124] Setting up ip3
I0428 19:59:03.178584 29145 net.cpp:131] Top shape: 64 10 (640)
I0428 19:59:03.178588 29145 net.cpp:139] Memory required for data: 2269440
I0428 19:59:03.178596 29145 layer_factory.hpp:77] Creating layer relu3
I0428 19:59:03.178603 29145 net.cpp:86] Creating Layer relu3
I0428 19:59:03.178606 29145 net.cpp:408] relu3 <- ip3
I0428 19:59:03.178611 29145 net.cpp:369] relu3 -> ip3 (in-place)
I0428 19:59:03.178788 29145 net.cpp:124] Setting up relu3
I0428 19:59:03.178798 29145 net.cpp:131] Top shape: 64 10 (640)
I0428 19:59:03.178802 29145 net.cpp:139] Memory required for data: 2272000
I0428 19:59:03.178807 29145 layer_factory.hpp:77] Creating layer loss
I0428 19:59:03.178812 29145 net.cpp:86] Creating Layer loss
I0428 19:59:03.178815 29145 net.cpp:408] loss <- ip3
I0428 19:59:03.178819 29145 net.cpp:408] loss <- label
I0428 19:59:03.178825 29145 net.cpp:382] loss -> loss
I0428 19:59:03.178844 29145 layer_factory.hpp:77] Creating layer loss
I0428 19:59:03.179085 29145 net.cpp:124] Setting up loss
I0428 19:59:03.179093 29145 net.cpp:131] Top shape: (1)
I0428 19:59:03.179097 29145 net.cpp:134]     with loss weight 1
I0428 19:59:03.179111 29145 net.cpp:139] Memory required for data: 2272004
I0428 19:59:03.179116 29145 net.cpp:200] loss needs backward computation.
I0428 19:59:03.179118 29145 net.cpp:200] relu3 needs backward computation.
I0428 19:59:03.179121 29145 net.cpp:200] ip3 needs backward computation.
I0428 19:59:03.179124 29145 net.cpp:200] relu2 needs backward computation.
I0428 19:59:03.179127 29145 net.cpp:200] ip2 needs backward computation.
I0428 19:59:03.179131 29145 net.cpp:200] relu1 needs backward computation.
I0428 19:59:03.179132 29145 net.cpp:200] ip1 needs backward computation.
I0428 19:59:03.179136 29145 net.cpp:200] pool1 needs backward computation.
I0428 19:59:03.179138 29145 net.cpp:200] conv1 needs backward computation.
I0428 19:59:03.179141 29145 net.cpp:200] pool0 needs backward computation.
I0428 19:59:03.179144 29145 net.cpp:200] conv0 needs backward computation.
I0428 19:59:03.179148 29145 net.cpp:202] mnist does not need backward computation.
I0428 19:59:03.179150 29145 net.cpp:244] This network produces output loss
I0428 19:59:03.179162 29145 net.cpp:257] Network initialization done.
I0428 19:59:03.179510 29145 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_everything2/lenet_train_test836.prototxt
I0428 19:59:03.179538 29145 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0428 19:59:03.179633 29145 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 10
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 10
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 19:59:03.179718 29145 layer_factory.hpp:77] Creating layer mnist
I0428 19:59:03.179769 29145 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0428 19:59:03.179785 29145 net.cpp:86] Creating Layer mnist
I0428 19:59:03.179791 29145 net.cpp:382] mnist -> data
I0428 19:59:03.179798 29145 net.cpp:382] mnist -> label
I0428 19:59:03.179885 29145 data_layer.cpp:45] output data size: 100,1,28,28
I0428 19:59:03.181812 29145 net.cpp:124] Setting up mnist
I0428 19:59:03.181824 29145 net.cpp:131] Top shape: 100 1 28 28 (78400)
I0428 19:59:03.181829 29145 net.cpp:131] Top shape: 100 (100)
I0428 19:59:03.181833 29145 net.cpp:139] Memory required for data: 314000
I0428 19:59:03.181836 29145 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0428 19:59:03.181849 29145 net.cpp:86] Creating Layer label_mnist_1_split
I0428 19:59:03.181852 29145 net.cpp:408] label_mnist_1_split <- label
I0428 19:59:03.181859 29145 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_0
I0428 19:59:03.181865 29145 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_1
I0428 19:59:03.181963 29145 net.cpp:124] Setting up label_mnist_1_split
I0428 19:59:03.181972 29145 net.cpp:131] Top shape: 100 (100)
I0428 19:59:03.181977 29145 net.cpp:131] Top shape: 100 (100)
I0428 19:59:03.181978 29145 net.cpp:139] Memory required for data: 314800
I0428 19:59:03.181982 29145 layer_factory.hpp:77] Creating layer conv0
I0428 19:59:03.181991 29145 net.cpp:86] Creating Layer conv0
I0428 19:59:03.181996 29145 net.cpp:408] conv0 <- data
I0428 19:59:03.182003 29145 net.cpp:382] conv0 -> conv0
I0428 19:59:03.183495 29145 net.cpp:124] Setting up conv0
I0428 19:59:03.183509 29145 net.cpp:131] Top shape: 100 10 24 24 (576000)
I0428 19:59:03.183513 29145 net.cpp:139] Memory required for data: 2618800
I0428 19:59:03.183522 29145 layer_factory.hpp:77] Creating layer pool0
I0428 19:59:03.183531 29145 net.cpp:86] Creating Layer pool0
I0428 19:59:03.183533 29145 net.cpp:408] pool0 <- conv0
I0428 19:59:03.183538 29145 net.cpp:382] pool0 -> pool0
I0428 19:59:03.183578 29145 net.cpp:124] Setting up pool0
I0428 19:59:03.183584 29145 net.cpp:131] Top shape: 100 10 12 12 (144000)
I0428 19:59:03.183588 29145 net.cpp:139] Memory required for data: 3194800
I0428 19:59:03.183590 29145 layer_factory.hpp:77] Creating layer conv1
I0428 19:59:03.183599 29145 net.cpp:86] Creating Layer conv1
I0428 19:59:03.183604 29145 net.cpp:408] conv1 <- pool0
I0428 19:59:03.183610 29145 net.cpp:382] conv1 -> conv1
I0428 19:59:03.185693 29145 net.cpp:124] Setting up conv1
I0428 19:59:03.185706 29145 net.cpp:131] Top shape: 100 10 8 8 (64000)
I0428 19:59:03.185710 29145 net.cpp:139] Memory required for data: 3450800
I0428 19:59:03.185719 29145 layer_factory.hpp:77] Creating layer pool1
I0428 19:59:03.185726 29145 net.cpp:86] Creating Layer pool1
I0428 19:59:03.185729 29145 net.cpp:408] pool1 <- conv1
I0428 19:59:03.185745 29145 net.cpp:382] pool1 -> pool1
I0428 19:59:03.185791 29145 net.cpp:124] Setting up pool1
I0428 19:59:03.185797 29145 net.cpp:131] Top shape: 100 10 4 4 (16000)
I0428 19:59:03.185801 29145 net.cpp:139] Memory required for data: 3514800
I0428 19:59:03.185804 29145 layer_factory.hpp:77] Creating layer ip1
I0428 19:59:03.185811 29145 net.cpp:86] Creating Layer ip1
I0428 19:59:03.185816 29145 net.cpp:408] ip1 <- pool1
I0428 19:59:03.185819 29145 net.cpp:382] ip1 -> ip1
I0428 19:59:03.185968 29145 net.cpp:124] Setting up ip1
I0428 19:59:03.185977 29145 net.cpp:131] Top shape: 100 10 (1000)
I0428 19:59:03.185992 29145 net.cpp:139] Memory required for data: 3518800
I0428 19:59:03.186000 29145 layer_factory.hpp:77] Creating layer relu1
I0428 19:59:03.186007 29145 net.cpp:86] Creating Layer relu1
I0428 19:59:03.186012 29145 net.cpp:408] relu1 <- ip1
I0428 19:59:03.186017 29145 net.cpp:369] relu1 -> ip1 (in-place)
I0428 19:59:03.186192 29145 net.cpp:124] Setting up relu1
I0428 19:59:03.186202 29145 net.cpp:131] Top shape: 100 10 (1000)
I0428 19:59:03.186206 29145 net.cpp:139] Memory required for data: 3522800
I0428 19:59:03.186209 29145 layer_factory.hpp:77] Creating layer ip2
I0428 19:59:03.186216 29145 net.cpp:86] Creating Layer ip2
I0428 19:59:03.186220 29145 net.cpp:408] ip2 <- ip1
I0428 19:59:03.186226 29145 net.cpp:382] ip2 -> ip2
I0428 19:59:03.186329 29145 net.cpp:124] Setting up ip2
I0428 19:59:03.186336 29145 net.cpp:131] Top shape: 100 25 (2500)
I0428 19:59:03.186339 29145 net.cpp:139] Memory required for data: 3532800
I0428 19:59:03.186345 29145 layer_factory.hpp:77] Creating layer relu2
I0428 19:59:03.186352 29145 net.cpp:86] Creating Layer relu2
I0428 19:59:03.186357 29145 net.cpp:408] relu2 <- ip2
I0428 19:59:03.186369 29145 net.cpp:369] relu2 -> ip2 (in-place)
I0428 19:59:03.186527 29145 net.cpp:124] Setting up relu2
I0428 19:59:03.186537 29145 net.cpp:131] Top shape: 100 25 (2500)
I0428 19:59:03.186539 29145 net.cpp:139] Memory required for data: 3542800
I0428 19:59:03.186543 29145 layer_factory.hpp:77] Creating layer ip3
I0428 19:59:03.186550 29145 net.cpp:86] Creating Layer ip3
I0428 19:59:03.186555 29145 net.cpp:408] ip3 <- ip2
I0428 19:59:03.186561 29145 net.cpp:382] ip3 -> ip3
I0428 19:59:03.186679 29145 net.cpp:124] Setting up ip3
I0428 19:59:03.186687 29145 net.cpp:131] Top shape: 100 10 (1000)
I0428 19:59:03.186691 29145 net.cpp:139] Memory required for data: 3546800
I0428 19:59:03.186698 29145 layer_factory.hpp:77] Creating layer relu3
I0428 19:59:03.186704 29145 net.cpp:86] Creating Layer relu3
I0428 19:59:03.186707 29145 net.cpp:408] relu3 <- ip3
I0428 19:59:03.186712 29145 net.cpp:369] relu3 -> ip3 (in-place)
I0428 19:59:03.187561 29145 net.cpp:124] Setting up relu3
I0428 19:59:03.187573 29145 net.cpp:131] Top shape: 100 10 (1000)
I0428 19:59:03.187577 29145 net.cpp:139] Memory required for data: 3550800
I0428 19:59:03.187585 29145 layer_factory.hpp:77] Creating layer ip3_relu3_0_split
I0428 19:59:03.187592 29145 net.cpp:86] Creating Layer ip3_relu3_0_split
I0428 19:59:03.187594 29145 net.cpp:408] ip3_relu3_0_split <- ip3
I0428 19:59:03.187602 29145 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_0
I0428 19:59:03.187608 29145 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_1
I0428 19:59:03.187650 29145 net.cpp:124] Setting up ip3_relu3_0_split
I0428 19:59:03.187659 29145 net.cpp:131] Top shape: 100 10 (1000)
I0428 19:59:03.187669 29145 net.cpp:131] Top shape: 100 10 (1000)
I0428 19:59:03.187671 29145 net.cpp:139] Memory required for data: 3558800
I0428 19:59:03.187674 29145 layer_factory.hpp:77] Creating layer accuracy
I0428 19:59:03.187680 29145 net.cpp:86] Creating Layer accuracy
I0428 19:59:03.187683 29145 net.cpp:408] accuracy <- ip3_relu3_0_split_0
I0428 19:59:03.187687 29145 net.cpp:408] accuracy <- label_mnist_1_split_0
I0428 19:59:03.187691 29145 net.cpp:382] accuracy -> accuracy
I0428 19:59:03.187700 29145 net.cpp:124] Setting up accuracy
I0428 19:59:03.187705 29145 net.cpp:131] Top shape: (1)
I0428 19:59:03.187721 29145 net.cpp:139] Memory required for data: 3558804
I0428 19:59:03.187722 29145 layer_factory.hpp:77] Creating layer loss
I0428 19:59:03.187729 29145 net.cpp:86] Creating Layer loss
I0428 19:59:03.187732 29145 net.cpp:408] loss <- ip3_relu3_0_split_1
I0428 19:59:03.187736 29145 net.cpp:408] loss <- label_mnist_1_split_1
I0428 19:59:03.187741 29145 net.cpp:382] loss -> loss
I0428 19:59:03.187747 29145 layer_factory.hpp:77] Creating layer loss
I0428 19:59:03.187999 29145 net.cpp:124] Setting up loss
I0428 19:59:03.188009 29145 net.cpp:131] Top shape: (1)
I0428 19:59:03.188012 29145 net.cpp:134]     with loss weight 1
I0428 19:59:03.188032 29145 net.cpp:139] Memory required for data: 3558808
I0428 19:59:03.188037 29145 net.cpp:200] loss needs backward computation.
I0428 19:59:03.188041 29145 net.cpp:202] accuracy does not need backward computation.
I0428 19:59:03.188045 29145 net.cpp:200] ip3_relu3_0_split needs backward computation.
I0428 19:59:03.188048 29145 net.cpp:200] relu3 needs backward computation.
I0428 19:59:03.188050 29145 net.cpp:200] ip3 needs backward computation.
I0428 19:59:03.188053 29145 net.cpp:200] relu2 needs backward computation.
I0428 19:59:03.188056 29145 net.cpp:200] ip2 needs backward computation.
I0428 19:59:03.188060 29145 net.cpp:200] relu1 needs backward computation.
I0428 19:59:03.188062 29145 net.cpp:200] ip1 needs backward computation.
I0428 19:59:03.188066 29145 net.cpp:200] pool1 needs backward computation.
I0428 19:59:03.188068 29145 net.cpp:200] conv1 needs backward computation.
I0428 19:59:03.188072 29145 net.cpp:200] pool0 needs backward computation.
I0428 19:59:03.188076 29145 net.cpp:200] conv0 needs backward computation.
I0428 19:59:03.188081 29145 net.cpp:202] label_mnist_1_split does not need backward computation.
I0428 19:59:03.188083 29145 net.cpp:202] mnist does not need backward computation.
I0428 19:59:03.188086 29145 net.cpp:244] This network produces output accuracy
I0428 19:59:03.188091 29145 net.cpp:244] This network produces output loss
I0428 19:59:03.188107 29145 net.cpp:257] Network initialization done.
I0428 19:59:03.188149 29145 solver.cpp:56] Solver scaffolding done.
I0428 19:59:03.188531 29145 caffe.cpp:248] Starting Optimization
I0428 19:59:03.188537 29145 solver.cpp:273] Solving LeNet
I0428 19:59:03.188540 29145 solver.cpp:274] Learning Rate Policy: inv
I0428 19:59:03.188740 29145 solver.cpp:331] Iteration 0, Testing net (#0)
I0428 19:59:03.193651 29145 blocking_queue.cpp:49] Waiting for data
I0428 19:59:03.244091 29152 data_layer.cpp:73] Restarting data prefetching from start.
I0428 19:59:03.244676 29145 solver.cpp:398]     Test net output #0: accuracy = 0.059
I0428 19:59:03.244699 29145 solver.cpp:398]     Test net output #1: loss = 2.31146 (* 1 = 2.31146 loss)
I0428 19:59:03.247087 29145 solver.cpp:219] Iteration 0 (-2.37851e-31 iter/s, 0.0584978s/100 iters), loss = 2.32172
I0428 19:59:03.247128 29145 solver.cpp:238]     Train net output #0: loss = 2.32172 (* 1 = 2.32172 loss)
I0428 19:59:03.247138 29145 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0428 19:59:03.324271 29145 solver.cpp:219] Iteration 100 (1296.47 iter/s, 0.0771328s/100 iters), loss = 1.33204
I0428 19:59:03.324311 29145 solver.cpp:238]     Train net output #0: loss = 1.33204 (* 1 = 1.33204 loss)
I0428 19:59:03.324317 29145 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0428 19:59:03.404966 29145 solver.cpp:219] Iteration 200 (1239.79 iter/s, 0.0806585s/100 iters), loss = 0.808225
I0428 19:59:03.405011 29145 solver.cpp:238]     Train net output #0: loss = 0.808225 (* 1 = 0.808225 loss)
I0428 19:59:03.405019 29145 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0428 19:59:03.488899 29145 solver.cpp:219] Iteration 300 (1191.98 iter/s, 0.0838943s/100 iters), loss = 1.25626
I0428 19:59:03.488929 29145 solver.cpp:238]     Train net output #0: loss = 1.25626 (* 1 = 1.25626 loss)
I0428 19:59:03.488936 29145 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0428 19:59:03.571995 29145 solver.cpp:219] Iteration 400 (1204 iter/s, 0.0830566s/100 iters), loss = 0.723444
I0428 19:59:03.572036 29145 solver.cpp:238]     Train net output #0: loss = 0.723444 (* 1 = 0.723444 loss)
I0428 19:59:03.572059 29145 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0428 19:59:03.653496 29145 solver.cpp:331] Iteration 500, Testing net (#0)
I0428 19:59:03.706502 29152 data_layer.cpp:73] Restarting data prefetching from start.
I0428 19:59:03.707016 29145 solver.cpp:398]     Test net output #0: accuracy = 0.6624
I0428 19:59:03.707037 29145 solver.cpp:398]     Test net output #1: loss = 0.849951 (* 1 = 0.849951 loss)
I0428 19:59:03.707890 29145 solver.cpp:219] Iteration 500 (736.056 iter/s, 0.135859s/100 iters), loss = 0.63734
I0428 19:59:03.707927 29145 solver.cpp:238]     Train net output #0: loss = 0.63734 (* 1 = 0.63734 loss)
I0428 19:59:03.707937 29145 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0428 19:59:03.802332 29145 solver.cpp:219] Iteration 600 (1059.37 iter/s, 0.0943953s/100 iters), loss = 0.662991
I0428 19:59:03.802371 29145 solver.cpp:238]     Train net output #0: loss = 0.662991 (* 1 = 0.662991 loss)
I0428 19:59:03.802377 29145 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0428 19:59:03.887523 29145 solver.cpp:219] Iteration 700 (1174.28 iter/s, 0.0851589s/100 iters), loss = 0.880306
I0428 19:59:03.887564 29145 solver.cpp:238]     Train net output #0: loss = 0.880306 (* 1 = 0.880306 loss)
I0428 19:59:03.887586 29145 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0428 19:59:03.969765 29145 solver.cpp:219] Iteration 800 (1216.45 iter/s, 0.0822067s/100 iters), loss = 1.13562
I0428 19:59:03.969791 29145 solver.cpp:238]     Train net output #0: loss = 1.13562 (* 1 = 1.13562 loss)
I0428 19:59:03.969799 29145 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0428 19:59:04.052186 29145 solver.cpp:219] Iteration 900 (1213.81 iter/s, 0.0823849s/100 iters), loss = 0.914902
I0428 19:59:04.052227 29145 solver.cpp:238]     Train net output #0: loss = 0.914902 (* 1 = 0.914902 loss)
I0428 19:59:04.052233 29145 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0428 19:59:04.078548 29151 data_layer.cpp:73] Restarting data prefetching from start.
I0428 19:59:04.129873 29145 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_1000.caffemodel
I0428 19:59:04.130698 29145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_1000.solverstate
I0428 19:59:04.131222 29145 solver.cpp:311] Iteration 1000, loss = 0.914024
I0428 19:59:04.131237 29145 solver.cpp:331] Iteration 1000, Testing net (#0)
I0428 19:59:04.205600 29152 data_layer.cpp:73] Restarting data prefetching from start.
I0428 19:59:04.206178 29145 solver.cpp:398]     Test net output #0: accuracy = 0.6829
I0428 19:59:04.206205 29145 solver.cpp:398]     Test net output #1: loss = 0.780763 (* 1 = 0.780763 loss)
I0428 19:59:04.206212 29145 solver.cpp:316] Optimization Done.
I0428 19:59:04.206218 29145 caffe.cpp:259] Optimization Done.
