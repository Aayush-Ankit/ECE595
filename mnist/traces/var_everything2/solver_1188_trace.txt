I0428 20:12:51.179965 32361 caffe.cpp:218] Using GPUs 0
I0428 20:12:51.217922 32361 caffe.cpp:223] GPU 0: TITAN X (Pascal)
I0428 20:12:51.731542 32361 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 1000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_everything2/lenet_train_test1188.prototxt"
train_state {
  level: 0
  stage: ""
}
I0428 20:12:51.731683 32361 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1188.prototxt
I0428 20:12:51.732110 32361 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0428 20:12:51.732128 32361 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0428 20:12:51.732230 32361 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:12:51.732309 32361 layer_factory.hpp:77] Creating layer mnist
I0428 20:12:51.732408 32361 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0428 20:12:51.732429 32361 net.cpp:86] Creating Layer mnist
I0428 20:12:51.732437 32361 net.cpp:382] mnist -> data
I0428 20:12:51.732460 32361 net.cpp:382] mnist -> label
I0428 20:12:51.733608 32361 data_layer.cpp:45] output data size: 64,1,28,28
I0428 20:12:51.736099 32361 net.cpp:124] Setting up mnist
I0428 20:12:51.736119 32361 net.cpp:131] Top shape: 64 1 28 28 (50176)
I0428 20:12:51.736124 32361 net.cpp:131] Top shape: 64 (64)
I0428 20:12:51.736129 32361 net.cpp:139] Memory required for data: 200960
I0428 20:12:51.736135 32361 layer_factory.hpp:77] Creating layer conv0
I0428 20:12:51.736151 32361 net.cpp:86] Creating Layer conv0
I0428 20:12:51.736178 32361 net.cpp:408] conv0 <- data
I0428 20:12:51.736191 32361 net.cpp:382] conv0 -> conv0
I0428 20:12:52.026752 32361 net.cpp:124] Setting up conv0
I0428 20:12:52.026783 32361 net.cpp:131] Top shape: 64 25 24 24 (921600)
I0428 20:12:52.026788 32361 net.cpp:139] Memory required for data: 3887360
I0428 20:12:52.026804 32361 layer_factory.hpp:77] Creating layer pool0
I0428 20:12:52.026820 32361 net.cpp:86] Creating Layer pool0
I0428 20:12:52.026825 32361 net.cpp:408] pool0 <- conv0
I0428 20:12:52.026831 32361 net.cpp:382] pool0 -> pool0
I0428 20:12:52.026880 32361 net.cpp:124] Setting up pool0
I0428 20:12:52.026885 32361 net.cpp:131] Top shape: 64 25 12 12 (230400)
I0428 20:12:52.026888 32361 net.cpp:139] Memory required for data: 4808960
I0428 20:12:52.026892 32361 layer_factory.hpp:77] Creating layer conv1
I0428 20:12:52.026903 32361 net.cpp:86] Creating Layer conv1
I0428 20:12:52.026906 32361 net.cpp:408] conv1 <- pool0
I0428 20:12:52.026911 32361 net.cpp:382] conv1 -> conv1
I0428 20:12:52.029304 32361 net.cpp:124] Setting up conv1
I0428 20:12:52.029320 32361 net.cpp:131] Top shape: 64 100 8 8 (409600)
I0428 20:12:52.029325 32361 net.cpp:139] Memory required for data: 6447360
I0428 20:12:52.029333 32361 layer_factory.hpp:77] Creating layer pool1
I0428 20:12:52.029341 32361 net.cpp:86] Creating Layer pool1
I0428 20:12:52.029345 32361 net.cpp:408] pool1 <- conv1
I0428 20:12:52.029350 32361 net.cpp:382] pool1 -> pool1
I0428 20:12:52.029388 32361 net.cpp:124] Setting up pool1
I0428 20:12:52.029394 32361 net.cpp:131] Top shape: 64 100 4 4 (102400)
I0428 20:12:52.029399 32361 net.cpp:139] Memory required for data: 6856960
I0428 20:12:52.029403 32361 layer_factory.hpp:77] Creating layer ip1
I0428 20:12:52.029412 32361 net.cpp:86] Creating Layer ip1
I0428 20:12:52.029414 32361 net.cpp:408] ip1 <- pool1
I0428 20:12:52.029419 32361 net.cpp:382] ip1 -> ip1
I0428 20:12:52.030500 32361 net.cpp:124] Setting up ip1
I0428 20:12:52.030514 32361 net.cpp:131] Top shape: 64 10 (640)
I0428 20:12:52.030517 32361 net.cpp:139] Memory required for data: 6859520
I0428 20:12:52.030526 32361 layer_factory.hpp:77] Creating layer relu1
I0428 20:12:52.030534 32361 net.cpp:86] Creating Layer relu1
I0428 20:12:52.030536 32361 net.cpp:408] relu1 <- ip1
I0428 20:12:52.030542 32361 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:12:52.030725 32361 net.cpp:124] Setting up relu1
I0428 20:12:52.030735 32361 net.cpp:131] Top shape: 64 10 (640)
I0428 20:12:52.030738 32361 net.cpp:139] Memory required for data: 6862080
I0428 20:12:52.030741 32361 layer_factory.hpp:77] Creating layer ip2
I0428 20:12:52.030748 32361 net.cpp:86] Creating Layer ip2
I0428 20:12:52.030752 32361 net.cpp:408] ip2 <- ip1
I0428 20:12:52.030757 32361 net.cpp:382] ip2 -> ip2
I0428 20:12:52.030869 32361 net.cpp:124] Setting up ip2
I0428 20:12:52.030877 32361 net.cpp:131] Top shape: 64 50 (3200)
I0428 20:12:52.030880 32361 net.cpp:139] Memory required for data: 6874880
I0428 20:12:52.030886 32361 layer_factory.hpp:77] Creating layer relu2
I0428 20:12:52.030894 32361 net.cpp:86] Creating Layer relu2
I0428 20:12:52.030896 32361 net.cpp:408] relu2 <- ip2
I0428 20:12:52.030901 32361 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:12:52.031677 32361 net.cpp:124] Setting up relu2
I0428 20:12:52.031689 32361 net.cpp:131] Top shape: 64 50 (3200)
I0428 20:12:52.031693 32361 net.cpp:139] Memory required for data: 6887680
I0428 20:12:52.031697 32361 layer_factory.hpp:77] Creating layer ip3
I0428 20:12:52.031704 32361 net.cpp:86] Creating Layer ip3
I0428 20:12:52.031708 32361 net.cpp:408] ip3 <- ip2
I0428 20:12:52.031713 32361 net.cpp:382] ip3 -> ip3
I0428 20:12:52.031824 32361 net.cpp:124] Setting up ip3
I0428 20:12:52.031832 32361 net.cpp:131] Top shape: 64 10 (640)
I0428 20:12:52.031836 32361 net.cpp:139] Memory required for data: 6890240
I0428 20:12:52.031844 32361 layer_factory.hpp:77] Creating layer relu3
I0428 20:12:52.031850 32361 net.cpp:86] Creating Layer relu3
I0428 20:12:52.031853 32361 net.cpp:408] relu3 <- ip3
I0428 20:12:52.031857 32361 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:12:52.032034 32361 net.cpp:124] Setting up relu3
I0428 20:12:52.032044 32361 net.cpp:131] Top shape: 64 10 (640)
I0428 20:12:52.032047 32361 net.cpp:139] Memory required for data: 6892800
I0428 20:12:52.032052 32361 layer_factory.hpp:77] Creating layer loss
I0428 20:12:52.032058 32361 net.cpp:86] Creating Layer loss
I0428 20:12:52.032060 32361 net.cpp:408] loss <- ip3
I0428 20:12:52.032064 32361 net.cpp:408] loss <- label
I0428 20:12:52.032070 32361 net.cpp:382] loss -> loss
I0428 20:12:52.032089 32361 layer_factory.hpp:77] Creating layer loss
I0428 20:12:52.032330 32361 net.cpp:124] Setting up loss
I0428 20:12:52.032341 32361 net.cpp:131] Top shape: (1)
I0428 20:12:52.032346 32361 net.cpp:134]     with loss weight 1
I0428 20:12:52.032364 32361 net.cpp:139] Memory required for data: 6892804
I0428 20:12:52.032368 32361 net.cpp:200] loss needs backward computation.
I0428 20:12:52.032372 32361 net.cpp:200] relu3 needs backward computation.
I0428 20:12:52.032376 32361 net.cpp:200] ip3 needs backward computation.
I0428 20:12:52.032378 32361 net.cpp:200] relu2 needs backward computation.
I0428 20:12:52.032382 32361 net.cpp:200] ip2 needs backward computation.
I0428 20:12:52.032384 32361 net.cpp:200] relu1 needs backward computation.
I0428 20:12:52.032387 32361 net.cpp:200] ip1 needs backward computation.
I0428 20:12:52.032390 32361 net.cpp:200] pool1 needs backward computation.
I0428 20:12:52.032393 32361 net.cpp:200] conv1 needs backward computation.
I0428 20:12:52.032397 32361 net.cpp:200] pool0 needs backward computation.
I0428 20:12:52.032400 32361 net.cpp:200] conv0 needs backward computation.
I0428 20:12:52.032403 32361 net.cpp:202] mnist does not need backward computation.
I0428 20:12:52.032407 32361 net.cpp:244] This network produces output loss
I0428 20:12:52.032418 32361 net.cpp:257] Network initialization done.
I0428 20:12:52.032763 32361 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1188.prototxt
I0428 20:12:52.032791 32361 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0428 20:12:52.032896 32361 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:12:52.032984 32361 layer_factory.hpp:77] Creating layer mnist
I0428 20:12:52.033030 32361 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0428 20:12:52.033043 32361 net.cpp:86] Creating Layer mnist
I0428 20:12:52.033048 32361 net.cpp:382] mnist -> data
I0428 20:12:52.033056 32361 net.cpp:382] mnist -> label
I0428 20:12:52.033145 32361 data_layer.cpp:45] output data size: 100,1,28,28
I0428 20:12:52.035346 32361 net.cpp:124] Setting up mnist
I0428 20:12:52.035359 32361 net.cpp:131] Top shape: 100 1 28 28 (78400)
I0428 20:12:52.035364 32361 net.cpp:131] Top shape: 100 (100)
I0428 20:12:52.035367 32361 net.cpp:139] Memory required for data: 314000
I0428 20:12:52.035372 32361 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0428 20:12:52.035379 32361 net.cpp:86] Creating Layer label_mnist_1_split
I0428 20:12:52.035383 32361 net.cpp:408] label_mnist_1_split <- label
I0428 20:12:52.035388 32361 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_0
I0428 20:12:52.035395 32361 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_1
I0428 20:12:52.035436 32361 net.cpp:124] Setting up label_mnist_1_split
I0428 20:12:52.035442 32361 net.cpp:131] Top shape: 100 (100)
I0428 20:12:52.035446 32361 net.cpp:131] Top shape: 100 (100)
I0428 20:12:52.035450 32361 net.cpp:139] Memory required for data: 314800
I0428 20:12:52.035454 32361 layer_factory.hpp:77] Creating layer conv0
I0428 20:12:52.035465 32361 net.cpp:86] Creating Layer conv0
I0428 20:12:52.035468 32361 net.cpp:408] conv0 <- data
I0428 20:12:52.035475 32361 net.cpp:382] conv0 -> conv0
I0428 20:12:52.037287 32361 net.cpp:124] Setting up conv0
I0428 20:12:52.037303 32361 net.cpp:131] Top shape: 100 25 24 24 (1440000)
I0428 20:12:52.037307 32361 net.cpp:139] Memory required for data: 6074800
I0428 20:12:52.037317 32361 layer_factory.hpp:77] Creating layer pool0
I0428 20:12:52.037324 32361 net.cpp:86] Creating Layer pool0
I0428 20:12:52.037328 32361 net.cpp:408] pool0 <- conv0
I0428 20:12:52.037333 32361 net.cpp:382] pool0 -> pool0
I0428 20:12:52.037372 32361 net.cpp:124] Setting up pool0
I0428 20:12:52.037379 32361 net.cpp:131] Top shape: 100 25 12 12 (360000)
I0428 20:12:52.037381 32361 net.cpp:139] Memory required for data: 7514800
I0428 20:12:52.037384 32361 layer_factory.hpp:77] Creating layer conv1
I0428 20:12:52.037394 32361 net.cpp:86] Creating Layer conv1
I0428 20:12:52.037396 32361 net.cpp:408] conv1 <- pool0
I0428 20:12:52.037402 32361 net.cpp:382] conv1 -> conv1
I0428 20:12:52.039453 32361 net.cpp:124] Setting up conv1
I0428 20:12:52.039466 32361 net.cpp:131] Top shape: 100 100 8 8 (640000)
I0428 20:12:52.039470 32361 net.cpp:139] Memory required for data: 10074800
I0428 20:12:52.039480 32361 layer_factory.hpp:77] Creating layer pool1
I0428 20:12:52.039487 32361 net.cpp:86] Creating Layer pool1
I0428 20:12:52.039491 32361 net.cpp:408] pool1 <- conv1
I0428 20:12:52.039497 32361 net.cpp:382] pool1 -> pool1
I0428 20:12:52.039536 32361 net.cpp:124] Setting up pool1
I0428 20:12:52.039542 32361 net.cpp:131] Top shape: 100 100 4 4 (160000)
I0428 20:12:52.039544 32361 net.cpp:139] Memory required for data: 10714800
I0428 20:12:52.039548 32361 layer_factory.hpp:77] Creating layer ip1
I0428 20:12:52.039556 32361 net.cpp:86] Creating Layer ip1
I0428 20:12:52.039559 32361 net.cpp:408] ip1 <- pool1
I0428 20:12:52.039572 32361 net.cpp:382] ip1 -> ip1
I0428 20:12:52.039767 32361 net.cpp:124] Setting up ip1
I0428 20:12:52.039775 32361 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:12:52.039789 32361 net.cpp:139] Memory required for data: 10718800
I0428 20:12:52.039804 32361 layer_factory.hpp:77] Creating layer relu1
I0428 20:12:52.039811 32361 net.cpp:86] Creating Layer relu1
I0428 20:12:52.039815 32361 net.cpp:408] relu1 <- ip1
I0428 20:12:52.039819 32361 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:12:52.040000 32361 net.cpp:124] Setting up relu1
I0428 20:12:52.040010 32361 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:12:52.040014 32361 net.cpp:139] Memory required for data: 10722800
I0428 20:12:52.040017 32361 layer_factory.hpp:77] Creating layer ip2
I0428 20:12:52.040031 32361 net.cpp:86] Creating Layer ip2
I0428 20:12:52.040035 32361 net.cpp:408] ip2 <- ip1
I0428 20:12:52.040046 32361 net.cpp:382] ip2 -> ip2
I0428 20:12:52.040158 32361 net.cpp:124] Setting up ip2
I0428 20:12:52.040165 32361 net.cpp:131] Top shape: 100 50 (5000)
I0428 20:12:52.040169 32361 net.cpp:139] Memory required for data: 10742800
I0428 20:12:52.040174 32361 layer_factory.hpp:77] Creating layer relu2
I0428 20:12:52.040180 32361 net.cpp:86] Creating Layer relu2
I0428 20:12:52.040184 32361 net.cpp:408] relu2 <- ip2
I0428 20:12:52.040189 32361 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:12:52.040354 32361 net.cpp:124] Setting up relu2
I0428 20:12:52.040364 32361 net.cpp:131] Top shape: 100 50 (5000)
I0428 20:12:52.040366 32361 net.cpp:139] Memory required for data: 10762800
I0428 20:12:52.040376 32361 layer_factory.hpp:77] Creating layer ip3
I0428 20:12:52.040383 32361 net.cpp:86] Creating Layer ip3
I0428 20:12:52.040392 32361 net.cpp:408] ip3 <- ip2
I0428 20:12:52.040400 32361 net.cpp:382] ip3 -> ip3
I0428 20:12:52.040547 32361 net.cpp:124] Setting up ip3
I0428 20:12:52.040555 32361 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:12:52.040558 32361 net.cpp:139] Memory required for data: 10766800
I0428 20:12:52.040571 32361 layer_factory.hpp:77] Creating layer relu3
I0428 20:12:52.040577 32361 net.cpp:86] Creating Layer relu3
I0428 20:12:52.040580 32361 net.cpp:408] relu3 <- ip3
I0428 20:12:52.040585 32361 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:12:52.041446 32361 net.cpp:124] Setting up relu3
I0428 20:12:52.041460 32361 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:12:52.041465 32361 net.cpp:139] Memory required for data: 10770800
I0428 20:12:52.041467 32361 layer_factory.hpp:77] Creating layer ip3_relu3_0_split
I0428 20:12:52.041472 32361 net.cpp:86] Creating Layer ip3_relu3_0_split
I0428 20:12:52.041483 32361 net.cpp:408] ip3_relu3_0_split <- ip3
I0428 20:12:52.041489 32361 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_0
I0428 20:12:52.041496 32361 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_1
I0428 20:12:52.041535 32361 net.cpp:124] Setting up ip3_relu3_0_split
I0428 20:12:52.041541 32361 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:12:52.041551 32361 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:12:52.041554 32361 net.cpp:139] Memory required for data: 10778800
I0428 20:12:52.041558 32361 layer_factory.hpp:77] Creating layer accuracy
I0428 20:12:52.041568 32361 net.cpp:86] Creating Layer accuracy
I0428 20:12:52.041570 32361 net.cpp:408] accuracy <- ip3_relu3_0_split_0
I0428 20:12:52.041574 32361 net.cpp:408] accuracy <- label_mnist_1_split_0
I0428 20:12:52.041579 32361 net.cpp:382] accuracy -> accuracy
I0428 20:12:52.041586 32361 net.cpp:124] Setting up accuracy
I0428 20:12:52.041590 32361 net.cpp:131] Top shape: (1)
I0428 20:12:52.041594 32361 net.cpp:139] Memory required for data: 10778804
I0428 20:12:52.041601 32361 layer_factory.hpp:77] Creating layer loss
I0428 20:12:52.041607 32361 net.cpp:86] Creating Layer loss
I0428 20:12:52.041610 32361 net.cpp:408] loss <- ip3_relu3_0_split_1
I0428 20:12:52.041620 32361 net.cpp:408] loss <- label_mnist_1_split_1
I0428 20:12:52.041625 32361 net.cpp:382] loss -> loss
I0428 20:12:52.041630 32361 layer_factory.hpp:77] Creating layer loss
I0428 20:12:52.041877 32361 net.cpp:124] Setting up loss
I0428 20:12:52.041885 32361 net.cpp:131] Top shape: (1)
I0428 20:12:52.041888 32361 net.cpp:134]     with loss weight 1
I0428 20:12:52.041905 32361 net.cpp:139] Memory required for data: 10778808
I0428 20:12:52.041916 32361 net.cpp:200] loss needs backward computation.
I0428 20:12:52.041920 32361 net.cpp:202] accuracy does not need backward computation.
I0428 20:12:52.041923 32361 net.cpp:200] ip3_relu3_0_split needs backward computation.
I0428 20:12:52.041926 32361 net.cpp:200] relu3 needs backward computation.
I0428 20:12:52.041929 32361 net.cpp:200] ip3 needs backward computation.
I0428 20:12:52.041934 32361 net.cpp:200] relu2 needs backward computation.
I0428 20:12:52.041935 32361 net.cpp:200] ip2 needs backward computation.
I0428 20:12:52.041939 32361 net.cpp:200] relu1 needs backward computation.
I0428 20:12:52.041941 32361 net.cpp:200] ip1 needs backward computation.
I0428 20:12:52.041944 32361 net.cpp:200] pool1 needs backward computation.
I0428 20:12:52.041947 32361 net.cpp:200] conv1 needs backward computation.
I0428 20:12:52.041949 32361 net.cpp:200] pool0 needs backward computation.
I0428 20:12:52.041954 32361 net.cpp:200] conv0 needs backward computation.
I0428 20:12:52.041965 32361 net.cpp:202] label_mnist_1_split does not need backward computation.
I0428 20:12:52.041967 32361 net.cpp:202] mnist does not need backward computation.
I0428 20:12:52.041980 32361 net.cpp:244] This network produces output accuracy
I0428 20:12:52.041985 32361 net.cpp:244] This network produces output loss
I0428 20:12:52.041996 32361 net.cpp:257] Network initialization done.
I0428 20:12:52.042038 32361 solver.cpp:56] Solver scaffolding done.
I0428 20:12:52.042371 32361 caffe.cpp:248] Starting Optimization
I0428 20:12:52.042377 32361 solver.cpp:273] Solving LeNet
I0428 20:12:52.042381 32361 solver.cpp:274] Learning Rate Policy: inv
I0428 20:12:52.043244 32361 solver.cpp:331] Iteration 0, Testing net (#0)
I0428 20:12:52.050454 32361 blocking_queue.cpp:49] Waiting for data
I0428 20:12:52.122545 32368 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:12:52.123322 32361 solver.cpp:398]     Test net output #0: accuracy = 0.1106
I0428 20:12:52.123338 32361 solver.cpp:398]     Test net output #1: loss = 2.30748 (* 1 = 2.30748 loss)
I0428 20:12:52.128165 32361 solver.cpp:219] Iteration 0 (0 iter/s, 0.085759s/100 iters), loss = 2.30759
I0428 20:12:52.128187 32361 solver.cpp:238]     Train net output #0: loss = 2.30759 (* 1 = 2.30759 loss)
I0428 20:12:52.128216 32361 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0428 20:12:52.284426 32361 solver.cpp:219] Iteration 100 (640.117 iter/s, 0.156221s/100 iters), loss = 0.928567
I0428 20:12:52.284451 32361 solver.cpp:238]     Train net output #0: loss = 0.928567 (* 1 = 0.928567 loss)
I0428 20:12:52.284472 32361 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0428 20:12:52.445027 32361 solver.cpp:219] Iteration 200 (622.808 iter/s, 0.160563s/100 iters), loss = 0.611282
I0428 20:12:52.445055 32361 solver.cpp:238]     Train net output #0: loss = 0.611282 (* 1 = 0.611282 loss)
I0428 20:12:52.445077 32361 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0428 20:12:52.614071 32361 solver.cpp:219] Iteration 300 (591.705 iter/s, 0.169003s/100 iters), loss = 0.616293
I0428 20:12:52.614099 32361 solver.cpp:238]     Train net output #0: loss = 0.616293 (* 1 = 0.616293 loss)
I0428 20:12:52.614104 32361 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0428 20:12:52.777745 32361 solver.cpp:219] Iteration 400 (611.123 iter/s, 0.163633s/100 iters), loss = 0.386347
I0428 20:12:52.777772 32361 solver.cpp:238]     Train net output #0: loss = 0.386347 (* 1 = 0.386347 loss)
I0428 20:12:52.777779 32361 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0428 20:12:52.938370 32361 solver.cpp:331] Iteration 500, Testing net (#0)
I0428 20:12:53.006142 32368 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:12:53.008522 32361 solver.cpp:398]     Test net output #0: accuracy = 0.8669
I0428 20:12:53.008541 32361 solver.cpp:398]     Test net output #1: loss = 0.363416 (* 1 = 0.363416 loss)
I0428 20:12:53.010006 32361 solver.cpp:219] Iteration 500 (430.661 iter/s, 0.232201s/100 iters), loss = 0.372763
I0428 20:12:53.010061 32361 solver.cpp:238]     Train net output #0: loss = 0.372763 (* 1 = 0.372763 loss)
I0428 20:12:53.010084 32361 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0428 20:12:53.171744 32361 solver.cpp:219] Iteration 600 (618.547 iter/s, 0.161669s/100 iters), loss = 0.361133
I0428 20:12:53.171769 32361 solver.cpp:238]     Train net output #0: loss = 0.361133 (* 1 = 0.361133 loss)
I0428 20:12:53.171792 32361 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0428 20:12:53.330966 32361 solver.cpp:219] Iteration 700 (628.204 iter/s, 0.159184s/100 iters), loss = 0.313872
I0428 20:12:53.330992 32361 solver.cpp:238]     Train net output #0: loss = 0.313872 (* 1 = 0.313872 loss)
I0428 20:12:53.330998 32361 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0428 20:12:53.494271 32361 solver.cpp:219] Iteration 800 (612.503 iter/s, 0.163265s/100 iters), loss = 0.529331
I0428 20:12:53.494295 32361 solver.cpp:238]     Train net output #0: loss = 0.529331 (* 1 = 0.529331 loss)
I0428 20:12:53.494302 32361 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0428 20:12:53.658738 32361 solver.cpp:219] Iteration 900 (608.166 iter/s, 0.164429s/100 iters), loss = 0.407515
I0428 20:12:53.658773 32361 solver.cpp:238]     Train net output #0: loss = 0.407515 (* 1 = 0.407515 loss)
I0428 20:12:53.658780 32361 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0428 20:12:53.712842 32367 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:12:53.817728 32361 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_1000.caffemodel
I0428 20:12:53.819983 32361 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_1000.solverstate
I0428 20:12:53.821178 32361 solver.cpp:311] Iteration 1000, loss = 0.371775
I0428 20:12:53.821200 32361 solver.cpp:331] Iteration 1000, Testing net (#0)
I0428 20:12:53.887627 32368 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:12:53.890079 32361 solver.cpp:398]     Test net output #0: accuracy = 0.8826
I0428 20:12:53.890095 32361 solver.cpp:398]     Test net output #1: loss = 0.306892 (* 1 = 0.306892 loss)
I0428 20:12:53.890100 32361 solver.cpp:316] Optimization Done.
I0428 20:12:53.890120 32361 caffe.cpp:259] Optimization Done.
