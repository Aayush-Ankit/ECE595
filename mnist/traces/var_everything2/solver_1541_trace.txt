I0428 20:30:34.968771  3750 caffe.cpp:218] Using GPUs 0
I0428 20:30:35.009694  3750 caffe.cpp:223] GPU 0: TITAN X (Pascal)
I0428 20:30:35.530175  3750 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 1000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_everything2/lenet_train_test1541.prototxt"
train_state {
  level: 0
  stage: ""
}
I0428 20:30:35.530319  3750 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1541.prototxt
I0428 20:30:35.530740  3750 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0428 20:30:35.530760  3750 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0428 20:30:35.530864  3750 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 10
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:30:35.530942  3750 layer_factory.hpp:77] Creating layer mnist
I0428 20:30:35.531039  3750 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0428 20:30:35.531064  3750 net.cpp:86] Creating Layer mnist
I0428 20:30:35.531072  3750 net.cpp:382] mnist -> data
I0428 20:30:35.531096  3750 net.cpp:382] mnist -> label
I0428 20:30:35.532193  3750 data_layer.cpp:45] output data size: 64,1,28,28
I0428 20:30:35.534884  3750 net.cpp:124] Setting up mnist
I0428 20:30:35.534903  3750 net.cpp:131] Top shape: 64 1 28 28 (50176)
I0428 20:30:35.534910  3750 net.cpp:131] Top shape: 64 (64)
I0428 20:30:35.534914  3750 net.cpp:139] Memory required for data: 200960
I0428 20:30:35.534921  3750 layer_factory.hpp:77] Creating layer conv0
I0428 20:30:35.534937  3750 net.cpp:86] Creating Layer conv0
I0428 20:30:35.534957  3750 net.cpp:408] conv0 <- data
I0428 20:30:35.534972  3750 net.cpp:382] conv0 -> conv0
I0428 20:30:35.824762  3750 net.cpp:124] Setting up conv0
I0428 20:30:35.824795  3750 net.cpp:131] Top shape: 64 100 24 24 (3686400)
I0428 20:30:35.824800  3750 net.cpp:139] Memory required for data: 14946560
I0428 20:30:35.824828  3750 layer_factory.hpp:77] Creating layer pool0
I0428 20:30:35.824844  3750 net.cpp:86] Creating Layer pool0
I0428 20:30:35.824849  3750 net.cpp:408] pool0 <- conv0
I0428 20:30:35.824856  3750 net.cpp:382] pool0 -> pool0
I0428 20:30:35.824918  3750 net.cpp:124] Setting up pool0
I0428 20:30:35.824929  3750 net.cpp:131] Top shape: 64 100 12 12 (921600)
I0428 20:30:35.824934  3750 net.cpp:139] Memory required for data: 18632960
I0428 20:30:35.824937  3750 layer_factory.hpp:77] Creating layer conv1
I0428 20:30:35.824950  3750 net.cpp:86] Creating Layer conv1
I0428 20:30:35.824954  3750 net.cpp:408] conv1 <- pool0
I0428 20:30:35.824960  3750 net.cpp:382] conv1 -> conv1
I0428 20:30:35.827267  3750 net.cpp:124] Setting up conv1
I0428 20:30:35.827286  3750 net.cpp:131] Top shape: 64 10 8 8 (40960)
I0428 20:30:35.827291  3750 net.cpp:139] Memory required for data: 18796800
I0428 20:30:35.827301  3750 layer_factory.hpp:77] Creating layer pool1
I0428 20:30:35.827311  3750 net.cpp:86] Creating Layer pool1
I0428 20:30:35.827314  3750 net.cpp:408] pool1 <- conv1
I0428 20:30:35.827320  3750 net.cpp:382] pool1 -> pool1
I0428 20:30:35.827364  3750 net.cpp:124] Setting up pool1
I0428 20:30:35.827371  3750 net.cpp:131] Top shape: 64 10 4 4 (10240)
I0428 20:30:35.827375  3750 net.cpp:139] Memory required for data: 18837760
I0428 20:30:35.827379  3750 layer_factory.hpp:77] Creating layer ip1
I0428 20:30:35.827392  3750 net.cpp:86] Creating Layer ip1
I0428 20:30:35.827396  3750 net.cpp:408] ip1 <- pool1
I0428 20:30:35.827404  3750 net.cpp:382] ip1 -> ip1
I0428 20:30:35.827533  3750 net.cpp:124] Setting up ip1
I0428 20:30:35.827543  3750 net.cpp:131] Top shape: 64 10 (640)
I0428 20:30:35.827546  3750 net.cpp:139] Memory required for data: 18840320
I0428 20:30:35.827554  3750 layer_factory.hpp:77] Creating layer relu1
I0428 20:30:35.827561  3750 net.cpp:86] Creating Layer relu1
I0428 20:30:35.827565  3750 net.cpp:408] relu1 <- ip1
I0428 20:30:35.827570  3750 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:30:35.827764  3750 net.cpp:124] Setting up relu1
I0428 20:30:35.827775  3750 net.cpp:131] Top shape: 64 10 (640)
I0428 20:30:35.827780  3750 net.cpp:139] Memory required for data: 18842880
I0428 20:30:35.827783  3750 layer_factory.hpp:77] Creating layer ip2
I0428 20:30:35.827791  3750 net.cpp:86] Creating Layer ip2
I0428 20:30:35.827795  3750 net.cpp:408] ip2 <- ip1
I0428 20:30:35.827805  3750 net.cpp:382] ip2 -> ip2
I0428 20:30:35.827922  3750 net.cpp:124] Setting up ip2
I0428 20:30:35.827931  3750 net.cpp:131] Top shape: 64 50 (3200)
I0428 20:30:35.827934  3750 net.cpp:139] Memory required for data: 18855680
I0428 20:30:35.827941  3750 layer_factory.hpp:77] Creating layer relu2
I0428 20:30:35.827949  3750 net.cpp:86] Creating Layer relu2
I0428 20:30:35.827952  3750 net.cpp:408] relu2 <- ip2
I0428 20:30:35.827957  3750 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:30:35.828804  3750 net.cpp:124] Setting up relu2
I0428 20:30:35.828825  3750 net.cpp:131] Top shape: 64 50 (3200)
I0428 20:30:35.828830  3750 net.cpp:139] Memory required for data: 18868480
I0428 20:30:35.828835  3750 layer_factory.hpp:77] Creating layer ip3
I0428 20:30:35.828843  3750 net.cpp:86] Creating Layer ip3
I0428 20:30:35.828847  3750 net.cpp:408] ip3 <- ip2
I0428 20:30:35.828855  3750 net.cpp:382] ip3 -> ip3
I0428 20:30:35.828977  3750 net.cpp:124] Setting up ip3
I0428 20:30:35.828986  3750 net.cpp:131] Top shape: 64 10 (640)
I0428 20:30:35.828990  3750 net.cpp:139] Memory required for data: 18871040
I0428 20:30:35.829000  3750 layer_factory.hpp:77] Creating layer relu3
I0428 20:30:35.829006  3750 net.cpp:86] Creating Layer relu3
I0428 20:30:35.829010  3750 net.cpp:408] relu3 <- ip3
I0428 20:30:35.829015  3750 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:30:35.829216  3750 net.cpp:124] Setting up relu3
I0428 20:30:35.829226  3750 net.cpp:131] Top shape: 64 10 (640)
I0428 20:30:35.829231  3750 net.cpp:139] Memory required for data: 18873600
I0428 20:30:35.829234  3750 layer_factory.hpp:77] Creating layer loss
I0428 20:30:35.829241  3750 net.cpp:86] Creating Layer loss
I0428 20:30:35.829246  3750 net.cpp:408] loss <- ip3
I0428 20:30:35.829251  3750 net.cpp:408] loss <- label
I0428 20:30:35.829257  3750 net.cpp:382] loss -> loss
I0428 20:30:35.829277  3750 layer_factory.hpp:77] Creating layer loss
I0428 20:30:35.829560  3750 net.cpp:124] Setting up loss
I0428 20:30:35.829573  3750 net.cpp:131] Top shape: (1)
I0428 20:30:35.829577  3750 net.cpp:134]     with loss weight 1
I0428 20:30:35.829593  3750 net.cpp:139] Memory required for data: 18873604
I0428 20:30:35.829597  3750 net.cpp:200] loss needs backward computation.
I0428 20:30:35.829602  3750 net.cpp:200] relu3 needs backward computation.
I0428 20:30:35.829605  3750 net.cpp:200] ip3 needs backward computation.
I0428 20:30:35.829609  3750 net.cpp:200] relu2 needs backward computation.
I0428 20:30:35.829612  3750 net.cpp:200] ip2 needs backward computation.
I0428 20:30:35.829615  3750 net.cpp:200] relu1 needs backward computation.
I0428 20:30:35.829619  3750 net.cpp:200] ip1 needs backward computation.
I0428 20:30:35.829622  3750 net.cpp:200] pool1 needs backward computation.
I0428 20:30:35.829627  3750 net.cpp:200] conv1 needs backward computation.
I0428 20:30:35.829629  3750 net.cpp:200] pool0 needs backward computation.
I0428 20:30:35.829633  3750 net.cpp:200] conv0 needs backward computation.
I0428 20:30:35.829638  3750 net.cpp:202] mnist does not need backward computation.
I0428 20:30:35.829640  3750 net.cpp:244] This network produces output loss
I0428 20:30:35.829651  3750 net.cpp:257] Network initialization done.
I0428 20:30:35.830034  3750 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1541.prototxt
I0428 20:30:35.830065  3750 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0428 20:30:35.830178  3750 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 10
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:30:35.830278  3750 layer_factory.hpp:77] Creating layer mnist
I0428 20:30:35.830333  3750 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0428 20:30:35.830348  3750 net.cpp:86] Creating Layer mnist
I0428 20:30:35.830355  3750 net.cpp:382] mnist -> data
I0428 20:30:35.830365  3750 net.cpp:382] mnist -> label
I0428 20:30:35.830469  3750 data_layer.cpp:45] output data size: 100,1,28,28
I0428 20:30:35.832669  3750 net.cpp:124] Setting up mnist
I0428 20:30:35.832684  3750 net.cpp:131] Top shape: 100 1 28 28 (78400)
I0428 20:30:35.832690  3750 net.cpp:131] Top shape: 100 (100)
I0428 20:30:35.832695  3750 net.cpp:139] Memory required for data: 314000
I0428 20:30:35.832700  3750 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0428 20:30:35.832726  3750 net.cpp:86] Creating Layer label_mnist_1_split
I0428 20:30:35.832731  3750 net.cpp:408] label_mnist_1_split <- label
I0428 20:30:35.832757  3750 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_0
I0428 20:30:35.832767  3750 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_1
I0428 20:30:35.832836  3750 net.cpp:124] Setting up label_mnist_1_split
I0428 20:30:35.832849  3750 net.cpp:131] Top shape: 100 (100)
I0428 20:30:35.832854  3750 net.cpp:131] Top shape: 100 (100)
I0428 20:30:35.832856  3750 net.cpp:139] Memory required for data: 314800
I0428 20:30:35.832860  3750 layer_factory.hpp:77] Creating layer conv0
I0428 20:30:35.832870  3750 net.cpp:86] Creating Layer conv0
I0428 20:30:35.832875  3750 net.cpp:408] conv0 <- data
I0428 20:30:35.832882  3750 net.cpp:382] conv0 -> conv0
I0428 20:30:35.834834  3750 net.cpp:124] Setting up conv0
I0428 20:30:35.834851  3750 net.cpp:131] Top shape: 100 100 24 24 (5760000)
I0428 20:30:35.834856  3750 net.cpp:139] Memory required for data: 23354800
I0428 20:30:35.834867  3750 layer_factory.hpp:77] Creating layer pool0
I0428 20:30:35.834874  3750 net.cpp:86] Creating Layer pool0
I0428 20:30:35.834878  3750 net.cpp:408] pool0 <- conv0
I0428 20:30:35.834887  3750 net.cpp:382] pool0 -> pool0
I0428 20:30:35.834930  3750 net.cpp:124] Setting up pool0
I0428 20:30:35.834938  3750 net.cpp:131] Top shape: 100 100 12 12 (1440000)
I0428 20:30:35.834940  3750 net.cpp:139] Memory required for data: 29114800
I0428 20:30:35.834944  3750 layer_factory.hpp:77] Creating layer conv1
I0428 20:30:35.834956  3750 net.cpp:86] Creating Layer conv1
I0428 20:30:35.834960  3750 net.cpp:408] conv1 <- pool0
I0428 20:30:35.834966  3750 net.cpp:382] conv1 -> conv1
I0428 20:30:35.836900  3750 net.cpp:124] Setting up conv1
I0428 20:30:35.836921  3750 net.cpp:131] Top shape: 100 10 8 8 (64000)
I0428 20:30:35.836926  3750 net.cpp:139] Memory required for data: 29370800
I0428 20:30:35.836937  3750 layer_factory.hpp:77] Creating layer pool1
I0428 20:30:35.836947  3750 net.cpp:86] Creating Layer pool1
I0428 20:30:35.836952  3750 net.cpp:408] pool1 <- conv1
I0428 20:30:35.836958  3750 net.cpp:382] pool1 -> pool1
I0428 20:30:35.837004  3750 net.cpp:124] Setting up pool1
I0428 20:30:35.837010  3750 net.cpp:131] Top shape: 100 10 4 4 (16000)
I0428 20:30:35.837014  3750 net.cpp:139] Memory required for data: 29434800
I0428 20:30:35.837018  3750 layer_factory.hpp:77] Creating layer ip1
I0428 20:30:35.837024  3750 net.cpp:86] Creating Layer ip1
I0428 20:30:35.837029  3750 net.cpp:408] ip1 <- pool1
I0428 20:30:35.837036  3750 net.cpp:382] ip1 -> ip1
I0428 20:30:35.837170  3750 net.cpp:124] Setting up ip1
I0428 20:30:35.837193  3750 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:30:35.837198  3750 net.cpp:139] Memory required for data: 29438800
I0428 20:30:35.837206  3750 layer_factory.hpp:77] Creating layer relu1
I0428 20:30:35.837213  3750 net.cpp:86] Creating Layer relu1
I0428 20:30:35.837218  3750 net.cpp:408] relu1 <- ip1
I0428 20:30:35.837224  3750 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:30:35.837430  3750 net.cpp:124] Setting up relu1
I0428 20:30:35.837441  3750 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:30:35.837445  3750 net.cpp:139] Memory required for data: 29442800
I0428 20:30:35.837448  3750 layer_factory.hpp:77] Creating layer ip2
I0428 20:30:35.837458  3750 net.cpp:86] Creating Layer ip2
I0428 20:30:35.837462  3750 net.cpp:408] ip2 <- ip1
I0428 20:30:35.837468  3750 net.cpp:382] ip2 -> ip2
I0428 20:30:35.837611  3750 net.cpp:124] Setting up ip2
I0428 20:30:35.837620  3750 net.cpp:131] Top shape: 100 50 (5000)
I0428 20:30:35.837625  3750 net.cpp:139] Memory required for data: 29462800
I0428 20:30:35.837630  3750 layer_factory.hpp:77] Creating layer relu2
I0428 20:30:35.837636  3750 net.cpp:86] Creating Layer relu2
I0428 20:30:35.837641  3750 net.cpp:408] relu2 <- ip2
I0428 20:30:35.837646  3750 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:30:35.837888  3750 net.cpp:124] Setting up relu2
I0428 20:30:35.837898  3750 net.cpp:131] Top shape: 100 50 (5000)
I0428 20:30:35.837903  3750 net.cpp:139] Memory required for data: 29482800
I0428 20:30:35.837906  3750 layer_factory.hpp:77] Creating layer ip3
I0428 20:30:35.837914  3750 net.cpp:86] Creating Layer ip3
I0428 20:30:35.837918  3750 net.cpp:408] ip3 <- ip2
I0428 20:30:35.837926  3750 net.cpp:382] ip3 -> ip3
I0428 20:30:35.838048  3750 net.cpp:124] Setting up ip3
I0428 20:30:35.838057  3750 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:30:35.838060  3750 net.cpp:139] Memory required for data: 29486800
I0428 20:30:35.838070  3750 layer_factory.hpp:77] Creating layer relu3
I0428 20:30:35.838076  3750 net.cpp:86] Creating Layer relu3
I0428 20:30:35.838079  3750 net.cpp:408] relu3 <- ip3
I0428 20:30:35.838084  3750 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:30:35.839038  3750 net.cpp:124] Setting up relu3
I0428 20:30:35.839053  3750 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:30:35.839057  3750 net.cpp:139] Memory required for data: 29490800
I0428 20:30:35.839061  3750 layer_factory.hpp:77] Creating layer ip3_relu3_0_split
I0428 20:30:35.839069  3750 net.cpp:86] Creating Layer ip3_relu3_0_split
I0428 20:30:35.839074  3750 net.cpp:408] ip3_relu3_0_split <- ip3
I0428 20:30:35.839081  3750 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_0
I0428 20:30:35.839088  3750 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_1
I0428 20:30:35.839146  3750 net.cpp:124] Setting up ip3_relu3_0_split
I0428 20:30:35.839155  3750 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:30:35.839160  3750 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:30:35.839164  3750 net.cpp:139] Memory required for data: 29498800
I0428 20:30:35.839179  3750 layer_factory.hpp:77] Creating layer accuracy
I0428 20:30:35.839186  3750 net.cpp:86] Creating Layer accuracy
I0428 20:30:35.839191  3750 net.cpp:408] accuracy <- ip3_relu3_0_split_0
I0428 20:30:35.839196  3750 net.cpp:408] accuracy <- label_mnist_1_split_0
I0428 20:30:35.839201  3750 net.cpp:382] accuracy -> accuracy
I0428 20:30:35.839215  3750 net.cpp:124] Setting up accuracy
I0428 20:30:35.839226  3750 net.cpp:131] Top shape: (1)
I0428 20:30:35.839229  3750 net.cpp:139] Memory required for data: 29498804
I0428 20:30:35.839233  3750 layer_factory.hpp:77] Creating layer loss
I0428 20:30:35.839239  3750 net.cpp:86] Creating Layer loss
I0428 20:30:35.839243  3750 net.cpp:408] loss <- ip3_relu3_0_split_1
I0428 20:30:35.839247  3750 net.cpp:408] loss <- label_mnist_1_split_1
I0428 20:30:35.839260  3750 net.cpp:382] loss -> loss
I0428 20:30:35.839267  3750 layer_factory.hpp:77] Creating layer loss
I0428 20:30:35.839550  3750 net.cpp:124] Setting up loss
I0428 20:30:35.839560  3750 net.cpp:131] Top shape: (1)
I0428 20:30:35.839565  3750 net.cpp:134]     with loss weight 1
I0428 20:30:35.839583  3750 net.cpp:139] Memory required for data: 29498808
I0428 20:30:35.839588  3750 net.cpp:200] loss needs backward computation.
I0428 20:30:35.839592  3750 net.cpp:202] accuracy does not need backward computation.
I0428 20:30:35.839597  3750 net.cpp:200] ip3_relu3_0_split needs backward computation.
I0428 20:30:35.839601  3750 net.cpp:200] relu3 needs backward computation.
I0428 20:30:35.839606  3750 net.cpp:200] ip3 needs backward computation.
I0428 20:30:35.839608  3750 net.cpp:200] relu2 needs backward computation.
I0428 20:30:35.839612  3750 net.cpp:200] ip2 needs backward computation.
I0428 20:30:35.839615  3750 net.cpp:200] relu1 needs backward computation.
I0428 20:30:35.839618  3750 net.cpp:200] ip1 needs backward computation.
I0428 20:30:35.839622  3750 net.cpp:200] pool1 needs backward computation.
I0428 20:30:35.839625  3750 net.cpp:200] conv1 needs backward computation.
I0428 20:30:35.839629  3750 net.cpp:200] pool0 needs backward computation.
I0428 20:30:35.839633  3750 net.cpp:200] conv0 needs backward computation.
I0428 20:30:35.839637  3750 net.cpp:202] label_mnist_1_split does not need backward computation.
I0428 20:30:35.839643  3750 net.cpp:202] mnist does not need backward computation.
I0428 20:30:35.839645  3750 net.cpp:244] This network produces output accuracy
I0428 20:30:35.839650  3750 net.cpp:244] This network produces output loss
I0428 20:30:35.839664  3750 net.cpp:257] Network initialization done.
I0428 20:30:35.839714  3750 solver.cpp:56] Solver scaffolding done.
I0428 20:30:35.840121  3750 caffe.cpp:248] Starting Optimization
I0428 20:30:35.840129  3750 solver.cpp:273] Solving LeNet
I0428 20:30:35.840133  3750 solver.cpp:274] Learning Rate Policy: inv
I0428 20:30:35.841140  3750 solver.cpp:331] Iteration 0, Testing net (#0)
I0428 20:30:35.937633  3780 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:30:35.940071  3750 solver.cpp:398]     Test net output #0: accuracy = 0.1197
I0428 20:30:35.940089  3750 solver.cpp:398]     Test net output #1: loss = 2.31855 (* 1 = 2.31855 loss)
I0428 20:30:35.944533  3750 solver.cpp:219] Iteration 0 (0 iter/s, 0.104357s/100 iters), loss = 2.31528
I0428 20:30:35.944556  3750 solver.cpp:238]     Train net output #0: loss = 2.31528 (* 1 = 2.31528 loss)
I0428 20:30:35.944582  3750 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0428 20:30:36.164424  3750 solver.cpp:219] Iteration 100 (454.875 iter/s, 0.219841s/100 iters), loss = 1.25146
I0428 20:30:36.164474  3750 solver.cpp:238]     Train net output #0: loss = 1.25146 (* 1 = 1.25146 loss)
I0428 20:30:36.164486  3750 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0428 20:30:36.391080  3750 solver.cpp:219] Iteration 200 (441.336 iter/s, 0.226585s/100 iters), loss = 1.13294
I0428 20:30:36.391129  3750 solver.cpp:238]     Train net output #0: loss = 1.13294 (* 1 = 1.13294 loss)
I0428 20:30:36.391142  3750 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0428 20:30:36.617102  3750 solver.cpp:219] Iteration 300 (442.576 iter/s, 0.22595s/100 iters), loss = 1.25724
I0428 20:30:36.617161  3750 solver.cpp:238]     Train net output #0: loss = 1.25724 (* 1 = 1.25724 loss)
I0428 20:30:36.617173  3750 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0428 20:30:36.840687  3750 solver.cpp:219] Iteration 400 (447.404 iter/s, 0.223512s/100 iters), loss = 1.19324
I0428 20:30:36.840735  3750 solver.cpp:238]     Train net output #0: loss = 1.19324 (* 1 = 1.19324 loss)
I0428 20:30:36.840747  3750 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0428 20:30:37.060588  3750 solver.cpp:331] Iteration 500, Testing net (#0)
I0428 20:30:37.163571  3780 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:30:37.166380  3750 solver.cpp:398]     Test net output #0: accuracy = 0.5853
I0428 20:30:37.166407  3750 solver.cpp:398]     Test net output #1: loss = 1.01863 (* 1 = 1.01863 loss)
I0428 20:30:37.168364  3750 solver.cpp:219] Iteration 500 (305.242 iter/s, 0.327609s/100 iters), loss = 1.18313
I0428 20:30:37.168390  3750 solver.cpp:238]     Train net output #0: loss = 1.18313 (* 1 = 1.18313 loss)
I0428 20:30:37.168416  3750 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0428 20:30:37.383859  3750 solver.cpp:219] Iteration 600 (464.152 iter/s, 0.215447s/100 iters), loss = 0.704349
I0428 20:30:37.383919  3750 solver.cpp:238]     Train net output #0: loss = 0.704349 (* 1 = 0.704349 loss)
I0428 20:30:37.383934  3750 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0428 20:30:37.615721  3750 solver.cpp:219] Iteration 700 (431.43 iter/s, 0.231788s/100 iters), loss = 0.524224
I0428 20:30:37.615769  3750 solver.cpp:238]     Train net output #0: loss = 0.524224 (* 1 = 0.524224 loss)
I0428 20:30:37.615788  3750 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0428 20:30:37.844666  3750 solver.cpp:219] Iteration 800 (436.913 iter/s, 0.228878s/100 iters), loss = 0.97464
I0428 20:30:37.844717  3750 solver.cpp:238]     Train net output #0: loss = 0.97464 (* 1 = 0.97464 loss)
I0428 20:30:37.844729  3750 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0428 20:30:38.072319  3750 solver.cpp:219] Iteration 900 (439.392 iter/s, 0.227587s/100 iters), loss = 0.922923
I0428 20:30:38.072367  3750 solver.cpp:238]     Train net output #0: loss = 0.922923 (* 1 = 0.922923 loss)
I0428 20:30:38.072379  3750 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0428 20:30:38.147970  3773 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:30:38.297636  3750 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_1000.caffemodel
I0428 20:30:38.299911  3750 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_1000.solverstate
I0428 20:30:38.301314  3750 solver.cpp:311] Iteration 1000, loss = 0.643075
I0428 20:30:38.301343  3750 solver.cpp:331] Iteration 1000, Testing net (#0)
I0428 20:30:38.404369  3780 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:30:38.407892  3750 solver.cpp:398]     Test net output #0: accuracy = 0.6767
I0428 20:30:38.407915  3750 solver.cpp:398]     Test net output #1: loss = 0.793395 (* 1 = 0.793395 loss)
I0428 20:30:38.407922  3750 solver.cpp:316] Optimization Done.
I0428 20:30:38.407925  3750 caffe.cpp:259] Optimization Done.
