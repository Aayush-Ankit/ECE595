I0428 20:35:57.592341  4724 caffe.cpp:218] Using GPUs 0
I0428 20:35:57.629011  4724 caffe.cpp:223] GPU 0: TITAN X (Pascal)
I0428 20:35:58.141369  4724 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 1000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_everything2/lenet_train_test1629.prototxt"
train_state {
  level: 0
  stage: ""
}
I0428 20:35:58.141530  4724 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1629.prototxt
I0428 20:35:58.141952  4724 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0428 20:35:58.141971  4724 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0428 20:35:58.142081  4724 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:35:58.142163  4724 layer_factory.hpp:77] Creating layer mnist
I0428 20:35:58.142261  4724 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0428 20:35:58.142287  4724 net.cpp:86] Creating Layer mnist
I0428 20:35:58.142294  4724 net.cpp:382] mnist -> data
I0428 20:35:58.142316  4724 net.cpp:382] mnist -> label
I0428 20:35:58.143411  4724 data_layer.cpp:45] output data size: 64,1,28,28
I0428 20:35:58.145879  4724 net.cpp:124] Setting up mnist
I0428 20:35:58.145895  4724 net.cpp:131] Top shape: 64 1 28 28 (50176)
I0428 20:35:58.145903  4724 net.cpp:131] Top shape: 64 (64)
I0428 20:35:58.145907  4724 net.cpp:139] Memory required for data: 200960
I0428 20:35:58.145915  4724 layer_factory.hpp:77] Creating layer conv0
I0428 20:35:58.145931  4724 net.cpp:86] Creating Layer conv0
I0428 20:35:58.145951  4724 net.cpp:408] conv0 <- data
I0428 20:35:58.145965  4724 net.cpp:382] conv0 -> conv0
I0428 20:35:58.427407  4724 net.cpp:124] Setting up conv0
I0428 20:35:58.427434  4724 net.cpp:131] Top shape: 64 100 24 24 (3686400)
I0428 20:35:58.427438  4724 net.cpp:139] Memory required for data: 14946560
I0428 20:35:58.427453  4724 layer_factory.hpp:77] Creating layer pool0
I0428 20:35:58.427465  4724 net.cpp:86] Creating Layer pool0
I0428 20:35:58.427469  4724 net.cpp:408] pool0 <- conv0
I0428 20:35:58.427474  4724 net.cpp:382] pool0 -> pool0
I0428 20:35:58.427520  4724 net.cpp:124] Setting up pool0
I0428 20:35:58.427526  4724 net.cpp:131] Top shape: 64 100 12 12 (921600)
I0428 20:35:58.427530  4724 net.cpp:139] Memory required for data: 18632960
I0428 20:35:58.427532  4724 layer_factory.hpp:77] Creating layer conv1
I0428 20:35:58.427542  4724 net.cpp:86] Creating Layer conv1
I0428 20:35:58.427548  4724 net.cpp:408] conv1 <- pool0
I0428 20:35:58.427553  4724 net.cpp:382] conv1 -> conv1
I0428 20:35:58.430944  4724 net.cpp:124] Setting up conv1
I0428 20:35:58.430959  4724 net.cpp:131] Top shape: 64 50 8 8 (204800)
I0428 20:35:58.430963  4724 net.cpp:139] Memory required for data: 19452160
I0428 20:35:58.430970  4724 layer_factory.hpp:77] Creating layer pool1
I0428 20:35:58.430977  4724 net.cpp:86] Creating Layer pool1
I0428 20:35:58.430980  4724 net.cpp:408] pool1 <- conv1
I0428 20:35:58.430985  4724 net.cpp:382] pool1 -> pool1
I0428 20:35:58.431021  4724 net.cpp:124] Setting up pool1
I0428 20:35:58.431026  4724 net.cpp:131] Top shape: 64 50 4 4 (51200)
I0428 20:35:58.431030  4724 net.cpp:139] Memory required for data: 19656960
I0428 20:35:58.431032  4724 layer_factory.hpp:77] Creating layer ip1
I0428 20:35:58.431038  4724 net.cpp:86] Creating Layer ip1
I0428 20:35:58.431041  4724 net.cpp:408] ip1 <- pool1
I0428 20:35:58.431046  4724 net.cpp:382] ip1 -> ip1
I0428 20:35:58.431354  4724 net.cpp:124] Setting up ip1
I0428 20:35:58.431360  4724 net.cpp:131] Top shape: 64 50 (3200)
I0428 20:35:58.431365  4724 net.cpp:139] Memory required for data: 19669760
I0428 20:35:58.431371  4724 layer_factory.hpp:77] Creating layer relu1
I0428 20:35:58.431376  4724 net.cpp:86] Creating Layer relu1
I0428 20:35:58.431380  4724 net.cpp:408] relu1 <- ip1
I0428 20:35:58.431383  4724 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:35:58.431538  4724 net.cpp:124] Setting up relu1
I0428 20:35:58.431547  4724 net.cpp:131] Top shape: 64 50 (3200)
I0428 20:35:58.431550  4724 net.cpp:139] Memory required for data: 19682560
I0428 20:35:58.431553  4724 layer_factory.hpp:77] Creating layer ip2
I0428 20:35:58.431560  4724 net.cpp:86] Creating Layer ip2
I0428 20:35:58.431562  4724 net.cpp:408] ip2 <- ip1
I0428 20:35:58.431566  4724 net.cpp:382] ip2 -> ip2
I0428 20:35:58.431658  4724 net.cpp:124] Setting up ip2
I0428 20:35:58.431663  4724 net.cpp:131] Top shape: 64 10 (640)
I0428 20:35:58.431668  4724 net.cpp:139] Memory required for data: 19685120
I0428 20:35:58.431673  4724 layer_factory.hpp:77] Creating layer relu2
I0428 20:35:58.431679  4724 net.cpp:86] Creating Layer relu2
I0428 20:35:58.431681  4724 net.cpp:408] relu2 <- ip2
I0428 20:35:58.431701  4724 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:35:58.432412  4724 net.cpp:124] Setting up relu2
I0428 20:35:58.432425  4724 net.cpp:131] Top shape: 64 10 (640)
I0428 20:35:58.432428  4724 net.cpp:139] Memory required for data: 19687680
I0428 20:35:58.432431  4724 layer_factory.hpp:77] Creating layer ip3
I0428 20:35:58.432438  4724 net.cpp:86] Creating Layer ip3
I0428 20:35:58.432441  4724 net.cpp:408] ip3 <- ip2
I0428 20:35:58.432446  4724 net.cpp:382] ip3 -> ip3
I0428 20:35:58.432555  4724 net.cpp:124] Setting up ip3
I0428 20:35:58.432562  4724 net.cpp:131] Top shape: 64 10 (640)
I0428 20:35:58.432566  4724 net.cpp:139] Memory required for data: 19690240
I0428 20:35:58.432574  4724 layer_factory.hpp:77] Creating layer relu3
I0428 20:35:58.432579  4724 net.cpp:86] Creating Layer relu3
I0428 20:35:58.432581  4724 net.cpp:408] relu3 <- ip3
I0428 20:35:58.432586  4724 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:35:58.432750  4724 net.cpp:124] Setting up relu3
I0428 20:35:58.432760  4724 net.cpp:131] Top shape: 64 10 (640)
I0428 20:35:58.432763  4724 net.cpp:139] Memory required for data: 19692800
I0428 20:35:58.432766  4724 layer_factory.hpp:77] Creating layer loss
I0428 20:35:58.432771  4724 net.cpp:86] Creating Layer loss
I0428 20:35:58.432775  4724 net.cpp:408] loss <- ip3
I0428 20:35:58.432778  4724 net.cpp:408] loss <- label
I0428 20:35:58.432799  4724 net.cpp:382] loss -> loss
I0428 20:35:58.432840  4724 layer_factory.hpp:77] Creating layer loss
I0428 20:35:58.433091  4724 net.cpp:124] Setting up loss
I0428 20:35:58.433100  4724 net.cpp:131] Top shape: (1)
I0428 20:35:58.433104  4724 net.cpp:134]     with loss weight 1
I0428 20:35:58.433118  4724 net.cpp:139] Memory required for data: 19692804
I0428 20:35:58.433121  4724 net.cpp:200] loss needs backward computation.
I0428 20:35:58.433140  4724 net.cpp:200] relu3 needs backward computation.
I0428 20:35:58.433142  4724 net.cpp:200] ip3 needs backward computation.
I0428 20:35:58.433145  4724 net.cpp:200] relu2 needs backward computation.
I0428 20:35:58.433148  4724 net.cpp:200] ip2 needs backward computation.
I0428 20:35:58.433151  4724 net.cpp:200] relu1 needs backward computation.
I0428 20:35:58.433153  4724 net.cpp:200] ip1 needs backward computation.
I0428 20:35:58.433156  4724 net.cpp:200] pool1 needs backward computation.
I0428 20:35:58.433159  4724 net.cpp:200] conv1 needs backward computation.
I0428 20:35:58.433162  4724 net.cpp:200] pool0 needs backward computation.
I0428 20:35:58.433166  4724 net.cpp:200] conv0 needs backward computation.
I0428 20:35:58.433168  4724 net.cpp:202] mnist does not need backward computation.
I0428 20:35:58.433171  4724 net.cpp:244] This network produces output loss
I0428 20:35:58.433179  4724 net.cpp:257] Network initialization done.
I0428 20:35:58.433517  4724 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1629.prototxt
I0428 20:35:58.433560  4724 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0428 20:35:58.433650  4724 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:35:58.433727  4724 layer_factory.hpp:77] Creating layer mnist
I0428 20:35:58.433782  4724 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0428 20:35:58.433794  4724 net.cpp:86] Creating Layer mnist
I0428 20:35:58.433799  4724 net.cpp:382] mnist -> data
I0428 20:35:58.433806  4724 net.cpp:382] mnist -> label
I0428 20:35:58.433887  4724 data_layer.cpp:45] output data size: 100,1,28,28
I0428 20:35:58.435102  4724 net.cpp:124] Setting up mnist
I0428 20:35:58.435132  4724 net.cpp:131] Top shape: 100 1 28 28 (78400)
I0428 20:35:58.435137  4724 net.cpp:131] Top shape: 100 (100)
I0428 20:35:58.435140  4724 net.cpp:139] Memory required for data: 314000
I0428 20:35:58.435144  4724 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0428 20:35:58.435161  4724 net.cpp:86] Creating Layer label_mnist_1_split
I0428 20:35:58.435165  4724 net.cpp:408] label_mnist_1_split <- label
I0428 20:35:58.435170  4724 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_0
I0428 20:35:58.435176  4724 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_1
I0428 20:35:58.435268  4724 net.cpp:124] Setting up label_mnist_1_split
I0428 20:35:58.435276  4724 net.cpp:131] Top shape: 100 (100)
I0428 20:35:58.435281  4724 net.cpp:131] Top shape: 100 (100)
I0428 20:35:58.435283  4724 net.cpp:139] Memory required for data: 314800
I0428 20:35:58.435286  4724 layer_factory.hpp:77] Creating layer conv0
I0428 20:35:58.435294  4724 net.cpp:86] Creating Layer conv0
I0428 20:35:58.435297  4724 net.cpp:408] conv0 <- data
I0428 20:35:58.435302  4724 net.cpp:382] conv0 -> conv0
I0428 20:35:58.436785  4724 net.cpp:124] Setting up conv0
I0428 20:35:58.436800  4724 net.cpp:131] Top shape: 100 100 24 24 (5760000)
I0428 20:35:58.436803  4724 net.cpp:139] Memory required for data: 23354800
I0428 20:35:58.436833  4724 layer_factory.hpp:77] Creating layer pool0
I0428 20:35:58.436841  4724 net.cpp:86] Creating Layer pool0
I0428 20:35:58.436844  4724 net.cpp:408] pool0 <- conv0
I0428 20:35:58.436848  4724 net.cpp:382] pool0 -> pool0
I0428 20:35:58.436959  4724 net.cpp:124] Setting up pool0
I0428 20:35:58.436966  4724 net.cpp:131] Top shape: 100 100 12 12 (1440000)
I0428 20:35:58.436969  4724 net.cpp:139] Memory required for data: 29114800
I0428 20:35:58.436988  4724 layer_factory.hpp:77] Creating layer conv1
I0428 20:35:58.436996  4724 net.cpp:86] Creating Layer conv1
I0428 20:35:58.437000  4724 net.cpp:408] conv1 <- pool0
I0428 20:35:58.437005  4724 net.cpp:382] conv1 -> conv1
I0428 20:35:58.440006  4724 net.cpp:124] Setting up conv1
I0428 20:35:58.440021  4724 net.cpp:131] Top shape: 100 50 8 8 (320000)
I0428 20:35:58.440024  4724 net.cpp:139] Memory required for data: 30394800
I0428 20:35:58.440033  4724 layer_factory.hpp:77] Creating layer pool1
I0428 20:35:58.440039  4724 net.cpp:86] Creating Layer pool1
I0428 20:35:58.440048  4724 net.cpp:408] pool1 <- conv1
I0428 20:35:58.440053  4724 net.cpp:382] pool1 -> pool1
I0428 20:35:58.440088  4724 net.cpp:124] Setting up pool1
I0428 20:35:58.440093  4724 net.cpp:131] Top shape: 100 50 4 4 (80000)
I0428 20:35:58.440095  4724 net.cpp:139] Memory required for data: 30714800
I0428 20:35:58.440099  4724 layer_factory.hpp:77] Creating layer ip1
I0428 20:35:58.440104  4724 net.cpp:86] Creating Layer ip1
I0428 20:35:58.440107  4724 net.cpp:408] ip1 <- pool1
I0428 20:35:58.440111  4724 net.cpp:382] ip1 -> ip1
I0428 20:35:58.440443  4724 net.cpp:124] Setting up ip1
I0428 20:35:58.440493  4724 net.cpp:131] Top shape: 100 50 (5000)
I0428 20:35:58.440513  4724 net.cpp:139] Memory required for data: 30734800
I0428 20:35:58.440521  4724 layer_factory.hpp:77] Creating layer relu1
I0428 20:35:58.440527  4724 net.cpp:86] Creating Layer relu1
I0428 20:35:58.440531  4724 net.cpp:408] relu1 <- ip1
I0428 20:35:58.440536  4724 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:35:58.440696  4724 net.cpp:124] Setting up relu1
I0428 20:35:58.440706  4724 net.cpp:131] Top shape: 100 50 (5000)
I0428 20:35:58.440708  4724 net.cpp:139] Memory required for data: 30754800
I0428 20:35:58.440712  4724 layer_factory.hpp:77] Creating layer ip2
I0428 20:35:58.440718  4724 net.cpp:86] Creating Layer ip2
I0428 20:35:58.440721  4724 net.cpp:408] ip2 <- ip1
I0428 20:35:58.440726  4724 net.cpp:382] ip2 -> ip2
I0428 20:35:58.440860  4724 net.cpp:124] Setting up ip2
I0428 20:35:58.440866  4724 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:35:58.440870  4724 net.cpp:139] Memory required for data: 30758800
I0428 20:35:58.440876  4724 layer_factory.hpp:77] Creating layer relu2
I0428 20:35:58.440881  4724 net.cpp:86] Creating Layer relu2
I0428 20:35:58.440883  4724 net.cpp:408] relu2 <- ip2
I0428 20:35:58.440886  4724 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:35:58.441160  4724 net.cpp:124] Setting up relu2
I0428 20:35:58.441169  4724 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:35:58.441174  4724 net.cpp:139] Memory required for data: 30762800
I0428 20:35:58.441177  4724 layer_factory.hpp:77] Creating layer ip3
I0428 20:35:58.441184  4724 net.cpp:86] Creating Layer ip3
I0428 20:35:58.441186  4724 net.cpp:408] ip3 <- ip2
I0428 20:35:58.441191  4724 net.cpp:382] ip3 -> ip3
I0428 20:35:58.441284  4724 net.cpp:124] Setting up ip3
I0428 20:35:58.441293  4724 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:35:58.441295  4724 net.cpp:139] Memory required for data: 30766800
I0428 20:35:58.441303  4724 layer_factory.hpp:77] Creating layer relu3
I0428 20:35:58.441308  4724 net.cpp:86] Creating Layer relu3
I0428 20:35:58.441310  4724 net.cpp:408] relu3 <- ip3
I0428 20:35:58.441314  4724 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:35:58.442122  4724 net.cpp:124] Setting up relu3
I0428 20:35:58.442133  4724 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:35:58.442152  4724 net.cpp:139] Memory required for data: 30770800
I0428 20:35:58.442155  4724 layer_factory.hpp:77] Creating layer ip3_relu3_0_split
I0428 20:35:58.442160  4724 net.cpp:86] Creating Layer ip3_relu3_0_split
I0428 20:35:58.442164  4724 net.cpp:408] ip3_relu3_0_split <- ip3
I0428 20:35:58.442168  4724 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_0
I0428 20:35:58.442174  4724 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_1
I0428 20:35:58.442210  4724 net.cpp:124] Setting up ip3_relu3_0_split
I0428 20:35:58.442215  4724 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:35:58.442219  4724 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:35:58.442221  4724 net.cpp:139] Memory required for data: 30778800
I0428 20:35:58.442224  4724 layer_factory.hpp:77] Creating layer accuracy
I0428 20:35:58.442229  4724 net.cpp:86] Creating Layer accuracy
I0428 20:35:58.442231  4724 net.cpp:408] accuracy <- ip3_relu3_0_split_0
I0428 20:35:58.442235  4724 net.cpp:408] accuracy <- label_mnist_1_split_0
I0428 20:35:58.442239  4724 net.cpp:382] accuracy -> accuracy
I0428 20:35:58.442245  4724 net.cpp:124] Setting up accuracy
I0428 20:35:58.442250  4724 net.cpp:131] Top shape: (1)
I0428 20:35:58.442252  4724 net.cpp:139] Memory required for data: 30778804
I0428 20:35:58.442255  4724 layer_factory.hpp:77] Creating layer loss
I0428 20:35:58.442260  4724 net.cpp:86] Creating Layer loss
I0428 20:35:58.442262  4724 net.cpp:408] loss <- ip3_relu3_0_split_1
I0428 20:35:58.442265  4724 net.cpp:408] loss <- label_mnist_1_split_1
I0428 20:35:58.442270  4724 net.cpp:382] loss -> loss
I0428 20:35:58.442276  4724 layer_factory.hpp:77] Creating layer loss
I0428 20:35:58.442514  4724 net.cpp:124] Setting up loss
I0428 20:35:58.442523  4724 net.cpp:131] Top shape: (1)
I0428 20:35:58.442526  4724 net.cpp:134]     with loss weight 1
I0428 20:35:58.442543  4724 net.cpp:139] Memory required for data: 30778808
I0428 20:35:58.442548  4724 net.cpp:200] loss needs backward computation.
I0428 20:35:58.442551  4724 net.cpp:202] accuracy does not need backward computation.
I0428 20:35:58.442555  4724 net.cpp:200] ip3_relu3_0_split needs backward computation.
I0428 20:35:58.442559  4724 net.cpp:200] relu3 needs backward computation.
I0428 20:35:58.442560  4724 net.cpp:200] ip3 needs backward computation.
I0428 20:35:58.442564  4724 net.cpp:200] relu2 needs backward computation.
I0428 20:35:58.442566  4724 net.cpp:200] ip2 needs backward computation.
I0428 20:35:58.442569  4724 net.cpp:200] relu1 needs backward computation.
I0428 20:35:58.442571  4724 net.cpp:200] ip1 needs backward computation.
I0428 20:35:58.442574  4724 net.cpp:200] pool1 needs backward computation.
I0428 20:35:58.442577  4724 net.cpp:200] conv1 needs backward computation.
I0428 20:35:58.442580  4724 net.cpp:200] pool0 needs backward computation.
I0428 20:35:58.442584  4724 net.cpp:200] conv0 needs backward computation.
I0428 20:35:58.442587  4724 net.cpp:202] label_mnist_1_split does not need backward computation.
I0428 20:35:58.442590  4724 net.cpp:202] mnist does not need backward computation.
I0428 20:35:58.442594  4724 net.cpp:244] This network produces output accuracy
I0428 20:35:58.442597  4724 net.cpp:244] This network produces output loss
I0428 20:35:58.442607  4724 net.cpp:257] Network initialization done.
I0428 20:35:58.442649  4724 solver.cpp:56] Solver scaffolding done.
I0428 20:35:58.443032  4724 caffe.cpp:248] Starting Optimization
I0428 20:35:58.443038  4724 solver.cpp:273] Solving LeNet
I0428 20:35:58.443042  4724 solver.cpp:274] Learning Rate Policy: inv
I0428 20:35:58.443809  4724 solver.cpp:331] Iteration 0, Testing net (#0)
I0428 20:35:58.552876  4732 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:35:58.555848  4724 solver.cpp:398]     Test net output #0: accuracy = 0.1213
I0428 20:35:58.555884  4724 solver.cpp:398]     Test net output #1: loss = 2.2937 (* 1 = 2.2937 loss)
I0428 20:35:58.560495  4724 solver.cpp:219] Iteration 0 (-3.60809e-31 iter/s, 0.117427s/100 iters), loss = 2.31467
I0428 20:35:58.560535  4724 solver.cpp:238]     Train net output #0: loss = 2.31467 (* 1 = 2.31467 loss)
I0428 20:35:58.560547  4724 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0428 20:35:58.792881  4724 solver.cpp:219] Iteration 100 (430.403 iter/s, 0.232341s/100 iters), loss = 0.236038
I0428 20:35:58.792923  4724 solver.cpp:238]     Train net output #0: loss = 0.236038 (* 1 = 0.236038 loss)
I0428 20:35:58.792932  4724 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0428 20:35:59.024706  4724 solver.cpp:219] Iteration 200 (431.437 iter/s, 0.231783s/100 iters), loss = 0.200518
I0428 20:35:59.024747  4724 solver.cpp:238]     Train net output #0: loss = 0.200518 (* 1 = 0.200518 loss)
I0428 20:35:59.024754  4724 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0428 20:35:59.258309  4724 solver.cpp:219] Iteration 300 (428.152 iter/s, 0.233562s/100 iters), loss = 0.230744
I0428 20:35:59.258352  4724 solver.cpp:238]     Train net output #0: loss = 0.230744 (* 1 = 0.230744 loss)
I0428 20:35:59.258358  4724 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0428 20:35:59.490396  4724 solver.cpp:219] Iteration 400 (430.956 iter/s, 0.232042s/100 iters), loss = 0.112555
I0428 20:35:59.490437  4724 solver.cpp:238]     Train net output #0: loss = 0.112555 (* 1 = 0.112555 loss)
I0428 20:35:59.490444  4724 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0428 20:35:59.719584  4724 solver.cpp:331] Iteration 500, Testing net (#0)
I0428 20:35:59.731740  4724 blocking_queue.cpp:49] Waiting for data
I0428 20:35:59.838618  4732 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:35:59.840603  4724 solver.cpp:398]     Test net output #0: accuracy = 0.9621
I0428 20:35:59.840643  4724 solver.cpp:398]     Test net output #1: loss = 0.123056 (* 1 = 0.123056 loss)
I0428 20:35:59.843034  4724 solver.cpp:219] Iteration 500 (283.629 iter/s, 0.352574s/100 iters), loss = 0.0925883
I0428 20:35:59.843086  4724 solver.cpp:238]     Train net output #0: loss = 0.0925883 (* 1 = 0.0925883 loss)
I0428 20:35:59.843108  4724 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0428 20:36:00.083174  4724 solver.cpp:219] Iteration 600 (416.542 iter/s, 0.240072s/100 iters), loss = 0.0619341
I0428 20:36:00.083220  4724 solver.cpp:238]     Train net output #0: loss = 0.061934 (* 1 = 0.061934 loss)
I0428 20:36:00.083227  4724 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0428 20:36:00.321228  4724 solver.cpp:219] Iteration 700 (420.184 iter/s, 0.237991s/100 iters), loss = 0.10536
I0428 20:36:00.321257  4724 solver.cpp:238]     Train net output #0: loss = 0.10536 (* 1 = 0.10536 loss)
I0428 20:36:00.321264  4724 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0428 20:36:00.561496  4724 solver.cpp:219] Iteration 800 (416.281 iter/s, 0.240222s/100 iters), loss = 0.198314
I0428 20:36:00.561538  4724 solver.cpp:238]     Train net output #0: loss = 0.198314 (* 1 = 0.198314 loss)
I0428 20:36:00.561544  4724 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0428 20:36:00.801724  4724 solver.cpp:219] Iteration 900 (416.375 iter/s, 0.240168s/100 iters), loss = 0.100497
I0428 20:36:00.801770  4724 solver.cpp:238]     Train net output #0: loss = 0.100497 (* 1 = 0.100497 loss)
I0428 20:36:00.801777  4724 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0428 20:36:00.881943  4730 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:36:01.041348  4724 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_1000.caffemodel
I0428 20:36:01.046079  4724 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_1000.solverstate
I0428 20:36:01.048233  4724 solver.cpp:311] Iteration 1000, loss = 0.131619
I0428 20:36:01.048251  4724 solver.cpp:331] Iteration 1000, Testing net (#0)
I0428 20:36:01.158457  4732 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:36:01.162266  4724 solver.cpp:398]     Test net output #0: accuracy = 0.9766
I0428 20:36:01.162302  4724 solver.cpp:398]     Test net output #1: loss = 0.0709407 (* 1 = 0.0709407 loss)
I0428 20:36:01.162307  4724 solver.cpp:316] Optimization Done.
I0428 20:36:01.162309  4724 caffe.cpp:259] Optimization Done.
