I0428 20:19:22.246132  1349 caffe.cpp:218] Using GPUs 0
I0428 20:19:22.289688  1349 caffe.cpp:223] GPU 0: TITAN X (Pascal)
I0428 20:19:22.809206  1349 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 1000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_everything2/lenet_train_test1340.prototxt"
train_state {
  level: 0
  stage: ""
}
I0428 20:19:22.809345  1349 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1340.prototxt
I0428 20:19:22.809756  1349 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0428 20:19:22.809778  1349 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0428 20:19:22.809885  1349 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:19:22.809967  1349 layer_factory.hpp:77] Creating layer mnist
I0428 20:19:22.810067  1349 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0428 20:19:22.810091  1349 net.cpp:86] Creating Layer mnist
I0428 20:19:22.810099  1349 net.cpp:382] mnist -> data
I0428 20:19:22.810120  1349 net.cpp:382] mnist -> label
I0428 20:19:22.811205  1349 data_layer.cpp:45] output data size: 64,1,28,28
I0428 20:19:22.813652  1349 net.cpp:124] Setting up mnist
I0428 20:19:22.813669  1349 net.cpp:131] Top shape: 64 1 28 28 (50176)
I0428 20:19:22.813675  1349 net.cpp:131] Top shape: 64 (64)
I0428 20:19:22.813679  1349 net.cpp:139] Memory required for data: 200960
I0428 20:19:22.813686  1349 layer_factory.hpp:77] Creating layer conv0
I0428 20:19:22.813704  1349 net.cpp:86] Creating Layer conv0
I0428 20:19:22.813725  1349 net.cpp:408] conv0 <- data
I0428 20:19:22.813740  1349 net.cpp:382] conv0 -> conv0
I0428 20:19:23.107005  1349 net.cpp:124] Setting up conv0
I0428 20:19:23.107033  1349 net.cpp:131] Top shape: 64 50 24 24 (1843200)
I0428 20:19:23.107038  1349 net.cpp:139] Memory required for data: 7573760
I0428 20:19:23.107054  1349 layer_factory.hpp:77] Creating layer pool0
I0428 20:19:23.107071  1349 net.cpp:86] Creating Layer pool0
I0428 20:19:23.107075  1349 net.cpp:408] pool0 <- conv0
I0428 20:19:23.107081  1349 net.cpp:382] pool0 -> pool0
I0428 20:19:23.107137  1349 net.cpp:124] Setting up pool0
I0428 20:19:23.107144  1349 net.cpp:131] Top shape: 64 50 12 12 (460800)
I0428 20:19:23.107147  1349 net.cpp:139] Memory required for data: 9416960
I0428 20:19:23.107151  1349 layer_factory.hpp:77] Creating layer conv1
I0428 20:19:23.107162  1349 net.cpp:86] Creating Layer conv1
I0428 20:19:23.107167  1349 net.cpp:408] conv1 <- pool0
I0428 20:19:23.107172  1349 net.cpp:382] conv1 -> conv1
I0428 20:19:23.109444  1349 net.cpp:124] Setting up conv1
I0428 20:19:23.109460  1349 net.cpp:131] Top shape: 64 25 8 8 (102400)
I0428 20:19:23.109464  1349 net.cpp:139] Memory required for data: 9826560
I0428 20:19:23.109474  1349 layer_factory.hpp:77] Creating layer pool1
I0428 20:19:23.109483  1349 net.cpp:86] Creating Layer pool1
I0428 20:19:23.109486  1349 net.cpp:408] pool1 <- conv1
I0428 20:19:23.109493  1349 net.cpp:382] pool1 -> pool1
I0428 20:19:23.109532  1349 net.cpp:124] Setting up pool1
I0428 20:19:23.109539  1349 net.cpp:131] Top shape: 64 25 4 4 (25600)
I0428 20:19:23.109541  1349 net.cpp:139] Memory required for data: 9928960
I0428 20:19:23.109544  1349 layer_factory.hpp:77] Creating layer ip1
I0428 20:19:23.109551  1349 net.cpp:86] Creating Layer ip1
I0428 20:19:23.109555  1349 net.cpp:408] ip1 <- pool1
I0428 20:19:23.109560  1349 net.cpp:382] ip1 -> ip1
I0428 20:19:23.109700  1349 net.cpp:124] Setting up ip1
I0428 20:19:23.109709  1349 net.cpp:131] Top shape: 64 10 (640)
I0428 20:19:23.109711  1349 net.cpp:139] Memory required for data: 9931520
I0428 20:19:23.109719  1349 layer_factory.hpp:77] Creating layer relu1
I0428 20:19:23.109726  1349 net.cpp:86] Creating Layer relu1
I0428 20:19:23.109730  1349 net.cpp:408] relu1 <- ip1
I0428 20:19:23.109733  1349 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:19:23.109915  1349 net.cpp:124] Setting up relu1
I0428 20:19:23.109923  1349 net.cpp:131] Top shape: 64 10 (640)
I0428 20:19:23.109927  1349 net.cpp:139] Memory required for data: 9934080
I0428 20:19:23.109930  1349 layer_factory.hpp:77] Creating layer ip2
I0428 20:19:23.109937  1349 net.cpp:86] Creating Layer ip2
I0428 20:19:23.109941  1349 net.cpp:408] ip2 <- ip1
I0428 20:19:23.109946  1349 net.cpp:382] ip2 -> ip2
I0428 20:19:23.110049  1349 net.cpp:124] Setting up ip2
I0428 20:19:23.110055  1349 net.cpp:131] Top shape: 64 10 (640)
I0428 20:19:23.110059  1349 net.cpp:139] Memory required for data: 9936640
I0428 20:19:23.110065  1349 layer_factory.hpp:77] Creating layer relu2
I0428 20:19:23.110071  1349 net.cpp:86] Creating Layer relu2
I0428 20:19:23.110075  1349 net.cpp:408] relu2 <- ip2
I0428 20:19:23.110080  1349 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:19:23.110864  1349 net.cpp:124] Setting up relu2
I0428 20:19:23.110878  1349 net.cpp:131] Top shape: 64 10 (640)
I0428 20:19:23.110882  1349 net.cpp:139] Memory required for data: 9939200
I0428 20:19:23.110887  1349 layer_factory.hpp:77] Creating layer ip3
I0428 20:19:23.110893  1349 net.cpp:86] Creating Layer ip3
I0428 20:19:23.110898  1349 net.cpp:408] ip3 <- ip2
I0428 20:19:23.110903  1349 net.cpp:382] ip3 -> ip3
I0428 20:19:23.111009  1349 net.cpp:124] Setting up ip3
I0428 20:19:23.111017  1349 net.cpp:131] Top shape: 64 10 (640)
I0428 20:19:23.111021  1349 net.cpp:139] Memory required for data: 9941760
I0428 20:19:23.111029  1349 layer_factory.hpp:77] Creating layer relu3
I0428 20:19:23.111035  1349 net.cpp:86] Creating Layer relu3
I0428 20:19:23.111038  1349 net.cpp:408] relu3 <- ip3
I0428 20:19:23.111042  1349 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:19:23.111222  1349 net.cpp:124] Setting up relu3
I0428 20:19:23.111232  1349 net.cpp:131] Top shape: 64 10 (640)
I0428 20:19:23.111237  1349 net.cpp:139] Memory required for data: 9944320
I0428 20:19:23.111239  1349 layer_factory.hpp:77] Creating layer loss
I0428 20:19:23.111246  1349 net.cpp:86] Creating Layer loss
I0428 20:19:23.111249  1349 net.cpp:408] loss <- ip3
I0428 20:19:23.111254  1349 net.cpp:408] loss <- label
I0428 20:19:23.111259  1349 net.cpp:382] loss -> loss
I0428 20:19:23.111275  1349 layer_factory.hpp:77] Creating layer loss
I0428 20:19:23.111522  1349 net.cpp:124] Setting up loss
I0428 20:19:23.111532  1349 net.cpp:131] Top shape: (1)
I0428 20:19:23.111536  1349 net.cpp:134]     with loss weight 1
I0428 20:19:23.111552  1349 net.cpp:139] Memory required for data: 9944324
I0428 20:19:23.111557  1349 net.cpp:200] loss needs backward computation.
I0428 20:19:23.111560  1349 net.cpp:200] relu3 needs backward computation.
I0428 20:19:23.111563  1349 net.cpp:200] ip3 needs backward computation.
I0428 20:19:23.111567  1349 net.cpp:200] relu2 needs backward computation.
I0428 20:19:23.111570  1349 net.cpp:200] ip2 needs backward computation.
I0428 20:19:23.111573  1349 net.cpp:200] relu1 needs backward computation.
I0428 20:19:23.111577  1349 net.cpp:200] ip1 needs backward computation.
I0428 20:19:23.111580  1349 net.cpp:200] pool1 needs backward computation.
I0428 20:19:23.111583  1349 net.cpp:200] conv1 needs backward computation.
I0428 20:19:23.111588  1349 net.cpp:200] pool0 needs backward computation.
I0428 20:19:23.111590  1349 net.cpp:200] conv0 needs backward computation.
I0428 20:19:23.111594  1349 net.cpp:202] mnist does not need backward computation.
I0428 20:19:23.111598  1349 net.cpp:244] This network produces output loss
I0428 20:19:23.111608  1349 net.cpp:257] Network initialization done.
I0428 20:19:23.111977  1349 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1340.prototxt
I0428 20:19:23.112005  1349 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0428 20:19:23.112104  1349 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:19:23.112188  1349 layer_factory.hpp:77] Creating layer mnist
I0428 20:19:23.112236  1349 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0428 20:19:23.112248  1349 net.cpp:86] Creating Layer mnist
I0428 20:19:23.112253  1349 net.cpp:382] mnist -> data
I0428 20:19:23.112262  1349 net.cpp:382] mnist -> label
I0428 20:19:23.112355  1349 data_layer.cpp:45] output data size: 100,1,28,28
I0428 20:19:23.114392  1349 net.cpp:124] Setting up mnist
I0428 20:19:23.114408  1349 net.cpp:131] Top shape: 100 1 28 28 (78400)
I0428 20:19:23.114413  1349 net.cpp:131] Top shape: 100 (100)
I0428 20:19:23.114415  1349 net.cpp:139] Memory required for data: 314000
I0428 20:19:23.114419  1349 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0428 20:19:23.114428  1349 net.cpp:86] Creating Layer label_mnist_1_split
I0428 20:19:23.114430  1349 net.cpp:408] label_mnist_1_split <- label
I0428 20:19:23.114437  1349 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_0
I0428 20:19:23.114444  1349 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_1
I0428 20:19:23.114518  1349 net.cpp:124] Setting up label_mnist_1_split
I0428 20:19:23.114531  1349 net.cpp:131] Top shape: 100 (100)
I0428 20:19:23.114534  1349 net.cpp:131] Top shape: 100 (100)
I0428 20:19:23.114537  1349 net.cpp:139] Memory required for data: 314800
I0428 20:19:23.114542  1349 layer_factory.hpp:77] Creating layer conv0
I0428 20:19:23.114552  1349 net.cpp:86] Creating Layer conv0
I0428 20:19:23.114555  1349 net.cpp:408] conv0 <- data
I0428 20:19:23.114562  1349 net.cpp:382] conv0 -> conv0
I0428 20:19:23.116230  1349 net.cpp:124] Setting up conv0
I0428 20:19:23.116245  1349 net.cpp:131] Top shape: 100 50 24 24 (2880000)
I0428 20:19:23.116250  1349 net.cpp:139] Memory required for data: 11834800
I0428 20:19:23.116259  1349 layer_factory.hpp:77] Creating layer pool0
I0428 20:19:23.116266  1349 net.cpp:86] Creating Layer pool0
I0428 20:19:23.116269  1349 net.cpp:408] pool0 <- conv0
I0428 20:19:23.116276  1349 net.cpp:382] pool0 -> pool0
I0428 20:19:23.116315  1349 net.cpp:124] Setting up pool0
I0428 20:19:23.116322  1349 net.cpp:131] Top shape: 100 50 12 12 (720000)
I0428 20:19:23.116323  1349 net.cpp:139] Memory required for data: 14714800
I0428 20:19:23.116328  1349 layer_factory.hpp:77] Creating layer conv1
I0428 20:19:23.116338  1349 net.cpp:86] Creating Layer conv1
I0428 20:19:23.116341  1349 net.cpp:408] conv1 <- pool0
I0428 20:19:23.116346  1349 net.cpp:382] conv1 -> conv1
I0428 20:19:23.118149  1349 net.cpp:124] Setting up conv1
I0428 20:19:23.118165  1349 net.cpp:131] Top shape: 100 25 8 8 (160000)
I0428 20:19:23.118170  1349 net.cpp:139] Memory required for data: 15354800
I0428 20:19:23.118180  1349 layer_factory.hpp:77] Creating layer pool1
I0428 20:19:23.118187  1349 net.cpp:86] Creating Layer pool1
I0428 20:19:23.118191  1349 net.cpp:408] pool1 <- conv1
I0428 20:19:23.118196  1349 net.cpp:382] pool1 -> pool1
I0428 20:19:23.118237  1349 net.cpp:124] Setting up pool1
I0428 20:19:23.118244  1349 net.cpp:131] Top shape: 100 25 4 4 (40000)
I0428 20:19:23.118248  1349 net.cpp:139] Memory required for data: 15514800
I0428 20:19:23.118252  1349 layer_factory.hpp:77] Creating layer ip1
I0428 20:19:23.118264  1349 net.cpp:86] Creating Layer ip1
I0428 20:19:23.118268  1349 net.cpp:408] ip1 <- pool1
I0428 20:19:23.118273  1349 net.cpp:382] ip1 -> ip1
I0428 20:19:23.118412  1349 net.cpp:124] Setting up ip1
I0428 20:19:23.118420  1349 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:19:23.118434  1349 net.cpp:139] Memory required for data: 15518800
I0428 20:19:23.118444  1349 layer_factory.hpp:77] Creating layer relu1
I0428 20:19:23.118451  1349 net.cpp:86] Creating Layer relu1
I0428 20:19:23.118454  1349 net.cpp:408] relu1 <- ip1
I0428 20:19:23.118460  1349 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:19:23.118639  1349 net.cpp:124] Setting up relu1
I0428 20:19:23.118649  1349 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:19:23.118654  1349 net.cpp:139] Memory required for data: 15522800
I0428 20:19:23.118657  1349 layer_factory.hpp:77] Creating layer ip2
I0428 20:19:23.118664  1349 net.cpp:86] Creating Layer ip2
I0428 20:19:23.118669  1349 net.cpp:408] ip2 <- ip1
I0428 20:19:23.118674  1349 net.cpp:382] ip2 -> ip2
I0428 20:19:23.118803  1349 net.cpp:124] Setting up ip2
I0428 20:19:23.118810  1349 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:19:23.118813  1349 net.cpp:139] Memory required for data: 15526800
I0428 20:19:23.118819  1349 layer_factory.hpp:77] Creating layer relu2
I0428 20:19:23.118825  1349 net.cpp:86] Creating Layer relu2
I0428 20:19:23.118829  1349 net.cpp:408] relu2 <- ip2
I0428 20:19:23.118832  1349 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:19:23.119041  1349 net.cpp:124] Setting up relu2
I0428 20:19:23.119051  1349 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:19:23.119055  1349 net.cpp:139] Memory required for data: 15530800
I0428 20:19:23.119058  1349 layer_factory.hpp:77] Creating layer ip3
I0428 20:19:23.119065  1349 net.cpp:86] Creating Layer ip3
I0428 20:19:23.119069  1349 net.cpp:408] ip3 <- ip2
I0428 20:19:23.119076  1349 net.cpp:382] ip3 -> ip3
I0428 20:19:23.119182  1349 net.cpp:124] Setting up ip3
I0428 20:19:23.119189  1349 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:19:23.119192  1349 net.cpp:139] Memory required for data: 15534800
I0428 20:19:23.119200  1349 layer_factory.hpp:77] Creating layer relu3
I0428 20:19:23.119205  1349 net.cpp:86] Creating Layer relu3
I0428 20:19:23.119209  1349 net.cpp:408] relu3 <- ip3
I0428 20:19:23.119215  1349 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:19:23.120107  1349 net.cpp:124] Setting up relu3
I0428 20:19:23.120121  1349 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:19:23.120124  1349 net.cpp:139] Memory required for data: 15538800
I0428 20:19:23.120128  1349 layer_factory.hpp:77] Creating layer ip3_relu3_0_split
I0428 20:19:23.120134  1349 net.cpp:86] Creating Layer ip3_relu3_0_split
I0428 20:19:23.120138  1349 net.cpp:408] ip3_relu3_0_split <- ip3
I0428 20:19:23.120144  1349 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_0
I0428 20:19:23.120151  1349 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_1
I0428 20:19:23.120194  1349 net.cpp:124] Setting up ip3_relu3_0_split
I0428 20:19:23.120200  1349 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:19:23.120204  1349 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:19:23.120208  1349 net.cpp:139] Memory required for data: 15546800
I0428 20:19:23.120211  1349 layer_factory.hpp:77] Creating layer accuracy
I0428 20:19:23.120218  1349 net.cpp:86] Creating Layer accuracy
I0428 20:19:23.120221  1349 net.cpp:408] accuracy <- ip3_relu3_0_split_0
I0428 20:19:23.120225  1349 net.cpp:408] accuracy <- label_mnist_1_split_0
I0428 20:19:23.120230  1349 net.cpp:382] accuracy -> accuracy
I0428 20:19:23.120239  1349 net.cpp:124] Setting up accuracy
I0428 20:19:23.120244  1349 net.cpp:131] Top shape: (1)
I0428 20:19:23.120246  1349 net.cpp:139] Memory required for data: 15546804
I0428 20:19:23.120249  1349 layer_factory.hpp:77] Creating layer loss
I0428 20:19:23.120255  1349 net.cpp:86] Creating Layer loss
I0428 20:19:23.120260  1349 net.cpp:408] loss <- ip3_relu3_0_split_1
I0428 20:19:23.120263  1349 net.cpp:408] loss <- label_mnist_1_split_1
I0428 20:19:23.120267  1349 net.cpp:382] loss -> loss
I0428 20:19:23.120273  1349 layer_factory.hpp:77] Creating layer loss
I0428 20:19:23.120533  1349 net.cpp:124] Setting up loss
I0428 20:19:23.120543  1349 net.cpp:131] Top shape: (1)
I0428 20:19:23.120548  1349 net.cpp:134]     with loss weight 1
I0428 20:19:23.120564  1349 net.cpp:139] Memory required for data: 15546808
I0428 20:19:23.120569  1349 net.cpp:200] loss needs backward computation.
I0428 20:19:23.120573  1349 net.cpp:202] accuracy does not need backward computation.
I0428 20:19:23.120578  1349 net.cpp:200] ip3_relu3_0_split needs backward computation.
I0428 20:19:23.120581  1349 net.cpp:200] relu3 needs backward computation.
I0428 20:19:23.120584  1349 net.cpp:200] ip3 needs backward computation.
I0428 20:19:23.120587  1349 net.cpp:200] relu2 needs backward computation.
I0428 20:19:23.120590  1349 net.cpp:200] ip2 needs backward computation.
I0428 20:19:23.120594  1349 net.cpp:200] relu1 needs backward computation.
I0428 20:19:23.120596  1349 net.cpp:200] ip1 needs backward computation.
I0428 20:19:23.120600  1349 net.cpp:200] pool1 needs backward computation.
I0428 20:19:23.120604  1349 net.cpp:200] conv1 needs backward computation.
I0428 20:19:23.120609  1349 net.cpp:200] pool0 needs backward computation.
I0428 20:19:23.120611  1349 net.cpp:200] conv0 needs backward computation.
I0428 20:19:23.120615  1349 net.cpp:202] label_mnist_1_split does not need backward computation.
I0428 20:19:23.120620  1349 net.cpp:202] mnist does not need backward computation.
I0428 20:19:23.120623  1349 net.cpp:244] This network produces output accuracy
I0428 20:19:23.120627  1349 net.cpp:244] This network produces output loss
I0428 20:19:23.120640  1349 net.cpp:257] Network initialization done.
I0428 20:19:23.120687  1349 solver.cpp:56] Solver scaffolding done.
I0428 20:19:23.121104  1349 caffe.cpp:248] Starting Optimization
I0428 20:19:23.121110  1349 solver.cpp:273] Solving LeNet
I0428 20:19:23.121114  1349 solver.cpp:274] Learning Rate Policy: inv
I0428 20:19:23.121316  1349 solver.cpp:331] Iteration 0, Testing net (#0)
I0428 20:19:23.141239  1349 blocking_queue.cpp:49] Waiting for data
I0428 20:19:23.190594  1356 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:19:23.191632  1349 solver.cpp:398]     Test net output #0: accuracy = 0.1171
I0428 20:19:23.191670  1349 solver.cpp:398]     Test net output #1: loss = 2.34778 (* 1 = 2.34778 loss)
I0428 20:19:23.195968  1349 solver.cpp:219] Iteration 0 (0 iter/s, 0.0748227s/100 iters), loss = 2.33413
I0428 20:19:23.195992  1349 solver.cpp:238]     Train net output #0: loss = 2.33413 (* 1 = 2.33413 loss)
I0428 20:19:23.196003  1349 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0428 20:19:23.339606  1349 solver.cpp:219] Iteration 100 (696.415 iter/s, 0.143592s/100 iters), loss = 0.920592
I0428 20:19:23.339645  1349 solver.cpp:238]     Train net output #0: loss = 0.920592 (* 1 = 0.920592 loss)
I0428 20:19:23.339655  1349 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0428 20:19:23.487810  1349 solver.cpp:219] Iteration 200 (674.986 iter/s, 0.148151s/100 iters), loss = 0.344603
I0428 20:19:23.487849  1349 solver.cpp:238]     Train net output #0: loss = 0.344603 (* 1 = 0.344603 loss)
I0428 20:19:23.487862  1349 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0428 20:19:23.637195  1349 solver.cpp:219] Iteration 300 (669.649 iter/s, 0.149332s/100 iters), loss = 0.291468
I0428 20:19:23.637238  1349 solver.cpp:238]     Train net output #0: loss = 0.291468 (* 1 = 0.291468 loss)
I0428 20:19:23.637249  1349 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0428 20:19:23.788236  1349 solver.cpp:219] Iteration 400 (662.319 iter/s, 0.150985s/100 iters), loss = 0.167175
I0428 20:19:23.788282  1349 solver.cpp:238]     Train net output #0: loss = 0.167175 (* 1 = 0.167175 loss)
I0428 20:19:23.788293  1349 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0428 20:19:23.937515  1349 solver.cpp:331] Iteration 500, Testing net (#0)
I0428 20:19:24.015964  1356 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:19:24.016919  1349 solver.cpp:398]     Test net output #0: accuracy = 0.9488
I0428 20:19:24.016945  1349 solver.cpp:398]     Test net output #1: loss = 0.169681 (* 1 = 0.169681 loss)
I0428 20:19:24.018359  1349 solver.cpp:219] Iteration 500 (434.661 iter/s, 0.230064s/100 iters), loss = 0.154251
I0428 20:19:24.018404  1349 solver.cpp:238]     Train net output #0: loss = 0.154251 (* 1 = 0.154251 loss)
I0428 20:19:24.018411  1349 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0428 20:19:24.163161  1349 solver.cpp:219] Iteration 600 (690.878 iter/s, 0.144743s/100 iters), loss = 0.0764503
I0428 20:19:24.163199  1349 solver.cpp:238]     Train net output #0: loss = 0.0764503 (* 1 = 0.0764503 loss)
I0428 20:19:24.163208  1349 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0428 20:19:24.310528  1349 solver.cpp:219] Iteration 700 (678.824 iter/s, 0.147314s/100 iters), loss = 0.184007
I0428 20:19:24.310571  1349 solver.cpp:238]     Train net output #0: loss = 0.184007 (* 1 = 0.184007 loss)
I0428 20:19:24.310581  1349 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0428 20:19:24.465761  1349 solver.cpp:219] Iteration 800 (644.43 iter/s, 0.155176s/100 iters), loss = 0.236415
I0428 20:19:24.465807  1349 solver.cpp:238]     Train net output #0: loss = 0.236415 (* 1 = 0.236415 loss)
I0428 20:19:24.465818  1349 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0428 20:19:24.618687  1349 solver.cpp:219] Iteration 900 (654.173 iter/s, 0.152865s/100 iters), loss = 0.16017
I0428 20:19:24.618738  1349 solver.cpp:238]     Train net output #0: loss = 0.160171 (* 1 = 0.160171 loss)
I0428 20:19:24.618749  1349 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0428 20:19:24.670274  1355 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:19:24.771613  1349 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_1000.caffemodel
I0428 20:19:24.773602  1349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_1000.solverstate
I0428 20:19:24.774780  1349 solver.cpp:311] Iteration 1000, loss = 0.137222
I0428 20:19:24.774806  1349 solver.cpp:331] Iteration 1000, Testing net (#0)
I0428 20:19:24.852757  1356 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:19:24.853724  1349 solver.cpp:398]     Test net output #0: accuracy = 0.9723
I0428 20:19:24.853746  1349 solver.cpp:398]     Test net output #1: loss = 0.0928736 (* 1 = 0.0928736 loss)
I0428 20:19:24.853754  1349 solver.cpp:316] Optimization Done.
I0428 20:19:24.853760  1349 caffe.cpp:259] Optimization Done.
