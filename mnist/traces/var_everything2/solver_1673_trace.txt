I0428 20:39:00.690363  5219 caffe.cpp:218] Using GPUs 0
I0428 20:39:00.728091  5219 caffe.cpp:223] GPU 0: TITAN X (Pascal)
I0428 20:39:01.239682  5219 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 1000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_everything2/lenet_train_test1673.prototxt"
train_state {
  level: 0
  stage: ""
}
I0428 20:39:01.239835  5219 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1673.prototxt
I0428 20:39:01.240262  5219 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0428 20:39:01.240280  5219 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0428 20:39:01.240387  5219 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:39:01.240466  5219 layer_factory.hpp:77] Creating layer mnist
I0428 20:39:01.240566  5219 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0428 20:39:01.240599  5219 net.cpp:86] Creating Layer mnist
I0428 20:39:01.240609  5219 net.cpp:382] mnist -> data
I0428 20:39:01.240631  5219 net.cpp:382] mnist -> label
I0428 20:39:01.241731  5219 data_layer.cpp:45] output data size: 64,1,28,28
I0428 20:39:01.244199  5219 net.cpp:124] Setting up mnist
I0428 20:39:01.244216  5219 net.cpp:131] Top shape: 64 1 28 28 (50176)
I0428 20:39:01.244222  5219 net.cpp:131] Top shape: 64 (64)
I0428 20:39:01.244226  5219 net.cpp:139] Memory required for data: 200960
I0428 20:39:01.244233  5219 layer_factory.hpp:77] Creating layer conv0
I0428 20:39:01.244251  5219 net.cpp:86] Creating Layer conv0
I0428 20:39:01.244271  5219 net.cpp:408] conv0 <- data
I0428 20:39:01.244284  5219 net.cpp:382] conv0 -> conv0
I0428 20:39:01.520965  5219 net.cpp:124] Setting up conv0
I0428 20:39:01.521008  5219 net.cpp:131] Top shape: 64 100 24 24 (3686400)
I0428 20:39:01.521013  5219 net.cpp:139] Memory required for data: 14946560
I0428 20:39:01.521028  5219 layer_factory.hpp:77] Creating layer pool0
I0428 20:39:01.521039  5219 net.cpp:86] Creating Layer pool0
I0428 20:39:01.521059  5219 net.cpp:408] pool0 <- conv0
I0428 20:39:01.521064  5219 net.cpp:382] pool0 -> pool0
I0428 20:39:01.521116  5219 net.cpp:124] Setting up pool0
I0428 20:39:01.521143  5219 net.cpp:131] Top shape: 64 100 12 12 (921600)
I0428 20:39:01.521147  5219 net.cpp:139] Memory required for data: 18632960
I0428 20:39:01.521148  5219 layer_factory.hpp:77] Creating layer conv1
I0428 20:39:01.521159  5219 net.cpp:86] Creating Layer conv1
I0428 20:39:01.521162  5219 net.cpp:408] conv1 <- pool0
I0428 20:39:01.521167  5219 net.cpp:382] conv1 -> conv1
I0428 20:39:01.525346  5219 net.cpp:124] Setting up conv1
I0428 20:39:01.525360  5219 net.cpp:131] Top shape: 64 100 8 8 (409600)
I0428 20:39:01.525363  5219 net.cpp:139] Memory required for data: 20271360
I0428 20:39:01.525372  5219 layer_factory.hpp:77] Creating layer pool1
I0428 20:39:01.525378  5219 net.cpp:86] Creating Layer pool1
I0428 20:39:01.525382  5219 net.cpp:408] pool1 <- conv1
I0428 20:39:01.525385  5219 net.cpp:382] pool1 -> pool1
I0428 20:39:01.525435  5219 net.cpp:124] Setting up pool1
I0428 20:39:01.525441  5219 net.cpp:131] Top shape: 64 100 4 4 (102400)
I0428 20:39:01.525444  5219 net.cpp:139] Memory required for data: 20680960
I0428 20:39:01.525447  5219 layer_factory.hpp:77] Creating layer ip1
I0428 20:39:01.525454  5219 net.cpp:86] Creating Layer ip1
I0428 20:39:01.525455  5219 net.cpp:408] ip1 <- pool1
I0428 20:39:01.525460  5219 net.cpp:382] ip1 -> ip1
I0428 20:39:01.526005  5219 net.cpp:124] Setting up ip1
I0428 20:39:01.526012  5219 net.cpp:131] Top shape: 64 50 (3200)
I0428 20:39:01.526031  5219 net.cpp:139] Memory required for data: 20693760
I0428 20:39:01.526036  5219 layer_factory.hpp:77] Creating layer relu1
I0428 20:39:01.526042  5219 net.cpp:86] Creating Layer relu1
I0428 20:39:01.526046  5219 net.cpp:408] relu1 <- ip1
I0428 20:39:01.526049  5219 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:39:01.526203  5219 net.cpp:124] Setting up relu1
I0428 20:39:01.526211  5219 net.cpp:131] Top shape: 64 50 (3200)
I0428 20:39:01.526214  5219 net.cpp:139] Memory required for data: 20706560
I0428 20:39:01.526217  5219 layer_factory.hpp:77] Creating layer ip2
I0428 20:39:01.526223  5219 net.cpp:86] Creating Layer ip2
I0428 20:39:01.526226  5219 net.cpp:408] ip2 <- ip1
I0428 20:39:01.526231  5219 net.cpp:382] ip2 -> ip2
I0428 20:39:01.526330  5219 net.cpp:124] Setting up ip2
I0428 20:39:01.526337  5219 net.cpp:131] Top shape: 64 25 (1600)
I0428 20:39:01.526340  5219 net.cpp:139] Memory required for data: 20712960
I0428 20:39:01.526345  5219 layer_factory.hpp:77] Creating layer relu2
I0428 20:39:01.526350  5219 net.cpp:86] Creating Layer relu2
I0428 20:39:01.526353  5219 net.cpp:408] relu2 <- ip2
I0428 20:39:01.526356  5219 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:39:01.527134  5219 net.cpp:124] Setting up relu2
I0428 20:39:01.527146  5219 net.cpp:131] Top shape: 64 25 (1600)
I0428 20:39:01.527149  5219 net.cpp:139] Memory required for data: 20719360
I0428 20:39:01.527153  5219 layer_factory.hpp:77] Creating layer ip3
I0428 20:39:01.527158  5219 net.cpp:86] Creating Layer ip3
I0428 20:39:01.527163  5219 net.cpp:408] ip3 <- ip2
I0428 20:39:01.527168  5219 net.cpp:382] ip3 -> ip3
I0428 20:39:01.527261  5219 net.cpp:124] Setting up ip3
I0428 20:39:01.527267  5219 net.cpp:131] Top shape: 64 10 (640)
I0428 20:39:01.527271  5219 net.cpp:139] Memory required for data: 20721920
I0428 20:39:01.527277  5219 layer_factory.hpp:77] Creating layer relu3
I0428 20:39:01.527282  5219 net.cpp:86] Creating Layer relu3
I0428 20:39:01.527285  5219 net.cpp:408] relu3 <- ip3
I0428 20:39:01.527302  5219 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:39:01.527441  5219 net.cpp:124] Setting up relu3
I0428 20:39:01.527448  5219 net.cpp:131] Top shape: 64 10 (640)
I0428 20:39:01.527451  5219 net.cpp:139] Memory required for data: 20724480
I0428 20:39:01.527454  5219 layer_factory.hpp:77] Creating layer loss
I0428 20:39:01.527459  5219 net.cpp:86] Creating Layer loss
I0428 20:39:01.527462  5219 net.cpp:408] loss <- ip3
I0428 20:39:01.527467  5219 net.cpp:408] loss <- label
I0428 20:39:01.527472  5219 net.cpp:382] loss -> loss
I0428 20:39:01.527487  5219 layer_factory.hpp:77] Creating layer loss
I0428 20:39:01.527694  5219 net.cpp:124] Setting up loss
I0428 20:39:01.527704  5219 net.cpp:131] Top shape: (1)
I0428 20:39:01.527706  5219 net.cpp:134]     with loss weight 1
I0428 20:39:01.527724  5219 net.cpp:139] Memory required for data: 20724484
I0428 20:39:01.527739  5219 net.cpp:200] loss needs backward computation.
I0428 20:39:01.527741  5219 net.cpp:200] relu3 needs backward computation.
I0428 20:39:01.527745  5219 net.cpp:200] ip3 needs backward computation.
I0428 20:39:01.527747  5219 net.cpp:200] relu2 needs backward computation.
I0428 20:39:01.527765  5219 net.cpp:200] ip2 needs backward computation.
I0428 20:39:01.527768  5219 net.cpp:200] relu1 needs backward computation.
I0428 20:39:01.527771  5219 net.cpp:200] ip1 needs backward computation.
I0428 20:39:01.527789  5219 net.cpp:200] pool1 needs backward computation.
I0428 20:39:01.527792  5219 net.cpp:200] conv1 needs backward computation.
I0428 20:39:01.527796  5219 net.cpp:200] pool0 needs backward computation.
I0428 20:39:01.527798  5219 net.cpp:200] conv0 needs backward computation.
I0428 20:39:01.527802  5219 net.cpp:202] mnist does not need backward computation.
I0428 20:39:01.527806  5219 net.cpp:244] This network produces output loss
I0428 20:39:01.527814  5219 net.cpp:257] Network initialization done.
I0428 20:39:01.528164  5219 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1673.prototxt
I0428 20:39:01.528189  5219 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0428 20:39:01.528277  5219 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:39:01.528350  5219 layer_factory.hpp:77] Creating layer mnist
I0428 20:39:01.528393  5219 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0428 20:39:01.528424  5219 net.cpp:86] Creating Layer mnist
I0428 20:39:01.528429  5219 net.cpp:382] mnist -> data
I0428 20:39:01.528435  5219 net.cpp:382] mnist -> label
I0428 20:39:01.528517  5219 data_layer.cpp:45] output data size: 100,1,28,28
I0428 20:39:01.530575  5219 net.cpp:124] Setting up mnist
I0428 20:39:01.530619  5219 net.cpp:131] Top shape: 100 1 28 28 (78400)
I0428 20:39:01.530625  5219 net.cpp:131] Top shape: 100 (100)
I0428 20:39:01.530628  5219 net.cpp:139] Memory required for data: 314000
I0428 20:39:01.530632  5219 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0428 20:39:01.530642  5219 net.cpp:86] Creating Layer label_mnist_1_split
I0428 20:39:01.530647  5219 net.cpp:408] label_mnist_1_split <- label
I0428 20:39:01.530652  5219 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_0
I0428 20:39:01.530658  5219 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_1
I0428 20:39:01.530737  5219 net.cpp:124] Setting up label_mnist_1_split
I0428 20:39:01.530745  5219 net.cpp:131] Top shape: 100 (100)
I0428 20:39:01.530750  5219 net.cpp:131] Top shape: 100 (100)
I0428 20:39:01.530752  5219 net.cpp:139] Memory required for data: 314800
I0428 20:39:01.530755  5219 layer_factory.hpp:77] Creating layer conv0
I0428 20:39:01.530763  5219 net.cpp:86] Creating Layer conv0
I0428 20:39:01.530766  5219 net.cpp:408] conv0 <- data
I0428 20:39:01.530771  5219 net.cpp:382] conv0 -> conv0
I0428 20:39:01.532299  5219 net.cpp:124] Setting up conv0
I0428 20:39:01.532313  5219 net.cpp:131] Top shape: 100 100 24 24 (5760000)
I0428 20:39:01.532316  5219 net.cpp:139] Memory required for data: 23354800
I0428 20:39:01.532341  5219 layer_factory.hpp:77] Creating layer pool0
I0428 20:39:01.532363  5219 net.cpp:86] Creating Layer pool0
I0428 20:39:01.532367  5219 net.cpp:408] pool0 <- conv0
I0428 20:39:01.532372  5219 net.cpp:382] pool0 -> pool0
I0428 20:39:01.532414  5219 net.cpp:124] Setting up pool0
I0428 20:39:01.532421  5219 net.cpp:131] Top shape: 100 100 12 12 (1440000)
I0428 20:39:01.532424  5219 net.cpp:139] Memory required for data: 29114800
I0428 20:39:01.532428  5219 layer_factory.hpp:77] Creating layer conv1
I0428 20:39:01.532436  5219 net.cpp:86] Creating Layer conv1
I0428 20:39:01.532440  5219 net.cpp:408] conv1 <- pool0
I0428 20:39:01.532445  5219 net.cpp:382] conv1 -> conv1
I0428 20:39:01.535601  5219 net.cpp:124] Setting up conv1
I0428 20:39:01.535624  5219 net.cpp:131] Top shape: 100 100 8 8 (640000)
I0428 20:39:01.535629  5219 net.cpp:139] Memory required for data: 31674800
I0428 20:39:01.535636  5219 layer_factory.hpp:77] Creating layer pool1
I0428 20:39:01.535643  5219 net.cpp:86] Creating Layer pool1
I0428 20:39:01.535647  5219 net.cpp:408] pool1 <- conv1
I0428 20:39:01.535673  5219 net.cpp:382] pool1 -> pool1
I0428 20:39:01.535712  5219 net.cpp:124] Setting up pool1
I0428 20:39:01.535719  5219 net.cpp:131] Top shape: 100 100 4 4 (160000)
I0428 20:39:01.535723  5219 net.cpp:139] Memory required for data: 32314800
I0428 20:39:01.535727  5219 layer_factory.hpp:77] Creating layer ip1
I0428 20:39:01.535734  5219 net.cpp:86] Creating Layer ip1
I0428 20:39:01.535737  5219 net.cpp:408] ip1 <- pool1
I0428 20:39:01.535742  5219 net.cpp:382] ip1 -> ip1
I0428 20:39:01.536295  5219 net.cpp:124] Setting up ip1
I0428 20:39:01.536311  5219 net.cpp:131] Top shape: 100 50 (5000)
I0428 20:39:01.536325  5219 net.cpp:139] Memory required for data: 32334800
I0428 20:39:01.536332  5219 layer_factory.hpp:77] Creating layer relu1
I0428 20:39:01.536339  5219 net.cpp:86] Creating Layer relu1
I0428 20:39:01.536342  5219 net.cpp:408] relu1 <- ip1
I0428 20:39:01.536346  5219 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:39:01.536535  5219 net.cpp:124] Setting up relu1
I0428 20:39:01.536542  5219 net.cpp:131] Top shape: 100 50 (5000)
I0428 20:39:01.536545  5219 net.cpp:139] Memory required for data: 32354800
I0428 20:39:01.536548  5219 layer_factory.hpp:77] Creating layer ip2
I0428 20:39:01.536556  5219 net.cpp:86] Creating Layer ip2
I0428 20:39:01.536574  5219 net.cpp:408] ip2 <- ip1
I0428 20:39:01.536581  5219 net.cpp:382] ip2 -> ip2
I0428 20:39:01.536722  5219 net.cpp:124] Setting up ip2
I0428 20:39:01.536731  5219 net.cpp:131] Top shape: 100 25 (2500)
I0428 20:39:01.536734  5219 net.cpp:139] Memory required for data: 32364800
I0428 20:39:01.536739  5219 layer_factory.hpp:77] Creating layer relu2
I0428 20:39:01.536746  5219 net.cpp:86] Creating Layer relu2
I0428 20:39:01.536748  5219 net.cpp:408] relu2 <- ip2
I0428 20:39:01.536752  5219 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:39:01.536945  5219 net.cpp:124] Setting up relu2
I0428 20:39:01.536957  5219 net.cpp:131] Top shape: 100 25 (2500)
I0428 20:39:01.536959  5219 net.cpp:139] Memory required for data: 32374800
I0428 20:39:01.536963  5219 layer_factory.hpp:77] Creating layer ip3
I0428 20:39:01.536968  5219 net.cpp:86] Creating Layer ip3
I0428 20:39:01.536972  5219 net.cpp:408] ip3 <- ip2
I0428 20:39:01.536978  5219 net.cpp:382] ip3 -> ip3
I0428 20:39:01.537113  5219 net.cpp:124] Setting up ip3
I0428 20:39:01.537134  5219 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:39:01.537137  5219 net.cpp:139] Memory required for data: 32378800
I0428 20:39:01.537160  5219 layer_factory.hpp:77] Creating layer relu3
I0428 20:39:01.537166  5219 net.cpp:86] Creating Layer relu3
I0428 20:39:01.537169  5219 net.cpp:408] relu3 <- ip3
I0428 20:39:01.537173  5219 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:39:01.537916  5219 net.cpp:124] Setting up relu3
I0428 20:39:01.537930  5219 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:39:01.537943  5219 net.cpp:139] Memory required for data: 32382800
I0428 20:39:01.537946  5219 layer_factory.hpp:77] Creating layer ip3_relu3_0_split
I0428 20:39:01.537951  5219 net.cpp:86] Creating Layer ip3_relu3_0_split
I0428 20:39:01.537955  5219 net.cpp:408] ip3_relu3_0_split <- ip3
I0428 20:39:01.537962  5219 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_0
I0428 20:39:01.537969  5219 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_1
I0428 20:39:01.538007  5219 net.cpp:124] Setting up ip3_relu3_0_split
I0428 20:39:01.538014  5219 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:39:01.538017  5219 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:39:01.538020  5219 net.cpp:139] Memory required for data: 32390800
I0428 20:39:01.538023  5219 layer_factory.hpp:77] Creating layer accuracy
I0428 20:39:01.538029  5219 net.cpp:86] Creating Layer accuracy
I0428 20:39:01.538033  5219 net.cpp:408] accuracy <- ip3_relu3_0_split_0
I0428 20:39:01.538036  5219 net.cpp:408] accuracy <- label_mnist_1_split_0
I0428 20:39:01.538041  5219 net.cpp:382] accuracy -> accuracy
I0428 20:39:01.538049  5219 net.cpp:124] Setting up accuracy
I0428 20:39:01.538053  5219 net.cpp:131] Top shape: (1)
I0428 20:39:01.538055  5219 net.cpp:139] Memory required for data: 32390804
I0428 20:39:01.538058  5219 layer_factory.hpp:77] Creating layer loss
I0428 20:39:01.538064  5219 net.cpp:86] Creating Layer loss
I0428 20:39:01.538066  5219 net.cpp:408] loss <- ip3_relu3_0_split_1
I0428 20:39:01.538069  5219 net.cpp:408] loss <- label_mnist_1_split_1
I0428 20:39:01.538074  5219 net.cpp:382] loss -> loss
I0428 20:39:01.538079  5219 layer_factory.hpp:77] Creating layer loss
I0428 20:39:01.538341  5219 net.cpp:124] Setting up loss
I0428 20:39:01.538349  5219 net.cpp:131] Top shape: (1)
I0428 20:39:01.538352  5219 net.cpp:134]     with loss weight 1
I0428 20:39:01.538367  5219 net.cpp:139] Memory required for data: 32390808
I0428 20:39:01.538370  5219 net.cpp:200] loss needs backward computation.
I0428 20:39:01.538374  5219 net.cpp:202] accuracy does not need backward computation.
I0428 20:39:01.538378  5219 net.cpp:200] ip3_relu3_0_split needs backward computation.
I0428 20:39:01.538380  5219 net.cpp:200] relu3 needs backward computation.
I0428 20:39:01.538383  5219 net.cpp:200] ip3 needs backward computation.
I0428 20:39:01.538386  5219 net.cpp:200] relu2 needs backward computation.
I0428 20:39:01.538388  5219 net.cpp:200] ip2 needs backward computation.
I0428 20:39:01.538391  5219 net.cpp:200] relu1 needs backward computation.
I0428 20:39:01.538393  5219 net.cpp:200] ip1 needs backward computation.
I0428 20:39:01.538396  5219 net.cpp:200] pool1 needs backward computation.
I0428 20:39:01.538399  5219 net.cpp:200] conv1 needs backward computation.
I0428 20:39:01.538403  5219 net.cpp:200] pool0 needs backward computation.
I0428 20:39:01.538404  5219 net.cpp:200] conv0 needs backward computation.
I0428 20:39:01.538408  5219 net.cpp:202] label_mnist_1_split does not need backward computation.
I0428 20:39:01.538411  5219 net.cpp:202] mnist does not need backward computation.
I0428 20:39:01.538414  5219 net.cpp:244] This network produces output accuracy
I0428 20:39:01.538417  5219 net.cpp:244] This network produces output loss
I0428 20:39:01.538427  5219 net.cpp:257] Network initialization done.
I0428 20:39:01.538467  5219 solver.cpp:56] Solver scaffolding done.
I0428 20:39:01.538792  5219 caffe.cpp:248] Starting Optimization
I0428 20:39:01.538799  5219 solver.cpp:273] Solving LeNet
I0428 20:39:01.538801  5219 solver.cpp:274] Learning Rate Policy: inv
I0428 20:39:01.539639  5219 solver.cpp:331] Iteration 0, Testing net (#0)
I0428 20:39:01.670634  5226 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:39:01.673877  5219 solver.cpp:398]     Test net output #0: accuracy = 0.091
I0428 20:39:01.673898  5219 solver.cpp:398]     Test net output #1: loss = 2.35027 (* 1 = 2.35027 loss)
I0428 20:39:01.679253  5219 solver.cpp:219] Iteration 0 (0 iter/s, 0.140409s/100 iters), loss = 2.31683
I0428 20:39:01.679288  5219 solver.cpp:238]     Train net output #0: loss = 2.31683 (* 1 = 2.31683 loss)
I0428 20:39:01.679301  5219 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0428 20:39:01.947444  5219 solver.cpp:219] Iteration 100 (372.93 iter/s, 0.268147s/100 iters), loss = 0.688369
I0428 20:39:01.947484  5219 solver.cpp:238]     Train net output #0: loss = 0.688369 (* 1 = 0.688369 loss)
I0428 20:39:01.947504  5219 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0428 20:39:02.217989  5219 solver.cpp:219] Iteration 200 (369.69 iter/s, 0.270497s/100 iters), loss = 0.170941
I0428 20:39:02.218024  5219 solver.cpp:238]     Train net output #0: loss = 0.170941 (* 1 = 0.170941 loss)
I0428 20:39:02.218032  5219 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0428 20:39:02.485615  5219 solver.cpp:219] Iteration 300 (373.728 iter/s, 0.267574s/100 iters), loss = 0.206977
I0428 20:39:02.485656  5219 solver.cpp:238]     Train net output #0: loss = 0.206977 (* 1 = 0.206977 loss)
I0428 20:39:02.485661  5219 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0428 20:39:02.755867  5219 solver.cpp:219] Iteration 400 (370.105 iter/s, 0.270194s/100 iters), loss = 0.0793139
I0428 20:39:02.755908  5219 solver.cpp:238]     Train net output #0: loss = 0.0793138 (* 1 = 0.0793138 loss)
I0428 20:39:02.755914  5219 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0428 20:39:03.021947  5219 solver.cpp:331] Iteration 500, Testing net (#0)
I0428 20:39:03.148092  5226 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:39:03.151484  5219 solver.cpp:398]     Test net output #0: accuracy = 0.9664
I0428 20:39:03.151505  5219 solver.cpp:398]     Test net output #1: loss = 0.112969 (* 1 = 0.112969 loss)
I0428 20:39:03.154233  5219 solver.cpp:219] Iteration 500 (251.055 iter/s, 0.398319s/100 iters), loss = 0.105083
I0428 20:39:03.154270  5219 solver.cpp:238]     Train net output #0: loss = 0.105083 (* 1 = 0.105083 loss)
I0428 20:39:03.154291  5219 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0428 20:39:03.432387  5219 solver.cpp:219] Iteration 600 (359.564 iter/s, 0.278114s/100 iters), loss = 0.0776352
I0428 20:39:03.432428  5219 solver.cpp:238]     Train net output #0: loss = 0.0776351 (* 1 = 0.0776351 loss)
I0428 20:39:03.432435  5219 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0428 20:39:03.707181  5219 solver.cpp:219] Iteration 700 (363.969 iter/s, 0.274748s/100 iters), loss = 0.14293
I0428 20:39:03.707226  5219 solver.cpp:238]     Train net output #0: loss = 0.14293 (* 1 = 0.14293 loss)
I0428 20:39:03.707232  5219 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0428 20:39:03.987889  5219 solver.cpp:219] Iteration 800 (356.303 iter/s, 0.28066s/100 iters), loss = 0.261481
I0428 20:39:03.987913  5219 solver.cpp:238]     Train net output #0: loss = 0.261481 (* 1 = 0.261481 loss)
I0428 20:39:03.987920  5219 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0428 20:39:04.276317  5219 solver.cpp:219] Iteration 900 (346.76 iter/s, 0.288384s/100 iters), loss = 0.0958856
I0428 20:39:04.276345  5219 solver.cpp:238]     Train net output #0: loss = 0.0958855 (* 1 = 0.0958855 loss)
I0428 20:39:04.276352  5219 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0428 20:39:04.372454  5225 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:39:04.559370  5219 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_1000.caffemodel
I0428 20:39:04.567466  5219 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_1000.solverstate
I0428 20:39:04.572033  5219 solver.cpp:311] Iteration 1000, loss = 0.0758141
I0428 20:39:04.572057  5219 solver.cpp:331] Iteration 1000, Testing net (#0)
I0428 20:39:04.704455  5226 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:39:04.709038  5219 solver.cpp:398]     Test net output #0: accuracy = 0.9815
I0428 20:39:04.709074  5219 solver.cpp:398]     Test net output #1: loss = 0.0575934 (* 1 = 0.0575934 loss)
I0428 20:39:04.709079  5219 solver.cpp:316] Optimization Done.
I0428 20:39:04.709084  5219 caffe.cpp:259] Optimization Done.
