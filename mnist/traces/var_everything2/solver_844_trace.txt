I0428 19:59:19.101418 29210 caffe.cpp:218] Using GPUs 0
I0428 19:59:19.136375 29210 caffe.cpp:223] GPU 0: TITAN X (Pascal)
I0428 19:59:19.587658 29210 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 1000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_everything2/lenet_train_test844.prototxt"
train_state {
  level: 0
  stage: ""
}
I0428 19:59:19.587787 29210 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_everything2/lenet_train_test844.prototxt
I0428 19:59:19.588151 29210 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0428 19:59:19.588201 29210 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0428 19:59:19.588287 29210 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 10
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 10
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 19:59:19.588354 29210 layer_factory.hpp:77] Creating layer mnist
I0428 19:59:19.588435 29210 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0428 19:59:19.588455 29210 net.cpp:86] Creating Layer mnist
I0428 19:59:19.588476 29210 net.cpp:382] mnist -> data
I0428 19:59:19.588510 29210 net.cpp:382] mnist -> label
I0428 19:59:19.589568 29210 data_layer.cpp:45] output data size: 64,1,28,28
I0428 19:59:19.591742 29210 net.cpp:124] Setting up mnist
I0428 19:59:19.591771 29210 net.cpp:131] Top shape: 64 1 28 28 (50176)
I0428 19:59:19.591787 29210 net.cpp:131] Top shape: 64 (64)
I0428 19:59:19.591790 29210 net.cpp:139] Memory required for data: 200960
I0428 19:59:19.591796 29210 layer_factory.hpp:77] Creating layer conv0
I0428 19:59:19.591809 29210 net.cpp:86] Creating Layer conv0
I0428 19:59:19.591827 29210 net.cpp:408] conv0 <- data
I0428 19:59:19.591840 29210 net.cpp:382] conv0 -> conv0
I0428 19:59:19.822677 29210 net.cpp:124] Setting up conv0
I0428 19:59:19.822718 29210 net.cpp:131] Top shape: 64 10 24 24 (368640)
I0428 19:59:19.822722 29210 net.cpp:139] Memory required for data: 1675520
I0428 19:59:19.822736 29210 layer_factory.hpp:77] Creating layer pool0
I0428 19:59:19.822749 29210 net.cpp:86] Creating Layer pool0
I0428 19:59:19.822752 29210 net.cpp:408] pool0 <- conv0
I0428 19:59:19.822773 29210 net.cpp:382] pool0 -> pool0
I0428 19:59:19.822818 29210 net.cpp:124] Setting up pool0
I0428 19:59:19.822824 29210 net.cpp:131] Top shape: 64 10 12 12 (92160)
I0428 19:59:19.822826 29210 net.cpp:139] Memory required for data: 2044160
I0428 19:59:19.822829 29210 layer_factory.hpp:77] Creating layer conv1
I0428 19:59:19.822839 29210 net.cpp:86] Creating Layer conv1
I0428 19:59:19.822842 29210 net.cpp:408] conv1 <- pool0
I0428 19:59:19.822846 29210 net.cpp:382] conv1 -> conv1
I0428 19:59:19.825672 29210 net.cpp:124] Setting up conv1
I0428 19:59:19.825686 29210 net.cpp:131] Top shape: 64 10 8 8 (40960)
I0428 19:59:19.825690 29210 net.cpp:139] Memory required for data: 2208000
I0428 19:59:19.825698 29210 layer_factory.hpp:77] Creating layer pool1
I0428 19:59:19.825705 29210 net.cpp:86] Creating Layer pool1
I0428 19:59:19.825723 29210 net.cpp:408] pool1 <- conv1
I0428 19:59:19.825728 29210 net.cpp:382] pool1 -> pool1
I0428 19:59:19.825780 29210 net.cpp:124] Setting up pool1
I0428 19:59:19.825793 29210 net.cpp:131] Top shape: 64 10 4 4 (10240)
I0428 19:59:19.825796 29210 net.cpp:139] Memory required for data: 2248960
I0428 19:59:19.825799 29210 layer_factory.hpp:77] Creating layer ip1
I0428 19:59:19.825809 29210 net.cpp:86] Creating Layer ip1
I0428 19:59:19.825812 29210 net.cpp:408] ip1 <- pool1
I0428 19:59:19.825817 29210 net.cpp:382] ip1 -> ip1
I0428 19:59:19.825939 29210 net.cpp:124] Setting up ip1
I0428 19:59:19.825947 29210 net.cpp:131] Top shape: 64 25 (1600)
I0428 19:59:19.825949 29210 net.cpp:139] Memory required for data: 2255360
I0428 19:59:19.825956 29210 layer_factory.hpp:77] Creating layer relu1
I0428 19:59:19.825961 29210 net.cpp:86] Creating Layer relu1
I0428 19:59:19.825964 29210 net.cpp:408] relu1 <- ip1
I0428 19:59:19.825969 29210 net.cpp:369] relu1 -> ip1 (in-place)
I0428 19:59:19.826150 29210 net.cpp:124] Setting up relu1
I0428 19:59:19.826159 29210 net.cpp:131] Top shape: 64 25 (1600)
I0428 19:59:19.826161 29210 net.cpp:139] Memory required for data: 2261760
I0428 19:59:19.826164 29210 layer_factory.hpp:77] Creating layer ip2
I0428 19:59:19.826174 29210 net.cpp:86] Creating Layer ip2
I0428 19:59:19.826177 29210 net.cpp:408] ip2 <- ip1
I0428 19:59:19.826181 29210 net.cpp:382] ip2 -> ip2
I0428 19:59:19.826277 29210 net.cpp:124] Setting up ip2
I0428 19:59:19.826283 29210 net.cpp:131] Top shape: 64 25 (1600)
I0428 19:59:19.826285 29210 net.cpp:139] Memory required for data: 2268160
I0428 19:59:19.826292 29210 layer_factory.hpp:77] Creating layer relu2
I0428 19:59:19.826297 29210 net.cpp:86] Creating Layer relu2
I0428 19:59:19.826299 29210 net.cpp:408] relu2 <- ip2
I0428 19:59:19.826304 29210 net.cpp:369] relu2 -> ip2 (in-place)
I0428 19:59:19.827081 29210 net.cpp:124] Setting up relu2
I0428 19:59:19.827095 29210 net.cpp:131] Top shape: 64 25 (1600)
I0428 19:59:19.827097 29210 net.cpp:139] Memory required for data: 2274560
I0428 19:59:19.827101 29210 layer_factory.hpp:77] Creating layer ip3
I0428 19:59:19.827108 29210 net.cpp:86] Creating Layer ip3
I0428 19:59:19.827111 29210 net.cpp:408] ip3 <- ip2
I0428 19:59:19.827116 29210 net.cpp:382] ip3 -> ip3
I0428 19:59:19.827217 29210 net.cpp:124] Setting up ip3
I0428 19:59:19.827224 29210 net.cpp:131] Top shape: 64 10 (640)
I0428 19:59:19.827227 29210 net.cpp:139] Memory required for data: 2277120
I0428 19:59:19.827234 29210 layer_factory.hpp:77] Creating layer relu3
I0428 19:59:19.827240 29210 net.cpp:86] Creating Layer relu3
I0428 19:59:19.827244 29210 net.cpp:408] relu3 <- ip3
I0428 19:59:19.827247 29210 net.cpp:369] relu3 -> ip3 (in-place)
I0428 19:59:19.827412 29210 net.cpp:124] Setting up relu3
I0428 19:59:19.827422 29210 net.cpp:131] Top shape: 64 10 (640)
I0428 19:59:19.827426 29210 net.cpp:139] Memory required for data: 2279680
I0428 19:59:19.827430 29210 layer_factory.hpp:77] Creating layer loss
I0428 19:59:19.827436 29210 net.cpp:86] Creating Layer loss
I0428 19:59:19.827440 29210 net.cpp:408] loss <- ip3
I0428 19:59:19.827443 29210 net.cpp:408] loss <- label
I0428 19:59:19.827450 29210 net.cpp:382] loss -> loss
I0428 19:59:19.827467 29210 layer_factory.hpp:77] Creating layer loss
I0428 19:59:19.827713 29210 net.cpp:124] Setting up loss
I0428 19:59:19.827721 29210 net.cpp:131] Top shape: (1)
I0428 19:59:19.827724 29210 net.cpp:134]     with loss weight 1
I0428 19:59:19.827739 29210 net.cpp:139] Memory required for data: 2279684
I0428 19:59:19.827741 29210 net.cpp:200] loss needs backward computation.
I0428 19:59:19.827745 29210 net.cpp:200] relu3 needs backward computation.
I0428 19:59:19.827749 29210 net.cpp:200] ip3 needs backward computation.
I0428 19:59:19.827750 29210 net.cpp:200] relu2 needs backward computation.
I0428 19:59:19.827754 29210 net.cpp:200] ip2 needs backward computation.
I0428 19:59:19.827756 29210 net.cpp:200] relu1 needs backward computation.
I0428 19:59:19.827759 29210 net.cpp:200] ip1 needs backward computation.
I0428 19:59:19.827764 29210 net.cpp:200] pool1 needs backward computation.
I0428 19:59:19.827765 29210 net.cpp:200] conv1 needs backward computation.
I0428 19:59:19.827769 29210 net.cpp:200] pool0 needs backward computation.
I0428 19:59:19.827771 29210 net.cpp:200] conv0 needs backward computation.
I0428 19:59:19.827775 29210 net.cpp:202] mnist does not need backward computation.
I0428 19:59:19.827792 29210 net.cpp:244] This network produces output loss
I0428 19:59:19.827801 29210 net.cpp:257] Network initialization done.
I0428 19:59:19.828146 29210 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_everything2/lenet_train_test844.prototxt
I0428 19:59:19.828178 29210 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0428 19:59:19.828270 29210 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 10
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 10
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 19:59:19.828366 29210 layer_factory.hpp:77] Creating layer mnist
I0428 19:59:19.828410 29210 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0428 19:59:19.828423 29210 net.cpp:86] Creating Layer mnist
I0428 19:59:19.828430 29210 net.cpp:382] mnist -> data
I0428 19:59:19.828438 29210 net.cpp:382] mnist -> label
I0428 19:59:19.828519 29210 data_layer.cpp:45] output data size: 100,1,28,28
I0428 19:59:19.830544 29210 net.cpp:124] Setting up mnist
I0428 19:59:19.830561 29210 net.cpp:131] Top shape: 100 1 28 28 (78400)
I0428 19:59:19.830567 29210 net.cpp:131] Top shape: 100 (100)
I0428 19:59:19.830569 29210 net.cpp:139] Memory required for data: 314000
I0428 19:59:19.830574 29210 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0428 19:59:19.830579 29210 net.cpp:86] Creating Layer label_mnist_1_split
I0428 19:59:19.830582 29210 net.cpp:408] label_mnist_1_split <- label
I0428 19:59:19.830588 29210 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_0
I0428 19:59:19.830595 29210 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_1
I0428 19:59:19.830680 29210 net.cpp:124] Setting up label_mnist_1_split
I0428 19:59:19.830687 29210 net.cpp:131] Top shape: 100 (100)
I0428 19:59:19.830691 29210 net.cpp:131] Top shape: 100 (100)
I0428 19:59:19.830693 29210 net.cpp:139] Memory required for data: 314800
I0428 19:59:19.830696 29210 layer_factory.hpp:77] Creating layer conv0
I0428 19:59:19.830706 29210 net.cpp:86] Creating Layer conv0
I0428 19:59:19.830709 29210 net.cpp:408] conv0 <- data
I0428 19:59:19.830714 29210 net.cpp:382] conv0 -> conv0
I0428 19:59:19.832250 29210 net.cpp:124] Setting up conv0
I0428 19:59:19.832265 29210 net.cpp:131] Top shape: 100 10 24 24 (576000)
I0428 19:59:19.832268 29210 net.cpp:139] Memory required for data: 2618800
I0428 19:59:19.832278 29210 layer_factory.hpp:77] Creating layer pool0
I0428 19:59:19.832285 29210 net.cpp:86] Creating Layer pool0
I0428 19:59:19.832288 29210 net.cpp:408] pool0 <- conv0
I0428 19:59:19.832293 29210 net.cpp:382] pool0 -> pool0
I0428 19:59:19.832345 29210 net.cpp:124] Setting up pool0
I0428 19:59:19.832357 29210 net.cpp:131] Top shape: 100 10 12 12 (144000)
I0428 19:59:19.832360 29210 net.cpp:139] Memory required for data: 3194800
I0428 19:59:19.832363 29210 layer_factory.hpp:77] Creating layer conv1
I0428 19:59:19.832373 29210 net.cpp:86] Creating Layer conv1
I0428 19:59:19.832376 29210 net.cpp:408] conv1 <- pool0
I0428 19:59:19.832381 29210 net.cpp:382] conv1 -> conv1
I0428 19:59:19.834458 29210 net.cpp:124] Setting up conv1
I0428 19:59:19.834471 29210 net.cpp:131] Top shape: 100 10 8 8 (64000)
I0428 19:59:19.834476 29210 net.cpp:139] Memory required for data: 3450800
I0428 19:59:19.834486 29210 layer_factory.hpp:77] Creating layer pool1
I0428 19:59:19.834506 29210 net.cpp:86] Creating Layer pool1
I0428 19:59:19.834509 29210 net.cpp:408] pool1 <- conv1
I0428 19:59:19.834530 29210 net.cpp:382] pool1 -> pool1
I0428 19:59:19.834622 29210 net.cpp:124] Setting up pool1
I0428 19:59:19.834631 29210 net.cpp:131] Top shape: 100 10 4 4 (16000)
I0428 19:59:19.834635 29210 net.cpp:139] Memory required for data: 3514800
I0428 19:59:19.834637 29210 layer_factory.hpp:77] Creating layer ip1
I0428 19:59:19.834642 29210 net.cpp:86] Creating Layer ip1
I0428 19:59:19.834646 29210 net.cpp:408] ip1 <- pool1
I0428 19:59:19.834652 29210 net.cpp:382] ip1 -> ip1
I0428 19:59:19.834771 29210 net.cpp:124] Setting up ip1
I0428 19:59:19.834779 29210 net.cpp:131] Top shape: 100 25 (2500)
I0428 19:59:19.834791 29210 net.cpp:139] Memory required for data: 3524800
I0428 19:59:19.834800 29210 layer_factory.hpp:77] Creating layer relu1
I0428 19:59:19.834806 29210 net.cpp:86] Creating Layer relu1
I0428 19:59:19.834810 29210 net.cpp:408] relu1 <- ip1
I0428 19:59:19.834813 29210 net.cpp:369] relu1 -> ip1 (in-place)
I0428 19:59:19.834972 29210 net.cpp:124] Setting up relu1
I0428 19:59:19.834987 29210 net.cpp:131] Top shape: 100 25 (2500)
I0428 19:59:19.834990 29210 net.cpp:139] Memory required for data: 3534800
I0428 19:59:19.834993 29210 layer_factory.hpp:77] Creating layer ip2
I0428 19:59:19.835001 29210 net.cpp:86] Creating Layer ip2
I0428 19:59:19.835005 29210 net.cpp:408] ip2 <- ip1
I0428 19:59:19.835008 29210 net.cpp:382] ip2 -> ip2
I0428 19:59:19.835149 29210 net.cpp:124] Setting up ip2
I0428 19:59:19.835156 29210 net.cpp:131] Top shape: 100 25 (2500)
I0428 19:59:19.835160 29210 net.cpp:139] Memory required for data: 3544800
I0428 19:59:19.835165 29210 layer_factory.hpp:77] Creating layer relu2
I0428 19:59:19.835170 29210 net.cpp:86] Creating Layer relu2
I0428 19:59:19.835173 29210 net.cpp:408] relu2 <- ip2
I0428 19:59:19.835176 29210 net.cpp:369] relu2 -> ip2 (in-place)
I0428 19:59:19.835363 29210 net.cpp:124] Setting up relu2
I0428 19:59:19.835372 29210 net.cpp:131] Top shape: 100 25 (2500)
I0428 19:59:19.835376 29210 net.cpp:139] Memory required for data: 3554800
I0428 19:59:19.835379 29210 layer_factory.hpp:77] Creating layer ip3
I0428 19:59:19.835388 29210 net.cpp:86] Creating Layer ip3
I0428 19:59:19.835391 29210 net.cpp:408] ip3 <- ip2
I0428 19:59:19.835397 29210 net.cpp:382] ip3 -> ip3
I0428 19:59:19.835506 29210 net.cpp:124] Setting up ip3
I0428 19:59:19.835513 29210 net.cpp:131] Top shape: 100 10 (1000)
I0428 19:59:19.835516 29210 net.cpp:139] Memory required for data: 3558800
I0428 19:59:19.835523 29210 layer_factory.hpp:77] Creating layer relu3
I0428 19:59:19.835544 29210 net.cpp:86] Creating Layer relu3
I0428 19:59:19.835547 29210 net.cpp:408] relu3 <- ip3
I0428 19:59:19.835552 29210 net.cpp:369] relu3 -> ip3 (in-place)
I0428 19:59:19.836426 29210 net.cpp:124] Setting up relu3
I0428 19:59:19.836438 29210 net.cpp:131] Top shape: 100 10 (1000)
I0428 19:59:19.836441 29210 net.cpp:139] Memory required for data: 3562800
I0428 19:59:19.836446 29210 layer_factory.hpp:77] Creating layer ip3_relu3_0_split
I0428 19:59:19.836450 29210 net.cpp:86] Creating Layer ip3_relu3_0_split
I0428 19:59:19.836453 29210 net.cpp:408] ip3_relu3_0_split <- ip3
I0428 19:59:19.836459 29210 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_0
I0428 19:59:19.836465 29210 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_1
I0428 19:59:19.836501 29210 net.cpp:124] Setting up ip3_relu3_0_split
I0428 19:59:19.836508 29210 net.cpp:131] Top shape: 100 10 (1000)
I0428 19:59:19.836513 29210 net.cpp:131] Top shape: 100 10 (1000)
I0428 19:59:19.836515 29210 net.cpp:139] Memory required for data: 3570800
I0428 19:59:19.836519 29210 layer_factory.hpp:77] Creating layer accuracy
I0428 19:59:19.836527 29210 net.cpp:86] Creating Layer accuracy
I0428 19:59:19.836530 29210 net.cpp:408] accuracy <- ip3_relu3_0_split_0
I0428 19:59:19.836534 29210 net.cpp:408] accuracy <- label_mnist_1_split_0
I0428 19:59:19.836552 29210 net.cpp:382] accuracy -> accuracy
I0428 19:59:19.836558 29210 net.cpp:124] Setting up accuracy
I0428 19:59:19.836562 29210 net.cpp:131] Top shape: (1)
I0428 19:59:19.836565 29210 net.cpp:139] Memory required for data: 3570804
I0428 19:59:19.836567 29210 layer_factory.hpp:77] Creating layer loss
I0428 19:59:19.836573 29210 net.cpp:86] Creating Layer loss
I0428 19:59:19.836575 29210 net.cpp:408] loss <- ip3_relu3_0_split_1
I0428 19:59:19.836580 29210 net.cpp:408] loss <- label_mnist_1_split_1
I0428 19:59:19.836583 29210 net.cpp:382] loss -> loss
I0428 19:59:19.836588 29210 layer_factory.hpp:77] Creating layer loss
I0428 19:59:19.836838 29210 net.cpp:124] Setting up loss
I0428 19:59:19.836848 29210 net.cpp:131] Top shape: (1)
I0428 19:59:19.836850 29210 net.cpp:134]     with loss weight 1
I0428 19:59:19.836868 29210 net.cpp:139] Memory required for data: 3570808
I0428 19:59:19.836872 29210 net.cpp:200] loss needs backward computation.
I0428 19:59:19.836875 29210 net.cpp:202] accuracy does not need backward computation.
I0428 19:59:19.836879 29210 net.cpp:200] ip3_relu3_0_split needs backward computation.
I0428 19:59:19.836881 29210 net.cpp:200] relu3 needs backward computation.
I0428 19:59:19.836884 29210 net.cpp:200] ip3 needs backward computation.
I0428 19:59:19.836887 29210 net.cpp:200] relu2 needs backward computation.
I0428 19:59:19.836889 29210 net.cpp:200] ip2 needs backward computation.
I0428 19:59:19.836892 29210 net.cpp:200] relu1 needs backward computation.
I0428 19:59:19.836894 29210 net.cpp:200] ip1 needs backward computation.
I0428 19:59:19.836897 29210 net.cpp:200] pool1 needs backward computation.
I0428 19:59:19.836900 29210 net.cpp:200] conv1 needs backward computation.
I0428 19:59:19.836904 29210 net.cpp:200] pool0 needs backward computation.
I0428 19:59:19.836906 29210 net.cpp:200] conv0 needs backward computation.
I0428 19:59:19.836910 29210 net.cpp:202] label_mnist_1_split does not need backward computation.
I0428 19:59:19.836912 29210 net.cpp:202] mnist does not need backward computation.
I0428 19:59:19.836915 29210 net.cpp:244] This network produces output accuracy
I0428 19:59:19.836918 29210 net.cpp:244] This network produces output loss
I0428 19:59:19.836930 29210 net.cpp:257] Network initialization done.
I0428 19:59:19.836971 29210 solver.cpp:56] Solver scaffolding done.
I0428 19:59:19.837321 29210 caffe.cpp:248] Starting Optimization
I0428 19:59:19.837327 29210 solver.cpp:273] Solving LeNet
I0428 19:59:19.837329 29210 solver.cpp:274] Learning Rate Policy: inv
I0428 19:59:19.838109 29210 solver.cpp:331] Iteration 0, Testing net (#0)
I0428 19:59:19.842733 29210 blocking_queue.cpp:49] Waiting for data
I0428 19:59:19.914814 29217 data_layer.cpp:73] Restarting data prefetching from start.
I0428 19:59:19.915366 29210 solver.cpp:398]     Test net output #0: accuracy = 0.1328
I0428 19:59:19.915401 29210 solver.cpp:398]     Test net output #1: loss = 2.32361 (* 1 = 2.32361 loss)
I0428 19:59:19.917978 29210 solver.cpp:219] Iteration 0 (-1.00753e-42 iter/s, 0.0806124s/100 iters), loss = 2.31534
I0428 19:59:19.918000 29210 solver.cpp:238]     Train net output #0: loss = 2.31534 (* 1 = 2.31534 loss)
I0428 19:59:19.918011 29210 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0428 19:59:19.997896 29210 solver.cpp:219] Iteration 100 (1251.83 iter/s, 0.0798832s/100 iters), loss = 0.900383
I0428 19:59:19.997936 29210 solver.cpp:238]     Train net output #0: loss = 0.900383 (* 1 = 0.900383 loss)
I0428 19:59:19.997942 29210 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0428 19:59:20.075350 29210 solver.cpp:219] Iteration 200 (1291.72 iter/s, 0.0774164s/100 iters), loss = 0.4367
I0428 19:59:20.075387 29210 solver.cpp:238]     Train net output #0: loss = 0.4367 (* 1 = 0.4367 loss)
I0428 19:59:20.075393 29210 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0428 19:59:20.153611 29210 solver.cpp:219] Iteration 300 (1278.29 iter/s, 0.0782296s/100 iters), loss = 0.643524
I0428 19:59:20.153650 29210 solver.cpp:238]     Train net output #0: loss = 0.643524 (* 1 = 0.643524 loss)
I0428 19:59:20.153654 29210 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0428 19:59:20.238183 29210 solver.cpp:219] Iteration 400 (1182.9 iter/s, 0.0845382s/100 iters), loss = 0.362829
I0428 19:59:20.238210 29210 solver.cpp:238]     Train net output #0: loss = 0.362829 (* 1 = 0.362829 loss)
I0428 19:59:20.238217 29210 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0428 19:59:20.315883 29210 solver.cpp:331] Iteration 500, Testing net (#0)
I0428 19:59:20.362282 29217 data_layer.cpp:73] Restarting data prefetching from start.
I0428 19:59:20.362838 29210 solver.cpp:398]     Test net output #0: accuracy = 0.8575
I0428 19:59:20.362856 29210 solver.cpp:398]     Test net output #1: loss = 0.387556 (* 1 = 0.387556 loss)
I0428 19:59:20.363642 29210 solver.cpp:219] Iteration 500 (797.323 iter/s, 0.12542s/100 iters), loss = 0.444451
I0428 19:59:20.363682 29210 solver.cpp:238]     Train net output #0: loss = 0.444451 (* 1 = 0.444451 loss)
I0428 19:59:20.363687 29210 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0428 19:59:20.441248 29210 solver.cpp:219] Iteration 600 (1289.29 iter/s, 0.0775618s/100 iters), loss = 0.300339
I0428 19:59:20.441287 29210 solver.cpp:238]     Train net output #0: loss = 0.300339 (* 1 = 0.300339 loss)
I0428 19:59:20.441293 29210 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0428 19:59:20.518306 29210 solver.cpp:219] Iteration 700 (1298.26 iter/s, 0.0770263s/100 iters), loss = 0.217756
I0428 19:59:20.518345 29210 solver.cpp:238]     Train net output #0: loss = 0.217756 (* 1 = 0.217756 loss)
I0428 19:59:20.518352 29210 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0428 19:59:20.594055 29210 solver.cpp:219] Iteration 800 (1320.71 iter/s, 0.0757166s/100 iters), loss = 0.523207
I0428 19:59:20.594094 29210 solver.cpp:238]     Train net output #0: loss = 0.523207 (* 1 = 0.523207 loss)
I0428 19:59:20.594099 29210 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0428 19:59:20.670233 29210 solver.cpp:219] Iteration 900 (1313.29 iter/s, 0.0761446s/100 iters), loss = 0.39289
I0428 19:59:20.670270 29210 solver.cpp:238]     Train net output #0: loss = 0.39289 (* 1 = 0.39289 loss)
I0428 19:59:20.670276 29210 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0428 19:59:20.695313 29216 data_layer.cpp:73] Restarting data prefetching from start.
I0428 19:59:20.746158 29210 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_1000.caffemodel
I0428 19:59:20.746991 29210 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_1000.solverstate
I0428 19:59:20.747560 29210 solver.cpp:311] Iteration 1000, loss = 0.317141
I0428 19:59:20.747575 29210 solver.cpp:331] Iteration 1000, Testing net (#0)
I0428 19:59:20.793699 29217 data_layer.cpp:73] Restarting data prefetching from start.
I0428 19:59:20.794293 29210 solver.cpp:398]     Test net output #0: accuracy = 0.8685
I0428 19:59:20.794327 29210 solver.cpp:398]     Test net output #1: loss = 0.348589 (* 1 = 0.348589 loss)
I0428 19:59:20.794332 29210 solver.cpp:316] Optimization Done.
I0428 19:59:20.794334 29210 caffe.cpp:259] Optimization Done.
