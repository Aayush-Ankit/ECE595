I0428 20:21:38.057926  1799 caffe.cpp:218] Using GPUs 0
I0428 20:21:38.089365  1799 caffe.cpp:223] GPU 0: TITAN X (Pascal)
I0428 20:21:38.542392  1799 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 1000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_everything2/lenet_train_test1388.prototxt"
train_state {
  level: 0
  stage: ""
}
I0428 20:21:38.542546  1799 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1388.prototxt
I0428 20:21:38.542891  1799 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0428 20:21:38.542908  1799 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0428 20:21:38.542994  1799 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:21:38.543076  1799 layer_factory.hpp:77] Creating layer mnist
I0428 20:21:38.543155  1799 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0428 20:21:38.543175  1799 net.cpp:86] Creating Layer mnist
I0428 20:21:38.543182  1799 net.cpp:382] mnist -> data
I0428 20:21:38.543201  1799 net.cpp:382] mnist -> label
I0428 20:21:38.544131  1799 data_layer.cpp:45] output data size: 64,1,28,28
I0428 20:21:38.546417  1799 net.cpp:124] Setting up mnist
I0428 20:21:38.546450  1799 net.cpp:131] Top shape: 64 1 28 28 (50176)
I0428 20:21:38.546456  1799 net.cpp:131] Top shape: 64 (64)
I0428 20:21:38.546459  1799 net.cpp:139] Memory required for data: 200960
I0428 20:21:38.546466  1799 layer_factory.hpp:77] Creating layer conv0
I0428 20:21:38.546479  1799 net.cpp:86] Creating Layer conv0
I0428 20:21:38.546505  1799 net.cpp:408] conv0 <- data
I0428 20:21:38.546517  1799 net.cpp:382] conv0 -> conv0
I0428 20:21:38.774123  1799 net.cpp:124] Setting up conv0
I0428 20:21:38.774166  1799 net.cpp:131] Top shape: 64 50 24 24 (1843200)
I0428 20:21:38.774170  1799 net.cpp:139] Memory required for data: 7573760
I0428 20:21:38.774199  1799 layer_factory.hpp:77] Creating layer pool0
I0428 20:21:38.774211  1799 net.cpp:86] Creating Layer pool0
I0428 20:21:38.774214  1799 net.cpp:408] pool0 <- conv0
I0428 20:21:38.774236  1799 net.cpp:382] pool0 -> pool0
I0428 20:21:38.774281  1799 net.cpp:124] Setting up pool0
I0428 20:21:38.774296  1799 net.cpp:131] Top shape: 64 50 12 12 (460800)
I0428 20:21:38.774299  1799 net.cpp:139] Memory required for data: 9416960
I0428 20:21:38.774302  1799 layer_factory.hpp:77] Creating layer conv1
I0428 20:21:38.774313  1799 net.cpp:86] Creating Layer conv1
I0428 20:21:38.774317  1799 net.cpp:408] conv1 <- pool0
I0428 20:21:38.774322  1799 net.cpp:382] conv1 -> conv1
I0428 20:21:38.776610  1799 net.cpp:124] Setting up conv1
I0428 20:21:38.776625  1799 net.cpp:131] Top shape: 64 50 8 8 (204800)
I0428 20:21:38.776630  1799 net.cpp:139] Memory required for data: 10236160
I0428 20:21:38.776638  1799 layer_factory.hpp:77] Creating layer pool1
I0428 20:21:38.776661  1799 net.cpp:86] Creating Layer pool1
I0428 20:21:38.776664  1799 net.cpp:408] pool1 <- conv1
I0428 20:21:38.776669  1799 net.cpp:382] pool1 -> pool1
I0428 20:21:38.776705  1799 net.cpp:124] Setting up pool1
I0428 20:21:38.776721  1799 net.cpp:131] Top shape: 64 50 4 4 (51200)
I0428 20:21:38.776723  1799 net.cpp:139] Memory required for data: 10440960
I0428 20:21:38.776726  1799 layer_factory.hpp:77] Creating layer ip1
I0428 20:21:38.776734  1799 net.cpp:86] Creating Layer ip1
I0428 20:21:38.776737  1799 net.cpp:408] ip1 <- pool1
I0428 20:21:38.776741  1799 net.cpp:382] ip1 -> ip1
I0428 20:21:38.776967  1799 net.cpp:124] Setting up ip1
I0428 20:21:38.776975  1799 net.cpp:131] Top shape: 64 25 (1600)
I0428 20:21:38.776978  1799 net.cpp:139] Memory required for data: 10447360
I0428 20:21:38.776985  1799 layer_factory.hpp:77] Creating layer relu1
I0428 20:21:38.776991  1799 net.cpp:86] Creating Layer relu1
I0428 20:21:38.776995  1799 net.cpp:408] relu1 <- ip1
I0428 20:21:38.776999  1799 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:21:38.777199  1799 net.cpp:124] Setting up relu1
I0428 20:21:38.777209  1799 net.cpp:131] Top shape: 64 25 (1600)
I0428 20:21:38.777211  1799 net.cpp:139] Memory required for data: 10453760
I0428 20:21:38.777215  1799 layer_factory.hpp:77] Creating layer ip2
I0428 20:21:38.777221  1799 net.cpp:86] Creating Layer ip2
I0428 20:21:38.777225  1799 net.cpp:408] ip2 <- ip1
I0428 20:21:38.777232  1799 net.cpp:382] ip2 -> ip2
I0428 20:21:38.777359  1799 net.cpp:124] Setting up ip2
I0428 20:21:38.777366  1799 net.cpp:131] Top shape: 64 10 (640)
I0428 20:21:38.777369  1799 net.cpp:139] Memory required for data: 10456320
I0428 20:21:38.777375  1799 layer_factory.hpp:77] Creating layer relu2
I0428 20:21:38.777381  1799 net.cpp:86] Creating Layer relu2
I0428 20:21:38.777385  1799 net.cpp:408] relu2 <- ip2
I0428 20:21:38.777391  1799 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:21:38.778136  1799 net.cpp:124] Setting up relu2
I0428 20:21:38.778147  1799 net.cpp:131] Top shape: 64 10 (640)
I0428 20:21:38.778165  1799 net.cpp:139] Memory required for data: 10458880
I0428 20:21:38.778168  1799 layer_factory.hpp:77] Creating layer ip3
I0428 20:21:38.778177  1799 net.cpp:86] Creating Layer ip3
I0428 20:21:38.778182  1799 net.cpp:408] ip3 <- ip2
I0428 20:21:38.778187  1799 net.cpp:382] ip3 -> ip3
I0428 20:21:38.778297  1799 net.cpp:124] Setting up ip3
I0428 20:21:38.778304  1799 net.cpp:131] Top shape: 64 10 (640)
I0428 20:21:38.778307  1799 net.cpp:139] Memory required for data: 10461440
I0428 20:21:38.778314  1799 layer_factory.hpp:77] Creating layer relu3
I0428 20:21:38.778319  1799 net.cpp:86] Creating Layer relu3
I0428 20:21:38.778322  1799 net.cpp:408] relu3 <- ip3
I0428 20:21:38.778327  1799 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:21:38.778499  1799 net.cpp:124] Setting up relu3
I0428 20:21:38.778508  1799 net.cpp:131] Top shape: 64 10 (640)
I0428 20:21:38.778512  1799 net.cpp:139] Memory required for data: 10464000
I0428 20:21:38.778515  1799 layer_factory.hpp:77] Creating layer loss
I0428 20:21:38.778522  1799 net.cpp:86] Creating Layer loss
I0428 20:21:38.778524  1799 net.cpp:408] loss <- ip3
I0428 20:21:38.778527  1799 net.cpp:408] loss <- label
I0428 20:21:38.778533  1799 net.cpp:382] loss -> loss
I0428 20:21:38.778550  1799 layer_factory.hpp:77] Creating layer loss
I0428 20:21:38.778822  1799 net.cpp:124] Setting up loss
I0428 20:21:38.778832  1799 net.cpp:131] Top shape: (1)
I0428 20:21:38.778836  1799 net.cpp:134]     with loss weight 1
I0428 20:21:38.778849  1799 net.cpp:139] Memory required for data: 10464004
I0428 20:21:38.778852  1799 net.cpp:200] loss needs backward computation.
I0428 20:21:38.778856  1799 net.cpp:200] relu3 needs backward computation.
I0428 20:21:38.778859  1799 net.cpp:200] ip3 needs backward computation.
I0428 20:21:38.778861  1799 net.cpp:200] relu2 needs backward computation.
I0428 20:21:38.778864  1799 net.cpp:200] ip2 needs backward computation.
I0428 20:21:38.778867  1799 net.cpp:200] relu1 needs backward computation.
I0428 20:21:38.778869  1799 net.cpp:200] ip1 needs backward computation.
I0428 20:21:38.778872  1799 net.cpp:200] pool1 needs backward computation.
I0428 20:21:38.778875  1799 net.cpp:200] conv1 needs backward computation.
I0428 20:21:38.778878  1799 net.cpp:200] pool0 needs backward computation.
I0428 20:21:38.778882  1799 net.cpp:200] conv0 needs backward computation.
I0428 20:21:38.778884  1799 net.cpp:202] mnist does not need backward computation.
I0428 20:21:38.778887  1799 net.cpp:244] This network produces output loss
I0428 20:21:38.778898  1799 net.cpp:257] Network initialization done.
I0428 20:21:38.779227  1799 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1388.prototxt
I0428 20:21:38.779266  1799 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0428 20:21:38.779371  1799 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:21:38.779451  1799 layer_factory.hpp:77] Creating layer mnist
I0428 20:21:38.779495  1799 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0428 20:21:38.779507  1799 net.cpp:86] Creating Layer mnist
I0428 20:21:38.779512  1799 net.cpp:382] mnist -> data
I0428 20:21:38.779520  1799 net.cpp:382] mnist -> label
I0428 20:21:38.779604  1799 data_layer.cpp:45] output data size: 100,1,28,28
I0428 20:21:38.781594  1799 net.cpp:124] Setting up mnist
I0428 20:21:38.781625  1799 net.cpp:131] Top shape: 100 1 28 28 (78400)
I0428 20:21:38.781646  1799 net.cpp:131] Top shape: 100 (100)
I0428 20:21:38.781648  1799 net.cpp:139] Memory required for data: 314000
I0428 20:21:38.781652  1799 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0428 20:21:38.781697  1799 net.cpp:86] Creating Layer label_mnist_1_split
I0428 20:21:38.781702  1799 net.cpp:408] label_mnist_1_split <- label
I0428 20:21:38.781708  1799 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_0
I0428 20:21:38.781714  1799 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_1
I0428 20:21:38.781764  1799 net.cpp:124] Setting up label_mnist_1_split
I0428 20:21:38.781772  1799 net.cpp:131] Top shape: 100 (100)
I0428 20:21:38.781776  1799 net.cpp:131] Top shape: 100 (100)
I0428 20:21:38.781780  1799 net.cpp:139] Memory required for data: 314800
I0428 20:21:38.781782  1799 layer_factory.hpp:77] Creating layer conv0
I0428 20:21:38.781792  1799 net.cpp:86] Creating Layer conv0
I0428 20:21:38.781795  1799 net.cpp:408] conv0 <- data
I0428 20:21:38.781802  1799 net.cpp:382] conv0 -> conv0
I0428 20:21:38.783540  1799 net.cpp:124] Setting up conv0
I0428 20:21:38.783553  1799 net.cpp:131] Top shape: 100 50 24 24 (2880000)
I0428 20:21:38.783572  1799 net.cpp:139] Memory required for data: 11834800
I0428 20:21:38.783581  1799 layer_factory.hpp:77] Creating layer pool0
I0428 20:21:38.783588  1799 net.cpp:86] Creating Layer pool0
I0428 20:21:38.783592  1799 net.cpp:408] pool0 <- conv0
I0428 20:21:38.783597  1799 net.cpp:382] pool0 -> pool0
I0428 20:21:38.783632  1799 net.cpp:124] Setting up pool0
I0428 20:21:38.783638  1799 net.cpp:131] Top shape: 100 50 12 12 (720000)
I0428 20:21:38.783640  1799 net.cpp:139] Memory required for data: 14714800
I0428 20:21:38.783643  1799 layer_factory.hpp:77] Creating layer conv1
I0428 20:21:38.783651  1799 net.cpp:86] Creating Layer conv1
I0428 20:21:38.783654  1799 net.cpp:408] conv1 <- pool0
I0428 20:21:38.783660  1799 net.cpp:382] conv1 -> conv1
I0428 20:21:38.785696  1799 net.cpp:124] Setting up conv1
I0428 20:21:38.785709  1799 net.cpp:131] Top shape: 100 50 8 8 (320000)
I0428 20:21:38.785713  1799 net.cpp:139] Memory required for data: 15994800
I0428 20:21:38.785722  1799 layer_factory.hpp:77] Creating layer pool1
I0428 20:21:38.785727  1799 net.cpp:86] Creating Layer pool1
I0428 20:21:38.785730  1799 net.cpp:408] pool1 <- conv1
I0428 20:21:38.785737  1799 net.cpp:382] pool1 -> pool1
I0428 20:21:38.785773  1799 net.cpp:124] Setting up pool1
I0428 20:21:38.785778  1799 net.cpp:131] Top shape: 100 50 4 4 (80000)
I0428 20:21:38.785781  1799 net.cpp:139] Memory required for data: 16314800
I0428 20:21:38.785791  1799 layer_factory.hpp:77] Creating layer ip1
I0428 20:21:38.785800  1799 net.cpp:86] Creating Layer ip1
I0428 20:21:38.785804  1799 net.cpp:408] ip1 <- pool1
I0428 20:21:38.785809  1799 net.cpp:382] ip1 -> ip1
I0428 20:21:38.786036  1799 net.cpp:124] Setting up ip1
I0428 20:21:38.786043  1799 net.cpp:131] Top shape: 100 25 (2500)
I0428 20:21:38.786056  1799 net.cpp:139] Memory required for data: 16324800
I0428 20:21:38.786064  1799 layer_factory.hpp:77] Creating layer relu1
I0428 20:21:38.786069  1799 net.cpp:86] Creating Layer relu1
I0428 20:21:38.786073  1799 net.cpp:408] relu1 <- ip1
I0428 20:21:38.786077  1799 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:21:38.786280  1799 net.cpp:124] Setting up relu1
I0428 20:21:38.786289  1799 net.cpp:131] Top shape: 100 25 (2500)
I0428 20:21:38.786293  1799 net.cpp:139] Memory required for data: 16334800
I0428 20:21:38.786295  1799 layer_factory.hpp:77] Creating layer ip2
I0428 20:21:38.786301  1799 net.cpp:86] Creating Layer ip2
I0428 20:21:38.786304  1799 net.cpp:408] ip2 <- ip1
I0428 20:21:38.786310  1799 net.cpp:382] ip2 -> ip2
I0428 20:21:38.786474  1799 net.cpp:124] Setting up ip2
I0428 20:21:38.786483  1799 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:21:38.786485  1799 net.cpp:139] Memory required for data: 16338800
I0428 20:21:38.786506  1799 layer_factory.hpp:77] Creating layer relu2
I0428 20:21:38.786511  1799 net.cpp:86] Creating Layer relu2
I0428 20:21:38.786514  1799 net.cpp:408] relu2 <- ip2
I0428 20:21:38.786520  1799 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:21:38.786702  1799 net.cpp:124] Setting up relu2
I0428 20:21:38.786711  1799 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:21:38.786715  1799 net.cpp:139] Memory required for data: 16342800
I0428 20:21:38.786720  1799 layer_factory.hpp:77] Creating layer ip3
I0428 20:21:38.786726  1799 net.cpp:86] Creating Layer ip3
I0428 20:21:38.786731  1799 net.cpp:408] ip3 <- ip2
I0428 20:21:38.786736  1799 net.cpp:382] ip3 -> ip3
I0428 20:21:38.786836  1799 net.cpp:124] Setting up ip3
I0428 20:21:38.786844  1799 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:21:38.786846  1799 net.cpp:139] Memory required for data: 16346800
I0428 20:21:38.786854  1799 layer_factory.hpp:77] Creating layer relu3
I0428 20:21:38.786859  1799 net.cpp:86] Creating Layer relu3
I0428 20:21:38.786862  1799 net.cpp:408] relu3 <- ip3
I0428 20:21:38.786867  1799 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:21:38.787677  1799 net.cpp:124] Setting up relu3
I0428 20:21:38.787703  1799 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:21:38.787706  1799 net.cpp:139] Memory required for data: 16350800
I0428 20:21:38.787709  1799 layer_factory.hpp:77] Creating layer ip3_relu3_0_split
I0428 20:21:38.787726  1799 net.cpp:86] Creating Layer ip3_relu3_0_split
I0428 20:21:38.787730  1799 net.cpp:408] ip3_relu3_0_split <- ip3
I0428 20:21:38.787734  1799 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_0
I0428 20:21:38.787741  1799 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_1
I0428 20:21:38.787816  1799 net.cpp:124] Setting up ip3_relu3_0_split
I0428 20:21:38.787824  1799 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:21:38.787828  1799 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:21:38.787832  1799 net.cpp:139] Memory required for data: 16358800
I0428 20:21:38.787834  1799 layer_factory.hpp:77] Creating layer accuracy
I0428 20:21:38.787839  1799 net.cpp:86] Creating Layer accuracy
I0428 20:21:38.787842  1799 net.cpp:408] accuracy <- ip3_relu3_0_split_0
I0428 20:21:38.787847  1799 net.cpp:408] accuracy <- label_mnist_1_split_0
I0428 20:21:38.787853  1799 net.cpp:382] accuracy -> accuracy
I0428 20:21:38.787861  1799 net.cpp:124] Setting up accuracy
I0428 20:21:38.787865  1799 net.cpp:131] Top shape: (1)
I0428 20:21:38.787868  1799 net.cpp:139] Memory required for data: 16358804
I0428 20:21:38.787871  1799 layer_factory.hpp:77] Creating layer loss
I0428 20:21:38.787876  1799 net.cpp:86] Creating Layer loss
I0428 20:21:38.787879  1799 net.cpp:408] loss <- ip3_relu3_0_split_1
I0428 20:21:38.787883  1799 net.cpp:408] loss <- label_mnist_1_split_1
I0428 20:21:38.787889  1799 net.cpp:382] loss -> loss
I0428 20:21:38.787894  1799 layer_factory.hpp:77] Creating layer loss
I0428 20:21:38.788204  1799 net.cpp:124] Setting up loss
I0428 20:21:38.788214  1799 net.cpp:131] Top shape: (1)
I0428 20:21:38.788218  1799 net.cpp:134]     with loss weight 1
I0428 20:21:38.788234  1799 net.cpp:139] Memory required for data: 16358808
I0428 20:21:38.788239  1799 net.cpp:200] loss needs backward computation.
I0428 20:21:38.788244  1799 net.cpp:202] accuracy does not need backward computation.
I0428 20:21:38.788246  1799 net.cpp:200] ip3_relu3_0_split needs backward computation.
I0428 20:21:38.788250  1799 net.cpp:200] relu3 needs backward computation.
I0428 20:21:38.788254  1799 net.cpp:200] ip3 needs backward computation.
I0428 20:21:38.788256  1799 net.cpp:200] relu2 needs backward computation.
I0428 20:21:38.788259  1799 net.cpp:200] ip2 needs backward computation.
I0428 20:21:38.788262  1799 net.cpp:200] relu1 needs backward computation.
I0428 20:21:38.788265  1799 net.cpp:200] ip1 needs backward computation.
I0428 20:21:38.788269  1799 net.cpp:200] pool1 needs backward computation.
I0428 20:21:38.788272  1799 net.cpp:200] conv1 needs backward computation.
I0428 20:21:38.788275  1799 net.cpp:200] pool0 needs backward computation.
I0428 20:21:38.788278  1799 net.cpp:200] conv0 needs backward computation.
I0428 20:21:38.788282  1799 net.cpp:202] label_mnist_1_split does not need backward computation.
I0428 20:21:38.788286  1799 net.cpp:202] mnist does not need backward computation.
I0428 20:21:38.788290  1799 net.cpp:244] This network produces output accuracy
I0428 20:21:38.788293  1799 net.cpp:244] This network produces output loss
I0428 20:21:38.788305  1799 net.cpp:257] Network initialization done.
I0428 20:21:38.788349  1799 solver.cpp:56] Solver scaffolding done.
I0428 20:21:38.788735  1799 caffe.cpp:248] Starting Optimization
I0428 20:21:38.788740  1799 solver.cpp:273] Solving LeNet
I0428 20:21:38.788743  1799 solver.cpp:274] Learning Rate Policy: inv
I0428 20:21:38.789108  1799 solver.cpp:331] Iteration 0, Testing net (#0)
I0428 20:21:38.796380  1799 blocking_queue.cpp:49] Waiting for data
I0428 20:21:38.877050  1806 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:21:38.877913  1799 solver.cpp:398]     Test net output #0: accuracy = 0.0938
I0428 20:21:38.877948  1799 solver.cpp:398]     Test net output #1: loss = 2.32143 (* 1 = 2.32143 loss)
I0428 20:21:38.882375  1799 solver.cpp:219] Iteration 0 (0 iter/s, 0.0935864s/100 iters), loss = 2.32052
I0428 20:21:38.882413  1799 solver.cpp:238]     Train net output #0: loss = 2.32052 (* 1 = 2.32052 loss)
I0428 20:21:38.882426  1799 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0428 20:21:39.042939  1799 solver.cpp:219] Iteration 100 (623.018 iter/s, 0.160509s/100 iters), loss = 0.81874
I0428 20:21:39.042980  1799 solver.cpp:238]     Train net output #0: loss = 0.81874 (* 1 = 0.81874 loss)
I0428 20:21:39.043002  1799 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0428 20:21:39.203117  1799 solver.cpp:219] Iteration 200 (624.457 iter/s, 0.160139s/100 iters), loss = 0.57779
I0428 20:21:39.203145  1799 solver.cpp:238]     Train net output #0: loss = 0.57779 (* 1 = 0.57779 loss)
I0428 20:21:39.203151  1799 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0428 20:21:39.355713  1799 solver.cpp:219] Iteration 300 (655.499 iter/s, 0.152556s/100 iters), loss = 0.573075
I0428 20:21:39.355737  1799 solver.cpp:238]     Train net output #0: loss = 0.573075 (* 1 = 0.573075 loss)
I0428 20:21:39.355743  1799 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0428 20:21:39.511262  1799 solver.cpp:219] Iteration 400 (643.037 iter/s, 0.155512s/100 iters), loss = 0.43104
I0428 20:21:39.511323  1799 solver.cpp:238]     Train net output #0: loss = 0.43104 (* 1 = 0.43104 loss)
I0428 20:21:39.511332  1799 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0428 20:21:39.662863  1799 solver.cpp:331] Iteration 500, Testing net (#0)
I0428 20:21:39.742015  1806 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:21:39.743064  1799 solver.cpp:398]     Test net output #0: accuracy = 0.7578
I0428 20:21:39.743084  1799 solver.cpp:398]     Test net output #1: loss = 0.611472 (* 1 = 0.611472 loss)
I0428 20:21:39.744681  1799 solver.cpp:219] Iteration 500 (428.554 iter/s, 0.233343s/100 iters), loss = 0.589171
I0428 20:21:39.744736  1799 solver.cpp:238]     Train net output #0: loss = 0.589171 (* 1 = 0.589171 loss)
I0428 20:21:39.744743  1799 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0428 20:21:39.905319  1799 solver.cpp:219] Iteration 600 (622.72 iter/s, 0.160586s/100 iters), loss = 0.795985
I0428 20:21:39.905360  1799 solver.cpp:238]     Train net output #0: loss = 0.795985 (* 1 = 0.795985 loss)
I0428 20:21:39.905366  1799 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0428 20:21:40.061251  1799 solver.cpp:219] Iteration 700 (641.529 iter/s, 0.155878s/100 iters), loss = 0.513812
I0428 20:21:40.061292  1799 solver.cpp:238]     Train net output #0: loss = 0.513812 (* 1 = 0.513812 loss)
I0428 20:21:40.061300  1799 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0428 20:21:40.216886  1799 solver.cpp:219] Iteration 800 (642.687 iter/s, 0.155597s/100 iters), loss = 0.618717
I0428 20:21:40.216925  1799 solver.cpp:238]     Train net output #0: loss = 0.618717 (* 1 = 0.618717 loss)
I0428 20:21:40.216931  1799 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0428 20:21:40.374752  1799 solver.cpp:219] Iteration 900 (633.658 iter/s, 0.157814s/100 iters), loss = 0.711651
I0428 20:21:40.374789  1799 solver.cpp:238]     Train net output #0: loss = 0.711651 (* 1 = 0.711651 loss)
I0428 20:21:40.374795  1799 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0428 20:21:40.427117  1805 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:21:40.527927  1799 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_1000.caffemodel
I0428 20:21:40.530230  1799 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_1000.solverstate
I0428 20:21:40.531591  1799 solver.cpp:311] Iteration 1000, loss = 0.62487
I0428 20:21:40.531607  1799 solver.cpp:331] Iteration 1000, Testing net (#0)
I0428 20:21:40.607762  1806 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:21:40.608885  1799 solver.cpp:398]     Test net output #0: accuracy = 0.7723
I0428 20:21:40.608919  1799 solver.cpp:398]     Test net output #1: loss = 0.55683 (* 1 = 0.55683 loss)
I0428 20:21:40.608924  1799 solver.cpp:316] Optimization Done.
I0428 20:21:40.608927  1799 caffe.cpp:259] Optimization Done.
