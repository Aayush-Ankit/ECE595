I0428 20:01:40.477303 29780 caffe.cpp:218] Using GPUs 0
I0428 20:01:40.506260 29780 caffe.cpp:223] GPU 0: TITAN X (Pascal)
I0428 20:01:40.957244 29780 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 1000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_everything2/lenet_train_test909.prototxt"
train_state {
  level: 0
  stage: ""
}
I0428 20:01:40.957393 29780 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_everything2/lenet_train_test909.prototxt
I0428 20:01:40.957753 29780 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0428 20:01:40.957785 29780 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0428 20:01:40.957870 29780 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 10
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:01:40.957937 29780 layer_factory.hpp:77] Creating layer mnist
I0428 20:01:40.958020 29780 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0428 20:01:40.958040 29780 net.cpp:86] Creating Layer mnist
I0428 20:01:40.958047 29780 net.cpp:382] mnist -> data
I0428 20:01:40.958065 29780 net.cpp:382] mnist -> label
I0428 20:01:40.959041 29780 data_layer.cpp:45] output data size: 64,1,28,28
I0428 20:01:40.961333 29780 net.cpp:124] Setting up mnist
I0428 20:01:40.961364 29780 net.cpp:131] Top shape: 64 1 28 28 (50176)
I0428 20:01:40.961371 29780 net.cpp:131] Top shape: 64 (64)
I0428 20:01:40.961374 29780 net.cpp:139] Memory required for data: 200960
I0428 20:01:40.961380 29780 layer_factory.hpp:77] Creating layer conv0
I0428 20:01:40.961393 29780 net.cpp:86] Creating Layer conv0
I0428 20:01:40.961410 29780 net.cpp:408] conv0 <- data
I0428 20:01:40.961422 29780 net.cpp:382] conv0 -> conv0
I0428 20:01:41.190946 29780 net.cpp:124] Setting up conv0
I0428 20:01:41.190970 29780 net.cpp:131] Top shape: 64 10 24 24 (368640)
I0428 20:01:41.190974 29780 net.cpp:139] Memory required for data: 1675520
I0428 20:01:41.190989 29780 layer_factory.hpp:77] Creating layer pool0
I0428 20:01:41.191000 29780 net.cpp:86] Creating Layer pool0
I0428 20:01:41.191004 29780 net.cpp:408] pool0 <- conv0
I0428 20:01:41.191009 29780 net.cpp:382] pool0 -> pool0
I0428 20:01:41.191067 29780 net.cpp:124] Setting up pool0
I0428 20:01:41.191073 29780 net.cpp:131] Top shape: 64 10 12 12 (92160)
I0428 20:01:41.191076 29780 net.cpp:139] Memory required for data: 2044160
I0428 20:01:41.191079 29780 layer_factory.hpp:77] Creating layer conv1
I0428 20:01:41.191089 29780 net.cpp:86] Creating Layer conv1
I0428 20:01:41.191092 29780 net.cpp:408] conv1 <- pool0
I0428 20:01:41.191097 29780 net.cpp:382] conv1 -> conv1
I0428 20:01:41.193918 29780 net.cpp:124] Setting up conv1
I0428 20:01:41.193949 29780 net.cpp:131] Top shape: 64 50 8 8 (204800)
I0428 20:01:41.193953 29780 net.cpp:139] Memory required for data: 2863360
I0428 20:01:41.193961 29780 layer_factory.hpp:77] Creating layer pool1
I0428 20:01:41.193969 29780 net.cpp:86] Creating Layer pool1
I0428 20:01:41.193972 29780 net.cpp:408] pool1 <- conv1
I0428 20:01:41.193977 29780 net.cpp:382] pool1 -> pool1
I0428 20:01:41.194031 29780 net.cpp:124] Setting up pool1
I0428 20:01:41.194036 29780 net.cpp:131] Top shape: 64 50 4 4 (51200)
I0428 20:01:41.194052 29780 net.cpp:139] Memory required for data: 3068160
I0428 20:01:41.194056 29780 layer_factory.hpp:77] Creating layer ip1
I0428 20:01:41.194062 29780 net.cpp:86] Creating Layer ip1
I0428 20:01:41.194066 29780 net.cpp:408] ip1 <- pool1
I0428 20:01:41.194070 29780 net.cpp:382] ip1 -> ip1
I0428 20:01:41.194205 29780 net.cpp:124] Setting up ip1
I0428 20:01:41.194212 29780 net.cpp:131] Top shape: 64 10 (640)
I0428 20:01:41.194216 29780 net.cpp:139] Memory required for data: 3070720
I0428 20:01:41.194222 29780 layer_factory.hpp:77] Creating layer relu1
I0428 20:01:41.194228 29780 net.cpp:86] Creating Layer relu1
I0428 20:01:41.194231 29780 net.cpp:408] relu1 <- ip1
I0428 20:01:41.194236 29780 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:01:41.194387 29780 net.cpp:124] Setting up relu1
I0428 20:01:41.194396 29780 net.cpp:131] Top shape: 64 10 (640)
I0428 20:01:41.194398 29780 net.cpp:139] Memory required for data: 3073280
I0428 20:01:41.194401 29780 layer_factory.hpp:77] Creating layer ip2
I0428 20:01:41.194407 29780 net.cpp:86] Creating Layer ip2
I0428 20:01:41.194411 29780 net.cpp:408] ip2 <- ip1
I0428 20:01:41.194414 29780 net.cpp:382] ip2 -> ip2
I0428 20:01:41.194502 29780 net.cpp:124] Setting up ip2
I0428 20:01:41.194509 29780 net.cpp:131] Top shape: 64 10 (640)
I0428 20:01:41.194512 29780 net.cpp:139] Memory required for data: 3075840
I0428 20:01:41.194517 29780 layer_factory.hpp:77] Creating layer relu2
I0428 20:01:41.194522 29780 net.cpp:86] Creating Layer relu2
I0428 20:01:41.194525 29780 net.cpp:408] relu2 <- ip2
I0428 20:01:41.194530 29780 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:01:41.195286 29780 net.cpp:124] Setting up relu2
I0428 20:01:41.195297 29780 net.cpp:131] Top shape: 64 10 (640)
I0428 20:01:41.195317 29780 net.cpp:139] Memory required for data: 3078400
I0428 20:01:41.195322 29780 layer_factory.hpp:77] Creating layer ip3
I0428 20:01:41.195328 29780 net.cpp:86] Creating Layer ip3
I0428 20:01:41.195332 29780 net.cpp:408] ip3 <- ip2
I0428 20:01:41.195338 29780 net.cpp:382] ip3 -> ip3
I0428 20:01:41.195459 29780 net.cpp:124] Setting up ip3
I0428 20:01:41.195467 29780 net.cpp:131] Top shape: 64 10 (640)
I0428 20:01:41.195469 29780 net.cpp:139] Memory required for data: 3080960
I0428 20:01:41.195477 29780 layer_factory.hpp:77] Creating layer relu3
I0428 20:01:41.195482 29780 net.cpp:86] Creating Layer relu3
I0428 20:01:41.195485 29780 net.cpp:408] relu3 <- ip3
I0428 20:01:41.195489 29780 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:01:41.195644 29780 net.cpp:124] Setting up relu3
I0428 20:01:41.195653 29780 net.cpp:131] Top shape: 64 10 (640)
I0428 20:01:41.195657 29780 net.cpp:139] Memory required for data: 3083520
I0428 20:01:41.195659 29780 layer_factory.hpp:77] Creating layer loss
I0428 20:01:41.195665 29780 net.cpp:86] Creating Layer loss
I0428 20:01:41.195668 29780 net.cpp:408] loss <- ip3
I0428 20:01:41.195672 29780 net.cpp:408] loss <- label
I0428 20:01:41.195677 29780 net.cpp:382] loss -> loss
I0428 20:01:41.195693 29780 layer_factory.hpp:77] Creating layer loss
I0428 20:01:41.195938 29780 net.cpp:124] Setting up loss
I0428 20:01:41.195947 29780 net.cpp:131] Top shape: (1)
I0428 20:01:41.195951 29780 net.cpp:134]     with loss weight 1
I0428 20:01:41.195964 29780 net.cpp:139] Memory required for data: 3083524
I0428 20:01:41.195968 29780 net.cpp:200] loss needs backward computation.
I0428 20:01:41.195971 29780 net.cpp:200] relu3 needs backward computation.
I0428 20:01:41.195974 29780 net.cpp:200] ip3 needs backward computation.
I0428 20:01:41.195977 29780 net.cpp:200] relu2 needs backward computation.
I0428 20:01:41.195979 29780 net.cpp:200] ip2 needs backward computation.
I0428 20:01:41.195982 29780 net.cpp:200] relu1 needs backward computation.
I0428 20:01:41.195986 29780 net.cpp:200] ip1 needs backward computation.
I0428 20:01:41.195987 29780 net.cpp:200] pool1 needs backward computation.
I0428 20:01:41.195991 29780 net.cpp:200] conv1 needs backward computation.
I0428 20:01:41.195993 29780 net.cpp:200] pool0 needs backward computation.
I0428 20:01:41.195996 29780 net.cpp:200] conv0 needs backward computation.
I0428 20:01:41.195999 29780 net.cpp:202] mnist does not need backward computation.
I0428 20:01:41.196002 29780 net.cpp:244] This network produces output loss
I0428 20:01:41.196010 29780 net.cpp:257] Network initialization done.
I0428 20:01:41.196317 29780 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_everything2/lenet_train_test909.prototxt
I0428 20:01:41.196343 29780 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0428 20:01:41.196444 29780 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 10
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:01:41.196522 29780 layer_factory.hpp:77] Creating layer mnist
I0428 20:01:41.196566 29780 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0428 20:01:41.196578 29780 net.cpp:86] Creating Layer mnist
I0428 20:01:41.196583 29780 net.cpp:382] mnist -> data
I0428 20:01:41.196591 29780 net.cpp:382] mnist -> label
I0428 20:01:41.196674 29780 data_layer.cpp:45] output data size: 100,1,28,28
I0428 20:01:41.198736 29780 net.cpp:124] Setting up mnist
I0428 20:01:41.198781 29780 net.cpp:131] Top shape: 100 1 28 28 (78400)
I0428 20:01:41.198786 29780 net.cpp:131] Top shape: 100 (100)
I0428 20:01:41.198789 29780 net.cpp:139] Memory required for data: 314000
I0428 20:01:41.198793 29780 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0428 20:01:41.198810 29780 net.cpp:86] Creating Layer label_mnist_1_split
I0428 20:01:41.198814 29780 net.cpp:408] label_mnist_1_split <- label
I0428 20:01:41.198819 29780 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_0
I0428 20:01:41.198827 29780 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_1
I0428 20:01:41.198868 29780 net.cpp:124] Setting up label_mnist_1_split
I0428 20:01:41.198874 29780 net.cpp:131] Top shape: 100 (100)
I0428 20:01:41.198878 29780 net.cpp:131] Top shape: 100 (100)
I0428 20:01:41.198880 29780 net.cpp:139] Memory required for data: 314800
I0428 20:01:41.198884 29780 layer_factory.hpp:77] Creating layer conv0
I0428 20:01:41.198891 29780 net.cpp:86] Creating Layer conv0
I0428 20:01:41.198895 29780 net.cpp:408] conv0 <- data
I0428 20:01:41.198900 29780 net.cpp:382] conv0 -> conv0
I0428 20:01:41.200685 29780 net.cpp:124] Setting up conv0
I0428 20:01:41.200714 29780 net.cpp:131] Top shape: 100 10 24 24 (576000)
I0428 20:01:41.200718 29780 net.cpp:139] Memory required for data: 2618800
I0428 20:01:41.200742 29780 layer_factory.hpp:77] Creating layer pool0
I0428 20:01:41.200748 29780 net.cpp:86] Creating Layer pool0
I0428 20:01:41.200752 29780 net.cpp:408] pool0 <- conv0
I0428 20:01:41.200757 29780 net.cpp:382] pool0 -> pool0
I0428 20:01:41.200806 29780 net.cpp:124] Setting up pool0
I0428 20:01:41.200836 29780 net.cpp:131] Top shape: 100 10 12 12 (144000)
I0428 20:01:41.200841 29780 net.cpp:139] Memory required for data: 3194800
I0428 20:01:41.200861 29780 layer_factory.hpp:77] Creating layer conv1
I0428 20:01:41.200872 29780 net.cpp:86] Creating Layer conv1
I0428 20:01:41.200875 29780 net.cpp:408] conv1 <- pool0
I0428 20:01:41.200882 29780 net.cpp:382] conv1 -> conv1
I0428 20:01:41.202610 29780 net.cpp:124] Setting up conv1
I0428 20:01:41.202639 29780 net.cpp:131] Top shape: 100 50 8 8 (320000)
I0428 20:01:41.202643 29780 net.cpp:139] Memory required for data: 4474800
I0428 20:01:41.202664 29780 layer_factory.hpp:77] Creating layer pool1
I0428 20:01:41.202672 29780 net.cpp:86] Creating Layer pool1
I0428 20:01:41.202675 29780 net.cpp:408] pool1 <- conv1
I0428 20:01:41.202680 29780 net.cpp:382] pool1 -> pool1
I0428 20:01:41.202733 29780 net.cpp:124] Setting up pool1
I0428 20:01:41.202738 29780 net.cpp:131] Top shape: 100 50 4 4 (80000)
I0428 20:01:41.202741 29780 net.cpp:139] Memory required for data: 4794800
I0428 20:01:41.202744 29780 layer_factory.hpp:77] Creating layer ip1
I0428 20:01:41.202749 29780 net.cpp:86] Creating Layer ip1
I0428 20:01:41.202754 29780 net.cpp:408] ip1 <- pool1
I0428 20:01:41.202759 29780 net.cpp:382] ip1 -> ip1
I0428 20:01:41.202913 29780 net.cpp:124] Setting up ip1
I0428 20:01:41.202922 29780 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:01:41.202936 29780 net.cpp:139] Memory required for data: 4798800
I0428 20:01:41.202945 29780 layer_factory.hpp:77] Creating layer relu1
I0428 20:01:41.202951 29780 net.cpp:86] Creating Layer relu1
I0428 20:01:41.202955 29780 net.cpp:408] relu1 <- ip1
I0428 20:01:41.202960 29780 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:01:41.203176 29780 net.cpp:124] Setting up relu1
I0428 20:01:41.203184 29780 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:01:41.203188 29780 net.cpp:139] Memory required for data: 4802800
I0428 20:01:41.203191 29780 layer_factory.hpp:77] Creating layer ip2
I0428 20:01:41.203199 29780 net.cpp:86] Creating Layer ip2
I0428 20:01:41.203202 29780 net.cpp:408] ip2 <- ip1
I0428 20:01:41.203208 29780 net.cpp:382] ip2 -> ip2
I0428 20:01:41.203346 29780 net.cpp:124] Setting up ip2
I0428 20:01:41.203353 29780 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:01:41.203356 29780 net.cpp:139] Memory required for data: 4806800
I0428 20:01:41.203377 29780 layer_factory.hpp:77] Creating layer relu2
I0428 20:01:41.203382 29780 net.cpp:86] Creating Layer relu2
I0428 20:01:41.203385 29780 net.cpp:408] relu2 <- ip2
I0428 20:01:41.203389 29780 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:01:41.203555 29780 net.cpp:124] Setting up relu2
I0428 20:01:41.203563 29780 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:01:41.203567 29780 net.cpp:139] Memory required for data: 4810800
I0428 20:01:41.203570 29780 layer_factory.hpp:77] Creating layer ip3
I0428 20:01:41.203577 29780 net.cpp:86] Creating Layer ip3
I0428 20:01:41.203580 29780 net.cpp:408] ip3 <- ip2
I0428 20:01:41.203585 29780 net.cpp:382] ip3 -> ip3
I0428 20:01:41.203716 29780 net.cpp:124] Setting up ip3
I0428 20:01:41.203723 29780 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:01:41.203727 29780 net.cpp:139] Memory required for data: 4814800
I0428 20:01:41.203734 29780 layer_factory.hpp:77] Creating layer relu3
I0428 20:01:41.203739 29780 net.cpp:86] Creating Layer relu3
I0428 20:01:41.203742 29780 net.cpp:408] relu3 <- ip3
I0428 20:01:41.203747 29780 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:01:41.204586 29780 net.cpp:124] Setting up relu3
I0428 20:01:41.204613 29780 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:01:41.204617 29780 net.cpp:139] Memory required for data: 4818800
I0428 20:01:41.204622 29780 layer_factory.hpp:77] Creating layer ip3_relu3_0_split
I0428 20:01:41.204627 29780 net.cpp:86] Creating Layer ip3_relu3_0_split
I0428 20:01:41.204632 29780 net.cpp:408] ip3_relu3_0_split <- ip3
I0428 20:01:41.204638 29780 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_0
I0428 20:01:41.204643 29780 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_1
I0428 20:01:41.204697 29780 net.cpp:124] Setting up ip3_relu3_0_split
I0428 20:01:41.204704 29780 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:01:41.204707 29780 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:01:41.204710 29780 net.cpp:139] Memory required for data: 4826800
I0428 20:01:41.204712 29780 layer_factory.hpp:77] Creating layer accuracy
I0428 20:01:41.204718 29780 net.cpp:86] Creating Layer accuracy
I0428 20:01:41.204721 29780 net.cpp:408] accuracy <- ip3_relu3_0_split_0
I0428 20:01:41.204726 29780 net.cpp:408] accuracy <- label_mnist_1_split_0
I0428 20:01:41.204730 29780 net.cpp:382] accuracy -> accuracy
I0428 20:01:41.204738 29780 net.cpp:124] Setting up accuracy
I0428 20:01:41.204742 29780 net.cpp:131] Top shape: (1)
I0428 20:01:41.204746 29780 net.cpp:139] Memory required for data: 4826804
I0428 20:01:41.204748 29780 layer_factory.hpp:77] Creating layer loss
I0428 20:01:41.204752 29780 net.cpp:86] Creating Layer loss
I0428 20:01:41.204761 29780 net.cpp:408] loss <- ip3_relu3_0_split_1
I0428 20:01:41.204766 29780 net.cpp:408] loss <- label_mnist_1_split_1
I0428 20:01:41.204769 29780 net.cpp:382] loss -> loss
I0428 20:01:41.204776 29780 layer_factory.hpp:77] Creating layer loss
I0428 20:01:41.205023 29780 net.cpp:124] Setting up loss
I0428 20:01:41.205034 29780 net.cpp:131] Top shape: (1)
I0428 20:01:41.205036 29780 net.cpp:134]     with loss weight 1
I0428 20:01:41.205073 29780 net.cpp:139] Memory required for data: 4826808
I0428 20:01:41.205092 29780 net.cpp:200] loss needs backward computation.
I0428 20:01:41.205097 29780 net.cpp:202] accuracy does not need backward computation.
I0428 20:01:41.205101 29780 net.cpp:200] ip3_relu3_0_split needs backward computation.
I0428 20:01:41.205104 29780 net.cpp:200] relu3 needs backward computation.
I0428 20:01:41.205107 29780 net.cpp:200] ip3 needs backward computation.
I0428 20:01:41.205111 29780 net.cpp:200] relu2 needs backward computation.
I0428 20:01:41.205113 29780 net.cpp:200] ip2 needs backward computation.
I0428 20:01:41.205116 29780 net.cpp:200] relu1 needs backward computation.
I0428 20:01:41.205119 29780 net.cpp:200] ip1 needs backward computation.
I0428 20:01:41.205122 29780 net.cpp:200] pool1 needs backward computation.
I0428 20:01:41.205126 29780 net.cpp:200] conv1 needs backward computation.
I0428 20:01:41.205150 29780 net.cpp:200] pool0 needs backward computation.
I0428 20:01:41.205153 29780 net.cpp:200] conv0 needs backward computation.
I0428 20:01:41.205157 29780 net.cpp:202] label_mnist_1_split does not need backward computation.
I0428 20:01:41.205162 29780 net.cpp:202] mnist does not need backward computation.
I0428 20:01:41.205164 29780 net.cpp:244] This network produces output accuracy
I0428 20:01:41.205168 29780 net.cpp:244] This network produces output loss
I0428 20:01:41.205178 29780 net.cpp:257] Network initialization done.
I0428 20:01:41.205236 29780 solver.cpp:56] Solver scaffolding done.
I0428 20:01:41.205659 29780 caffe.cpp:248] Starting Optimization
I0428 20:01:41.205665 29780 solver.cpp:273] Solving LeNet
I0428 20:01:41.205668 29780 solver.cpp:274] Learning Rate Policy: inv
I0428 20:01:41.205955 29780 solver.cpp:331] Iteration 0, Testing net (#0)
I0428 20:01:41.211305 29780 blocking_queue.cpp:49] Waiting for data
I0428 20:01:41.273684 29787 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:01:41.274291 29780 solver.cpp:398]     Test net output #0: accuracy = 0.1043
I0428 20:01:41.274328 29780 solver.cpp:398]     Test net output #1: loss = 2.31554 (* 1 = 2.31554 loss)
I0428 20:01:41.277415 29780 solver.cpp:219] Iteration 0 (0 iter/s, 0.0717025s/100 iters), loss = 2.31952
I0428 20:01:41.277456 29780 solver.cpp:238]     Train net output #0: loss = 2.31952 (* 1 = 2.31952 loss)
I0428 20:01:41.277467 29780 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0428 20:01:41.384114 29780 solver.cpp:219] Iteration 100 (937.659 iter/s, 0.106649s/100 iters), loss = 1.47142
I0428 20:01:41.384138 29780 solver.cpp:238]     Train net output #0: loss = 1.47142 (* 1 = 1.47142 loss)
I0428 20:01:41.384145 29780 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0428 20:01:41.488930 29780 solver.cpp:219] Iteration 200 (954.372 iter/s, 0.104781s/100 iters), loss = 0.691557
I0428 20:01:41.488970 29780 solver.cpp:238]     Train net output #0: loss = 0.691557 (* 1 = 0.691557 loss)
I0428 20:01:41.488977 29780 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0428 20:01:41.596429 29780 solver.cpp:219] Iteration 300 (930.671 iter/s, 0.107449s/100 iters), loss = 0.416614
I0428 20:01:41.596472 29780 solver.cpp:238]     Train net output #0: loss = 0.416614 (* 1 = 0.416614 loss)
I0428 20:01:41.596478 29780 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0428 20:01:41.703116 29780 solver.cpp:219] Iteration 400 (937.776 iter/s, 0.106635s/100 iters), loss = 0.161362
I0428 20:01:41.703157 29780 solver.cpp:238]     Train net output #0: loss = 0.161362 (* 1 = 0.161362 loss)
I0428 20:01:41.703163 29780 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0428 20:01:41.806828 29780 solver.cpp:331] Iteration 500, Testing net (#0)
I0428 20:01:41.860586 29787 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:01:41.861115 29780 solver.cpp:398]     Test net output #0: accuracy = 0.9545
I0428 20:01:41.861145 29780 solver.cpp:398]     Test net output #1: loss = 0.158627 (* 1 = 0.158627 loss)
I0428 20:01:41.862203 29780 solver.cpp:219] Iteration 500 (628.803 iter/s, 0.159032s/100 iters), loss = 0.15604
I0428 20:01:41.862252 29780 solver.cpp:238]     Train net output #0: loss = 0.15604 (* 1 = 0.15604 loss)
I0428 20:01:41.862274 29780 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0428 20:01:41.977216 29780 solver.cpp:219] Iteration 600 (869.898 iter/s, 0.114956s/100 iters), loss = 0.224932
I0428 20:01:41.977255 29780 solver.cpp:238]     Train net output #0: loss = 0.224932 (* 1 = 0.224932 loss)
I0428 20:01:41.977262 29780 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0428 20:01:42.083356 29780 solver.cpp:219] Iteration 700 (942.446 iter/s, 0.106107s/100 iters), loss = 0.1901
I0428 20:01:42.083398 29780 solver.cpp:238]     Train net output #0: loss = 0.1901 (* 1 = 0.1901 loss)
I0428 20:01:42.083405 29780 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0428 20:01:42.189913 29780 solver.cpp:219] Iteration 800 (938.794 iter/s, 0.10652s/100 iters), loss = 0.430765
I0428 20:01:42.189954 29780 solver.cpp:238]     Train net output #0: loss = 0.430765 (* 1 = 0.430765 loss)
I0428 20:01:42.189960 29780 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0428 20:01:42.295493 29780 solver.cpp:219] Iteration 900 (947.458 iter/s, 0.105546s/100 iters), loss = 0.21287
I0428 20:01:42.295534 29780 solver.cpp:238]     Train net output #0: loss = 0.21287 (* 1 = 0.21287 loss)
I0428 20:01:42.295542 29780 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0428 20:01:42.330302 29786 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:01:42.399336 29780 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_1000.caffemodel
I0428 20:01:42.400540 29780 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_1000.solverstate
I0428 20:01:42.401265 29780 solver.cpp:311] Iteration 1000, loss = 0.100573
I0428 20:01:42.401281 29780 solver.cpp:331] Iteration 1000, Testing net (#0)
I0428 20:01:42.476054 29787 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:01:42.476594 29780 solver.cpp:398]     Test net output #0: accuracy = 0.9683
I0428 20:01:42.476629 29780 solver.cpp:398]     Test net output #1: loss = 0.107557 (* 1 = 0.107557 loss)
I0428 20:01:42.476634 29780 solver.cpp:316] Optimization Done.
I0428 20:01:42.476637 29780 caffe.cpp:259] Optimization Done.
