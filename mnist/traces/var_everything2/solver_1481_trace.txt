I0428 20:27:01.629755  2915 caffe.cpp:218] Using GPUs 0
I0428 20:27:01.667099  2915 caffe.cpp:223] GPU 0: TITAN X (Pascal)
I0428 20:27:02.181089  2915 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 1000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_everything2/lenet_train_test1481.prototxt"
train_state {
  level: 0
  stage: ""
}
I0428 20:27:02.181232  2915 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1481.prototxt
I0428 20:27:02.181653  2915 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0428 20:27:02.181676  2915 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0428 20:27:02.181778  2915 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:27:02.181857  2915 layer_factory.hpp:77] Creating layer mnist
I0428 20:27:02.181959  2915 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0428 20:27:02.181982  2915 net.cpp:86] Creating Layer mnist
I0428 20:27:02.181993  2915 net.cpp:382] mnist -> data
I0428 20:27:02.182014  2915 net.cpp:382] mnist -> label
I0428 20:27:02.183106  2915 data_layer.cpp:45] output data size: 64,1,28,28
I0428 20:27:02.185659  2915 net.cpp:124] Setting up mnist
I0428 20:27:02.185683  2915 net.cpp:131] Top shape: 64 1 28 28 (50176)
I0428 20:27:02.185694  2915 net.cpp:131] Top shape: 64 (64)
I0428 20:27:02.185700  2915 net.cpp:139] Memory required for data: 200960
I0428 20:27:02.185711  2915 layer_factory.hpp:77] Creating layer conv0
I0428 20:27:02.185735  2915 net.cpp:86] Creating Layer conv0
I0428 20:27:02.185765  2915 net.cpp:408] conv0 <- data
I0428 20:27:02.185784  2915 net.cpp:382] conv0 -> conv0
I0428 20:27:02.471762  2915 net.cpp:124] Setting up conv0
I0428 20:27:02.471791  2915 net.cpp:131] Top shape: 64 100 24 24 (3686400)
I0428 20:27:02.471794  2915 net.cpp:139] Memory required for data: 14946560
I0428 20:27:02.471809  2915 layer_factory.hpp:77] Creating layer pool0
I0428 20:27:02.471822  2915 net.cpp:86] Creating Layer pool0
I0428 20:27:02.471827  2915 net.cpp:408] pool0 <- conv0
I0428 20:27:02.471832  2915 net.cpp:382] pool0 -> pool0
I0428 20:27:02.471877  2915 net.cpp:124] Setting up pool0
I0428 20:27:02.471882  2915 net.cpp:131] Top shape: 64 100 12 12 (921600)
I0428 20:27:02.471886  2915 net.cpp:139] Memory required for data: 18632960
I0428 20:27:02.471889  2915 layer_factory.hpp:77] Creating layer conv1
I0428 20:27:02.471899  2915 net.cpp:86] Creating Layer conv1
I0428 20:27:02.471902  2915 net.cpp:408] conv1 <- pool0
I0428 20:27:02.471907  2915 net.cpp:382] conv1 -> conv1
I0428 20:27:02.474616  2915 net.cpp:124] Setting up conv1
I0428 20:27:02.474632  2915 net.cpp:131] Top shape: 64 2 8 8 (8192)
I0428 20:27:02.474635  2915 net.cpp:139] Memory required for data: 18665728
I0428 20:27:02.474643  2915 layer_factory.hpp:77] Creating layer pool1
I0428 20:27:02.474650  2915 net.cpp:86] Creating Layer pool1
I0428 20:27:02.474654  2915 net.cpp:408] pool1 <- conv1
I0428 20:27:02.474659  2915 net.cpp:382] pool1 -> pool1
I0428 20:27:02.474696  2915 net.cpp:124] Setting up pool1
I0428 20:27:02.474705  2915 net.cpp:131] Top shape: 64 2 4 4 (2048)
I0428 20:27:02.474709  2915 net.cpp:139] Memory required for data: 18673920
I0428 20:27:02.474712  2915 layer_factory.hpp:77] Creating layer ip1
I0428 20:27:02.474720  2915 net.cpp:86] Creating Layer ip1
I0428 20:27:02.474722  2915 net.cpp:408] ip1 <- pool1
I0428 20:27:02.474727  2915 net.cpp:382] ip1 -> ip1
I0428 20:27:02.474838  2915 net.cpp:124] Setting up ip1
I0428 20:27:02.474844  2915 net.cpp:131] Top shape: 64 50 (3200)
I0428 20:27:02.474848  2915 net.cpp:139] Memory required for data: 18686720
I0428 20:27:02.474854  2915 layer_factory.hpp:77] Creating layer relu1
I0428 20:27:02.474859  2915 net.cpp:86] Creating Layer relu1
I0428 20:27:02.474862  2915 net.cpp:408] relu1 <- ip1
I0428 20:27:02.474866  2915 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:27:02.475047  2915 net.cpp:124] Setting up relu1
I0428 20:27:02.475059  2915 net.cpp:131] Top shape: 64 50 (3200)
I0428 20:27:02.475061  2915 net.cpp:139] Memory required for data: 18699520
I0428 20:27:02.475065  2915 layer_factory.hpp:77] Creating layer ip2
I0428 20:27:02.475071  2915 net.cpp:86] Creating Layer ip2
I0428 20:27:02.475075  2915 net.cpp:408] ip2 <- ip1
I0428 20:27:02.475080  2915 net.cpp:382] ip2 -> ip2
I0428 20:27:02.475185  2915 net.cpp:124] Setting up ip2
I0428 20:27:02.475193  2915 net.cpp:131] Top shape: 64 50 (3200)
I0428 20:27:02.475195  2915 net.cpp:139] Memory required for data: 18712320
I0428 20:27:02.475201  2915 layer_factory.hpp:77] Creating layer relu2
I0428 20:27:02.475208  2915 net.cpp:86] Creating Layer relu2
I0428 20:27:02.475210  2915 net.cpp:408] relu2 <- ip2
I0428 20:27:02.475214  2915 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:27:02.475973  2915 net.cpp:124] Setting up relu2
I0428 20:27:02.475988  2915 net.cpp:131] Top shape: 64 50 (3200)
I0428 20:27:02.475991  2915 net.cpp:139] Memory required for data: 18725120
I0428 20:27:02.475996  2915 layer_factory.hpp:77] Creating layer ip3
I0428 20:27:02.476002  2915 net.cpp:86] Creating Layer ip3
I0428 20:27:02.476006  2915 net.cpp:408] ip3 <- ip2
I0428 20:27:02.476011  2915 net.cpp:382] ip3 -> ip3
I0428 20:27:02.476112  2915 net.cpp:124] Setting up ip3
I0428 20:27:02.476120  2915 net.cpp:131] Top shape: 64 10 (640)
I0428 20:27:02.476124  2915 net.cpp:139] Memory required for data: 18727680
I0428 20:27:02.476131  2915 layer_factory.hpp:77] Creating layer relu3
I0428 20:27:02.476136  2915 net.cpp:86] Creating Layer relu3
I0428 20:27:02.476140  2915 net.cpp:408] relu3 <- ip3
I0428 20:27:02.476143  2915 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:27:02.476302  2915 net.cpp:124] Setting up relu3
I0428 20:27:02.476311  2915 net.cpp:131] Top shape: 64 10 (640)
I0428 20:27:02.476315  2915 net.cpp:139] Memory required for data: 18730240
I0428 20:27:02.476317  2915 layer_factory.hpp:77] Creating layer loss
I0428 20:27:02.476328  2915 net.cpp:86] Creating Layer loss
I0428 20:27:02.476331  2915 net.cpp:408] loss <- ip3
I0428 20:27:02.476336  2915 net.cpp:408] loss <- label
I0428 20:27:02.476341  2915 net.cpp:382] loss -> loss
I0428 20:27:02.476354  2915 layer_factory.hpp:77] Creating layer loss
I0428 20:27:02.476577  2915 net.cpp:124] Setting up loss
I0428 20:27:02.476586  2915 net.cpp:131] Top shape: (1)
I0428 20:27:02.476590  2915 net.cpp:134]     with loss weight 1
I0428 20:27:02.476604  2915 net.cpp:139] Memory required for data: 18730244
I0428 20:27:02.476608  2915 net.cpp:200] loss needs backward computation.
I0428 20:27:02.476611  2915 net.cpp:200] relu3 needs backward computation.
I0428 20:27:02.476614  2915 net.cpp:200] ip3 needs backward computation.
I0428 20:27:02.476618  2915 net.cpp:200] relu2 needs backward computation.
I0428 20:27:02.476619  2915 net.cpp:200] ip2 needs backward computation.
I0428 20:27:02.476622  2915 net.cpp:200] relu1 needs backward computation.
I0428 20:27:02.476624  2915 net.cpp:200] ip1 needs backward computation.
I0428 20:27:02.476627  2915 net.cpp:200] pool1 needs backward computation.
I0428 20:27:02.476630  2915 net.cpp:200] conv1 needs backward computation.
I0428 20:27:02.476634  2915 net.cpp:200] pool0 needs backward computation.
I0428 20:27:02.476637  2915 net.cpp:200] conv0 needs backward computation.
I0428 20:27:02.476640  2915 net.cpp:202] mnist does not need backward computation.
I0428 20:27:02.476644  2915 net.cpp:244] This network produces output loss
I0428 20:27:02.476652  2915 net.cpp:257] Network initialization done.
I0428 20:27:02.477033  2915 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1481.prototxt
I0428 20:27:02.477087  2915 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0428 20:27:02.477195  2915 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:27:02.477272  2915 layer_factory.hpp:77] Creating layer mnist
I0428 20:27:02.477316  2915 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0428 20:27:02.477329  2915 net.cpp:86] Creating Layer mnist
I0428 20:27:02.477334  2915 net.cpp:382] mnist -> data
I0428 20:27:02.477340  2915 net.cpp:382] mnist -> label
I0428 20:27:02.477423  2915 data_layer.cpp:45] output data size: 100,1,28,28
I0428 20:27:02.479511  2915 net.cpp:124] Setting up mnist
I0428 20:27:02.479526  2915 net.cpp:131] Top shape: 100 1 28 28 (78400)
I0428 20:27:02.479531  2915 net.cpp:131] Top shape: 100 (100)
I0428 20:27:02.479533  2915 net.cpp:139] Memory required for data: 314000
I0428 20:27:02.479537  2915 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0428 20:27:02.479543  2915 net.cpp:86] Creating Layer label_mnist_1_split
I0428 20:27:02.479547  2915 net.cpp:408] label_mnist_1_split <- label
I0428 20:27:02.479552  2915 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_0
I0428 20:27:02.479558  2915 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_1
I0428 20:27:02.479596  2915 net.cpp:124] Setting up label_mnist_1_split
I0428 20:27:02.479601  2915 net.cpp:131] Top shape: 100 (100)
I0428 20:27:02.479604  2915 net.cpp:131] Top shape: 100 (100)
I0428 20:27:02.479607  2915 net.cpp:139] Memory required for data: 314800
I0428 20:27:02.479610  2915 layer_factory.hpp:77] Creating layer conv0
I0428 20:27:02.479619  2915 net.cpp:86] Creating Layer conv0
I0428 20:27:02.479621  2915 net.cpp:408] conv0 <- data
I0428 20:27:02.479625  2915 net.cpp:382] conv0 -> conv0
I0428 20:27:02.481283  2915 net.cpp:124] Setting up conv0
I0428 20:27:02.481297  2915 net.cpp:131] Top shape: 100 100 24 24 (5760000)
I0428 20:27:02.481302  2915 net.cpp:139] Memory required for data: 23354800
I0428 20:27:02.481310  2915 layer_factory.hpp:77] Creating layer pool0
I0428 20:27:02.481317  2915 net.cpp:86] Creating Layer pool0
I0428 20:27:02.481320  2915 net.cpp:408] pool0 <- conv0
I0428 20:27:02.481324  2915 net.cpp:382] pool0 -> pool0
I0428 20:27:02.481359  2915 net.cpp:124] Setting up pool0
I0428 20:27:02.481364  2915 net.cpp:131] Top shape: 100 100 12 12 (1440000)
I0428 20:27:02.481367  2915 net.cpp:139] Memory required for data: 29114800
I0428 20:27:02.481370  2915 layer_factory.hpp:77] Creating layer conv1
I0428 20:27:02.481379  2915 net.cpp:86] Creating Layer conv1
I0428 20:27:02.481381  2915 net.cpp:408] conv1 <- pool0
I0428 20:27:02.481385  2915 net.cpp:382] conv1 -> conv1
I0428 20:27:02.482843  2915 net.cpp:124] Setting up conv1
I0428 20:27:02.482857  2915 net.cpp:131] Top shape: 100 2 8 8 (12800)
I0428 20:27:02.482861  2915 net.cpp:139] Memory required for data: 29166000
I0428 20:27:02.482869  2915 layer_factory.hpp:77] Creating layer pool1
I0428 20:27:02.482875  2915 net.cpp:86] Creating Layer pool1
I0428 20:27:02.482879  2915 net.cpp:408] pool1 <- conv1
I0428 20:27:02.482883  2915 net.cpp:382] pool1 -> pool1
I0428 20:27:02.482919  2915 net.cpp:124] Setting up pool1
I0428 20:27:02.482924  2915 net.cpp:131] Top shape: 100 2 4 4 (3200)
I0428 20:27:02.482928  2915 net.cpp:139] Memory required for data: 29178800
I0428 20:27:02.482930  2915 layer_factory.hpp:77] Creating layer ip1
I0428 20:27:02.482935  2915 net.cpp:86] Creating Layer ip1
I0428 20:27:02.482939  2915 net.cpp:408] ip1 <- pool1
I0428 20:27:02.482950  2915 net.cpp:382] ip1 -> ip1
I0428 20:27:02.483055  2915 net.cpp:124] Setting up ip1
I0428 20:27:02.483063  2915 net.cpp:131] Top shape: 100 50 (5000)
I0428 20:27:02.483077  2915 net.cpp:139] Memory required for data: 29198800
I0428 20:27:02.483089  2915 layer_factory.hpp:77] Creating layer relu1
I0428 20:27:02.483094  2915 net.cpp:86] Creating Layer relu1
I0428 20:27:02.483098  2915 net.cpp:408] relu1 <- ip1
I0428 20:27:02.483103  2915 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:27:02.483337  2915 net.cpp:124] Setting up relu1
I0428 20:27:02.483348  2915 net.cpp:131] Top shape: 100 50 (5000)
I0428 20:27:02.483352  2915 net.cpp:139] Memory required for data: 29218800
I0428 20:27:02.483356  2915 layer_factory.hpp:77] Creating layer ip2
I0428 20:27:02.483371  2915 net.cpp:86] Creating Layer ip2
I0428 20:27:02.483374  2915 net.cpp:408] ip2 <- ip1
I0428 20:27:02.483379  2915 net.cpp:382] ip2 -> ip2
I0428 20:27:02.483520  2915 net.cpp:124] Setting up ip2
I0428 20:27:02.483528  2915 net.cpp:131] Top shape: 100 50 (5000)
I0428 20:27:02.483531  2915 net.cpp:139] Memory required for data: 29238800
I0428 20:27:02.483538  2915 layer_factory.hpp:77] Creating layer relu2
I0428 20:27:02.483542  2915 net.cpp:86] Creating Layer relu2
I0428 20:27:02.483546  2915 net.cpp:408] relu2 <- ip2
I0428 20:27:02.483551  2915 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:27:02.483772  2915 net.cpp:124] Setting up relu2
I0428 20:27:02.483781  2915 net.cpp:131] Top shape: 100 50 (5000)
I0428 20:27:02.483785  2915 net.cpp:139] Memory required for data: 29258800
I0428 20:27:02.483788  2915 layer_factory.hpp:77] Creating layer ip3
I0428 20:27:02.483798  2915 net.cpp:86] Creating Layer ip3
I0428 20:27:02.483801  2915 net.cpp:408] ip3 <- ip2
I0428 20:27:02.483806  2915 net.cpp:382] ip3 -> ip3
I0428 20:27:02.483942  2915 net.cpp:124] Setting up ip3
I0428 20:27:02.483950  2915 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:27:02.483954  2915 net.cpp:139] Memory required for data: 29262800
I0428 20:27:02.483963  2915 layer_factory.hpp:77] Creating layer relu3
I0428 20:27:02.483966  2915 net.cpp:86] Creating Layer relu3
I0428 20:27:02.483969  2915 net.cpp:408] relu3 <- ip3
I0428 20:27:02.483973  2915 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:27:02.484731  2915 net.cpp:124] Setting up relu3
I0428 20:27:02.484745  2915 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:27:02.484747  2915 net.cpp:139] Memory required for data: 29266800
I0428 20:27:02.484751  2915 layer_factory.hpp:77] Creating layer ip3_relu3_0_split
I0428 20:27:02.484756  2915 net.cpp:86] Creating Layer ip3_relu3_0_split
I0428 20:27:02.484760  2915 net.cpp:408] ip3_relu3_0_split <- ip3
I0428 20:27:02.484764  2915 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_0
I0428 20:27:02.484771  2915 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_1
I0428 20:27:02.484817  2915 net.cpp:124] Setting up ip3_relu3_0_split
I0428 20:27:02.484824  2915 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:27:02.484827  2915 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:27:02.484830  2915 net.cpp:139] Memory required for data: 29274800
I0428 20:27:02.484833  2915 layer_factory.hpp:77] Creating layer accuracy
I0428 20:27:02.484838  2915 net.cpp:86] Creating Layer accuracy
I0428 20:27:02.484841  2915 net.cpp:408] accuracy <- ip3_relu3_0_split_0
I0428 20:27:02.484846  2915 net.cpp:408] accuracy <- label_mnist_1_split_0
I0428 20:27:02.484850  2915 net.cpp:382] accuracy -> accuracy
I0428 20:27:02.484858  2915 net.cpp:124] Setting up accuracy
I0428 20:27:02.484863  2915 net.cpp:131] Top shape: (1)
I0428 20:27:02.484881  2915 net.cpp:139] Memory required for data: 29274804
I0428 20:27:02.484884  2915 layer_factory.hpp:77] Creating layer loss
I0428 20:27:02.484889  2915 net.cpp:86] Creating Layer loss
I0428 20:27:02.484891  2915 net.cpp:408] loss <- ip3_relu3_0_split_1
I0428 20:27:02.484910  2915 net.cpp:408] loss <- label_mnist_1_split_1
I0428 20:27:02.484918  2915 net.cpp:382] loss -> loss
I0428 20:27:02.484928  2915 layer_factory.hpp:77] Creating layer loss
I0428 20:27:02.485246  2915 net.cpp:124] Setting up loss
I0428 20:27:02.485271  2915 net.cpp:131] Top shape: (1)
I0428 20:27:02.485275  2915 net.cpp:134]     with loss weight 1
I0428 20:27:02.485292  2915 net.cpp:139] Memory required for data: 29274808
I0428 20:27:02.485296  2915 net.cpp:200] loss needs backward computation.
I0428 20:27:02.485301  2915 net.cpp:202] accuracy does not need backward computation.
I0428 20:27:02.485304  2915 net.cpp:200] ip3_relu3_0_split needs backward computation.
I0428 20:27:02.485308  2915 net.cpp:200] relu3 needs backward computation.
I0428 20:27:02.485311  2915 net.cpp:200] ip3 needs backward computation.
I0428 20:27:02.485313  2915 net.cpp:200] relu2 needs backward computation.
I0428 20:27:02.485316  2915 net.cpp:200] ip2 needs backward computation.
I0428 20:27:02.485325  2915 net.cpp:200] relu1 needs backward computation.
I0428 20:27:02.485328  2915 net.cpp:200] ip1 needs backward computation.
I0428 20:27:02.485337  2915 net.cpp:200] pool1 needs backward computation.
I0428 20:27:02.485339  2915 net.cpp:200] conv1 needs backward computation.
I0428 20:27:02.485343  2915 net.cpp:200] pool0 needs backward computation.
I0428 20:27:02.485347  2915 net.cpp:200] conv0 needs backward computation.
I0428 20:27:02.485349  2915 net.cpp:202] label_mnist_1_split does not need backward computation.
I0428 20:27:02.485353  2915 net.cpp:202] mnist does not need backward computation.
I0428 20:27:02.485357  2915 net.cpp:244] This network produces output accuracy
I0428 20:27:02.485360  2915 net.cpp:244] This network produces output loss
I0428 20:27:02.485370  2915 net.cpp:257] Network initialization done.
I0428 20:27:02.485411  2915 solver.cpp:56] Solver scaffolding done.
I0428 20:27:02.485827  2915 caffe.cpp:248] Starting Optimization
I0428 20:27:02.485834  2915 solver.cpp:273] Solving LeNet
I0428 20:27:02.485853  2915 solver.cpp:274] Learning Rate Policy: inv
I0428 20:27:02.486699  2915 solver.cpp:331] Iteration 0, Testing net (#0)
I0428 20:27:02.582144  2926 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:27:02.583633  2915 solver.cpp:398]     Test net output #0: accuracy = 0.0657
I0428 20:27:02.583669  2915 solver.cpp:398]     Test net output #1: loss = 2.32468 (* 1 = 2.32468 loss)
I0428 20:27:02.588196  2915 solver.cpp:219] Iteration 0 (-1.61191e-31 iter/s, 0.102309s/100 iters), loss = 2.28353
I0428 20:27:02.588235  2915 solver.cpp:238]     Train net output #0: loss = 2.28353 (* 1 = 2.28353 loss)
I0428 20:27:02.588248  2915 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0428 20:27:02.788499  2915 solver.cpp:219] Iteration 100 (499.342 iter/s, 0.200264s/100 iters), loss = 0.609489
I0428 20:27:02.788542  2915 solver.cpp:238]     Train net output #0: loss = 0.609489 (* 1 = 0.609489 loss)
I0428 20:27:02.788564  2915 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0428 20:27:02.989724  2915 solver.cpp:219] Iteration 200 (497.064 iter/s, 0.201181s/100 iters), loss = 0.25391
I0428 20:27:02.989756  2915 solver.cpp:238]     Train net output #0: loss = 0.25391 (* 1 = 0.25391 loss)
I0428 20:27:02.989764  2915 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0428 20:27:03.187569  2915 solver.cpp:219] Iteration 300 (505.561 iter/s, 0.1978s/100 iters), loss = 0.178684
I0428 20:27:03.187611  2915 solver.cpp:238]     Train net output #0: loss = 0.178685 (* 1 = 0.178685 loss)
I0428 20:27:03.187618  2915 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0428 20:27:03.388113  2915 solver.cpp:219] Iteration 400 (498.783 iter/s, 0.200488s/100 iters), loss = 0.133552
I0428 20:27:03.388140  2915 solver.cpp:238]     Train net output #0: loss = 0.133552 (* 1 = 0.133552 loss)
I0428 20:27:03.388147  2915 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0428 20:27:03.583468  2915 solver.cpp:331] Iteration 500, Testing net (#0)
I0428 20:27:03.677682  2926 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:27:03.680007  2915 solver.cpp:398]     Test net output #0: accuracy = 0.9493
I0428 20:27:03.680032  2915 solver.cpp:398]     Test net output #1: loss = 0.156961 (* 1 = 0.156961 loss)
I0428 20:27:03.681932  2915 solver.cpp:219] Iteration 500 (340.4 iter/s, 0.293772s/100 iters), loss = 0.264823
I0428 20:27:03.681957  2915 solver.cpp:238]     Train net output #0: loss = 0.264823 (* 1 = 0.264823 loss)
I0428 20:27:03.681979  2915 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0428 20:27:03.882833  2915 solver.cpp:219] Iteration 600 (497.858 iter/s, 0.200861s/100 iters), loss = 0.108877
I0428 20:27:03.882875  2915 solver.cpp:238]     Train net output #0: loss = 0.108877 (* 1 = 0.108877 loss)
I0428 20:27:03.882882  2915 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0428 20:27:04.091879  2915 solver.cpp:219] Iteration 700 (478.503 iter/s, 0.208985s/100 iters), loss = 0.284641
I0428 20:27:04.091928  2915 solver.cpp:238]     Train net output #0: loss = 0.284641 (* 1 = 0.284641 loss)
I0428 20:27:04.091940  2915 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0428 20:27:04.300571  2915 solver.cpp:219] Iteration 800 (479.313 iter/s, 0.208632s/100 iters), loss = 0.237073
I0428 20:27:04.300606  2915 solver.cpp:238]     Train net output #0: loss = 0.237073 (* 1 = 0.237073 loss)
I0428 20:27:04.300613  2915 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0428 20:27:04.513123  2915 solver.cpp:219] Iteration 900 (470.592 iter/s, 0.212498s/100 iters), loss = 0.213854
I0428 20:27:04.513169  2915 solver.cpp:238]     Train net output #0: loss = 0.213854 (* 1 = 0.213854 loss)
I0428 20:27:04.513180  2915 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0428 20:27:04.584627  2924 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:27:04.727854  2915 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_1000.caffemodel
I0428 20:27:04.729725  2915 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_1000.solverstate
I0428 20:27:04.730965  2915 solver.cpp:311] Iteration 1000, loss = 0.125577
I0428 20:27:04.731001  2915 solver.cpp:331] Iteration 1000, Testing net (#0)
I0428 20:27:04.831821  2926 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:27:04.834535  2915 solver.cpp:398]     Test net output #0: accuracy = 0.9645
I0428 20:27:04.834561  2915 solver.cpp:398]     Test net output #1: loss = 0.109771 (* 1 = 0.109771 loss)
I0428 20:27:04.834570  2915 solver.cpp:316] Optimization Done.
I0428 20:27:04.834575  2915 caffe.cpp:259] Optimization Done.
