I0428 20:38:35.147481  5142 caffe.cpp:218] Using GPUs 0
I0428 20:38:35.185533  5142 caffe.cpp:223] GPU 0: TITAN X (Pascal)
I0428 20:38:35.698175  5142 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 1000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_everything2/lenet_train_test1667.prototxt"
train_state {
  level: 0
  stage: ""
}
I0428 20:38:35.698341  5142 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1667.prototxt
I0428 20:38:35.699221  5142 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0428 20:38:35.699241  5142 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0428 20:38:35.699343  5142 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:38:35.699424  5142 layer_factory.hpp:77] Creating layer mnist
I0428 20:38:35.699525  5142 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0428 20:38:35.699549  5142 net.cpp:86] Creating Layer mnist
I0428 20:38:35.699559  5142 net.cpp:382] mnist -> data
I0428 20:38:35.699581  5142 net.cpp:382] mnist -> label
I0428 20:38:35.700700  5142 data_layer.cpp:45] output data size: 64,1,28,28
I0428 20:38:35.703174  5142 net.cpp:124] Setting up mnist
I0428 20:38:35.703192  5142 net.cpp:131] Top shape: 64 1 28 28 (50176)
I0428 20:38:35.703199  5142 net.cpp:131] Top shape: 64 (64)
I0428 20:38:35.703202  5142 net.cpp:139] Memory required for data: 200960
I0428 20:38:35.703209  5142 layer_factory.hpp:77] Creating layer conv0
I0428 20:38:35.703249  5142 net.cpp:86] Creating Layer conv0
I0428 20:38:35.703271  5142 net.cpp:408] conv0 <- data
I0428 20:38:35.703284  5142 net.cpp:382] conv0 -> conv0
I0428 20:38:35.987054  5142 net.cpp:124] Setting up conv0
I0428 20:38:35.987082  5142 net.cpp:131] Top shape: 64 100 24 24 (3686400)
I0428 20:38:35.987085  5142 net.cpp:139] Memory required for data: 14946560
I0428 20:38:35.987100  5142 layer_factory.hpp:77] Creating layer pool0
I0428 20:38:35.987113  5142 net.cpp:86] Creating Layer pool0
I0428 20:38:35.987118  5142 net.cpp:408] pool0 <- conv0
I0428 20:38:35.987123  5142 net.cpp:382] pool0 -> pool0
I0428 20:38:35.987197  5142 net.cpp:124] Setting up pool0
I0428 20:38:35.987203  5142 net.cpp:131] Top shape: 64 100 12 12 (921600)
I0428 20:38:35.987206  5142 net.cpp:139] Memory required for data: 18632960
I0428 20:38:35.987210  5142 layer_factory.hpp:77] Creating layer conv1
I0428 20:38:35.987221  5142 net.cpp:86] Creating Layer conv1
I0428 20:38:35.987223  5142 net.cpp:408] conv1 <- pool0
I0428 20:38:35.987227  5142 net.cpp:382] conv1 -> conv1
I0428 20:38:35.991273  5142 net.cpp:124] Setting up conv1
I0428 20:38:35.991287  5142 net.cpp:131] Top shape: 64 100 8 8 (409600)
I0428 20:38:35.991291  5142 net.cpp:139] Memory required for data: 20271360
I0428 20:38:35.991299  5142 layer_factory.hpp:77] Creating layer pool1
I0428 20:38:35.991307  5142 net.cpp:86] Creating Layer pool1
I0428 20:38:35.991310  5142 net.cpp:408] pool1 <- conv1
I0428 20:38:35.991315  5142 net.cpp:382] pool1 -> pool1
I0428 20:38:35.991350  5142 net.cpp:124] Setting up pool1
I0428 20:38:35.991355  5142 net.cpp:131] Top shape: 64 100 4 4 (102400)
I0428 20:38:35.991358  5142 net.cpp:139] Memory required for data: 20680960
I0428 20:38:35.991361  5142 layer_factory.hpp:77] Creating layer ip1
I0428 20:38:35.991369  5142 net.cpp:86] Creating Layer ip1
I0428 20:38:35.991370  5142 net.cpp:408] ip1 <- pool1
I0428 20:38:35.991375  5142 net.cpp:382] ip1 -> ip1
I0428 20:38:35.991683  5142 net.cpp:124] Setting up ip1
I0428 20:38:35.991690  5142 net.cpp:131] Top shape: 64 25 (1600)
I0428 20:38:35.991693  5142 net.cpp:139] Memory required for data: 20687360
I0428 20:38:35.991699  5142 layer_factory.hpp:77] Creating layer relu1
I0428 20:38:35.991705  5142 net.cpp:86] Creating Layer relu1
I0428 20:38:35.991708  5142 net.cpp:408] relu1 <- ip1
I0428 20:38:35.991713  5142 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:38:35.991866  5142 net.cpp:124] Setting up relu1
I0428 20:38:35.991874  5142 net.cpp:131] Top shape: 64 25 (1600)
I0428 20:38:35.991878  5142 net.cpp:139] Memory required for data: 20693760
I0428 20:38:35.991880  5142 layer_factory.hpp:77] Creating layer ip2
I0428 20:38:35.991886  5142 net.cpp:86] Creating Layer ip2
I0428 20:38:35.991889  5142 net.cpp:408] ip2 <- ip1
I0428 20:38:35.991894  5142 net.cpp:382] ip2 -> ip2
I0428 20:38:35.991998  5142 net.cpp:124] Setting up ip2
I0428 20:38:35.992005  5142 net.cpp:131] Top shape: 64 50 (3200)
I0428 20:38:35.992008  5142 net.cpp:139] Memory required for data: 20706560
I0428 20:38:35.992014  5142 layer_factory.hpp:77] Creating layer relu2
I0428 20:38:35.992019  5142 net.cpp:86] Creating Layer relu2
I0428 20:38:35.992022  5142 net.cpp:408] relu2 <- ip2
I0428 20:38:35.992027  5142 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:38:35.992784  5142 net.cpp:124] Setting up relu2
I0428 20:38:35.992796  5142 net.cpp:131] Top shape: 64 50 (3200)
I0428 20:38:35.992799  5142 net.cpp:139] Memory required for data: 20719360
I0428 20:38:35.992804  5142 layer_factory.hpp:77] Creating layer ip3
I0428 20:38:35.992831  5142 net.cpp:86] Creating Layer ip3
I0428 20:38:35.992835  5142 net.cpp:408] ip3 <- ip2
I0428 20:38:35.992841  5142 net.cpp:382] ip3 -> ip3
I0428 20:38:35.992944  5142 net.cpp:124] Setting up ip3
I0428 20:38:35.992952  5142 net.cpp:131] Top shape: 64 10 (640)
I0428 20:38:35.992955  5142 net.cpp:139] Memory required for data: 20721920
I0428 20:38:35.992964  5142 layer_factory.hpp:77] Creating layer relu3
I0428 20:38:35.992969  5142 net.cpp:86] Creating Layer relu3
I0428 20:38:35.992971  5142 net.cpp:408] relu3 <- ip3
I0428 20:38:35.992990  5142 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:38:35.993156  5142 net.cpp:124] Setting up relu3
I0428 20:38:35.993165  5142 net.cpp:131] Top shape: 64 10 (640)
I0428 20:38:35.993170  5142 net.cpp:139] Memory required for data: 20724480
I0428 20:38:35.993173  5142 layer_factory.hpp:77] Creating layer loss
I0428 20:38:35.993180  5142 net.cpp:86] Creating Layer loss
I0428 20:38:35.993198  5142 net.cpp:408] loss <- ip3
I0428 20:38:35.993202  5142 net.cpp:408] loss <- label
I0428 20:38:35.993207  5142 net.cpp:382] loss -> loss
I0428 20:38:35.993224  5142 layer_factory.hpp:77] Creating layer loss
I0428 20:38:35.993468  5142 net.cpp:124] Setting up loss
I0428 20:38:35.993477  5142 net.cpp:131] Top shape: (1)
I0428 20:38:35.993480  5142 net.cpp:134]     with loss weight 1
I0428 20:38:35.993494  5142 net.cpp:139] Memory required for data: 20724484
I0428 20:38:35.993499  5142 net.cpp:200] loss needs backward computation.
I0428 20:38:35.993501  5142 net.cpp:200] relu3 needs backward computation.
I0428 20:38:35.993505  5142 net.cpp:200] ip3 needs backward computation.
I0428 20:38:35.993507  5142 net.cpp:200] relu2 needs backward computation.
I0428 20:38:35.993510  5142 net.cpp:200] ip2 needs backward computation.
I0428 20:38:35.993512  5142 net.cpp:200] relu1 needs backward computation.
I0428 20:38:35.993515  5142 net.cpp:200] ip1 needs backward computation.
I0428 20:38:35.993517  5142 net.cpp:200] pool1 needs backward computation.
I0428 20:38:35.993520  5142 net.cpp:200] conv1 needs backward computation.
I0428 20:38:35.993523  5142 net.cpp:200] pool0 needs backward computation.
I0428 20:38:35.993526  5142 net.cpp:200] conv0 needs backward computation.
I0428 20:38:35.993530  5142 net.cpp:202] mnist does not need backward computation.
I0428 20:38:35.993532  5142 net.cpp:244] This network produces output loss
I0428 20:38:35.993542  5142 net.cpp:257] Network initialization done.
I0428 20:38:35.993899  5142 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1667.prototxt
I0428 20:38:35.993942  5142 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0428 20:38:35.994055  5142 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:38:35.994148  5142 layer_factory.hpp:77] Creating layer mnist
I0428 20:38:35.994190  5142 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0428 20:38:35.994204  5142 net.cpp:86] Creating Layer mnist
I0428 20:38:35.994207  5142 net.cpp:382] mnist -> data
I0428 20:38:35.994215  5142 net.cpp:382] mnist -> label
I0428 20:38:35.994303  5142 data_layer.cpp:45] output data size: 100,1,28,28
I0428 20:38:35.996618  5142 net.cpp:124] Setting up mnist
I0428 20:38:35.996631  5142 net.cpp:131] Top shape: 100 1 28 28 (78400)
I0428 20:38:35.996636  5142 net.cpp:131] Top shape: 100 (100)
I0428 20:38:35.996639  5142 net.cpp:139] Memory required for data: 314000
I0428 20:38:35.996642  5142 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0428 20:38:35.996649  5142 net.cpp:86] Creating Layer label_mnist_1_split
I0428 20:38:35.996652  5142 net.cpp:408] label_mnist_1_split <- label
I0428 20:38:35.996657  5142 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_0
I0428 20:38:35.996665  5142 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_1
I0428 20:38:35.996719  5142 net.cpp:124] Setting up label_mnist_1_split
I0428 20:38:35.996724  5142 net.cpp:131] Top shape: 100 (100)
I0428 20:38:35.996728  5142 net.cpp:131] Top shape: 100 (100)
I0428 20:38:35.996731  5142 net.cpp:139] Memory required for data: 314800
I0428 20:38:35.996734  5142 layer_factory.hpp:77] Creating layer conv0
I0428 20:38:35.996744  5142 net.cpp:86] Creating Layer conv0
I0428 20:38:35.996747  5142 net.cpp:408] conv0 <- data
I0428 20:38:35.996752  5142 net.cpp:382] conv0 -> conv0
I0428 20:38:35.998497  5142 net.cpp:124] Setting up conv0
I0428 20:38:35.998510  5142 net.cpp:131] Top shape: 100 100 24 24 (5760000)
I0428 20:38:35.998514  5142 net.cpp:139] Memory required for data: 23354800
I0428 20:38:35.998544  5142 layer_factory.hpp:77] Creating layer pool0
I0428 20:38:35.998553  5142 net.cpp:86] Creating Layer pool0
I0428 20:38:35.998555  5142 net.cpp:408] pool0 <- conv0
I0428 20:38:35.998563  5142 net.cpp:382] pool0 -> pool0
I0428 20:38:35.998598  5142 net.cpp:124] Setting up pool0
I0428 20:38:35.998605  5142 net.cpp:131] Top shape: 100 100 12 12 (1440000)
I0428 20:38:35.998608  5142 net.cpp:139] Memory required for data: 29114800
I0428 20:38:35.998610  5142 layer_factory.hpp:77] Creating layer conv1
I0428 20:38:35.998620  5142 net.cpp:86] Creating Layer conv1
I0428 20:38:35.998622  5142 net.cpp:408] conv1 <- pool0
I0428 20:38:35.998627  5142 net.cpp:382] conv1 -> conv1
I0428 20:38:36.001729  5142 net.cpp:124] Setting up conv1
I0428 20:38:36.001744  5142 net.cpp:131] Top shape: 100 100 8 8 (640000)
I0428 20:38:36.001747  5142 net.cpp:139] Memory required for data: 31674800
I0428 20:38:36.001755  5142 layer_factory.hpp:77] Creating layer pool1
I0428 20:38:36.001770  5142 net.cpp:86] Creating Layer pool1
I0428 20:38:36.001773  5142 net.cpp:408] pool1 <- conv1
I0428 20:38:36.001783  5142 net.cpp:382] pool1 -> pool1
I0428 20:38:36.001821  5142 net.cpp:124] Setting up pool1
I0428 20:38:36.001827  5142 net.cpp:131] Top shape: 100 100 4 4 (160000)
I0428 20:38:36.001828  5142 net.cpp:139] Memory required for data: 32314800
I0428 20:38:36.001832  5142 layer_factory.hpp:77] Creating layer ip1
I0428 20:38:36.001838  5142 net.cpp:86] Creating Layer ip1
I0428 20:38:36.001842  5142 net.cpp:408] ip1 <- pool1
I0428 20:38:36.001847  5142 net.cpp:382] ip1 -> ip1
I0428 20:38:36.002172  5142 net.cpp:124] Setting up ip1
I0428 20:38:36.002190  5142 net.cpp:131] Top shape: 100 25 (2500)
I0428 20:38:36.002193  5142 net.cpp:139] Memory required for data: 32324800
I0428 20:38:36.002200  5142 layer_factory.hpp:77] Creating layer relu1
I0428 20:38:36.002207  5142 net.cpp:86] Creating Layer relu1
I0428 20:38:36.002209  5142 net.cpp:408] relu1 <- ip1
I0428 20:38:36.002226  5142 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:38:36.002385  5142 net.cpp:124] Setting up relu1
I0428 20:38:36.002394  5142 net.cpp:131] Top shape: 100 25 (2500)
I0428 20:38:36.002398  5142 net.cpp:139] Memory required for data: 32334800
I0428 20:38:36.002401  5142 layer_factory.hpp:77] Creating layer ip2
I0428 20:38:36.002408  5142 net.cpp:86] Creating Layer ip2
I0428 20:38:36.002413  5142 net.cpp:408] ip2 <- ip1
I0428 20:38:36.002418  5142 net.cpp:382] ip2 -> ip2
I0428 20:38:36.002523  5142 net.cpp:124] Setting up ip2
I0428 20:38:36.002532  5142 net.cpp:131] Top shape: 100 50 (5000)
I0428 20:38:36.002535  5142 net.cpp:139] Memory required for data: 32354800
I0428 20:38:36.002540  5142 layer_factory.hpp:77] Creating layer relu2
I0428 20:38:36.002544  5142 net.cpp:86] Creating Layer relu2
I0428 20:38:36.002553  5142 net.cpp:408] relu2 <- ip2
I0428 20:38:36.002557  5142 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:38:36.002764  5142 net.cpp:124] Setting up relu2
I0428 20:38:36.002774  5142 net.cpp:131] Top shape: 100 50 (5000)
I0428 20:38:36.002777  5142 net.cpp:139] Memory required for data: 32374800
I0428 20:38:36.002800  5142 layer_factory.hpp:77] Creating layer ip3
I0428 20:38:36.002805  5142 net.cpp:86] Creating Layer ip3
I0428 20:38:36.002810  5142 net.cpp:408] ip3 <- ip2
I0428 20:38:36.002815  5142 net.cpp:382] ip3 -> ip3
I0428 20:38:36.002970  5142 net.cpp:124] Setting up ip3
I0428 20:38:36.002979  5142 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:38:36.002981  5142 net.cpp:139] Memory required for data: 32378800
I0428 20:38:36.002990  5142 layer_factory.hpp:77] Creating layer relu3
I0428 20:38:36.002995  5142 net.cpp:86] Creating Layer relu3
I0428 20:38:36.002997  5142 net.cpp:408] relu3 <- ip3
I0428 20:38:36.003003  5142 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:38:36.003811  5142 net.cpp:124] Setting up relu3
I0428 20:38:36.003823  5142 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:38:36.003826  5142 net.cpp:139] Memory required for data: 32382800
I0428 20:38:36.003830  5142 layer_factory.hpp:77] Creating layer ip3_relu3_0_split
I0428 20:38:36.003835  5142 net.cpp:86] Creating Layer ip3_relu3_0_split
I0428 20:38:36.003839  5142 net.cpp:408] ip3_relu3_0_split <- ip3
I0428 20:38:36.003844  5142 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_0
I0428 20:38:36.003851  5142 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_1
I0428 20:38:36.003893  5142 net.cpp:124] Setting up ip3_relu3_0_split
I0428 20:38:36.003898  5142 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:38:36.003902  5142 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:38:36.003906  5142 net.cpp:139] Memory required for data: 32390800
I0428 20:38:36.003908  5142 layer_factory.hpp:77] Creating layer accuracy
I0428 20:38:36.003917  5142 net.cpp:86] Creating Layer accuracy
I0428 20:38:36.003921  5142 net.cpp:408] accuracy <- ip3_relu3_0_split_0
I0428 20:38:36.003924  5142 net.cpp:408] accuracy <- label_mnist_1_split_0
I0428 20:38:36.003928  5142 net.cpp:382] accuracy -> accuracy
I0428 20:38:36.003937  5142 net.cpp:124] Setting up accuracy
I0428 20:38:36.003940  5142 net.cpp:131] Top shape: (1)
I0428 20:38:36.003943  5142 net.cpp:139] Memory required for data: 32390804
I0428 20:38:36.003947  5142 layer_factory.hpp:77] Creating layer loss
I0428 20:38:36.003950  5142 net.cpp:86] Creating Layer loss
I0428 20:38:36.003953  5142 net.cpp:408] loss <- ip3_relu3_0_split_1
I0428 20:38:36.003957  5142 net.cpp:408] loss <- label_mnist_1_split_1
I0428 20:38:36.003960  5142 net.cpp:382] loss -> loss
I0428 20:38:36.003967  5142 layer_factory.hpp:77] Creating layer loss
I0428 20:38:36.004252  5142 net.cpp:124] Setting up loss
I0428 20:38:36.004266  5142 net.cpp:131] Top shape: (1)
I0428 20:38:36.004281  5142 net.cpp:134]     with loss weight 1
I0428 20:38:36.004299  5142 net.cpp:139] Memory required for data: 32390808
I0428 20:38:36.004303  5142 net.cpp:200] loss needs backward computation.
I0428 20:38:36.004307  5142 net.cpp:202] accuracy does not need backward computation.
I0428 20:38:36.004312  5142 net.cpp:200] ip3_relu3_0_split needs backward computation.
I0428 20:38:36.004314  5142 net.cpp:200] relu3 needs backward computation.
I0428 20:38:36.004317  5142 net.cpp:200] ip3 needs backward computation.
I0428 20:38:36.004325  5142 net.cpp:200] relu2 needs backward computation.
I0428 20:38:36.004328  5142 net.cpp:200] ip2 needs backward computation.
I0428 20:38:36.004330  5142 net.cpp:200] relu1 needs backward computation.
I0428 20:38:36.004333  5142 net.cpp:200] ip1 needs backward computation.
I0428 20:38:36.004336  5142 net.cpp:200] pool1 needs backward computation.
I0428 20:38:36.004340  5142 net.cpp:200] conv1 needs backward computation.
I0428 20:38:36.004348  5142 net.cpp:200] pool0 needs backward computation.
I0428 20:38:36.004351  5142 net.cpp:200] conv0 needs backward computation.
I0428 20:38:36.004355  5142 net.cpp:202] label_mnist_1_split does not need backward computation.
I0428 20:38:36.004359  5142 net.cpp:202] mnist does not need backward computation.
I0428 20:38:36.004361  5142 net.cpp:244] This network produces output accuracy
I0428 20:38:36.004365  5142 net.cpp:244] This network produces output loss
I0428 20:38:36.004375  5142 net.cpp:257] Network initialization done.
I0428 20:38:36.004417  5142 solver.cpp:56] Solver scaffolding done.
I0428 20:38:36.004768  5142 caffe.cpp:248] Starting Optimization
I0428 20:38:36.004778  5142 solver.cpp:273] Solving LeNet
I0428 20:38:36.004781  5142 solver.cpp:274] Learning Rate Policy: inv
I0428 20:38:36.006402  5142 solver.cpp:331] Iteration 0, Testing net (#0)
I0428 20:38:36.137805  5149 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:38:36.140933  5142 solver.cpp:398]     Test net output #0: accuracy = 0.0783
I0428 20:38:36.140954  5142 solver.cpp:398]     Test net output #1: loss = 2.31694 (* 1 = 2.31694 loss)
I0428 20:38:36.146131  5142 solver.cpp:219] Iteration 0 (0 iter/s, 0.141319s/100 iters), loss = 2.31436
I0428 20:38:36.146153  5142 solver.cpp:238]     Train net output #0: loss = 2.31436 (* 1 = 2.31436 loss)
I0428 20:38:36.146179  5142 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0428 20:38:36.413640  5142 solver.cpp:219] Iteration 100 (373.878 iter/s, 0.267467s/100 iters), loss = 0.231368
I0428 20:38:36.413666  5142 solver.cpp:238]     Train net output #0: loss = 0.231368 (* 1 = 0.231368 loss)
I0428 20:38:36.413673  5142 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0428 20:38:36.682258  5142 solver.cpp:219] Iteration 200 (372.34 iter/s, 0.268572s/100 iters), loss = 0.124473
I0428 20:38:36.682293  5142 solver.cpp:238]     Train net output #0: loss = 0.124473 (* 1 = 0.124473 loss)
I0428 20:38:36.682301  5142 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0428 20:38:36.951130  5142 solver.cpp:219] Iteration 300 (371.998 iter/s, 0.268818s/100 iters), loss = 0.168819
I0428 20:38:36.951158  5142 solver.cpp:238]     Train net output #0: loss = 0.16882 (* 1 = 0.16882 loss)
I0428 20:38:36.951164  5142 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0428 20:38:37.219760  5142 solver.cpp:219] Iteration 400 (372.32 iter/s, 0.268586s/100 iters), loss = 0.0349315
I0428 20:38:37.219789  5142 solver.cpp:238]     Train net output #0: loss = 0.0349315 (* 1 = 0.0349315 loss)
I0428 20:38:37.219794  5142 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0428 20:38:37.488572  5142 solver.cpp:331] Iteration 500, Testing net (#0)
I0428 20:38:37.613266  5149 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:38:37.617957  5142 solver.cpp:398]     Test net output #0: accuracy = 0.9699
I0428 20:38:37.617980  5142 solver.cpp:398]     Test net output #1: loss = 0.0971837 (* 1 = 0.0971837 loss)
I0428 20:38:37.620563  5142 solver.cpp:219] Iteration 500 (249.532 iter/s, 0.400751s/100 iters), loss = 0.0462535
I0428 20:38:37.620586  5142 solver.cpp:238]     Train net output #0: loss = 0.0462535 (* 1 = 0.0462535 loss)
I0428 20:38:37.620623  5142 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0428 20:38:37.897090  5142 solver.cpp:219] Iteration 600 (361.688 iter/s, 0.276481s/100 iters), loss = 0.0792086
I0428 20:38:37.897127  5142 solver.cpp:238]     Train net output #0: loss = 0.0792085 (* 1 = 0.0792085 loss)
I0428 20:38:37.897135  5142 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0428 20:38:38.172118  5142 solver.cpp:219] Iteration 700 (363.67 iter/s, 0.274975s/100 iters), loss = 0.0960122
I0428 20:38:38.172145  5142 solver.cpp:238]     Train net output #0: loss = 0.0960122 (* 1 = 0.0960122 loss)
I0428 20:38:38.172152  5142 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0428 20:38:38.453258  5142 solver.cpp:219] Iteration 800 (355.754 iter/s, 0.281093s/100 iters), loss = 0.206102
I0428 20:38:38.453282  5142 solver.cpp:238]     Train net output #0: loss = 0.206102 (* 1 = 0.206102 loss)
I0428 20:38:38.453289  5142 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0428 20:38:38.735249  5142 solver.cpp:219] Iteration 900 (354.678 iter/s, 0.281946s/100 iters), loss = 0.090272
I0428 20:38:38.735287  5142 solver.cpp:238]     Train net output #0: loss = 0.0902719 (* 1 = 0.0902719 loss)
I0428 20:38:38.735309  5142 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0428 20:38:38.829439  5148 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:38:39.015471  5142 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_1000.caffemodel
I0428 20:38:39.020891  5142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_1000.solverstate
I0428 20:38:39.024006  5142 solver.cpp:311] Iteration 1000, loss = 0.127856
I0428 20:38:39.024022  5142 solver.cpp:331] Iteration 1000, Testing net (#0)
I0428 20:38:39.153076  5149 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:38:39.156919  5142 solver.cpp:398]     Test net output #0: accuracy = 0.9771
I0428 20:38:39.156942  5142 solver.cpp:398]     Test net output #1: loss = 0.074393 (* 1 = 0.074393 loss)
I0428 20:38:39.156949  5142 solver.cpp:316] Optimization Done.
I0428 20:38:39.156951  5142 caffe.cpp:259] Optimization Done.
