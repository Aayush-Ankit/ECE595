I0428 20:09:56.473955 31734 caffe.cpp:218] Using GPUs 0
I0428 20:09:56.503840 31734 caffe.cpp:223] GPU 0: TITAN X (Pascal)
I0428 20:09:56.948869 31734 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 1000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_everything2/lenet_train_test1122.prototxt"
train_state {
  level: 0
  stage: ""
}
I0428 20:09:56.949015 31734 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1122.prototxt
I0428 20:09:56.949357 31734 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0428 20:09:56.949385 31734 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0428 20:09:56.949479 31734 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:09:56.949544 31734 layer_factory.hpp:77] Creating layer mnist
I0428 20:09:56.949640 31734 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0428 20:09:56.949661 31734 net.cpp:86] Creating Layer mnist
I0428 20:09:56.949667 31734 net.cpp:382] mnist -> data
I0428 20:09:56.949687 31734 net.cpp:382] mnist -> label
I0428 20:09:56.950599 31734 data_layer.cpp:45] output data size: 64,1,28,28
I0428 20:09:56.952745 31734 net.cpp:124] Setting up mnist
I0428 20:09:56.952775 31734 net.cpp:131] Top shape: 64 1 28 28 (50176)
I0428 20:09:56.952781 31734 net.cpp:131] Top shape: 64 (64)
I0428 20:09:56.952783 31734 net.cpp:139] Memory required for data: 200960
I0428 20:09:56.952790 31734 layer_factory.hpp:77] Creating layer conv0
I0428 20:09:56.952801 31734 net.cpp:86] Creating Layer conv0
I0428 20:09:56.952838 31734 net.cpp:408] conv0 <- data
I0428 20:09:56.952880 31734 net.cpp:382] conv0 -> conv0
I0428 20:09:57.187252 31734 net.cpp:124] Setting up conv0
I0428 20:09:57.187278 31734 net.cpp:131] Top shape: 64 25 24 24 (921600)
I0428 20:09:57.187297 31734 net.cpp:139] Memory required for data: 3887360
I0428 20:09:57.187312 31734 layer_factory.hpp:77] Creating layer pool0
I0428 20:09:57.187325 31734 net.cpp:86] Creating Layer pool0
I0428 20:09:57.187328 31734 net.cpp:408] pool0 <- conv0
I0428 20:09:57.187333 31734 net.cpp:382] pool0 -> pool0
I0428 20:09:57.187391 31734 net.cpp:124] Setting up pool0
I0428 20:09:57.187397 31734 net.cpp:131] Top shape: 64 25 12 12 (230400)
I0428 20:09:57.187400 31734 net.cpp:139] Memory required for data: 4808960
I0428 20:09:57.187403 31734 layer_factory.hpp:77] Creating layer conv1
I0428 20:09:57.187413 31734 net.cpp:86] Creating Layer conv1
I0428 20:09:57.187417 31734 net.cpp:408] conv1 <- pool0
I0428 20:09:57.187420 31734 net.cpp:382] conv1 -> conv1
I0428 20:09:57.190352 31734 net.cpp:124] Setting up conv1
I0428 20:09:57.190382 31734 net.cpp:131] Top shape: 64 25 8 8 (102400)
I0428 20:09:57.190387 31734 net.cpp:139] Memory required for data: 5218560
I0428 20:09:57.190393 31734 layer_factory.hpp:77] Creating layer pool1
I0428 20:09:57.190400 31734 net.cpp:86] Creating Layer pool1
I0428 20:09:57.190404 31734 net.cpp:408] pool1 <- conv1
I0428 20:09:57.190408 31734 net.cpp:382] pool1 -> pool1
I0428 20:09:57.190459 31734 net.cpp:124] Setting up pool1
I0428 20:09:57.190464 31734 net.cpp:131] Top shape: 64 25 4 4 (25600)
I0428 20:09:57.190467 31734 net.cpp:139] Memory required for data: 5320960
I0428 20:09:57.190470 31734 layer_factory.hpp:77] Creating layer ip1
I0428 20:09:57.190476 31734 net.cpp:86] Creating Layer ip1
I0428 20:09:57.190479 31734 net.cpp:408] ip1 <- pool1
I0428 20:09:57.190485 31734 net.cpp:382] ip1 -> ip1
I0428 20:09:57.190702 31734 net.cpp:124] Setting up ip1
I0428 20:09:57.190711 31734 net.cpp:131] Top shape: 64 50 (3200)
I0428 20:09:57.190713 31734 net.cpp:139] Memory required for data: 5333760
I0428 20:09:57.190721 31734 layer_factory.hpp:77] Creating layer relu1
I0428 20:09:57.190726 31734 net.cpp:86] Creating Layer relu1
I0428 20:09:57.190731 31734 net.cpp:408] relu1 <- ip1
I0428 20:09:57.190734 31734 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:09:57.190912 31734 net.cpp:124] Setting up relu1
I0428 20:09:57.190922 31734 net.cpp:131] Top shape: 64 50 (3200)
I0428 20:09:57.190924 31734 net.cpp:139] Memory required for data: 5346560
I0428 20:09:57.190927 31734 layer_factory.hpp:77] Creating layer ip2
I0428 20:09:57.190932 31734 net.cpp:86] Creating Layer ip2
I0428 20:09:57.190935 31734 net.cpp:408] ip2 <- ip1
I0428 20:09:57.190940 31734 net.cpp:382] ip2 -> ip2
I0428 20:09:57.191031 31734 net.cpp:124] Setting up ip2
I0428 20:09:57.191037 31734 net.cpp:131] Top shape: 64 10 (640)
I0428 20:09:57.191040 31734 net.cpp:139] Memory required for data: 5349120
I0428 20:09:57.191045 31734 layer_factory.hpp:77] Creating layer relu2
I0428 20:09:57.191052 31734 net.cpp:86] Creating Layer relu2
I0428 20:09:57.191056 31734 net.cpp:408] relu2 <- ip2
I0428 20:09:57.191059 31734 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:09:57.191844 31734 net.cpp:124] Setting up relu2
I0428 20:09:57.191856 31734 net.cpp:131] Top shape: 64 10 (640)
I0428 20:09:57.191875 31734 net.cpp:139] Memory required for data: 5351680
I0428 20:09:57.191879 31734 layer_factory.hpp:77] Creating layer ip3
I0428 20:09:57.191885 31734 net.cpp:86] Creating Layer ip3
I0428 20:09:57.191889 31734 net.cpp:408] ip3 <- ip2
I0428 20:09:57.191893 31734 net.cpp:382] ip3 -> ip3
I0428 20:09:57.192000 31734 net.cpp:124] Setting up ip3
I0428 20:09:57.192008 31734 net.cpp:131] Top shape: 64 10 (640)
I0428 20:09:57.192010 31734 net.cpp:139] Memory required for data: 5354240
I0428 20:09:57.192018 31734 layer_factory.hpp:77] Creating layer relu3
I0428 20:09:57.192021 31734 net.cpp:86] Creating Layer relu3
I0428 20:09:57.192024 31734 net.cpp:408] relu3 <- ip3
I0428 20:09:57.192028 31734 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:09:57.192178 31734 net.cpp:124] Setting up relu3
I0428 20:09:57.192185 31734 net.cpp:131] Top shape: 64 10 (640)
I0428 20:09:57.192188 31734 net.cpp:139] Memory required for data: 5356800
I0428 20:09:57.192191 31734 layer_factory.hpp:77] Creating layer loss
I0428 20:09:57.192198 31734 net.cpp:86] Creating Layer loss
I0428 20:09:57.192200 31734 net.cpp:408] loss <- ip3
I0428 20:09:57.192203 31734 net.cpp:408] loss <- label
I0428 20:09:57.192224 31734 net.cpp:382] loss -> loss
I0428 20:09:57.192237 31734 layer_factory.hpp:77] Creating layer loss
I0428 20:09:57.192447 31734 net.cpp:124] Setting up loss
I0428 20:09:57.192456 31734 net.cpp:131] Top shape: (1)
I0428 20:09:57.192459 31734 net.cpp:134]     with loss weight 1
I0428 20:09:57.192472 31734 net.cpp:139] Memory required for data: 5356804
I0428 20:09:57.192476 31734 net.cpp:200] loss needs backward computation.
I0428 20:09:57.192479 31734 net.cpp:200] relu3 needs backward computation.
I0428 20:09:57.192482 31734 net.cpp:200] ip3 needs backward computation.
I0428 20:09:57.192486 31734 net.cpp:200] relu2 needs backward computation.
I0428 20:09:57.192487 31734 net.cpp:200] ip2 needs backward computation.
I0428 20:09:57.192490 31734 net.cpp:200] relu1 needs backward computation.
I0428 20:09:57.192493 31734 net.cpp:200] ip1 needs backward computation.
I0428 20:09:57.192495 31734 net.cpp:200] pool1 needs backward computation.
I0428 20:09:57.192498 31734 net.cpp:200] conv1 needs backward computation.
I0428 20:09:57.192502 31734 net.cpp:200] pool0 needs backward computation.
I0428 20:09:57.192505 31734 net.cpp:200] conv0 needs backward computation.
I0428 20:09:57.192508 31734 net.cpp:202] mnist does not need backward computation.
I0428 20:09:57.192510 31734 net.cpp:244] This network produces output loss
I0428 20:09:57.192519 31734 net.cpp:257] Network initialization done.
I0428 20:09:57.192899 31734 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1122.prototxt
I0428 20:09:57.192944 31734 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0428 20:09:57.193038 31734 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:09:57.193132 31734 layer_factory.hpp:77] Creating layer mnist
I0428 20:09:57.193203 31734 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0428 20:09:57.193217 31734 net.cpp:86] Creating Layer mnist
I0428 20:09:57.193222 31734 net.cpp:382] mnist -> data
I0428 20:09:57.193228 31734 net.cpp:382] mnist -> label
I0428 20:09:57.193308 31734 data_layer.cpp:45] output data size: 100,1,28,28
I0428 20:09:57.195231 31734 net.cpp:124] Setting up mnist
I0428 20:09:57.195274 31734 net.cpp:131] Top shape: 100 1 28 28 (78400)
I0428 20:09:57.195279 31734 net.cpp:131] Top shape: 100 (100)
I0428 20:09:57.195282 31734 net.cpp:139] Memory required for data: 314000
I0428 20:09:57.195286 31734 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0428 20:09:57.195291 31734 net.cpp:86] Creating Layer label_mnist_1_split
I0428 20:09:57.195294 31734 net.cpp:408] label_mnist_1_split <- label
I0428 20:09:57.195299 31734 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_0
I0428 20:09:57.195305 31734 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_1
I0428 20:09:57.195418 31734 net.cpp:124] Setting up label_mnist_1_split
I0428 20:09:57.195425 31734 net.cpp:131] Top shape: 100 (100)
I0428 20:09:57.195430 31734 net.cpp:131] Top shape: 100 (100)
I0428 20:09:57.195432 31734 net.cpp:139] Memory required for data: 314800
I0428 20:09:57.195436 31734 layer_factory.hpp:77] Creating layer conv0
I0428 20:09:57.195442 31734 net.cpp:86] Creating Layer conv0
I0428 20:09:57.195446 31734 net.cpp:408] conv0 <- data
I0428 20:09:57.195451 31734 net.cpp:382] conv0 -> conv0
I0428 20:09:57.197151 31734 net.cpp:124] Setting up conv0
I0428 20:09:57.197166 31734 net.cpp:131] Top shape: 100 25 24 24 (1440000)
I0428 20:09:57.197185 31734 net.cpp:139] Memory required for data: 6074800
I0428 20:09:57.197206 31734 layer_factory.hpp:77] Creating layer pool0
I0428 20:09:57.197222 31734 net.cpp:86] Creating Layer pool0
I0428 20:09:57.197226 31734 net.cpp:408] pool0 <- conv0
I0428 20:09:57.197230 31734 net.cpp:382] pool0 -> pool0
I0428 20:09:57.197266 31734 net.cpp:124] Setting up pool0
I0428 20:09:57.197271 31734 net.cpp:131] Top shape: 100 25 12 12 (360000)
I0428 20:09:57.197274 31734 net.cpp:139] Memory required for data: 7514800
I0428 20:09:57.197278 31734 layer_factory.hpp:77] Creating layer conv1
I0428 20:09:57.197285 31734 net.cpp:86] Creating Layer conv1
I0428 20:09:57.197288 31734 net.cpp:408] conv1 <- pool0
I0428 20:09:57.197293 31734 net.cpp:382] conv1 -> conv1
I0428 20:09:57.199394 31734 net.cpp:124] Setting up conv1
I0428 20:09:57.199410 31734 net.cpp:131] Top shape: 100 25 8 8 (160000)
I0428 20:09:57.199414 31734 net.cpp:139] Memory required for data: 8154800
I0428 20:09:57.199424 31734 layer_factory.hpp:77] Creating layer pool1
I0428 20:09:57.199429 31734 net.cpp:86] Creating Layer pool1
I0428 20:09:57.199432 31734 net.cpp:408] pool1 <- conv1
I0428 20:09:57.199446 31734 net.cpp:382] pool1 -> pool1
I0428 20:09:57.199486 31734 net.cpp:124] Setting up pool1
I0428 20:09:57.199498 31734 net.cpp:131] Top shape: 100 25 4 4 (40000)
I0428 20:09:57.199501 31734 net.cpp:139] Memory required for data: 8314800
I0428 20:09:57.199504 31734 layer_factory.hpp:77] Creating layer ip1
I0428 20:09:57.199512 31734 net.cpp:86] Creating Layer ip1
I0428 20:09:57.199514 31734 net.cpp:408] ip1 <- pool1
I0428 20:09:57.199524 31734 net.cpp:382] ip1 -> ip1
I0428 20:09:57.199769 31734 net.cpp:124] Setting up ip1
I0428 20:09:57.199776 31734 net.cpp:131] Top shape: 100 50 (5000)
I0428 20:09:57.199789 31734 net.cpp:139] Memory required for data: 8334800
I0428 20:09:57.199795 31734 layer_factory.hpp:77] Creating layer relu1
I0428 20:09:57.199800 31734 net.cpp:86] Creating Layer relu1
I0428 20:09:57.199803 31734 net.cpp:408] relu1 <- ip1
I0428 20:09:57.199807 31734 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:09:57.200060 31734 net.cpp:124] Setting up relu1
I0428 20:09:57.200070 31734 net.cpp:131] Top shape: 100 50 (5000)
I0428 20:09:57.200079 31734 net.cpp:139] Memory required for data: 8354800
I0428 20:09:57.200083 31734 layer_factory.hpp:77] Creating layer ip2
I0428 20:09:57.200089 31734 net.cpp:86] Creating Layer ip2
I0428 20:09:57.200093 31734 net.cpp:408] ip2 <- ip1
I0428 20:09:57.200098 31734 net.cpp:382] ip2 -> ip2
I0428 20:09:57.200198 31734 net.cpp:124] Setting up ip2
I0428 20:09:57.200206 31734 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:09:57.200209 31734 net.cpp:139] Memory required for data: 8358800
I0428 20:09:57.200214 31734 layer_factory.hpp:77] Creating layer relu2
I0428 20:09:57.200219 31734 net.cpp:86] Creating Layer relu2
I0428 20:09:57.200222 31734 net.cpp:408] relu2 <- ip2
I0428 20:09:57.200232 31734 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:09:57.200423 31734 net.cpp:124] Setting up relu2
I0428 20:09:57.200431 31734 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:09:57.200435 31734 net.cpp:139] Memory required for data: 8362800
I0428 20:09:57.200438 31734 layer_factory.hpp:77] Creating layer ip3
I0428 20:09:57.200444 31734 net.cpp:86] Creating Layer ip3
I0428 20:09:57.200448 31734 net.cpp:408] ip3 <- ip2
I0428 20:09:57.200454 31734 net.cpp:382] ip3 -> ip3
I0428 20:09:57.200554 31734 net.cpp:124] Setting up ip3
I0428 20:09:57.200562 31734 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:09:57.200572 31734 net.cpp:139] Memory required for data: 8366800
I0428 20:09:57.200579 31734 layer_factory.hpp:77] Creating layer relu3
I0428 20:09:57.200584 31734 net.cpp:86] Creating Layer relu3
I0428 20:09:57.200587 31734 net.cpp:408] relu3 <- ip3
I0428 20:09:57.200606 31734 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:09:57.201464 31734 net.cpp:124] Setting up relu3
I0428 20:09:57.201478 31734 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:09:57.201481 31734 net.cpp:139] Memory required for data: 8370800
I0428 20:09:57.201484 31734 layer_factory.hpp:77] Creating layer ip3_relu3_0_split
I0428 20:09:57.201489 31734 net.cpp:86] Creating Layer ip3_relu3_0_split
I0428 20:09:57.201493 31734 net.cpp:408] ip3_relu3_0_split <- ip3
I0428 20:09:57.201499 31734 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_0
I0428 20:09:57.201505 31734 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_1
I0428 20:09:57.201581 31734 net.cpp:124] Setting up ip3_relu3_0_split
I0428 20:09:57.201589 31734 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:09:57.201593 31734 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:09:57.201596 31734 net.cpp:139] Memory required for data: 8378800
I0428 20:09:57.201606 31734 layer_factory.hpp:77] Creating layer accuracy
I0428 20:09:57.201617 31734 net.cpp:86] Creating Layer accuracy
I0428 20:09:57.201618 31734 net.cpp:408] accuracy <- ip3_relu3_0_split_0
I0428 20:09:57.201622 31734 net.cpp:408] accuracy <- label_mnist_1_split_0
I0428 20:09:57.201627 31734 net.cpp:382] accuracy -> accuracy
I0428 20:09:57.201633 31734 net.cpp:124] Setting up accuracy
I0428 20:09:57.201637 31734 net.cpp:131] Top shape: (1)
I0428 20:09:57.201650 31734 net.cpp:139] Memory required for data: 8378804
I0428 20:09:57.201653 31734 layer_factory.hpp:77] Creating layer loss
I0428 20:09:57.201659 31734 net.cpp:86] Creating Layer loss
I0428 20:09:57.201663 31734 net.cpp:408] loss <- ip3_relu3_0_split_1
I0428 20:09:57.201666 31734 net.cpp:408] loss <- label_mnist_1_split_1
I0428 20:09:57.201670 31734 net.cpp:382] loss -> loss
I0428 20:09:57.201676 31734 layer_factory.hpp:77] Creating layer loss
I0428 20:09:57.201944 31734 net.cpp:124] Setting up loss
I0428 20:09:57.201954 31734 net.cpp:131] Top shape: (1)
I0428 20:09:57.201969 31734 net.cpp:134]     with loss weight 1
I0428 20:09:57.201984 31734 net.cpp:139] Memory required for data: 8378808
I0428 20:09:57.201988 31734 net.cpp:200] loss needs backward computation.
I0428 20:09:57.201992 31734 net.cpp:202] accuracy does not need backward computation.
I0428 20:09:57.201995 31734 net.cpp:200] ip3_relu3_0_split needs backward computation.
I0428 20:09:57.201998 31734 net.cpp:200] relu3 needs backward computation.
I0428 20:09:57.202000 31734 net.cpp:200] ip3 needs backward computation.
I0428 20:09:57.202003 31734 net.cpp:200] relu2 needs backward computation.
I0428 20:09:57.202006 31734 net.cpp:200] ip2 needs backward computation.
I0428 20:09:57.202009 31734 net.cpp:200] relu1 needs backward computation.
I0428 20:09:57.202011 31734 net.cpp:200] ip1 needs backward computation.
I0428 20:09:57.202029 31734 net.cpp:200] pool1 needs backward computation.
I0428 20:09:57.202033 31734 net.cpp:200] conv1 needs backward computation.
I0428 20:09:57.202042 31734 net.cpp:200] pool0 needs backward computation.
I0428 20:09:57.202045 31734 net.cpp:200] conv0 needs backward computation.
I0428 20:09:57.202049 31734 net.cpp:202] label_mnist_1_split does not need backward computation.
I0428 20:09:57.202052 31734 net.cpp:202] mnist does not need backward computation.
I0428 20:09:57.202069 31734 net.cpp:244] This network produces output accuracy
I0428 20:09:57.202072 31734 net.cpp:244] This network produces output loss
I0428 20:09:57.202088 31734 net.cpp:257] Network initialization done.
I0428 20:09:57.202126 31734 solver.cpp:56] Solver scaffolding done.
I0428 20:09:57.202427 31734 caffe.cpp:248] Starting Optimization
I0428 20:09:57.202433 31734 solver.cpp:273] Solving LeNet
I0428 20:09:57.202435 31734 solver.cpp:274] Learning Rate Policy: inv
I0428 20:09:57.203312 31734 solver.cpp:331] Iteration 0, Testing net (#0)
I0428 20:09:57.209272 31734 blocking_queue.cpp:49] Waiting for data
I0428 20:09:57.279117 31741 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:09:57.279737 31734 solver.cpp:398]     Test net output #0: accuracy = 0.0917
I0428 20:09:57.279757 31734 solver.cpp:398]     Test net output #1: loss = 2.33084 (* 1 = 2.33084 loss)
I0428 20:09:57.283566 31734 solver.cpp:219] Iteration 0 (0 iter/s, 0.0811049s/100 iters), loss = 2.30488
I0428 20:09:57.283591 31734 solver.cpp:238]     Train net output #0: loss = 2.30488 (* 1 = 2.30488 loss)
I0428 20:09:57.283602 31734 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0428 20:09:57.386631 31734 solver.cpp:219] Iteration 100 (970.622 iter/s, 0.103027s/100 iters), loss = 0.966541
I0428 20:09:57.386654 31734 solver.cpp:238]     Train net output #0: loss = 0.966541 (* 1 = 0.966541 loss)
I0428 20:09:57.386659 31734 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0428 20:09:57.493963 31734 solver.cpp:219] Iteration 200 (931.995 iter/s, 0.107297s/100 iters), loss = 0.646633
I0428 20:09:57.493994 31734 solver.cpp:238]     Train net output #0: loss = 0.646633 (* 1 = 0.646633 loss)
I0428 20:09:57.494000 31734 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0428 20:09:57.599850 31734 solver.cpp:219] Iteration 300 (944.771 iter/s, 0.105846s/100 iters), loss = 0.277349
I0428 20:09:57.599875 31734 solver.cpp:238]     Train net output #0: loss = 0.277349 (* 1 = 0.277349 loss)
I0428 20:09:57.599881 31734 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0428 20:09:57.701508 31734 solver.cpp:219] Iteration 400 (984.031 iter/s, 0.101623s/100 iters), loss = 0.192677
I0428 20:09:57.701534 31734 solver.cpp:238]     Train net output #0: loss = 0.192677 (* 1 = 0.192677 loss)
I0428 20:09:57.701539 31734 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0428 20:09:57.802233 31734 solver.cpp:331] Iteration 500, Testing net (#0)
I0428 20:09:57.858836 31741 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:09:57.859508 31734 solver.cpp:398]     Test net output #0: accuracy = 0.9578
I0428 20:09:57.859529 31734 solver.cpp:398]     Test net output #1: loss = 0.140197 (* 1 = 0.140197 loss)
I0428 20:09:57.860478 31734 solver.cpp:219] Iteration 500 (629.203 iter/s, 0.158931s/100 iters), loss = 0.113286
I0428 20:09:57.860529 31734 solver.cpp:238]     Train net output #0: loss = 0.113286 (* 1 = 0.113286 loss)
I0428 20:09:57.860538 31734 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0428 20:09:57.969898 31734 solver.cpp:219] Iteration 600 (914.429 iter/s, 0.109358s/100 iters), loss = 0.0794573
I0428 20:09:57.969934 31734 solver.cpp:238]     Train net output #0: loss = 0.0794573 (* 1 = 0.0794573 loss)
I0428 20:09:57.969949 31734 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0428 20:09:58.075510 31734 solver.cpp:219] Iteration 700 (947.273 iter/s, 0.105566s/100 iters), loss = 0.20473
I0428 20:09:58.075538 31734 solver.cpp:238]     Train net output #0: loss = 0.20473 (* 1 = 0.20473 loss)
I0428 20:09:58.075551 31734 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0428 20:09:58.187495 31734 solver.cpp:219] Iteration 800 (893.297 iter/s, 0.111945s/100 iters), loss = 0.234443
I0428 20:09:58.187528 31734 solver.cpp:238]     Train net output #0: loss = 0.234443 (* 1 = 0.234443 loss)
I0428 20:09:58.187541 31734 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0428 20:09:58.290596 31734 solver.cpp:219] Iteration 900 (970.315 iter/s, 0.103059s/100 iters), loss = 0.156723
I0428 20:09:58.290624 31734 solver.cpp:238]     Train net output #0: loss = 0.156723 (* 1 = 0.156723 loss)
I0428 20:09:58.290647 31734 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0428 20:09:58.326316 31740 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:09:58.400400 31734 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_1000.caffemodel
I0428 20:09:58.401918 31734 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_1000.solverstate
I0428 20:09:58.402766 31734 solver.cpp:311] Iteration 1000, loss = 0.152997
I0428 20:09:58.402786 31734 solver.cpp:331] Iteration 1000, Testing net (#0)
I0428 20:09:58.479301 31741 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:09:58.479930 31734 solver.cpp:398]     Test net output #0: accuracy = 0.9734
I0428 20:09:58.479950 31734 solver.cpp:398]     Test net output #1: loss = 0.0888819 (* 1 = 0.0888819 loss)
I0428 20:09:58.479956 31734 solver.cpp:316] Optimization Done.
I0428 20:09:58.479959 31734 caffe.cpp:259] Optimization Done.
