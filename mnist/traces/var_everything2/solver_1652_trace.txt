I0428 20:37:30.999866  4959 caffe.cpp:218] Using GPUs 0
I0428 20:37:31.029218  4959 caffe.cpp:223] GPU 0: TITAN X (Pascal)
I0428 20:37:31.477937  4959 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 1000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_everything2/lenet_train_test1652.prototxt"
train_state {
  level: 0
  stage: ""
}
I0428 20:37:31.478065  4959 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1652.prototxt
I0428 20:37:31.478407  4959 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0428 20:37:31.478437  4959 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0428 20:37:31.478516  4959 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:37:31.478577  4959 layer_factory.hpp:77] Creating layer mnist
I0428 20:37:31.478654  4959 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0428 20:37:31.478673  4959 net.cpp:86] Creating Layer mnist
I0428 20:37:31.478679  4959 net.cpp:382] mnist -> data
I0428 20:37:31.478698  4959 net.cpp:382] mnist -> label
I0428 20:37:31.479588  4959 data_layer.cpp:45] output data size: 64,1,28,28
I0428 20:37:31.481714  4959 net.cpp:124] Setting up mnist
I0428 20:37:31.481745  4959 net.cpp:131] Top shape: 64 1 28 28 (50176)
I0428 20:37:31.481750  4959 net.cpp:131] Top shape: 64 (64)
I0428 20:37:31.481751  4959 net.cpp:139] Memory required for data: 200960
I0428 20:37:31.481757  4959 layer_factory.hpp:77] Creating layer conv0
I0428 20:37:31.481786  4959 net.cpp:86] Creating Layer conv0
I0428 20:37:31.481802  4959 net.cpp:408] conv0 <- data
I0428 20:37:31.481813  4959 net.cpp:382] conv0 -> conv0
I0428 20:37:31.716467  4959 net.cpp:124] Setting up conv0
I0428 20:37:31.716495  4959 net.cpp:131] Top shape: 64 100 24 24 (3686400)
I0428 20:37:31.716498  4959 net.cpp:139] Memory required for data: 14946560
I0428 20:37:31.716512  4959 layer_factory.hpp:77] Creating layer pool0
I0428 20:37:31.716524  4959 net.cpp:86] Creating Layer pool0
I0428 20:37:31.716528  4959 net.cpp:408] pool0 <- conv0
I0428 20:37:31.716533  4959 net.cpp:382] pool0 -> pool0
I0428 20:37:31.716595  4959 net.cpp:124] Setting up pool0
I0428 20:37:31.716600  4959 net.cpp:131] Top shape: 64 100 12 12 (921600)
I0428 20:37:31.716603  4959 net.cpp:139] Memory required for data: 18632960
I0428 20:37:31.716606  4959 layer_factory.hpp:77] Creating layer conv1
I0428 20:37:31.716616  4959 net.cpp:86] Creating Layer conv1
I0428 20:37:31.716619  4959 net.cpp:408] conv1 <- pool0
I0428 20:37:31.716624  4959 net.cpp:382] conv1 -> conv1
I0428 20:37:31.720835  4959 net.cpp:124] Setting up conv1
I0428 20:37:31.720865  4959 net.cpp:131] Top shape: 64 100 8 8 (409600)
I0428 20:37:31.720868  4959 net.cpp:139] Memory required for data: 20271360
I0428 20:37:31.720876  4959 layer_factory.hpp:77] Creating layer pool1
I0428 20:37:31.720883  4959 net.cpp:86] Creating Layer pool1
I0428 20:37:31.720887  4959 net.cpp:408] pool1 <- conv1
I0428 20:37:31.720891  4959 net.cpp:382] pool1 -> pool1
I0428 20:37:31.720927  4959 net.cpp:124] Setting up pool1
I0428 20:37:31.720932  4959 net.cpp:131] Top shape: 64 100 4 4 (102400)
I0428 20:37:31.720934  4959 net.cpp:139] Memory required for data: 20680960
I0428 20:37:31.720937  4959 layer_factory.hpp:77] Creating layer ip1
I0428 20:37:31.720947  4959 net.cpp:86] Creating Layer ip1
I0428 20:37:31.720950  4959 net.cpp:408] ip1 <- pool1
I0428 20:37:31.720955  4959 net.cpp:382] ip1 -> ip1
I0428 20:37:31.721972  4959 net.cpp:124] Setting up ip1
I0428 20:37:31.721985  4959 net.cpp:131] Top shape: 64 10 (640)
I0428 20:37:31.721989  4959 net.cpp:139] Memory required for data: 20683520
I0428 20:37:31.722002  4959 layer_factory.hpp:77] Creating layer relu1
I0428 20:37:31.722007  4959 net.cpp:86] Creating Layer relu1
I0428 20:37:31.722010  4959 net.cpp:408] relu1 <- ip1
I0428 20:37:31.722015  4959 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:37:31.722206  4959 net.cpp:124] Setting up relu1
I0428 20:37:31.722214  4959 net.cpp:131] Top shape: 64 10 (640)
I0428 20:37:31.722218  4959 net.cpp:139] Memory required for data: 20686080
I0428 20:37:31.722220  4959 layer_factory.hpp:77] Creating layer ip2
I0428 20:37:31.722226  4959 net.cpp:86] Creating Layer ip2
I0428 20:37:31.722229  4959 net.cpp:408] ip2 <- ip1
I0428 20:37:31.722234  4959 net.cpp:382] ip2 -> ip2
I0428 20:37:31.722321  4959 net.cpp:124] Setting up ip2
I0428 20:37:31.722327  4959 net.cpp:131] Top shape: 64 10 (640)
I0428 20:37:31.722329  4959 net.cpp:139] Memory required for data: 20688640
I0428 20:37:31.722335  4959 layer_factory.hpp:77] Creating layer relu2
I0428 20:37:31.722340  4959 net.cpp:86] Creating Layer relu2
I0428 20:37:31.722343  4959 net.cpp:408] relu2 <- ip2
I0428 20:37:31.722347  4959 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:37:31.723019  4959 net.cpp:124] Setting up relu2
I0428 20:37:31.723031  4959 net.cpp:131] Top shape: 64 10 (640)
I0428 20:37:31.723044  4959 net.cpp:139] Memory required for data: 20691200
I0428 20:37:31.723047  4959 layer_factory.hpp:77] Creating layer ip3
I0428 20:37:31.723054  4959 net.cpp:86] Creating Layer ip3
I0428 20:37:31.723057  4959 net.cpp:408] ip3 <- ip2
I0428 20:37:31.723062  4959 net.cpp:382] ip3 -> ip3
I0428 20:37:31.723186  4959 net.cpp:124] Setting up ip3
I0428 20:37:31.723193  4959 net.cpp:131] Top shape: 64 10 (640)
I0428 20:37:31.723196  4959 net.cpp:139] Memory required for data: 20693760
I0428 20:37:31.723203  4959 layer_factory.hpp:77] Creating layer relu3
I0428 20:37:31.723208  4959 net.cpp:86] Creating Layer relu3
I0428 20:37:31.723212  4959 net.cpp:408] relu3 <- ip3
I0428 20:37:31.723230  4959 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:37:31.723379  4959 net.cpp:124] Setting up relu3
I0428 20:37:31.723388  4959 net.cpp:131] Top shape: 64 10 (640)
I0428 20:37:31.723392  4959 net.cpp:139] Memory required for data: 20696320
I0428 20:37:31.723394  4959 layer_factory.hpp:77] Creating layer loss
I0428 20:37:31.723400  4959 net.cpp:86] Creating Layer loss
I0428 20:37:31.723403  4959 net.cpp:408] loss <- ip3
I0428 20:37:31.723407  4959 net.cpp:408] loss <- label
I0428 20:37:31.723412  4959 net.cpp:382] loss -> loss
I0428 20:37:31.723429  4959 layer_factory.hpp:77] Creating layer loss
I0428 20:37:31.723667  4959 net.cpp:124] Setting up loss
I0428 20:37:31.723676  4959 net.cpp:131] Top shape: (1)
I0428 20:37:31.723680  4959 net.cpp:134]     with loss weight 1
I0428 20:37:31.723692  4959 net.cpp:139] Memory required for data: 20696324
I0428 20:37:31.723695  4959 net.cpp:200] loss needs backward computation.
I0428 20:37:31.723700  4959 net.cpp:200] relu3 needs backward computation.
I0428 20:37:31.723701  4959 net.cpp:200] ip3 needs backward computation.
I0428 20:37:31.723704  4959 net.cpp:200] relu2 needs backward computation.
I0428 20:37:31.723707  4959 net.cpp:200] ip2 needs backward computation.
I0428 20:37:31.723711  4959 net.cpp:200] relu1 needs backward computation.
I0428 20:37:31.723712  4959 net.cpp:200] ip1 needs backward computation.
I0428 20:37:31.723716  4959 net.cpp:200] pool1 needs backward computation.
I0428 20:37:31.723718  4959 net.cpp:200] conv1 needs backward computation.
I0428 20:37:31.723721  4959 net.cpp:200] pool0 needs backward computation.
I0428 20:37:31.723723  4959 net.cpp:200] conv0 needs backward computation.
I0428 20:37:31.723727  4959 net.cpp:202] mnist does not need backward computation.
I0428 20:37:31.723729  4959 net.cpp:244] This network produces output loss
I0428 20:37:31.723738  4959 net.cpp:257] Network initialization done.
I0428 20:37:31.724097  4959 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1652.prototxt
I0428 20:37:31.724134  4959 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0428 20:37:31.724226  4959 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:37:31.724303  4959 layer_factory.hpp:77] Creating layer mnist
I0428 20:37:31.724376  4959 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0428 20:37:31.724388  4959 net.cpp:86] Creating Layer mnist
I0428 20:37:31.724392  4959 net.cpp:382] mnist -> data
I0428 20:37:31.724414  4959 net.cpp:382] mnist -> label
I0428 20:37:31.724494  4959 data_layer.cpp:45] output data size: 100,1,28,28
I0428 20:37:31.726413  4959 net.cpp:124] Setting up mnist
I0428 20:37:31.726442  4959 net.cpp:131] Top shape: 100 1 28 28 (78400)
I0428 20:37:31.726447  4959 net.cpp:131] Top shape: 100 (100)
I0428 20:37:31.726451  4959 net.cpp:139] Memory required for data: 314000
I0428 20:37:31.726454  4959 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0428 20:37:31.726481  4959 net.cpp:86] Creating Layer label_mnist_1_split
I0428 20:37:31.726487  4959 net.cpp:408] label_mnist_1_split <- label
I0428 20:37:31.726492  4959 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_0
I0428 20:37:31.726500  4959 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_1
I0428 20:37:31.726541  4959 net.cpp:124] Setting up label_mnist_1_split
I0428 20:37:31.726547  4959 net.cpp:131] Top shape: 100 (100)
I0428 20:37:31.726550  4959 net.cpp:131] Top shape: 100 (100)
I0428 20:37:31.726553  4959 net.cpp:139] Memory required for data: 314800
I0428 20:37:31.726557  4959 layer_factory.hpp:77] Creating layer conv0
I0428 20:37:31.726564  4959 net.cpp:86] Creating Layer conv0
I0428 20:37:31.726567  4959 net.cpp:408] conv0 <- data
I0428 20:37:31.726572  4959 net.cpp:382] conv0 -> conv0
I0428 20:37:31.728416  4959 net.cpp:124] Setting up conv0
I0428 20:37:31.728446  4959 net.cpp:131] Top shape: 100 100 24 24 (5760000)
I0428 20:37:31.728448  4959 net.cpp:139] Memory required for data: 23354800
I0428 20:37:31.728457  4959 layer_factory.hpp:77] Creating layer pool0
I0428 20:37:31.728464  4959 net.cpp:86] Creating Layer pool0
I0428 20:37:31.728467  4959 net.cpp:408] pool0 <- conv0
I0428 20:37:31.728472  4959 net.cpp:382] pool0 -> pool0
I0428 20:37:31.728518  4959 net.cpp:124] Setting up pool0
I0428 20:37:31.728523  4959 net.cpp:131] Top shape: 100 100 12 12 (1440000)
I0428 20:37:31.728526  4959 net.cpp:139] Memory required for data: 29114800
I0428 20:37:31.728529  4959 layer_factory.hpp:77] Creating layer conv1
I0428 20:37:31.728538  4959 net.cpp:86] Creating Layer conv1
I0428 20:37:31.728540  4959 net.cpp:408] conv1 <- pool0
I0428 20:37:31.728545  4959 net.cpp:382] conv1 -> conv1
I0428 20:37:31.731650  4959 net.cpp:124] Setting up conv1
I0428 20:37:31.731679  4959 net.cpp:131] Top shape: 100 100 8 8 (640000)
I0428 20:37:31.731683  4959 net.cpp:139] Memory required for data: 31674800
I0428 20:37:31.731691  4959 layer_factory.hpp:77] Creating layer pool1
I0428 20:37:31.731699  4959 net.cpp:86] Creating Layer pool1
I0428 20:37:31.731703  4959 net.cpp:408] pool1 <- conv1
I0428 20:37:31.731709  4959 net.cpp:382] pool1 -> pool1
I0428 20:37:31.731755  4959 net.cpp:124] Setting up pool1
I0428 20:37:31.731761  4959 net.cpp:131] Top shape: 100 100 4 4 (160000)
I0428 20:37:31.731765  4959 net.cpp:139] Memory required for data: 32314800
I0428 20:37:31.731768  4959 layer_factory.hpp:77] Creating layer ip1
I0428 20:37:31.731775  4959 net.cpp:86] Creating Layer ip1
I0428 20:37:31.731777  4959 net.cpp:408] ip1 <- pool1
I0428 20:37:31.731782  4959 net.cpp:382] ip1 -> ip1
I0428 20:37:31.731971  4959 net.cpp:124] Setting up ip1
I0428 20:37:31.731988  4959 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:37:31.731992  4959 net.cpp:139] Memory required for data: 32318800
I0428 20:37:31.731999  4959 layer_factory.hpp:77] Creating layer relu1
I0428 20:37:31.732004  4959 net.cpp:86] Creating Layer relu1
I0428 20:37:31.732014  4959 net.cpp:408] relu1 <- ip1
I0428 20:37:31.732018  4959 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:37:31.732178  4959 net.cpp:124] Setting up relu1
I0428 20:37:31.732187  4959 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:37:31.732190  4959 net.cpp:139] Memory required for data: 32322800
I0428 20:37:31.732193  4959 layer_factory.hpp:77] Creating layer ip2
I0428 20:37:31.732201  4959 net.cpp:86] Creating Layer ip2
I0428 20:37:31.732204  4959 net.cpp:408] ip2 <- ip1
I0428 20:37:31.732208  4959 net.cpp:382] ip2 -> ip2
I0428 20:37:31.732321  4959 net.cpp:124] Setting up ip2
I0428 20:37:31.732328  4959 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:37:31.732331  4959 net.cpp:139] Memory required for data: 32326800
I0428 20:37:31.732337  4959 layer_factory.hpp:77] Creating layer relu2
I0428 20:37:31.732342  4959 net.cpp:86] Creating Layer relu2
I0428 20:37:31.732345  4959 net.cpp:408] relu2 <- ip2
I0428 20:37:31.732349  4959 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:37:31.732558  4959 net.cpp:124] Setting up relu2
I0428 20:37:31.732566  4959 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:37:31.732569  4959 net.cpp:139] Memory required for data: 32330800
I0428 20:37:31.732573  4959 layer_factory.hpp:77] Creating layer ip3
I0428 20:37:31.732579  4959 net.cpp:86] Creating Layer ip3
I0428 20:37:31.732583  4959 net.cpp:408] ip3 <- ip2
I0428 20:37:31.732587  4959 net.cpp:382] ip3 -> ip3
I0428 20:37:31.732709  4959 net.cpp:124] Setting up ip3
I0428 20:37:31.732717  4959 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:37:31.732720  4959 net.cpp:139] Memory required for data: 32334800
I0428 20:37:31.732728  4959 layer_factory.hpp:77] Creating layer relu3
I0428 20:37:31.732733  4959 net.cpp:86] Creating Layer relu3
I0428 20:37:31.732734  4959 net.cpp:408] relu3 <- ip3
I0428 20:37:31.732738  4959 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:37:31.733590  4959 net.cpp:124] Setting up relu3
I0428 20:37:31.733606  4959 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:37:31.733609  4959 net.cpp:139] Memory required for data: 32338800
I0428 20:37:31.733613  4959 layer_factory.hpp:77] Creating layer ip3_relu3_0_split
I0428 20:37:31.733619  4959 net.cpp:86] Creating Layer ip3_relu3_0_split
I0428 20:37:31.733623  4959 net.cpp:408] ip3_relu3_0_split <- ip3
I0428 20:37:31.733628  4959 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_0
I0428 20:37:31.733634  4959 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_1
I0428 20:37:31.733674  4959 net.cpp:124] Setting up ip3_relu3_0_split
I0428 20:37:31.733680  4959 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:37:31.733685  4959 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:37:31.733687  4959 net.cpp:139] Memory required for data: 32346800
I0428 20:37:31.733690  4959 layer_factory.hpp:77] Creating layer accuracy
I0428 20:37:31.733696  4959 net.cpp:86] Creating Layer accuracy
I0428 20:37:31.733700  4959 net.cpp:408] accuracy <- ip3_relu3_0_split_0
I0428 20:37:31.733703  4959 net.cpp:408] accuracy <- label_mnist_1_split_0
I0428 20:37:31.733708  4959 net.cpp:382] accuracy -> accuracy
I0428 20:37:31.733716  4959 net.cpp:124] Setting up accuracy
I0428 20:37:31.733719  4959 net.cpp:131] Top shape: (1)
I0428 20:37:31.733722  4959 net.cpp:139] Memory required for data: 32346804
I0428 20:37:31.733731  4959 layer_factory.hpp:77] Creating layer loss
I0428 20:37:31.733736  4959 net.cpp:86] Creating Layer loss
I0428 20:37:31.733739  4959 net.cpp:408] loss <- ip3_relu3_0_split_1
I0428 20:37:31.733743  4959 net.cpp:408] loss <- label_mnist_1_split_1
I0428 20:37:31.733747  4959 net.cpp:382] loss -> loss
I0428 20:37:31.733753  4959 layer_factory.hpp:77] Creating layer loss
I0428 20:37:31.733991  4959 net.cpp:124] Setting up loss
I0428 20:37:31.734017  4959 net.cpp:131] Top shape: (1)
I0428 20:37:31.734020  4959 net.cpp:134]     with loss weight 1
I0428 20:37:31.734035  4959 net.cpp:139] Memory required for data: 32346808
I0428 20:37:31.734038  4959 net.cpp:200] loss needs backward computation.
I0428 20:37:31.734048  4959 net.cpp:202] accuracy does not need backward computation.
I0428 20:37:31.734051  4959 net.cpp:200] ip3_relu3_0_split needs backward computation.
I0428 20:37:31.734055  4959 net.cpp:200] relu3 needs backward computation.
I0428 20:37:31.734058  4959 net.cpp:200] ip3 needs backward computation.
I0428 20:37:31.734061  4959 net.cpp:200] relu2 needs backward computation.
I0428 20:37:31.734063  4959 net.cpp:200] ip2 needs backward computation.
I0428 20:37:31.734067  4959 net.cpp:200] relu1 needs backward computation.
I0428 20:37:31.734069  4959 net.cpp:200] ip1 needs backward computation.
I0428 20:37:31.734072  4959 net.cpp:200] pool1 needs backward computation.
I0428 20:37:31.734081  4959 net.cpp:200] conv1 needs backward computation.
I0428 20:37:31.734083  4959 net.cpp:200] pool0 needs backward computation.
I0428 20:37:31.734103  4959 net.cpp:200] conv0 needs backward computation.
I0428 20:37:31.734107  4959 net.cpp:202] label_mnist_1_split does not need backward computation.
I0428 20:37:31.734110  4959 net.cpp:202] mnist does not need backward computation.
I0428 20:37:31.734112  4959 net.cpp:244] This network produces output accuracy
I0428 20:37:31.734117  4959 net.cpp:244] This network produces output loss
I0428 20:37:31.734128  4959 net.cpp:257] Network initialization done.
I0428 20:37:31.734169  4959 solver.cpp:56] Solver scaffolding done.
I0428 20:37:31.734581  4959 caffe.cpp:248] Starting Optimization
I0428 20:37:31.734587  4959 solver.cpp:273] Solving LeNet
I0428 20:37:31.734591  4959 solver.cpp:274] Learning Rate Policy: inv
I0428 20:37:31.735358  4959 solver.cpp:331] Iteration 0, Testing net (#0)
I0428 20:37:31.866143  4971 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:37:31.869690  4959 solver.cpp:398]     Test net output #0: accuracy = 0.135
I0428 20:37:31.869724  4959 solver.cpp:398]     Test net output #1: loss = 2.29771 (* 1 = 2.29771 loss)
I0428 20:37:31.875198  4959 solver.cpp:219] Iteration 0 (-3.07985e-31 iter/s, 0.140574s/100 iters), loss = 2.29279
I0428 20:37:31.875236  4959 solver.cpp:238]     Train net output #0: loss = 2.29279 (* 1 = 2.29279 loss)
I0428 20:37:31.875247  4959 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0428 20:37:32.137606  4959 solver.cpp:219] Iteration 100 (381.148 iter/s, 0.262365s/100 iters), loss = 1.10395
I0428 20:37:32.137647  4959 solver.cpp:238]     Train net output #0: loss = 1.10395 (* 1 = 1.10395 loss)
I0428 20:37:32.137653  4959 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0428 20:37:32.398052  4959 solver.cpp:219] Iteration 200 (384.044 iter/s, 0.260387s/100 iters), loss = 1.03972
I0428 20:37:32.398093  4959 solver.cpp:238]     Train net output #0: loss = 1.03972 (* 1 = 1.03972 loss)
I0428 20:37:32.398099  4959 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0428 20:37:32.668261  4959 solver.cpp:219] Iteration 300 (370.165 iter/s, 0.27015s/100 iters), loss = 0.637757
I0428 20:37:32.668299  4959 solver.cpp:238]     Train net output #0: loss = 0.637757 (* 1 = 0.637757 loss)
I0428 20:37:32.668305  4959 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0428 20:37:32.928249  4959 solver.cpp:219] Iteration 400 (384.693 iter/s, 0.259947s/100 iters), loss = 0.868622
I0428 20:37:32.928288  4959 solver.cpp:238]     Train net output #0: loss = 0.868622 (* 1 = 0.868622 loss)
I0428 20:37:32.928294  4959 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0428 20:37:33.184095  4959 solver.cpp:331] Iteration 500, Testing net (#0)
I0428 20:37:33.306646  4971 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:37:33.311183  4959 solver.cpp:398]     Test net output #0: accuracy = 0.7151
I0428 20:37:33.311218  4959 solver.cpp:398]     Test net output #1: loss = 0.870838 (* 1 = 0.870838 loss)
I0428 20:37:33.313653  4959 solver.cpp:219] Iteration 500 (259.5 iter/s, 0.385357s/100 iters), loss = 0.930933
I0428 20:37:33.313691  4959 solver.cpp:238]     Train net output #0: loss = 0.930933 (* 1 = 0.930933 loss)
I0428 20:37:33.313714  4959 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0428 20:37:33.573215  4959 solver.cpp:219] Iteration 600 (385.359 iter/s, 0.259498s/100 iters), loss = 0.811553
I0428 20:37:33.573287  4959 solver.cpp:238]     Train net output #0: loss = 0.811553 (* 1 = 0.811553 loss)
I0428 20:37:33.573300  4959 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0428 20:37:33.853437  4959 solver.cpp:219] Iteration 700 (356.972 iter/s, 0.280134s/100 iters), loss = 0.999957
I0428 20:37:33.853492  4959 solver.cpp:238]     Train net output #0: loss = 0.999957 (* 1 = 0.999957 loss)
I0428 20:37:33.853503  4959 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0428 20:37:34.128057  4959 solver.cpp:219] Iteration 800 (364.229 iter/s, 0.274553s/100 iters), loss = 0.857018
I0428 20:37:34.128106  4959 solver.cpp:238]     Train net output #0: loss = 0.857018 (* 1 = 0.857018 loss)
I0428 20:37:34.128118  4959 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0428 20:37:34.403734  4959 solver.cpp:219] Iteration 900 (362.821 iter/s, 0.275618s/100 iters), loss = 0.791071
I0428 20:37:34.403784  4959 solver.cpp:238]     Train net output #0: loss = 0.791071 (* 1 = 0.791071 loss)
I0428 20:37:34.403794  4959 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0428 20:37:34.492045  4969 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:37:34.665776  4959 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_1000.caffemodel
I0428 20:37:34.671702  4959 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_1000.solverstate
I0428 20:37:34.675045  4959 solver.cpp:311] Iteration 1000, loss = 0.978238
I0428 20:37:34.675065  4959 solver.cpp:331] Iteration 1000, Testing net (#0)
I0428 20:37:34.808331  4971 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:37:34.813282  4959 solver.cpp:398]     Test net output #0: accuracy = 0.7659
I0428 20:37:34.813314  4959 solver.cpp:398]     Test net output #1: loss = 0.817361 (* 1 = 0.817361 loss)
I0428 20:37:34.813321  4959 solver.cpp:316] Optimization Done.
I0428 20:37:34.813326  4959 caffe.cpp:259] Optimization Done.
