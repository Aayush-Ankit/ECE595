I0428 20:11:27.702857 32074 caffe.cpp:218] Using GPUs 0
I0428 20:11:27.731309 32074 caffe.cpp:223] GPU 0: TITAN X (Pascal)
I0428 20:11:28.167279 32074 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 1000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_everything2/lenet_train_test1159.prototxt"
train_state {
  level: 0
  stage: ""
}
I0428 20:11:28.167415 32074 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1159.prototxt
I0428 20:11:28.167757 32074 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0428 20:11:28.167786 32074 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0428 20:11:28.167866 32074 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:11:28.167944 32074 layer_factory.hpp:77] Creating layer mnist
I0428 20:11:28.168026 32074 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0428 20:11:28.168045 32074 net.cpp:86] Creating Layer mnist
I0428 20:11:28.168052 32074 net.cpp:382] mnist -> data
I0428 20:11:28.168071 32074 net.cpp:382] mnist -> label
I0428 20:11:28.168982 32074 data_layer.cpp:45] output data size: 64,1,28,28
I0428 20:11:28.171212 32074 net.cpp:124] Setting up mnist
I0428 20:11:28.171243 32074 net.cpp:131] Top shape: 64 1 28 28 (50176)
I0428 20:11:28.171248 32074 net.cpp:131] Top shape: 64 (64)
I0428 20:11:28.171252 32074 net.cpp:139] Memory required for data: 200960
I0428 20:11:28.171257 32074 layer_factory.hpp:77] Creating layer conv0
I0428 20:11:28.171272 32074 net.cpp:86] Creating Layer conv0
I0428 20:11:28.171288 32074 net.cpp:408] conv0 <- data
I0428 20:11:28.171300 32074 net.cpp:382] conv0 -> conv0
I0428 20:11:28.398257 32074 net.cpp:124] Setting up conv0
I0428 20:11:28.398283 32074 net.cpp:131] Top shape: 64 25 24 24 (921600)
I0428 20:11:28.398286 32074 net.cpp:139] Memory required for data: 3887360
I0428 20:11:28.398299 32074 layer_factory.hpp:77] Creating layer pool0
I0428 20:11:28.398326 32074 net.cpp:86] Creating Layer pool0
I0428 20:11:28.398331 32074 net.cpp:408] pool0 <- conv0
I0428 20:11:28.398336 32074 net.cpp:382] pool0 -> pool0
I0428 20:11:28.398386 32074 net.cpp:124] Setting up pool0
I0428 20:11:28.398391 32074 net.cpp:131] Top shape: 64 25 12 12 (230400)
I0428 20:11:28.398392 32074 net.cpp:139] Memory required for data: 4808960
I0428 20:11:28.398396 32074 layer_factory.hpp:77] Creating layer conv1
I0428 20:11:28.398406 32074 net.cpp:86] Creating Layer conv1
I0428 20:11:28.398408 32074 net.cpp:408] conv1 <- pool0
I0428 20:11:28.398413 32074 net.cpp:382] conv1 -> conv1
I0428 20:11:28.400459 32074 net.cpp:124] Setting up conv1
I0428 20:11:28.400472 32074 net.cpp:131] Top shape: 64 50 8 8 (204800)
I0428 20:11:28.400477 32074 net.cpp:139] Memory required for data: 5628160
I0428 20:11:28.400486 32074 layer_factory.hpp:77] Creating layer pool1
I0428 20:11:28.400493 32074 net.cpp:86] Creating Layer pool1
I0428 20:11:28.400497 32074 net.cpp:408] pool1 <- conv1
I0428 20:11:28.400502 32074 net.cpp:382] pool1 -> pool1
I0428 20:11:28.400537 32074 net.cpp:124] Setting up pool1
I0428 20:11:28.400542 32074 net.cpp:131] Top shape: 64 50 4 4 (51200)
I0428 20:11:28.400545 32074 net.cpp:139] Memory required for data: 5832960
I0428 20:11:28.400548 32074 layer_factory.hpp:77] Creating layer ip1
I0428 20:11:28.400555 32074 net.cpp:86] Creating Layer ip1
I0428 20:11:28.400558 32074 net.cpp:408] ip1 <- pool1
I0428 20:11:28.400563 32074 net.cpp:382] ip1 -> ip1
I0428 20:11:28.400807 32074 net.cpp:124] Setting up ip1
I0428 20:11:28.400821 32074 net.cpp:131] Top shape: 64 25 (1600)
I0428 20:11:28.400825 32074 net.cpp:139] Memory required for data: 5839360
I0428 20:11:28.400831 32074 layer_factory.hpp:77] Creating layer relu1
I0428 20:11:28.400836 32074 net.cpp:86] Creating Layer relu1
I0428 20:11:28.400840 32074 net.cpp:408] relu1 <- ip1
I0428 20:11:28.400845 32074 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:11:28.401000 32074 net.cpp:124] Setting up relu1
I0428 20:11:28.401008 32074 net.cpp:131] Top shape: 64 25 (1600)
I0428 20:11:28.401011 32074 net.cpp:139] Memory required for data: 5845760
I0428 20:11:28.401015 32074 layer_factory.hpp:77] Creating layer ip2
I0428 20:11:28.401021 32074 net.cpp:86] Creating Layer ip2
I0428 20:11:28.401023 32074 net.cpp:408] ip2 <- ip1
I0428 20:11:28.401027 32074 net.cpp:382] ip2 -> ip2
I0428 20:11:28.402001 32074 net.cpp:124] Setting up ip2
I0428 20:11:28.402014 32074 net.cpp:131] Top shape: 64 50 (3200)
I0428 20:11:28.402032 32074 net.cpp:139] Memory required for data: 5858560
I0428 20:11:28.402039 32074 layer_factory.hpp:77] Creating layer relu2
I0428 20:11:28.402045 32074 net.cpp:86] Creating Layer relu2
I0428 20:11:28.402048 32074 net.cpp:408] relu2 <- ip2
I0428 20:11:28.402053 32074 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:11:28.402868 32074 net.cpp:124] Setting up relu2
I0428 20:11:28.402880 32074 net.cpp:131] Top shape: 64 50 (3200)
I0428 20:11:28.402899 32074 net.cpp:139] Memory required for data: 5871360
I0428 20:11:28.402904 32074 layer_factory.hpp:77] Creating layer ip3
I0428 20:11:28.402910 32074 net.cpp:86] Creating Layer ip3
I0428 20:11:28.402915 32074 net.cpp:408] ip3 <- ip2
I0428 20:11:28.402935 32074 net.cpp:382] ip3 -> ip3
I0428 20:11:28.403051 32074 net.cpp:124] Setting up ip3
I0428 20:11:28.403059 32074 net.cpp:131] Top shape: 64 10 (640)
I0428 20:11:28.403061 32074 net.cpp:139] Memory required for data: 5873920
I0428 20:11:28.403069 32074 layer_factory.hpp:77] Creating layer relu3
I0428 20:11:28.403074 32074 net.cpp:86] Creating Layer relu3
I0428 20:11:28.403077 32074 net.cpp:408] relu3 <- ip3
I0428 20:11:28.403081 32074 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:11:28.403259 32074 net.cpp:124] Setting up relu3
I0428 20:11:28.403266 32074 net.cpp:131] Top shape: 64 10 (640)
I0428 20:11:28.403270 32074 net.cpp:139] Memory required for data: 5876480
I0428 20:11:28.403273 32074 layer_factory.hpp:77] Creating layer loss
I0428 20:11:28.403278 32074 net.cpp:86] Creating Layer loss
I0428 20:11:28.403282 32074 net.cpp:408] loss <- ip3
I0428 20:11:28.403285 32074 net.cpp:408] loss <- label
I0428 20:11:28.403290 32074 net.cpp:382] loss -> loss
I0428 20:11:28.403308 32074 layer_factory.hpp:77] Creating layer loss
I0428 20:11:28.403534 32074 net.cpp:124] Setting up loss
I0428 20:11:28.403543 32074 net.cpp:131] Top shape: (1)
I0428 20:11:28.403547 32074 net.cpp:134]     with loss weight 1
I0428 20:11:28.403559 32074 net.cpp:139] Memory required for data: 5876484
I0428 20:11:28.403563 32074 net.cpp:200] loss needs backward computation.
I0428 20:11:28.403566 32074 net.cpp:200] relu3 needs backward computation.
I0428 20:11:28.403569 32074 net.cpp:200] ip3 needs backward computation.
I0428 20:11:28.403573 32074 net.cpp:200] relu2 needs backward computation.
I0428 20:11:28.403574 32074 net.cpp:200] ip2 needs backward computation.
I0428 20:11:28.403578 32074 net.cpp:200] relu1 needs backward computation.
I0428 20:11:28.403580 32074 net.cpp:200] ip1 needs backward computation.
I0428 20:11:28.403584 32074 net.cpp:200] pool1 needs backward computation.
I0428 20:11:28.403585 32074 net.cpp:200] conv1 needs backward computation.
I0428 20:11:28.403604 32074 net.cpp:200] pool0 needs backward computation.
I0428 20:11:28.403607 32074 net.cpp:200] conv0 needs backward computation.
I0428 20:11:28.403610 32074 net.cpp:202] mnist does not need backward computation.
I0428 20:11:28.403614 32074 net.cpp:244] This network produces output loss
I0428 20:11:28.403622 32074 net.cpp:257] Network initialization done.
I0428 20:11:28.404012 32074 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1159.prototxt
I0428 20:11:28.404053 32074 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0428 20:11:28.404157 32074 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:11:28.404233 32074 layer_factory.hpp:77] Creating layer mnist
I0428 20:11:28.404275 32074 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0428 20:11:28.404291 32074 net.cpp:86] Creating Layer mnist
I0428 20:11:28.404295 32074 net.cpp:382] mnist -> data
I0428 20:11:28.404304 32074 net.cpp:382] mnist -> label
I0428 20:11:28.404383 32074 data_layer.cpp:45] output data size: 100,1,28,28
I0428 20:11:28.406397 32074 net.cpp:124] Setting up mnist
I0428 20:11:28.406426 32074 net.cpp:131] Top shape: 100 1 28 28 (78400)
I0428 20:11:28.406448 32074 net.cpp:131] Top shape: 100 (100)
I0428 20:11:28.406451 32074 net.cpp:139] Memory required for data: 314000
I0428 20:11:28.406455 32074 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0428 20:11:28.406461 32074 net.cpp:86] Creating Layer label_mnist_1_split
I0428 20:11:28.406464 32074 net.cpp:408] label_mnist_1_split <- label
I0428 20:11:28.406469 32074 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_0
I0428 20:11:28.406476 32074 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_1
I0428 20:11:28.406517 32074 net.cpp:124] Setting up label_mnist_1_split
I0428 20:11:28.406522 32074 net.cpp:131] Top shape: 100 (100)
I0428 20:11:28.406527 32074 net.cpp:131] Top shape: 100 (100)
I0428 20:11:28.406528 32074 net.cpp:139] Memory required for data: 314800
I0428 20:11:28.406532 32074 layer_factory.hpp:77] Creating layer conv0
I0428 20:11:28.406539 32074 net.cpp:86] Creating Layer conv0
I0428 20:11:28.406558 32074 net.cpp:408] conv0 <- data
I0428 20:11:28.406564 32074 net.cpp:382] conv0 -> conv0
I0428 20:11:28.408311 32074 net.cpp:124] Setting up conv0
I0428 20:11:28.408341 32074 net.cpp:131] Top shape: 100 25 24 24 (1440000)
I0428 20:11:28.408345 32074 net.cpp:139] Memory required for data: 6074800
I0428 20:11:28.408368 32074 layer_factory.hpp:77] Creating layer pool0
I0428 20:11:28.408375 32074 net.cpp:86] Creating Layer pool0
I0428 20:11:28.408377 32074 net.cpp:408] pool0 <- conv0
I0428 20:11:28.408382 32074 net.cpp:382] pool0 -> pool0
I0428 20:11:28.408416 32074 net.cpp:124] Setting up pool0
I0428 20:11:28.408421 32074 net.cpp:131] Top shape: 100 25 12 12 (360000)
I0428 20:11:28.408424 32074 net.cpp:139] Memory required for data: 7514800
I0428 20:11:28.408427 32074 layer_factory.hpp:77] Creating layer conv1
I0428 20:11:28.408434 32074 net.cpp:86] Creating Layer conv1
I0428 20:11:28.408437 32074 net.cpp:408] conv1 <- pool0
I0428 20:11:28.408442 32074 net.cpp:382] conv1 -> conv1
I0428 20:11:28.410176 32074 net.cpp:124] Setting up conv1
I0428 20:11:28.410187 32074 net.cpp:131] Top shape: 100 50 8 8 (320000)
I0428 20:11:28.410210 32074 net.cpp:139] Memory required for data: 8794800
I0428 20:11:28.410234 32074 layer_factory.hpp:77] Creating layer pool1
I0428 20:11:28.410241 32074 net.cpp:86] Creating Layer pool1
I0428 20:11:28.410245 32074 net.cpp:408] pool1 <- conv1
I0428 20:11:28.410251 32074 net.cpp:382] pool1 -> pool1
I0428 20:11:28.410287 32074 net.cpp:124] Setting up pool1
I0428 20:11:28.410293 32074 net.cpp:131] Top shape: 100 50 4 4 (80000)
I0428 20:11:28.410297 32074 net.cpp:139] Memory required for data: 9114800
I0428 20:11:28.410300 32074 layer_factory.hpp:77] Creating layer ip1
I0428 20:11:28.410306 32074 net.cpp:86] Creating Layer ip1
I0428 20:11:28.410318 32074 net.cpp:408] ip1 <- pool1
I0428 20:11:28.410323 32074 net.cpp:382] ip1 -> ip1
I0428 20:11:28.410554 32074 net.cpp:124] Setting up ip1
I0428 20:11:28.410562 32074 net.cpp:131] Top shape: 100 25 (2500)
I0428 20:11:28.410576 32074 net.cpp:139] Memory required for data: 9124800
I0428 20:11:28.410585 32074 layer_factory.hpp:77] Creating layer relu1
I0428 20:11:28.410590 32074 net.cpp:86] Creating Layer relu1
I0428 20:11:28.410593 32074 net.cpp:408] relu1 <- ip1
I0428 20:11:28.410598 32074 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:11:28.410759 32074 net.cpp:124] Setting up relu1
I0428 20:11:28.410769 32074 net.cpp:131] Top shape: 100 25 (2500)
I0428 20:11:28.410778 32074 net.cpp:139] Memory required for data: 9134800
I0428 20:11:28.410781 32074 layer_factory.hpp:77] Creating layer ip2
I0428 20:11:28.410789 32074 net.cpp:86] Creating Layer ip2
I0428 20:11:28.410791 32074 net.cpp:408] ip2 <- ip1
I0428 20:11:28.410796 32074 net.cpp:382] ip2 -> ip2
I0428 20:11:28.410926 32074 net.cpp:124] Setting up ip2
I0428 20:11:28.410934 32074 net.cpp:131] Top shape: 100 50 (5000)
I0428 20:11:28.410938 32074 net.cpp:139] Memory required for data: 9154800
I0428 20:11:28.410943 32074 layer_factory.hpp:77] Creating layer relu2
I0428 20:11:28.410948 32074 net.cpp:86] Creating Layer relu2
I0428 20:11:28.410950 32074 net.cpp:408] relu2 <- ip2
I0428 20:11:28.410954 32074 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:11:28.411180 32074 net.cpp:124] Setting up relu2
I0428 20:11:28.411190 32074 net.cpp:131] Top shape: 100 50 (5000)
I0428 20:11:28.411192 32074 net.cpp:139] Memory required for data: 9174800
I0428 20:11:28.411195 32074 layer_factory.hpp:77] Creating layer ip3
I0428 20:11:28.411201 32074 net.cpp:86] Creating Layer ip3
I0428 20:11:28.411218 32074 net.cpp:408] ip3 <- ip2
I0428 20:11:28.411223 32074 net.cpp:382] ip3 -> ip3
I0428 20:11:28.411317 32074 net.cpp:124] Setting up ip3
I0428 20:11:28.411324 32074 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:11:28.411326 32074 net.cpp:139] Memory required for data: 9178800
I0428 20:11:28.411334 32074 layer_factory.hpp:77] Creating layer relu3
I0428 20:11:28.411339 32074 net.cpp:86] Creating Layer relu3
I0428 20:11:28.411342 32074 net.cpp:408] relu3 <- ip3
I0428 20:11:28.411346 32074 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:11:28.412192 32074 net.cpp:124] Setting up relu3
I0428 20:11:28.412204 32074 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:11:28.412221 32074 net.cpp:139] Memory required for data: 9182800
I0428 20:11:28.412225 32074 layer_factory.hpp:77] Creating layer ip3_relu3_0_split
I0428 20:11:28.412230 32074 net.cpp:86] Creating Layer ip3_relu3_0_split
I0428 20:11:28.412233 32074 net.cpp:408] ip3_relu3_0_split <- ip3
I0428 20:11:28.412238 32074 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_0
I0428 20:11:28.412245 32074 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_1
I0428 20:11:28.412289 32074 net.cpp:124] Setting up ip3_relu3_0_split
I0428 20:11:28.412295 32074 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:11:28.412299 32074 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:11:28.412302 32074 net.cpp:139] Memory required for data: 9190800
I0428 20:11:28.412312 32074 layer_factory.hpp:77] Creating layer accuracy
I0428 20:11:28.412317 32074 net.cpp:86] Creating Layer accuracy
I0428 20:11:28.412319 32074 net.cpp:408] accuracy <- ip3_relu3_0_split_0
I0428 20:11:28.412323 32074 net.cpp:408] accuracy <- label_mnist_1_split_0
I0428 20:11:28.412328 32074 net.cpp:382] accuracy -> accuracy
I0428 20:11:28.412335 32074 net.cpp:124] Setting up accuracy
I0428 20:11:28.412340 32074 net.cpp:131] Top shape: (1)
I0428 20:11:28.412344 32074 net.cpp:139] Memory required for data: 9190804
I0428 20:11:28.412346 32074 layer_factory.hpp:77] Creating layer loss
I0428 20:11:28.412351 32074 net.cpp:86] Creating Layer loss
I0428 20:11:28.412354 32074 net.cpp:408] loss <- ip3_relu3_0_split_1
I0428 20:11:28.412358 32074 net.cpp:408] loss <- label_mnist_1_split_1
I0428 20:11:28.412362 32074 net.cpp:382] loss -> loss
I0428 20:11:28.412369 32074 layer_factory.hpp:77] Creating layer loss
I0428 20:11:28.412606 32074 net.cpp:124] Setting up loss
I0428 20:11:28.412616 32074 net.cpp:131] Top shape: (1)
I0428 20:11:28.412618 32074 net.cpp:134]     with loss weight 1
I0428 20:11:28.412649 32074 net.cpp:139] Memory required for data: 9190808
I0428 20:11:28.412653 32074 net.cpp:200] loss needs backward computation.
I0428 20:11:28.412673 32074 net.cpp:202] accuracy does not need backward computation.
I0428 20:11:28.412678 32074 net.cpp:200] ip3_relu3_0_split needs backward computation.
I0428 20:11:28.412681 32074 net.cpp:200] relu3 needs backward computation.
I0428 20:11:28.412684 32074 net.cpp:200] ip3 needs backward computation.
I0428 20:11:28.412688 32074 net.cpp:200] relu2 needs backward computation.
I0428 20:11:28.412696 32074 net.cpp:200] ip2 needs backward computation.
I0428 20:11:28.412699 32074 net.cpp:200] relu1 needs backward computation.
I0428 20:11:28.412703 32074 net.cpp:200] ip1 needs backward computation.
I0428 20:11:28.412705 32074 net.cpp:200] pool1 needs backward computation.
I0428 20:11:28.412708 32074 net.cpp:200] conv1 needs backward computation.
I0428 20:11:28.412713 32074 net.cpp:200] pool0 needs backward computation.
I0428 20:11:28.412715 32074 net.cpp:200] conv0 needs backward computation.
I0428 20:11:28.412719 32074 net.cpp:202] label_mnist_1_split does not need backward computation.
I0428 20:11:28.412722 32074 net.cpp:202] mnist does not need backward computation.
I0428 20:11:28.412730 32074 net.cpp:244] This network produces output accuracy
I0428 20:11:28.412734 32074 net.cpp:244] This network produces output loss
I0428 20:11:28.412760 32074 net.cpp:257] Network initialization done.
I0428 20:11:28.412804 32074 solver.cpp:56] Solver scaffolding done.
I0428 20:11:28.413228 32074 caffe.cpp:248] Starting Optimization
I0428 20:11:28.413234 32074 solver.cpp:273] Solving LeNet
I0428 20:11:28.413236 32074 solver.cpp:274] Learning Rate Policy: inv
I0428 20:11:28.414151 32074 solver.cpp:331] Iteration 0, Testing net (#0)
I0428 20:11:28.420028 32074 blocking_queue.cpp:49] Waiting for data
I0428 20:11:28.492079 32081 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:11:28.492727 32074 solver.cpp:398]     Test net output #0: accuracy = 0.1374
I0428 20:11:28.492761 32074 solver.cpp:398]     Test net output #1: loss = 2.30269 (* 1 = 2.30269 loss)
I0428 20:11:28.496830 32074 solver.cpp:219] Iteration 0 (-1.79548e-33 iter/s, 0.0835329s/100 iters), loss = 2.30078
I0428 20:11:28.496884 32074 solver.cpp:238]     Train net output #0: loss = 2.30078 (* 1 = 2.30078 loss)
I0428 20:11:28.496896 32074 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0428 20:11:28.621017 32074 solver.cpp:219] Iteration 100 (805.572 iter/s, 0.124135s/100 iters), loss = 0.803274
I0428 20:11:28.621043 32074 solver.cpp:238]     Train net output #0: loss = 0.803274 (* 1 = 0.803274 loss)
I0428 20:11:28.621049 32074 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0428 20:11:28.753536 32074 solver.cpp:219] Iteration 200 (754.825 iter/s, 0.132481s/100 iters), loss = 0.261055
I0428 20:11:28.753577 32074 solver.cpp:238]     Train net output #0: loss = 0.261055 (* 1 = 0.261055 loss)
I0428 20:11:28.753583 32074 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0428 20:11:28.879412 32074 solver.cpp:219] Iteration 300 (794.651 iter/s, 0.125841s/100 iters), loss = 0.224512
I0428 20:11:28.879454 32074 solver.cpp:238]     Train net output #0: loss = 0.224512 (* 1 = 0.224512 loss)
I0428 20:11:28.879461 32074 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0428 20:11:29.002763 32074 solver.cpp:219] Iteration 400 (811.045 iter/s, 0.123298s/100 iters), loss = 0.0899106
I0428 20:11:29.002807 32074 solver.cpp:238]     Train net output #0: loss = 0.0899106 (* 1 = 0.0899106 loss)
I0428 20:11:29.002813 32074 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0428 20:11:29.122313 32074 solver.cpp:331] Iteration 500, Testing net (#0)
I0428 20:11:29.194728 32081 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:11:29.195363 32074 solver.cpp:398]     Test net output #0: accuracy = 0.965
I0428 20:11:29.195399 32074 solver.cpp:398]     Test net output #1: loss = 0.111463 (* 1 = 0.111463 loss)
I0428 20:11:29.196669 32074 solver.cpp:219] Iteration 500 (515.824 iter/s, 0.193865s/100 iters), loss = 0.12884
I0428 20:11:29.196741 32074 solver.cpp:238]     Train net output #0: loss = 0.12884 (* 1 = 0.12884 loss)
I0428 20:11:29.196748 32074 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0428 20:11:29.323194 32074 solver.cpp:219] Iteration 600 (790.783 iter/s, 0.126457s/100 iters), loss = 0.0891056
I0428 20:11:29.323233 32074 solver.cpp:238]     Train net output #0: loss = 0.0891056 (* 1 = 0.0891056 loss)
I0428 20:11:29.323240 32074 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0428 20:11:29.450582 32074 solver.cpp:219] Iteration 700 (785.214 iter/s, 0.127354s/100 iters), loss = 0.11648
I0428 20:11:29.450625 32074 solver.cpp:238]     Train net output #0: loss = 0.11648 (* 1 = 0.11648 loss)
I0428 20:11:29.450633 32074 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0428 20:11:29.572535 32074 solver.cpp:219] Iteration 800 (820.358 iter/s, 0.121898s/100 iters), loss = 0.244616
I0428 20:11:29.572558 32074 solver.cpp:238]     Train net output #0: loss = 0.244616 (* 1 = 0.244616 loss)
I0428 20:11:29.572566 32074 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0428 20:11:29.696241 32074 solver.cpp:219] Iteration 900 (808.6 iter/s, 0.123671s/100 iters), loss = 0.120057
I0428 20:11:29.696283 32074 solver.cpp:238]     Train net output #0: loss = 0.120057 (* 1 = 0.120057 loss)
I0428 20:11:29.696290 32074 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0428 20:11:29.737368 32080 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:11:29.818892 32074 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_1000.caffemodel
I0428 20:11:29.820499 32074 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_1000.solverstate
I0428 20:11:29.821566 32074 solver.cpp:311] Iteration 1000, loss = 0.0921402
I0428 20:11:29.821581 32074 solver.cpp:331] Iteration 1000, Testing net (#0)
I0428 20:11:29.893848 32081 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:11:29.894489 32074 solver.cpp:398]     Test net output #0: accuracy = 0.978
I0428 20:11:29.894523 32074 solver.cpp:398]     Test net output #1: loss = 0.0721625 (* 1 = 0.0721625 loss)
I0428 20:11:29.894529 32074 solver.cpp:316] Optimization Done.
I0428 20:11:29.894532 32074 caffe.cpp:259] Optimization Done.
