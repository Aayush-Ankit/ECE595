I0428 20:30:56.909382  3881 caffe.cpp:218] Using GPUs 0
I0428 20:30:56.947023  3881 caffe.cpp:223] GPU 0: TITAN X (Pascal)
I0428 20:30:57.399183  3881 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 1000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_everything2/lenet_train_test1547.prototxt"
train_state {
  level: 0
  stage: ""
}
I0428 20:30:57.399324  3881 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1547.prototxt
I0428 20:30:57.399693  3881 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0428 20:30:57.399713  3881 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0428 20:30:57.399806  3881 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 10
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:30:57.399927  3881 layer_factory.hpp:77] Creating layer mnist
I0428 20:30:57.400034  3881 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0428 20:30:57.400063  3881 net.cpp:86] Creating Layer mnist
I0428 20:30:57.400073  3881 net.cpp:382] mnist -> data
I0428 20:30:57.400099  3881 net.cpp:382] mnist -> label
I0428 20:30:57.401306  3881 data_layer.cpp:45] output data size: 64,1,28,28
I0428 20:30:57.403468  3881 net.cpp:124] Setting up mnist
I0428 20:30:57.403501  3881 net.cpp:131] Top shape: 64 1 28 28 (50176)
I0428 20:30:57.403518  3881 net.cpp:131] Top shape: 64 (64)
I0428 20:30:57.403528  3881 net.cpp:139] Memory required for data: 200960
I0428 20:30:57.403537  3881 layer_factory.hpp:77] Creating layer conv0
I0428 20:30:57.403558  3881 net.cpp:86] Creating Layer conv0
I0428 20:30:57.403578  3881 net.cpp:408] conv0 <- data
I0428 20:30:57.403594  3881 net.cpp:382] conv0 -> conv0
I0428 20:30:57.631991  3881 net.cpp:124] Setting up conv0
I0428 20:30:57.632019  3881 net.cpp:131] Top shape: 64 100 24 24 (3686400)
I0428 20:30:57.632024  3881 net.cpp:139] Memory required for data: 14946560
I0428 20:30:57.632042  3881 layer_factory.hpp:77] Creating layer pool0
I0428 20:30:57.632057  3881 net.cpp:86] Creating Layer pool0
I0428 20:30:57.632064  3881 net.cpp:408] pool0 <- conv0
I0428 20:30:57.632072  3881 net.cpp:382] pool0 -> pool0
I0428 20:30:57.632146  3881 net.cpp:124] Setting up pool0
I0428 20:30:57.632155  3881 net.cpp:131] Top shape: 64 100 12 12 (921600)
I0428 20:30:57.632160  3881 net.cpp:139] Memory required for data: 18632960
I0428 20:30:57.632165  3881 layer_factory.hpp:77] Creating layer conv1
I0428 20:30:57.632180  3881 net.cpp:86] Creating Layer conv1
I0428 20:30:57.632186  3881 net.cpp:408] conv1 <- pool0
I0428 20:30:57.632194  3881 net.cpp:382] conv1 -> conv1
I0428 20:30:57.634346  3881 net.cpp:124] Setting up conv1
I0428 20:30:57.634363  3881 net.cpp:131] Top shape: 64 10 8 8 (40960)
I0428 20:30:57.634369  3881 net.cpp:139] Memory required for data: 18796800
I0428 20:30:57.634398  3881 layer_factory.hpp:77] Creating layer pool1
I0428 20:30:57.634410  3881 net.cpp:86] Creating Layer pool1
I0428 20:30:57.634418  3881 net.cpp:408] pool1 <- conv1
I0428 20:30:57.634425  3881 net.cpp:382] pool1 -> pool1
I0428 20:30:57.634472  3881 net.cpp:124] Setting up pool1
I0428 20:30:57.634483  3881 net.cpp:131] Top shape: 64 10 4 4 (10240)
I0428 20:30:57.634488  3881 net.cpp:139] Memory required for data: 18837760
I0428 20:30:57.634495  3881 layer_factory.hpp:77] Creating layer ip1
I0428 20:30:57.634506  3881 net.cpp:86] Creating Layer ip1
I0428 20:30:57.634517  3881 net.cpp:408] ip1 <- pool1
I0428 20:30:57.634526  3881 net.cpp:382] ip1 -> ip1
I0428 20:30:57.634685  3881 net.cpp:124] Setting up ip1
I0428 20:30:57.634694  3881 net.cpp:131] Top shape: 64 25 (1600)
I0428 20:30:57.634699  3881 net.cpp:139] Memory required for data: 18844160
I0428 20:30:57.634711  3881 layer_factory.hpp:77] Creating layer relu1
I0428 20:30:57.634723  3881 net.cpp:86] Creating Layer relu1
I0428 20:30:57.634732  3881 net.cpp:408] relu1 <- ip1
I0428 20:30:57.634739  3881 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:30:57.634919  3881 net.cpp:124] Setting up relu1
I0428 20:30:57.634929  3881 net.cpp:131] Top shape: 64 25 (1600)
I0428 20:30:57.634934  3881 net.cpp:139] Memory required for data: 18850560
I0428 20:30:57.634939  3881 layer_factory.hpp:77] Creating layer ip2
I0428 20:30:57.634948  3881 net.cpp:86] Creating Layer ip2
I0428 20:30:57.634953  3881 net.cpp:408] ip2 <- ip1
I0428 20:30:57.634963  3881 net.cpp:382] ip2 -> ip2
I0428 20:30:57.635074  3881 net.cpp:124] Setting up ip2
I0428 20:30:57.635083  3881 net.cpp:131] Top shape: 64 25 (1600)
I0428 20:30:57.635087  3881 net.cpp:139] Memory required for data: 18856960
I0428 20:30:57.635097  3881 layer_factory.hpp:77] Creating layer relu2
I0428 20:30:57.635105  3881 net.cpp:86] Creating Layer relu2
I0428 20:30:57.635110  3881 net.cpp:408] relu2 <- ip2
I0428 20:30:57.635118  3881 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:30:57.635910  3881 net.cpp:124] Setting up relu2
I0428 20:30:57.635923  3881 net.cpp:131] Top shape: 64 25 (1600)
I0428 20:30:57.635929  3881 net.cpp:139] Memory required for data: 18863360
I0428 20:30:57.635934  3881 layer_factory.hpp:77] Creating layer ip3
I0428 20:30:57.635943  3881 net.cpp:86] Creating Layer ip3
I0428 20:30:57.635949  3881 net.cpp:408] ip3 <- ip2
I0428 20:30:57.635957  3881 net.cpp:382] ip3 -> ip3
I0428 20:30:57.636071  3881 net.cpp:124] Setting up ip3
I0428 20:30:57.636081  3881 net.cpp:131] Top shape: 64 10 (640)
I0428 20:30:57.636085  3881 net.cpp:139] Memory required for data: 18865920
I0428 20:30:57.636098  3881 layer_factory.hpp:77] Creating layer relu3
I0428 20:30:57.636107  3881 net.cpp:86] Creating Layer relu3
I0428 20:30:57.636127  3881 net.cpp:408] relu3 <- ip3
I0428 20:30:57.636134  3881 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:30:57.636293  3881 net.cpp:124] Setting up relu3
I0428 20:30:57.636303  3881 net.cpp:131] Top shape: 64 10 (640)
I0428 20:30:57.636307  3881 net.cpp:139] Memory required for data: 18868480
I0428 20:30:57.636312  3881 layer_factory.hpp:77] Creating layer loss
I0428 20:30:57.636320  3881 net.cpp:86] Creating Layer loss
I0428 20:30:57.636327  3881 net.cpp:408] loss <- ip3
I0428 20:30:57.636332  3881 net.cpp:408] loss <- label
I0428 20:30:57.636340  3881 net.cpp:382] loss -> loss
I0428 20:30:57.636363  3881 layer_factory.hpp:77] Creating layer loss
I0428 20:30:57.636593  3881 net.cpp:124] Setting up loss
I0428 20:30:57.636603  3881 net.cpp:131] Top shape: (1)
I0428 20:30:57.636608  3881 net.cpp:134]     with loss weight 1
I0428 20:30:57.636627  3881 net.cpp:139] Memory required for data: 18868484
I0428 20:30:57.636633  3881 net.cpp:200] loss needs backward computation.
I0428 20:30:57.636639  3881 net.cpp:200] relu3 needs backward computation.
I0428 20:30:57.636646  3881 net.cpp:200] ip3 needs backward computation.
I0428 20:30:57.636651  3881 net.cpp:200] relu2 needs backward computation.
I0428 20:30:57.636656  3881 net.cpp:200] ip2 needs backward computation.
I0428 20:30:57.636660  3881 net.cpp:200] relu1 needs backward computation.
I0428 20:30:57.636665  3881 net.cpp:200] ip1 needs backward computation.
I0428 20:30:57.636670  3881 net.cpp:200] pool1 needs backward computation.
I0428 20:30:57.636675  3881 net.cpp:200] conv1 needs backward computation.
I0428 20:30:57.636680  3881 net.cpp:200] pool0 needs backward computation.
I0428 20:30:57.636685  3881 net.cpp:200] conv0 needs backward computation.
I0428 20:30:57.636692  3881 net.cpp:202] mnist does not need backward computation.
I0428 20:30:57.636696  3881 net.cpp:244] This network produces output loss
I0428 20:30:57.636710  3881 net.cpp:257] Network initialization done.
I0428 20:30:57.637073  3881 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_everything2/lenet_train_test1547.prototxt
I0428 20:30:57.637107  3881 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0428 20:30:57.637225  3881 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 10
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 20:30:57.637332  3881 layer_factory.hpp:77] Creating layer mnist
I0428 20:30:57.637387  3881 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0428 20:30:57.637404  3881 net.cpp:86] Creating Layer mnist
I0428 20:30:57.637411  3881 net.cpp:382] mnist -> data
I0428 20:30:57.637423  3881 net.cpp:382] mnist -> label
I0428 20:30:57.637544  3881 data_layer.cpp:45] output data size: 100,1,28,28
I0428 20:30:57.639761  3881 net.cpp:124] Setting up mnist
I0428 20:30:57.639807  3881 net.cpp:131] Top shape: 100 1 28 28 (78400)
I0428 20:30:57.639816  3881 net.cpp:131] Top shape: 100 (100)
I0428 20:30:57.639822  3881 net.cpp:139] Memory required for data: 314000
I0428 20:30:57.639828  3881 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0428 20:30:57.639842  3881 net.cpp:86] Creating Layer label_mnist_1_split
I0428 20:30:57.639849  3881 net.cpp:408] label_mnist_1_split <- label
I0428 20:30:57.639858  3881 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_0
I0428 20:30:57.639869  3881 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_1
I0428 20:30:57.639976  3881 net.cpp:124] Setting up label_mnist_1_split
I0428 20:30:57.639984  3881 net.cpp:131] Top shape: 100 (100)
I0428 20:30:57.639991  3881 net.cpp:131] Top shape: 100 (100)
I0428 20:30:57.639995  3881 net.cpp:139] Memory required for data: 314800
I0428 20:30:57.640000  3881 layer_factory.hpp:77] Creating layer conv0
I0428 20:30:57.640012  3881 net.cpp:86] Creating Layer conv0
I0428 20:30:57.640018  3881 net.cpp:408] conv0 <- data
I0428 20:30:57.640027  3881 net.cpp:382] conv0 -> conv0
I0428 20:30:57.641661  3881 net.cpp:124] Setting up conv0
I0428 20:30:57.641679  3881 net.cpp:131] Top shape: 100 100 24 24 (5760000)
I0428 20:30:57.641683  3881 net.cpp:139] Memory required for data: 23354800
I0428 20:30:57.641700  3881 layer_factory.hpp:77] Creating layer pool0
I0428 20:30:57.641710  3881 net.cpp:86] Creating Layer pool0
I0428 20:30:57.641717  3881 net.cpp:408] pool0 <- conv0
I0428 20:30:57.641724  3881 net.cpp:382] pool0 -> pool0
I0428 20:30:57.641764  3881 net.cpp:124] Setting up pool0
I0428 20:30:57.641772  3881 net.cpp:131] Top shape: 100 100 12 12 (1440000)
I0428 20:30:57.641777  3881 net.cpp:139] Memory required for data: 29114800
I0428 20:30:57.641782  3881 layer_factory.hpp:77] Creating layer conv1
I0428 20:30:57.641794  3881 net.cpp:86] Creating Layer conv1
I0428 20:30:57.641800  3881 net.cpp:408] conv1 <- pool0
I0428 20:30:57.641811  3881 net.cpp:382] conv1 -> conv1
I0428 20:30:57.643460  3881 net.cpp:124] Setting up conv1
I0428 20:30:57.643476  3881 net.cpp:131] Top shape: 100 10 8 8 (64000)
I0428 20:30:57.643482  3881 net.cpp:139] Memory required for data: 29370800
I0428 20:30:57.643496  3881 layer_factory.hpp:77] Creating layer pool1
I0428 20:30:57.643506  3881 net.cpp:86] Creating Layer pool1
I0428 20:30:57.643515  3881 net.cpp:408] pool1 <- conv1
I0428 20:30:57.643523  3881 net.cpp:382] pool1 -> pool1
I0428 20:30:57.643568  3881 net.cpp:124] Setting up pool1
I0428 20:30:57.643575  3881 net.cpp:131] Top shape: 100 10 4 4 (16000)
I0428 20:30:57.643580  3881 net.cpp:139] Memory required for data: 29434800
I0428 20:30:57.643585  3881 layer_factory.hpp:77] Creating layer ip1
I0428 20:30:57.643594  3881 net.cpp:86] Creating Layer ip1
I0428 20:30:57.643600  3881 net.cpp:408] ip1 <- pool1
I0428 20:30:57.643610  3881 net.cpp:382] ip1 -> ip1
I0428 20:30:57.643748  3881 net.cpp:124] Setting up ip1
I0428 20:30:57.643769  3881 net.cpp:131] Top shape: 100 25 (2500)
I0428 20:30:57.643774  3881 net.cpp:139] Memory required for data: 29444800
I0428 20:30:57.643786  3881 layer_factory.hpp:77] Creating layer relu1
I0428 20:30:57.643795  3881 net.cpp:86] Creating Layer relu1
I0428 20:30:57.643801  3881 net.cpp:408] relu1 <- ip1
I0428 20:30:57.643810  3881 net.cpp:369] relu1 -> ip1 (in-place)
I0428 20:30:57.644037  3881 net.cpp:124] Setting up relu1
I0428 20:30:57.644047  3881 net.cpp:131] Top shape: 100 25 (2500)
I0428 20:30:57.644052  3881 net.cpp:139] Memory required for data: 29454800
I0428 20:30:57.644057  3881 layer_factory.hpp:77] Creating layer ip2
I0428 20:30:57.644068  3881 net.cpp:86] Creating Layer ip2
I0428 20:30:57.644074  3881 net.cpp:408] ip2 <- ip1
I0428 20:30:57.644083  3881 net.cpp:382] ip2 -> ip2
I0428 20:30:57.644220  3881 net.cpp:124] Setting up ip2
I0428 20:30:57.644232  3881 net.cpp:131] Top shape: 100 25 (2500)
I0428 20:30:57.644237  3881 net.cpp:139] Memory required for data: 29464800
I0428 20:30:57.644246  3881 layer_factory.hpp:77] Creating layer relu2
I0428 20:30:57.644254  3881 net.cpp:86] Creating Layer relu2
I0428 20:30:57.644260  3881 net.cpp:408] relu2 <- ip2
I0428 20:30:57.644268  3881 net.cpp:369] relu2 -> ip2 (in-place)
I0428 20:30:57.644454  3881 net.cpp:124] Setting up relu2
I0428 20:30:57.644465  3881 net.cpp:131] Top shape: 100 25 (2500)
I0428 20:30:57.644470  3881 net.cpp:139] Memory required for data: 29474800
I0428 20:30:57.644479  3881 layer_factory.hpp:77] Creating layer ip3
I0428 20:30:57.644489  3881 net.cpp:86] Creating Layer ip3
I0428 20:30:57.644495  3881 net.cpp:408] ip3 <- ip2
I0428 20:30:57.644505  3881 net.cpp:382] ip3 -> ip3
I0428 20:30:57.644616  3881 net.cpp:124] Setting up ip3
I0428 20:30:57.644625  3881 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:30:57.644630  3881 net.cpp:139] Memory required for data: 29478800
I0428 20:30:57.644644  3881 layer_factory.hpp:77] Creating layer relu3
I0428 20:30:57.644651  3881 net.cpp:86] Creating Layer relu3
I0428 20:30:57.644659  3881 net.cpp:408] relu3 <- ip3
I0428 20:30:57.644666  3881 net.cpp:369] relu3 -> ip3 (in-place)
I0428 20:30:57.645499  3881 net.cpp:124] Setting up relu3
I0428 20:30:57.645514  3881 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:30:57.645520  3881 net.cpp:139] Memory required for data: 29482800
I0428 20:30:57.645525  3881 layer_factory.hpp:77] Creating layer ip3_relu3_0_split
I0428 20:30:57.645534  3881 net.cpp:86] Creating Layer ip3_relu3_0_split
I0428 20:30:57.645539  3881 net.cpp:408] ip3_relu3_0_split <- ip3
I0428 20:30:57.645547  3881 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_0
I0428 20:30:57.645557  3881 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_1
I0428 20:30:57.645612  3881 net.cpp:124] Setting up ip3_relu3_0_split
I0428 20:30:57.645620  3881 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:30:57.645627  3881 net.cpp:131] Top shape: 100 10 (1000)
I0428 20:30:57.645632  3881 net.cpp:139] Memory required for data: 29490800
I0428 20:30:57.645637  3881 layer_factory.hpp:77] Creating layer accuracy
I0428 20:30:57.645644  3881 net.cpp:86] Creating Layer accuracy
I0428 20:30:57.645649  3881 net.cpp:408] accuracy <- ip3_relu3_0_split_0
I0428 20:30:57.645656  3881 net.cpp:408] accuracy <- label_mnist_1_split_0
I0428 20:30:57.645663  3881 net.cpp:382] accuracy -> accuracy
I0428 20:30:57.645674  3881 net.cpp:124] Setting up accuracy
I0428 20:30:57.645683  3881 net.cpp:131] Top shape: (1)
I0428 20:30:57.645687  3881 net.cpp:139] Memory required for data: 29490804
I0428 20:30:57.645692  3881 layer_factory.hpp:77] Creating layer loss
I0428 20:30:57.645699  3881 net.cpp:86] Creating Layer loss
I0428 20:30:57.645704  3881 net.cpp:408] loss <- ip3_relu3_0_split_1
I0428 20:30:57.645710  3881 net.cpp:408] loss <- label_mnist_1_split_1
I0428 20:30:57.645716  3881 net.cpp:382] loss -> loss
I0428 20:30:57.645725  3881 layer_factory.hpp:77] Creating layer loss
I0428 20:30:57.645987  3881 net.cpp:124] Setting up loss
I0428 20:30:57.645998  3881 net.cpp:131] Top shape: (1)
I0428 20:30:57.646003  3881 net.cpp:134]     with loss weight 1
I0428 20:30:57.646023  3881 net.cpp:139] Memory required for data: 29490808
I0428 20:30:57.646029  3881 net.cpp:200] loss needs backward computation.
I0428 20:30:57.646035  3881 net.cpp:202] accuracy does not need backward computation.
I0428 20:30:57.646042  3881 net.cpp:200] ip3_relu3_0_split needs backward computation.
I0428 20:30:57.646047  3881 net.cpp:200] relu3 needs backward computation.
I0428 20:30:57.646052  3881 net.cpp:200] ip3 needs backward computation.
I0428 20:30:57.646057  3881 net.cpp:200] relu2 needs backward computation.
I0428 20:30:57.646062  3881 net.cpp:200] ip2 needs backward computation.
I0428 20:30:57.646069  3881 net.cpp:200] relu1 needs backward computation.
I0428 20:30:57.646073  3881 net.cpp:200] ip1 needs backward computation.
I0428 20:30:57.646078  3881 net.cpp:200] pool1 needs backward computation.
I0428 20:30:57.646085  3881 net.cpp:200] conv1 needs backward computation.
I0428 20:30:57.646090  3881 net.cpp:200] pool0 needs backward computation.
I0428 20:30:57.646095  3881 net.cpp:200] conv0 needs backward computation.
I0428 20:30:57.646101  3881 net.cpp:202] label_mnist_1_split does not need backward computation.
I0428 20:30:57.646107  3881 net.cpp:202] mnist does not need backward computation.
I0428 20:30:57.646112  3881 net.cpp:244] This network produces output accuracy
I0428 20:30:57.646118  3881 net.cpp:244] This network produces output loss
I0428 20:30:57.646134  3881 net.cpp:257] Network initialization done.
I0428 20:30:57.646195  3881 solver.cpp:56] Solver scaffolding done.
I0428 20:30:57.646528  3881 caffe.cpp:248] Starting Optimization
I0428 20:30:57.646535  3881 solver.cpp:273] Solving LeNet
I0428 20:30:57.646539  3881 solver.cpp:274] Learning Rate Policy: inv
I0428 20:30:57.647378  3881 solver.cpp:331] Iteration 0, Testing net (#0)
I0428 20:30:57.743765  3890 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:30:57.747023  3881 solver.cpp:398]     Test net output #0: accuracy = 0.1013
I0428 20:30:57.747057  3881 solver.cpp:398]     Test net output #1: loss = 2.31587 (* 1 = 2.31587 loss)
I0428 20:30:57.751332  3881 solver.cpp:219] Iteration 0 (0 iter/s, 0.104762s/100 iters), loss = 2.3304
I0428 20:30:57.751358  3881 solver.cpp:238]     Train net output #0: loss = 2.3304 (* 1 = 2.3304 loss)
I0428 20:30:57.751404  3881 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0428 20:30:57.969370  3881 solver.cpp:219] Iteration 100 (458.728 iter/s, 0.217994s/100 iters), loss = 0.84333
I0428 20:30:57.969429  3881 solver.cpp:238]     Train net output #0: loss = 0.84333 (* 1 = 0.84333 loss)
I0428 20:30:57.969449  3881 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0428 20:30:58.194506  3881 solver.cpp:219] Iteration 200 (444.31 iter/s, 0.225068s/100 iters), loss = 0.286457
I0428 20:30:58.194561  3881 solver.cpp:238]     Train net output #0: loss = 0.286457 (* 1 = 0.286457 loss)
I0428 20:30:58.194581  3881 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0428 20:30:58.421422  3881 solver.cpp:219] Iteration 300 (440.82 iter/s, 0.22685s/100 iters), loss = 0.323733
I0428 20:30:58.421478  3881 solver.cpp:238]     Train net output #0: loss = 0.323733 (* 1 = 0.323733 loss)
I0428 20:30:58.421499  3881 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0428 20:30:58.643234  3881 solver.cpp:219] Iteration 400 (450.968 iter/s, 0.221745s/100 iters), loss = 0.103011
I0428 20:30:58.643291  3881 solver.cpp:238]     Train net output #0: loss = 0.103011 (* 1 = 0.103011 loss)
I0428 20:30:58.643311  3881 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0428 20:30:58.866504  3881 solver.cpp:331] Iteration 500, Testing net (#0)
I0428 20:30:58.970222  3890 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:30:58.973809  3881 solver.cpp:398]     Test net output #0: accuracy = 0.954
I0428 20:30:58.973837  3881 solver.cpp:398]     Test net output #1: loss = 0.154037 (* 1 = 0.154037 loss)
I0428 20:30:58.975796  3881 solver.cpp:219] Iteration 500 (300.757 iter/s, 0.332494s/100 iters), loss = 0.124101
I0428 20:30:58.975829  3881 solver.cpp:238]     Train net output #0: loss = 0.124101 (* 1 = 0.124101 loss)
I0428 20:30:58.975873  3881 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0428 20:30:59.191895  3881 solver.cpp:219] Iteration 600 (462.854 iter/s, 0.216051s/100 iters), loss = 0.066321
I0428 20:30:59.191936  3881 solver.cpp:238]     Train net output #0: loss = 0.0663211 (* 1 = 0.0663211 loss)
I0428 20:30:59.191951  3881 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0428 20:30:59.411864  3881 solver.cpp:219] Iteration 700 (454.721 iter/s, 0.219915s/100 iters), loss = 0.240838
I0428 20:30:59.411911  3881 solver.cpp:238]     Train net output #0: loss = 0.240838 (* 1 = 0.240838 loss)
I0428 20:30:59.411927  3881 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0428 20:30:59.632966  3881 solver.cpp:219] Iteration 800 (452.403 iter/s, 0.221042s/100 iters), loss = 0.327897
I0428 20:30:59.633013  3881 solver.cpp:238]     Train net output #0: loss = 0.327897 (* 1 = 0.327897 loss)
I0428 20:30:59.633029  3881 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0428 20:30:59.853499  3881 solver.cpp:219] Iteration 900 (453.569 iter/s, 0.220473s/100 iters), loss = 0.20025
I0428 20:30:59.853551  3881 solver.cpp:238]     Train net output #0: loss = 0.20025 (* 1 = 0.20025 loss)
I0428 20:30:59.853569  3881 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0428 20:30:59.927351  3889 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:31:00.072533  3881 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_1000.caffemodel
I0428 20:31:00.074631  3881 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_1000.solverstate
I0428 20:31:00.075985  3881 solver.cpp:311] Iteration 1000, loss = 0.190989
I0428 20:31:00.076011  3881 solver.cpp:331] Iteration 1000, Testing net (#0)
I0428 20:31:00.175503  3890 data_layer.cpp:73] Restarting data prefetching from start.
I0428 20:31:00.179100  3881 solver.cpp:398]     Test net output #0: accuracy = 0.9712
I0428 20:31:00.179126  3881 solver.cpp:398]     Test net output #1: loss = 0.0887151 (* 1 = 0.0887151 loss)
I0428 20:31:00.179136  3881 solver.cpp:316] Optimization Done.
I0428 20:31:00.179141  3881 caffe.cpp:259] Optimization Done.
