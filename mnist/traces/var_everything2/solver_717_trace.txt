I0428 19:54:43.608355 28047 caffe.cpp:218] Using GPUs 0
I0428 19:54:43.641137 28047 caffe.cpp:223] GPU 0: TITAN X (Pascal)
I0428 19:54:44.151290 28047 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 1000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_everything2/lenet_train_test717.prototxt"
train_state {
  level: 0
  stage: ""
}
I0428 19:54:44.151429 28047 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_everything2/lenet_train_test717.prototxt
I0428 19:54:44.151832 28047 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0428 19:54:44.151850 28047 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0428 19:54:44.151948 28047 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 5
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 19:54:44.152024 28047 layer_factory.hpp:77] Creating layer mnist
I0428 19:54:44.152122 28047 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0428 19:54:44.152145 28047 net.cpp:86] Creating Layer mnist
I0428 19:54:44.152154 28047 net.cpp:382] mnist -> data
I0428 19:54:44.152176 28047 net.cpp:382] mnist -> label
I0428 19:54:44.153278 28047 data_layer.cpp:45] output data size: 64,1,28,28
I0428 19:54:44.155726 28047 net.cpp:124] Setting up mnist
I0428 19:54:44.155745 28047 net.cpp:131] Top shape: 64 1 28 28 (50176)
I0428 19:54:44.155750 28047 net.cpp:131] Top shape: 64 (64)
I0428 19:54:44.155755 28047 net.cpp:139] Memory required for data: 200960
I0428 19:54:44.155762 28047 layer_factory.hpp:77] Creating layer conv0
I0428 19:54:44.155778 28047 net.cpp:86] Creating Layer conv0
I0428 19:54:44.155798 28047 net.cpp:408] conv0 <- data
I0428 19:54:44.155815 28047 net.cpp:382] conv0 -> conv0
I0428 19:54:44.399305 28047 net.cpp:124] Setting up conv0
I0428 19:54:44.399332 28047 net.cpp:131] Top shape: 64 5 24 24 (184320)
I0428 19:54:44.399335 28047 net.cpp:139] Memory required for data: 938240
I0428 19:54:44.399349 28047 layer_factory.hpp:77] Creating layer pool0
I0428 19:54:44.399377 28047 net.cpp:86] Creating Layer pool0
I0428 19:54:44.399381 28047 net.cpp:408] pool0 <- conv0
I0428 19:54:44.399387 28047 net.cpp:382] pool0 -> pool0
I0428 19:54:44.399435 28047 net.cpp:124] Setting up pool0
I0428 19:54:44.399441 28047 net.cpp:131] Top shape: 64 5 12 12 (46080)
I0428 19:54:44.399444 28047 net.cpp:139] Memory required for data: 1122560
I0428 19:54:44.399447 28047 layer_factory.hpp:77] Creating layer conv1
I0428 19:54:44.399457 28047 net.cpp:86] Creating Layer conv1
I0428 19:54:44.399461 28047 net.cpp:408] conv1 <- pool0
I0428 19:54:44.399466 28047 net.cpp:382] conv1 -> conv1
I0428 19:54:44.402346 28047 net.cpp:124] Setting up conv1
I0428 19:54:44.402360 28047 net.cpp:131] Top shape: 64 100 8 8 (409600)
I0428 19:54:44.402364 28047 net.cpp:139] Memory required for data: 2760960
I0428 19:54:44.402389 28047 layer_factory.hpp:77] Creating layer pool1
I0428 19:54:44.402395 28047 net.cpp:86] Creating Layer pool1
I0428 19:54:44.402400 28047 net.cpp:408] pool1 <- conv1
I0428 19:54:44.402405 28047 net.cpp:382] pool1 -> pool1
I0428 19:54:44.402456 28047 net.cpp:124] Setting up pool1
I0428 19:54:44.402463 28047 net.cpp:131] Top shape: 64 100 4 4 (102400)
I0428 19:54:44.402467 28047 net.cpp:139] Memory required for data: 3170560
I0428 19:54:44.402469 28047 layer_factory.hpp:77] Creating layer ip1
I0428 19:54:44.402477 28047 net.cpp:86] Creating Layer ip1
I0428 19:54:44.402479 28047 net.cpp:408] ip1 <- pool1
I0428 19:54:44.402484 28047 net.cpp:382] ip1 -> ip1
I0428 19:54:44.402669 28047 net.cpp:124] Setting up ip1
I0428 19:54:44.402676 28047 net.cpp:131] Top shape: 64 10 (640)
I0428 19:54:44.402680 28047 net.cpp:139] Memory required for data: 3173120
I0428 19:54:44.402688 28047 layer_factory.hpp:77] Creating layer relu1
I0428 19:54:44.402693 28047 net.cpp:86] Creating Layer relu1
I0428 19:54:44.402696 28047 net.cpp:408] relu1 <- ip1
I0428 19:54:44.402700 28047 net.cpp:369] relu1 -> ip1 (in-place)
I0428 19:54:44.402889 28047 net.cpp:124] Setting up relu1
I0428 19:54:44.402897 28047 net.cpp:131] Top shape: 64 10 (640)
I0428 19:54:44.402900 28047 net.cpp:139] Memory required for data: 3175680
I0428 19:54:44.402904 28047 layer_factory.hpp:77] Creating layer ip2
I0428 19:54:44.402910 28047 net.cpp:86] Creating Layer ip2
I0428 19:54:44.402914 28047 net.cpp:408] ip2 <- ip1
I0428 19:54:44.402918 28047 net.cpp:382] ip2 -> ip2
I0428 19:54:44.403029 28047 net.cpp:124] Setting up ip2
I0428 19:54:44.403036 28047 net.cpp:131] Top shape: 64 25 (1600)
I0428 19:54:44.403039 28047 net.cpp:139] Memory required for data: 3182080
I0428 19:54:44.403045 28047 layer_factory.hpp:77] Creating layer relu2
I0428 19:54:44.403051 28047 net.cpp:86] Creating Layer relu2
I0428 19:54:44.403054 28047 net.cpp:408] relu2 <- ip2
I0428 19:54:44.403059 28047 net.cpp:369] relu2 -> ip2 (in-place)
I0428 19:54:44.403830 28047 net.cpp:124] Setting up relu2
I0428 19:54:44.403841 28047 net.cpp:131] Top shape: 64 25 (1600)
I0428 19:54:44.403861 28047 net.cpp:139] Memory required for data: 3188480
I0428 19:54:44.403864 28047 layer_factory.hpp:77] Creating layer ip3
I0428 19:54:44.403872 28047 net.cpp:86] Creating Layer ip3
I0428 19:54:44.403875 28047 net.cpp:408] ip3 <- ip2
I0428 19:54:44.403880 28047 net.cpp:382] ip3 -> ip3
I0428 19:54:44.403995 28047 net.cpp:124] Setting up ip3
I0428 19:54:44.404003 28047 net.cpp:131] Top shape: 64 10 (640)
I0428 19:54:44.404006 28047 net.cpp:139] Memory required for data: 3191040
I0428 19:54:44.404019 28047 layer_factory.hpp:77] Creating layer relu3
I0428 19:54:44.404026 28047 net.cpp:86] Creating Layer relu3
I0428 19:54:44.404028 28047 net.cpp:408] relu3 <- ip3
I0428 19:54:44.404032 28047 net.cpp:369] relu3 -> ip3 (in-place)
I0428 19:54:44.404199 28047 net.cpp:124] Setting up relu3
I0428 19:54:44.404208 28047 net.cpp:131] Top shape: 64 10 (640)
I0428 19:54:44.404227 28047 net.cpp:139] Memory required for data: 3193600
I0428 19:54:44.404230 28047 layer_factory.hpp:77] Creating layer loss
I0428 19:54:44.404237 28047 net.cpp:86] Creating Layer loss
I0428 19:54:44.404239 28047 net.cpp:408] loss <- ip3
I0428 19:54:44.404243 28047 net.cpp:408] loss <- label
I0428 19:54:44.404248 28047 net.cpp:382] loss -> loss
I0428 19:54:44.404265 28047 layer_factory.hpp:77] Creating layer loss
I0428 19:54:44.404497 28047 net.cpp:124] Setting up loss
I0428 19:54:44.404506 28047 net.cpp:131] Top shape: (1)
I0428 19:54:44.404510 28047 net.cpp:134]     with loss weight 1
I0428 19:54:44.404522 28047 net.cpp:139] Memory required for data: 3193604
I0428 19:54:44.404525 28047 net.cpp:200] loss needs backward computation.
I0428 19:54:44.404528 28047 net.cpp:200] relu3 needs backward computation.
I0428 19:54:44.404531 28047 net.cpp:200] ip3 needs backward computation.
I0428 19:54:44.404534 28047 net.cpp:200] relu2 needs backward computation.
I0428 19:54:44.404537 28047 net.cpp:200] ip2 needs backward computation.
I0428 19:54:44.404539 28047 net.cpp:200] relu1 needs backward computation.
I0428 19:54:44.404542 28047 net.cpp:200] ip1 needs backward computation.
I0428 19:54:44.404546 28047 net.cpp:200] pool1 needs backward computation.
I0428 19:54:44.404548 28047 net.cpp:200] conv1 needs backward computation.
I0428 19:54:44.404551 28047 net.cpp:200] pool0 needs backward computation.
I0428 19:54:44.404553 28047 net.cpp:200] conv0 needs backward computation.
I0428 19:54:44.404557 28047 net.cpp:202] mnist does not need backward computation.
I0428 19:54:44.404559 28047 net.cpp:244] This network produces output loss
I0428 19:54:44.404568 28047 net.cpp:257] Network initialization done.
I0428 19:54:44.404965 28047 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_everything2/lenet_train_test717.prototxt
I0428 19:54:44.405009 28047 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0428 19:54:44.405122 28047 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 5
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 100
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0428 19:54:44.405784 28047 layer_factory.hpp:77] Creating layer mnist
I0428 19:54:44.405905 28047 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0428 19:54:44.405936 28047 net.cpp:86] Creating Layer mnist
I0428 19:54:44.405948 28047 net.cpp:382] mnist -> data
I0428 19:54:44.405966 28047 net.cpp:382] mnist -> label
I0428 19:54:44.406169 28047 data_layer.cpp:45] output data size: 100,1,28,28
I0428 19:54:44.409919 28047 net.cpp:124] Setting up mnist
I0428 19:54:44.409958 28047 net.cpp:131] Top shape: 100 1 28 28 (78400)
I0428 19:54:44.409970 28047 net.cpp:131] Top shape: 100 (100)
I0428 19:54:44.409977 28047 net.cpp:139] Memory required for data: 314000
I0428 19:54:44.409986 28047 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0428 19:54:44.410006 28047 net.cpp:86] Creating Layer label_mnist_1_split
I0428 19:54:44.410014 28047 net.cpp:408] label_mnist_1_split <- label
I0428 19:54:44.410024 28047 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_0
I0428 19:54:44.410039 28047 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_1
I0428 19:54:44.410161 28047 net.cpp:124] Setting up label_mnist_1_split
I0428 19:54:44.410174 28047 net.cpp:131] Top shape: 100 (100)
I0428 19:54:44.410183 28047 net.cpp:131] Top shape: 100 (100)
I0428 19:54:44.410190 28047 net.cpp:139] Memory required for data: 314800
I0428 19:54:44.410197 28047 layer_factory.hpp:77] Creating layer conv0
I0428 19:54:44.410215 28047 net.cpp:86] Creating Layer conv0
I0428 19:54:44.410226 28047 net.cpp:408] conv0 <- data
I0428 19:54:44.410238 28047 net.cpp:382] conv0 -> conv0
I0428 19:54:44.413219 28047 net.cpp:124] Setting up conv0
I0428 19:54:44.413261 28047 net.cpp:131] Top shape: 100 5 24 24 (288000)
I0428 19:54:44.413270 28047 net.cpp:139] Memory required for data: 1466800
I0428 19:54:44.413290 28047 layer_factory.hpp:77] Creating layer pool0
I0428 19:54:44.413317 28047 net.cpp:86] Creating Layer pool0
I0428 19:54:44.413326 28047 net.cpp:408] pool0 <- conv0
I0428 19:54:44.413336 28047 net.cpp:382] pool0 -> pool0
I0428 19:54:44.413411 28047 net.cpp:124] Setting up pool0
I0428 19:54:44.413425 28047 net.cpp:131] Top shape: 100 5 12 12 (72000)
I0428 19:54:44.413432 28047 net.cpp:139] Memory required for data: 1754800
I0428 19:54:44.413439 28047 layer_factory.hpp:77] Creating layer conv1
I0428 19:54:44.413456 28047 net.cpp:86] Creating Layer conv1
I0428 19:54:44.413465 28047 net.cpp:408] conv1 <- pool0
I0428 19:54:44.413476 28047 net.cpp:382] conv1 -> conv1
I0428 19:54:44.416496 28047 net.cpp:124] Setting up conv1
I0428 19:54:44.416534 28047 net.cpp:131] Top shape: 100 100 8 8 (640000)
I0428 19:54:44.416543 28047 net.cpp:139] Memory required for data: 4314800
I0428 19:54:44.416560 28047 layer_factory.hpp:77] Creating layer pool1
I0428 19:54:44.416584 28047 net.cpp:86] Creating Layer pool1
I0428 19:54:44.416592 28047 net.cpp:408] pool1 <- conv1
I0428 19:54:44.416609 28047 net.cpp:382] pool1 -> pool1
I0428 19:54:44.416684 28047 net.cpp:124] Setting up pool1
I0428 19:54:44.416697 28047 net.cpp:131] Top shape: 100 100 4 4 (160000)
I0428 19:54:44.416705 28047 net.cpp:139] Memory required for data: 4954800
I0428 19:54:44.416712 28047 layer_factory.hpp:77] Creating layer ip1
I0428 19:54:44.416725 28047 net.cpp:86] Creating Layer ip1
I0428 19:54:44.416733 28047 net.cpp:408] ip1 <- pool1
I0428 19:54:44.416743 28047 net.cpp:382] ip1 -> ip1
I0428 19:54:44.417202 28047 net.cpp:124] Setting up ip1
I0428 19:54:44.417219 28047 net.cpp:131] Top shape: 100 10 (1000)
I0428 19:54:44.417258 28047 net.cpp:139] Memory required for data: 4958800
I0428 19:54:44.417274 28047 layer_factory.hpp:77] Creating layer relu1
I0428 19:54:44.417284 28047 net.cpp:86] Creating Layer relu1
I0428 19:54:44.417291 28047 net.cpp:408] relu1 <- ip1
I0428 19:54:44.417301 28047 net.cpp:369] relu1 -> ip1 (in-place)
I0428 19:54:44.417636 28047 net.cpp:124] Setting up relu1
I0428 19:54:44.417652 28047 net.cpp:131] Top shape: 100 10 (1000)
I0428 19:54:44.417668 28047 net.cpp:139] Memory required for data: 4962800
I0428 19:54:44.417675 28047 layer_factory.hpp:77] Creating layer ip2
I0428 19:54:44.417690 28047 net.cpp:86] Creating Layer ip2
I0428 19:54:44.417696 28047 net.cpp:408] ip2 <- ip1
I0428 19:54:44.417714 28047 net.cpp:382] ip2 -> ip2
I0428 19:54:44.417920 28047 net.cpp:124] Setting up ip2
I0428 19:54:44.417933 28047 net.cpp:131] Top shape: 100 25 (2500)
I0428 19:54:44.417940 28047 net.cpp:139] Memory required for data: 4972800
I0428 19:54:44.417953 28047 layer_factory.hpp:77] Creating layer relu2
I0428 19:54:44.417961 28047 net.cpp:86] Creating Layer relu2
I0428 19:54:44.417982 28047 net.cpp:408] relu2 <- ip2
I0428 19:54:44.417991 28047 net.cpp:369] relu2 -> ip2 (in-place)
I0428 19:54:44.418329 28047 net.cpp:124] Setting up relu2
I0428 19:54:44.418341 28047 net.cpp:131] Top shape: 100 25 (2500)
I0428 19:54:44.418349 28047 net.cpp:139] Memory required for data: 4982800
I0428 19:54:44.418355 28047 layer_factory.hpp:77] Creating layer ip3
I0428 19:54:44.418366 28047 net.cpp:86] Creating Layer ip3
I0428 19:54:44.418372 28047 net.cpp:408] ip3 <- ip2
I0428 19:54:44.418383 28047 net.cpp:382] ip3 -> ip3
I0428 19:54:44.418582 28047 net.cpp:124] Setting up ip3
I0428 19:54:44.418594 28047 net.cpp:131] Top shape: 100 10 (1000)
I0428 19:54:44.418601 28047 net.cpp:139] Memory required for data: 4986800
I0428 19:54:44.418617 28047 layer_factory.hpp:77] Creating layer relu3
I0428 19:54:44.418627 28047 net.cpp:86] Creating Layer relu3
I0428 19:54:44.418633 28047 net.cpp:408] relu3 <- ip3
I0428 19:54:44.418642 28047 net.cpp:369] relu3 -> ip3 (in-place)
I0428 19:54:44.420107 28047 net.cpp:124] Setting up relu3
I0428 19:54:44.420155 28047 net.cpp:131] Top shape: 100 10 (1000)
I0428 19:54:44.420162 28047 net.cpp:139] Memory required for data: 4990800
I0428 19:54:44.420169 28047 layer_factory.hpp:77] Creating layer ip3_relu3_0_split
I0428 19:54:44.420194 28047 net.cpp:86] Creating Layer ip3_relu3_0_split
I0428 19:54:44.420202 28047 net.cpp:408] ip3_relu3_0_split <- ip3
I0428 19:54:44.420223 28047 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_0
I0428 19:54:44.420238 28047 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_1
I0428 19:54:44.420310 28047 net.cpp:124] Setting up ip3_relu3_0_split
I0428 19:54:44.420322 28047 net.cpp:131] Top shape: 100 10 (1000)
I0428 19:54:44.420331 28047 net.cpp:131] Top shape: 100 10 (1000)
I0428 19:54:44.420337 28047 net.cpp:139] Memory required for data: 4998800
I0428 19:54:44.420344 28047 layer_factory.hpp:77] Creating layer accuracy
I0428 19:54:44.420353 28047 net.cpp:86] Creating Layer accuracy
I0428 19:54:44.420367 28047 net.cpp:408] accuracy <- ip3_relu3_0_split_0
I0428 19:54:44.420375 28047 net.cpp:408] accuracy <- label_mnist_1_split_0
I0428 19:54:44.420385 28047 net.cpp:382] accuracy -> accuracy
I0428 19:54:44.420398 28047 net.cpp:124] Setting up accuracy
I0428 19:54:44.420406 28047 net.cpp:131] Top shape: (1)
I0428 19:54:44.420413 28047 net.cpp:139] Memory required for data: 4998804
I0428 19:54:44.420419 28047 layer_factory.hpp:77] Creating layer loss
I0428 19:54:44.420428 28047 net.cpp:86] Creating Layer loss
I0428 19:54:44.420435 28047 net.cpp:408] loss <- ip3_relu3_0_split_1
I0428 19:54:44.420455 28047 net.cpp:408] loss <- label_mnist_1_split_1
I0428 19:54:44.420464 28047 net.cpp:382] loss -> loss
I0428 19:54:44.420477 28047 layer_factory.hpp:77] Creating layer loss
I0428 19:54:44.420990 28047 net.cpp:124] Setting up loss
I0428 19:54:44.421020 28047 net.cpp:131] Top shape: (1)
I0428 19:54:44.421027 28047 net.cpp:134]     with loss weight 1
I0428 19:54:44.421061 28047 net.cpp:139] Memory required for data: 4998808
I0428 19:54:44.421067 28047 net.cpp:200] loss needs backward computation.
I0428 19:54:44.421077 28047 net.cpp:202] accuracy does not need backward computation.
I0428 19:54:44.421084 28047 net.cpp:200] ip3_relu3_0_split needs backward computation.
I0428 19:54:44.421090 28047 net.cpp:200] relu3 needs backward computation.
I0428 19:54:44.421097 28047 net.cpp:200] ip3 needs backward computation.
I0428 19:54:44.421103 28047 net.cpp:200] relu2 needs backward computation.
I0428 19:54:44.421109 28047 net.cpp:200] ip2 needs backward computation.
I0428 19:54:44.421123 28047 net.cpp:200] relu1 needs backward computation.
I0428 19:54:44.421129 28047 net.cpp:200] ip1 needs backward computation.
I0428 19:54:44.421136 28047 net.cpp:200] pool1 needs backward computation.
I0428 19:54:44.421142 28047 net.cpp:200] conv1 needs backward computation.
I0428 19:54:44.421149 28047 net.cpp:200] pool0 needs backward computation.
I0428 19:54:44.421156 28047 net.cpp:200] conv0 needs backward computation.
I0428 19:54:44.421164 28047 net.cpp:202] label_mnist_1_split does not need backward computation.
I0428 19:54:44.421172 28047 net.cpp:202] mnist does not need backward computation.
I0428 19:54:44.421178 28047 net.cpp:244] This network produces output accuracy
I0428 19:54:44.421185 28047 net.cpp:244] This network produces output loss
I0428 19:54:44.421207 28047 net.cpp:257] Network initialization done.
I0428 19:54:44.421324 28047 solver.cpp:56] Solver scaffolding done.
I0428 19:54:44.422060 28047 caffe.cpp:248] Starting Optimization
I0428 19:54:44.422070 28047 solver.cpp:273] Solving LeNet
I0428 19:54:44.422087 28047 solver.cpp:274] Learning Rate Policy: inv
I0428 19:54:44.422427 28047 solver.cpp:331] Iteration 0, Testing net (#0)
I0428 19:54:44.432783 28047 blocking_queue.cpp:49] Waiting for data
I0428 19:54:44.503396 28054 data_layer.cpp:73] Restarting data prefetching from start.
I0428 19:54:44.504019 28047 solver.cpp:398]     Test net output #0: accuracy = 0.1031
I0428 19:54:44.504053 28047 solver.cpp:398]     Test net output #1: loss = 2.30881 (* 1 = 2.30881 loss)
I0428 19:54:44.507813 28047 solver.cpp:219] Iteration 0 (-1.06814e-30 iter/s, 0.0856935s/100 iters), loss = 2.31671
I0428 19:54:44.507851 28047 solver.cpp:238]     Train net output #0: loss = 2.31671 (* 1 = 2.31671 loss)
I0428 19:54:44.507863 28047 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0428 19:54:44.655879 28047 solver.cpp:219] Iteration 100 (675.546 iter/s, 0.148028s/100 iters), loss = 0.397801
I0428 19:54:44.655902 28047 solver.cpp:238]     Train net output #0: loss = 0.397801 (* 1 = 0.397801 loss)
I0428 19:54:44.655910 28047 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0428 19:54:44.795012 28047 solver.cpp:219] Iteration 200 (718.922 iter/s, 0.139097s/100 iters), loss = 0.295191
I0428 19:54:44.795035 28047 solver.cpp:238]     Train net output #0: loss = 0.295191 (* 1 = 0.295191 loss)
I0428 19:54:44.795058 28047 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0428 19:54:44.937460 28047 solver.cpp:219] Iteration 300 (702.189 iter/s, 0.142412s/100 iters), loss = 0.303099
I0428 19:54:44.937484 28047 solver.cpp:238]     Train net output #0: loss = 0.303099 (* 1 = 0.303099 loss)
I0428 19:54:44.937505 28047 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0428 19:54:45.095602 28047 solver.cpp:219] Iteration 400 (632.517 iter/s, 0.158099s/100 iters), loss = 0.127741
I0428 19:54:45.095662 28047 solver.cpp:238]     Train net output #0: loss = 0.127741 (* 1 = 0.127741 loss)
I0428 19:54:45.095677 28047 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0428 19:54:45.270908 28047 solver.cpp:331] Iteration 500, Testing net (#0)
I0428 19:54:45.347350 28054 data_layer.cpp:73] Restarting data prefetching from start.
I0428 19:54:45.348070 28047 solver.cpp:398]     Test net output #0: accuracy = 0.9543
I0428 19:54:45.348101 28047 solver.cpp:398]     Test net output #1: loss = 0.152556 (* 1 = 0.152556 loss)
I0428 19:54:45.349894 28047 solver.cpp:219] Iteration 500 (393.352 iter/s, 0.254225s/100 iters), loss = 0.137989
I0428 19:54:45.349958 28047 solver.cpp:238]     Train net output #0: loss = 0.137989 (* 1 = 0.137989 loss)
I0428 19:54:45.349969 28047 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0428 19:54:45.521699 28047 solver.cpp:219] Iteration 600 (582.299 iter/s, 0.171733s/100 iters), loss = 0.122882
I0428 19:54:45.521747 28047 solver.cpp:238]     Train net output #0: loss = 0.122882 (* 1 = 0.122882 loss)
I0428 19:54:45.521759 28047 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0428 19:54:45.698549 28047 solver.cpp:219] Iteration 700 (565.66 iter/s, 0.176785s/100 iters), loss = 0.207918
I0428 19:54:45.698603 28047 solver.cpp:238]     Train net output #0: loss = 0.207918 (* 1 = 0.207918 loss)
I0428 19:54:45.698616 28047 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0428 19:54:45.878995 28047 solver.cpp:219] Iteration 800 (554.389 iter/s, 0.180379s/100 iters), loss = 0.307985
I0428 19:54:45.879042 28047 solver.cpp:238]     Train net output #0: loss = 0.307985 (* 1 = 0.307985 loss)
I0428 19:54:45.879055 28047 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0428 19:54:46.055258 28047 solver.cpp:219] Iteration 900 (567.537 iter/s, 0.1762s/100 iters), loss = 0.214081
I0428 19:54:46.055317 28047 solver.cpp:238]     Train net output #0: loss = 0.214081 (* 1 = 0.214081 loss)
I0428 19:54:46.055330 28047 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0428 19:54:46.114040 28053 data_layer.cpp:73] Restarting data prefetching from start.
I0428 19:54:46.229511 28047 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_1000.caffemodel
I0428 19:54:46.231549 28047 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_1000.solverstate
I0428 19:54:46.232565 28047 solver.cpp:311] Iteration 1000, loss = 0.180133
I0428 19:54:46.232591 28047 solver.cpp:331] Iteration 1000, Testing net (#0)
I0428 19:54:46.307714 28054 data_layer.cpp:73] Restarting data prefetching from start.
I0428 19:54:46.308360 28047 solver.cpp:398]     Test net output #0: accuracy = 0.9686
I0428 19:54:46.308387 28047 solver.cpp:398]     Test net output #1: loss = 0.102434 (* 1 = 0.102434 loss)
I0428 19:54:46.308393 28047 solver.cpp:316] Optimization Done.
I0428 19:54:46.308396 28047 caffe.cpp:259] Optimization Done.
