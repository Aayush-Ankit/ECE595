I0408 11:50:52.937412 10019 caffe.cpp:218] Using GPUs 0
I0408 11:50:52.951689 10019 caffe.cpp:223] GPU 0: GeForce GTX 950M
I0408 11:50:53.131836 10019 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_fc_size/lenet_train_test_fcl1_fcn300.prototxt"
train_state {
  level: 0
  stage: ""
}
I0408 11:50:53.132058 10019 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_fc_size/lenet_train_test_fcl1_fcn300.prototxt
I0408 11:50:53.132280 10019 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0408 11:50:53.132288 10019 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0408 11:50:53.132410 10019 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0408 11:50:53.132480 10019 layer_factory.hpp:77] Creating layer mnist
I0408 11:50:53.132618 10019 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0408 11:50:53.132670 10019 net.cpp:84] Creating Layer mnist
I0408 11:50:53.132678 10019 net.cpp:380] mnist -> data
I0408 11:50:53.132694 10019 net.cpp:380] mnist -> label
I0408 11:50:53.133222 10019 data_layer.cpp:45] output data size: 64,1,28,28
I0408 11:50:53.134539 10019 net.cpp:122] Setting up mnist
I0408 11:50:53.134548 10019 net.cpp:129] Top shape: 64 1 28 28 (50176)
I0408 11:50:53.134572 10019 net.cpp:129] Top shape: 64 (64)
I0408 11:50:53.134574 10019 net.cpp:137] Memory required for data: 200960
I0408 11:50:53.134598 10019 layer_factory.hpp:77] Creating layer conv0
I0408 11:50:53.134608 10019 net.cpp:84] Creating Layer conv0
I0408 11:50:53.134613 10019 net.cpp:406] conv0 <- data
I0408 11:50:53.134624 10019 net.cpp:380] conv0 -> conv0
I0408 11:50:53.135828 10019 net.cpp:122] Setting up conv0
I0408 11:50:53.135835 10019 net.cpp:129] Top shape: 64 50 24 24 (1843200)
I0408 11:50:53.135838 10019 net.cpp:137] Memory required for data: 7573760
I0408 11:50:53.135869 10019 layer_factory.hpp:77] Creating layer pool0
I0408 11:50:53.135874 10019 net.cpp:84] Creating Layer pool0
I0408 11:50:53.135876 10019 net.cpp:406] pool0 <- conv0
I0408 11:50:53.135881 10019 net.cpp:380] pool0 -> pool0
I0408 11:50:53.135970 10019 net.cpp:122] Setting up pool0
I0408 11:50:53.135975 10019 net.cpp:129] Top shape: 64 50 12 12 (460800)
I0408 11:50:53.136006 10019 net.cpp:137] Memory required for data: 9416960
I0408 11:50:53.136008 10019 layer_factory.hpp:77] Creating layer conv1
I0408 11:50:53.136016 10019 net.cpp:84] Creating Layer conv1
I0408 11:50:53.136019 10019 net.cpp:406] conv1 <- pool0
I0408 11:50:53.136023 10019 net.cpp:380] conv1 -> conv1
I0408 11:50:53.136853 10019 net.cpp:122] Setting up conv1
I0408 11:50:53.136862 10019 net.cpp:129] Top shape: 64 50 8 8 (204800)
I0408 11:50:53.136864 10019 net.cpp:137] Memory required for data: 10236160
I0408 11:50:53.136889 10019 layer_factory.hpp:77] Creating layer pool1
I0408 11:50:53.136895 10019 net.cpp:84] Creating Layer pool1
I0408 11:50:53.136912 10019 net.cpp:406] pool1 <- conv1
I0408 11:50:53.136916 10019 net.cpp:380] pool1 -> pool1
I0408 11:50:53.136943 10019 net.cpp:122] Setting up pool1
I0408 11:50:53.136948 10019 net.cpp:129] Top shape: 64 50 4 4 (51200)
I0408 11:50:53.136950 10019 net.cpp:137] Memory required for data: 10440960
I0408 11:50:53.136952 10019 layer_factory.hpp:77] Creating layer ip1
I0408 11:50:53.136956 10019 net.cpp:84] Creating Layer ip1
I0408 11:50:53.136958 10019 net.cpp:406] ip1 <- pool1
I0408 11:50:53.136963 10019 net.cpp:380] ip1 -> ip1
I0408 11:50:53.137593 10019 net.cpp:122] Setting up ip1
I0408 11:50:53.137598 10019 net.cpp:129] Top shape: 64 10 (640)
I0408 11:50:53.137614 10019 net.cpp:137] Memory required for data: 10443520
I0408 11:50:53.137620 10019 layer_factory.hpp:77] Creating layer relu1
I0408 11:50:53.137625 10019 net.cpp:84] Creating Layer relu1
I0408 11:50:53.137627 10019 net.cpp:406] relu1 <- ip1
I0408 11:50:53.137631 10019 net.cpp:367] relu1 -> ip1 (in-place)
I0408 11:50:53.137656 10019 net.cpp:122] Setting up relu1
I0408 11:50:53.137660 10019 net.cpp:129] Top shape: 64 10 (640)
I0408 11:50:53.137662 10019 net.cpp:137] Memory required for data: 10446080
I0408 11:50:53.137665 10019 layer_factory.hpp:77] Creating layer loss
I0408 11:50:53.137668 10019 net.cpp:84] Creating Layer loss
I0408 11:50:53.137671 10019 net.cpp:406] loss <- ip1
I0408 11:50:53.137673 10019 net.cpp:406] loss <- label
I0408 11:50:53.137677 10019 net.cpp:380] loss -> loss
I0408 11:50:53.137686 10019 layer_factory.hpp:77] Creating layer loss
I0408 11:50:53.137791 10019 net.cpp:122] Setting up loss
I0408 11:50:53.137796 10019 net.cpp:129] Top shape: (1)
I0408 11:50:53.137799 10019 net.cpp:132]     with loss weight 1
I0408 11:50:53.137815 10019 net.cpp:137] Memory required for data: 10446084
I0408 11:50:53.137818 10019 net.cpp:198] loss needs backward computation.
I0408 11:50:53.137823 10019 net.cpp:198] relu1 needs backward computation.
I0408 11:50:53.137825 10019 net.cpp:198] ip1 needs backward computation.
I0408 11:50:53.137828 10019 net.cpp:198] pool1 needs backward computation.
I0408 11:50:53.137830 10019 net.cpp:198] conv1 needs backward computation.
I0408 11:50:53.137832 10019 net.cpp:198] pool0 needs backward computation.
I0408 11:50:53.137850 10019 net.cpp:198] conv0 needs backward computation.
I0408 11:50:53.137851 10019 net.cpp:200] mnist does not need backward computation.
I0408 11:50:53.137854 10019 net.cpp:242] This network produces output loss
I0408 11:50:53.137863 10019 net.cpp:255] Network initialization done.
I0408 11:50:53.138011 10019 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_fc_size/lenet_train_test_fcl1_fcn300.prototxt
I0408 11:50:53.138027 10019 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0408 11:50:53.138087 10019 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0408 11:50:53.138160 10019 layer_factory.hpp:77] Creating layer mnist
I0408 11:50:53.138236 10019 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0408 11:50:53.138247 10019 net.cpp:84] Creating Layer mnist
I0408 11:50:53.138252 10019 net.cpp:380] mnist -> data
I0408 11:50:53.138257 10019 net.cpp:380] mnist -> label
I0408 11:50:53.138420 10019 data_layer.cpp:45] output data size: 100,1,28,28
I0408 11:50:53.140281 10019 net.cpp:122] Setting up mnist
I0408 11:50:53.140310 10019 net.cpp:129] Top shape: 100 1 28 28 (78400)
I0408 11:50:53.140312 10019 net.cpp:129] Top shape: 100 (100)
I0408 11:50:53.140314 10019 net.cpp:137] Memory required for data: 314000
I0408 11:50:53.140317 10019 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0408 11:50:53.140323 10019 net.cpp:84] Creating Layer label_mnist_1_split
I0408 11:50:53.140327 10019 net.cpp:406] label_mnist_1_split <- label
I0408 11:50:53.140333 10019 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_0
I0408 11:50:53.140339 10019 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_1
I0408 11:50:53.140374 10019 net.cpp:122] Setting up label_mnist_1_split
I0408 11:50:53.140379 10019 net.cpp:129] Top shape: 100 (100)
I0408 11:50:53.140383 10019 net.cpp:129] Top shape: 100 (100)
I0408 11:50:53.140383 10019 net.cpp:137] Memory required for data: 314800
I0408 11:50:53.140386 10019 layer_factory.hpp:77] Creating layer conv0
I0408 11:50:53.140394 10019 net.cpp:84] Creating Layer conv0
I0408 11:50:53.140398 10019 net.cpp:406] conv0 <- data
I0408 11:50:53.140403 10019 net.cpp:380] conv0 -> conv0
I0408 11:50:53.140625 10019 net.cpp:122] Setting up conv0
I0408 11:50:53.140631 10019 net.cpp:129] Top shape: 100 50 24 24 (2880000)
I0408 11:50:53.140633 10019 net.cpp:137] Memory required for data: 11834800
I0408 11:50:53.140641 10019 layer_factory.hpp:77] Creating layer pool0
I0408 11:50:53.140647 10019 net.cpp:84] Creating Layer pool0
I0408 11:50:53.140650 10019 net.cpp:406] pool0 <- conv0
I0408 11:50:53.140653 10019 net.cpp:380] pool0 -> pool0
I0408 11:50:53.140679 10019 net.cpp:122] Setting up pool0
I0408 11:50:53.140684 10019 net.cpp:129] Top shape: 100 50 12 12 (720000)
I0408 11:50:53.140686 10019 net.cpp:137] Memory required for data: 14714800
I0408 11:50:53.140688 10019 layer_factory.hpp:77] Creating layer conv1
I0408 11:50:53.140694 10019 net.cpp:84] Creating Layer conv1
I0408 11:50:53.140698 10019 net.cpp:406] conv1 <- pool0
I0408 11:50:53.140702 10019 net.cpp:380] conv1 -> conv1
I0408 11:50:53.141178 10019 net.cpp:122] Setting up conv1
I0408 11:50:53.141183 10019 net.cpp:129] Top shape: 100 50 8 8 (320000)
I0408 11:50:53.141186 10019 net.cpp:137] Memory required for data: 15994800
I0408 11:50:53.141191 10019 layer_factory.hpp:77] Creating layer pool1
I0408 11:50:53.141206 10019 net.cpp:84] Creating Layer pool1
I0408 11:50:53.141207 10019 net.cpp:406] pool1 <- conv1
I0408 11:50:53.141212 10019 net.cpp:380] pool1 -> pool1
I0408 11:50:53.141269 10019 net.cpp:122] Setting up pool1
I0408 11:50:53.141274 10019 net.cpp:129] Top shape: 100 50 4 4 (80000)
I0408 11:50:53.141276 10019 net.cpp:137] Memory required for data: 16314800
I0408 11:50:53.141280 10019 layer_factory.hpp:77] Creating layer ip1
I0408 11:50:53.141288 10019 net.cpp:84] Creating Layer ip1
I0408 11:50:53.141290 10019 net.cpp:406] ip1 <- pool1
I0408 11:50:53.141294 10019 net.cpp:380] ip1 -> ip1
I0408 11:50:53.141414 10019 net.cpp:122] Setting up ip1
I0408 11:50:53.141419 10019 net.cpp:129] Top shape: 100 10 (1000)
I0408 11:50:53.141422 10019 net.cpp:137] Memory required for data: 16318800
I0408 11:50:53.141429 10019 layer_factory.hpp:77] Creating layer relu1
I0408 11:50:53.141434 10019 net.cpp:84] Creating Layer relu1
I0408 11:50:53.141438 10019 net.cpp:406] relu1 <- ip1
I0408 11:50:53.141441 10019 net.cpp:367] relu1 -> ip1 (in-place)
I0408 11:50:53.141445 10019 net.cpp:122] Setting up relu1
I0408 11:50:53.141449 10019 net.cpp:129] Top shape: 100 10 (1000)
I0408 11:50:53.141451 10019 net.cpp:137] Memory required for data: 16322800
I0408 11:50:53.141453 10019 layer_factory.hpp:77] Creating layer ip1_relu1_0_split
I0408 11:50:53.141458 10019 net.cpp:84] Creating Layer ip1_relu1_0_split
I0408 11:50:53.141461 10019 net.cpp:406] ip1_relu1_0_split <- ip1
I0408 11:50:53.141465 10019 net.cpp:380] ip1_relu1_0_split -> ip1_relu1_0_split_0
I0408 11:50:53.141472 10019 net.cpp:380] ip1_relu1_0_split -> ip1_relu1_0_split_1
I0408 11:50:53.141525 10019 net.cpp:122] Setting up ip1_relu1_0_split
I0408 11:50:53.141530 10019 net.cpp:129] Top shape: 100 10 (1000)
I0408 11:50:53.141532 10019 net.cpp:129] Top shape: 100 10 (1000)
I0408 11:50:53.141535 10019 net.cpp:137] Memory required for data: 16330800
I0408 11:50:53.141536 10019 layer_factory.hpp:77] Creating layer accuracy
I0408 11:50:53.141541 10019 net.cpp:84] Creating Layer accuracy
I0408 11:50:53.141544 10019 net.cpp:406] accuracy <- ip1_relu1_0_split_0
I0408 11:50:53.141547 10019 net.cpp:406] accuracy <- label_mnist_1_split_0
I0408 11:50:53.141551 10019 net.cpp:380] accuracy -> accuracy
I0408 11:50:53.141558 10019 net.cpp:122] Setting up accuracy
I0408 11:50:53.141561 10019 net.cpp:129] Top shape: (1)
I0408 11:50:53.141563 10019 net.cpp:137] Memory required for data: 16330804
I0408 11:50:53.141566 10019 layer_factory.hpp:77] Creating layer loss
I0408 11:50:53.141571 10019 net.cpp:84] Creating Layer loss
I0408 11:50:53.141574 10019 net.cpp:406] loss <- ip1_relu1_0_split_1
I0408 11:50:53.141577 10019 net.cpp:406] loss <- label_mnist_1_split_1
I0408 11:50:53.141580 10019 net.cpp:380] loss -> loss
I0408 11:50:53.141587 10019 layer_factory.hpp:77] Creating layer loss
I0408 11:50:53.141680 10019 net.cpp:122] Setting up loss
I0408 11:50:53.141685 10019 net.cpp:129] Top shape: (1)
I0408 11:50:53.141686 10019 net.cpp:132]     with loss weight 1
I0408 11:50:53.141711 10019 net.cpp:137] Memory required for data: 16330808
I0408 11:50:53.141715 10019 net.cpp:198] loss needs backward computation.
I0408 11:50:53.141717 10019 net.cpp:200] accuracy does not need backward computation.
I0408 11:50:53.141733 10019 net.cpp:198] ip1_relu1_0_split needs backward computation.
I0408 11:50:53.141736 10019 net.cpp:198] relu1 needs backward computation.
I0408 11:50:53.141738 10019 net.cpp:198] ip1 needs backward computation.
I0408 11:50:53.141741 10019 net.cpp:198] pool1 needs backward computation.
I0408 11:50:53.141742 10019 net.cpp:198] conv1 needs backward computation.
I0408 11:50:53.141744 10019 net.cpp:198] pool0 needs backward computation.
I0408 11:50:53.141746 10019 net.cpp:198] conv0 needs backward computation.
I0408 11:50:53.141749 10019 net.cpp:200] label_mnist_1_split does not need backward computation.
I0408 11:50:53.141752 10019 net.cpp:200] mnist does not need backward computation.
I0408 11:50:53.141754 10019 net.cpp:242] This network produces output accuracy
I0408 11:50:53.141757 10019 net.cpp:242] This network produces output loss
I0408 11:50:53.141772 10019 net.cpp:255] Network initialization done.
I0408 11:50:53.141814 10019 solver.cpp:56] Solver scaffolding done.
I0408 11:50:53.141984 10019 caffe.cpp:248] Starting Optimization
I0408 11:50:53.141988 10019 solver.cpp:273] Solving LeNet
I0408 11:50:53.141990 10019 solver.cpp:274] Learning Rate Policy: inv
I0408 11:50:53.142563 10019 solver.cpp:331] Iteration 0, Testing net (#0)
I0408 11:50:55.262316 10027 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:50:55.358062 10019 solver.cpp:398]     Test net output #0: accuracy = 0.1126
I0408 11:50:55.358103 10019 solver.cpp:398]     Test net output #1: loss = 2.32085 (* 1 = 2.32085 loss)
I0408 11:50:55.389822 10019 solver.cpp:219] Iteration 0 (-7.05778e+12 iter/s, 2.24778s/100 iters), loss = 2.35838
I0408 11:50:55.389844 10019 solver.cpp:238]     Train net output #0: loss = 2.35838 (* 1 = 2.35838 loss)
I0408 11:50:55.389874 10019 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0408 11:50:58.199084 10019 solver.cpp:219] Iteration 100 (35.6247 iter/s, 2.80704s/100 iters), loss = 0.988091
I0408 11:50:58.199111 10019 solver.cpp:238]     Train net output #0: loss = 0.988091 (* 1 = 0.988091 loss)
I0408 11:50:58.199116 10019 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0408 11:51:01.001503 10019 solver.cpp:219] Iteration 200 (35.6844 iter/s, 2.80234s/100 iters), loss = 0.375039
I0408 11:51:01.001549 10019 solver.cpp:238]     Train net output #0: loss = 0.375039 (* 1 = 0.375039 loss)
I0408 11:51:01.001567 10019 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0408 11:51:03.805094 10019 solver.cpp:219] Iteration 300 (35.6696 iter/s, 2.80351s/100 iters), loss = 0.18465
I0408 11:51:03.805122 10019 solver.cpp:238]     Train net output #0: loss = 0.18465 (* 1 = 0.18465 loss)
I0408 11:51:03.805127 10019 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0408 11:51:06.600198 10019 solver.cpp:219] Iteration 400 (35.7778 iter/s, 2.79503s/100 iters), loss = 0.0853203
I0408 11:51:06.600227 10019 solver.cpp:238]     Train net output #0: loss = 0.0853202 (* 1 = 0.0853202 loss)
I0408 11:51:06.600250 10019 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0408 11:51:09.353503 10019 solver.cpp:331] Iteration 500, Testing net (#0)
I0408 11:51:11.478545 10027 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:51:11.572937 10019 solver.cpp:398]     Test net output #0: accuracy = 0.968
I0408 11:51:11.572978 10019 solver.cpp:398]     Test net output #1: loss = 0.107544 (* 1 = 0.107544 loss)
I0408 11:51:11.601013 10019 solver.cpp:219] Iteration 500 (19.9971 iter/s, 5.00072s/100 iters), loss = 0.128879
I0408 11:51:11.601052 10019 solver.cpp:238]     Train net output #0: loss = 0.128879 (* 1 = 0.128879 loss)
I0408 11:51:11.601058 10019 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0408 11:51:14.399116 10019 solver.cpp:219] Iteration 600 (35.7669 iter/s, 2.79588s/100 iters), loss = 0.0980754
I0408 11:51:14.399144 10019 solver.cpp:238]     Train net output #0: loss = 0.0980754 (* 1 = 0.0980754 loss)
I0408 11:51:14.399148 10019 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0408 11:51:17.190114 10019 solver.cpp:219] Iteration 700 (35.8304 iter/s, 2.79092s/100 iters), loss = 0.122459
I0408 11:51:17.190160 10019 solver.cpp:238]     Train net output #0: loss = 0.122459 (* 1 = 0.122459 loss)
I0408 11:51:17.190165 10019 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0408 11:51:19.982683 10019 solver.cpp:219] Iteration 800 (35.8105 iter/s, 2.79248s/100 iters), loss = 0.195764
I0408 11:51:19.982730 10019 solver.cpp:238]     Train net output #0: loss = 0.195764 (* 1 = 0.195764 loss)
I0408 11:51:19.982748 10019 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0408 11:51:22.772852 10019 solver.cpp:219] Iteration 900 (35.8413 iter/s, 2.79008s/100 iters), loss = 0.138159
I0408 11:51:22.772881 10019 solver.cpp:238]     Train net output #0: loss = 0.138159 (* 1 = 0.138159 loss)
I0408 11:51:22.772886 10019 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0408 11:51:23.701489 10026 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:51:25.535665 10019 solver.cpp:331] Iteration 1000, Testing net (#0)
I0408 11:51:27.663461 10027 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:51:27.758071 10019 solver.cpp:398]     Test net output #0: accuracy = 0.9739
I0408 11:51:27.758095 10019 solver.cpp:398]     Test net output #1: loss = 0.0778735 (* 1 = 0.0778735 loss)
I0408 11:51:27.785743 10019 solver.cpp:219] Iteration 1000 (19.949 iter/s, 5.01279s/100 iters), loss = 0.117821
I0408 11:51:27.785765 10019 solver.cpp:238]     Train net output #0: loss = 0.117821 (* 1 = 0.117821 loss)
I0408 11:51:27.785790 10019 sgd_solver.cpp:105] Iteration 1000, lr = 0.00931012
I0408 11:51:30.588634 10019 solver.cpp:219] Iteration 1100 (35.6783 iter/s, 2.80283s/100 iters), loss = 0.0175365
I0408 11:51:30.588663 10019 solver.cpp:238]     Train net output #0: loss = 0.0175365 (* 1 = 0.0175365 loss)
I0408 11:51:30.588668 10019 sgd_solver.cpp:105] Iteration 1100, lr = 0.00924715
I0408 11:51:33.375934 10019 solver.cpp:219] Iteration 1200 (35.878 iter/s, 2.78723s/100 iters), loss = 0.0340557
I0408 11:51:33.375963 10019 solver.cpp:238]     Train net output #0: loss = 0.0340558 (* 1 = 0.0340558 loss)
I0408 11:51:33.375967 10019 sgd_solver.cpp:105] Iteration 1200, lr = 0.00918515
I0408 11:51:36.167290 10019 solver.cpp:219] Iteration 1300 (35.8258 iter/s, 2.79128s/100 iters), loss = 0.0326836
I0408 11:51:36.167320 10019 solver.cpp:238]     Train net output #0: loss = 0.0326836 (* 1 = 0.0326836 loss)
I0408 11:51:36.167325 10019 sgd_solver.cpp:105] Iteration 1300, lr = 0.00912412
I0408 11:51:38.961024 10019 solver.cpp:219] Iteration 1400 (35.7953 iter/s, 2.79366s/100 iters), loss = 0.00964233
I0408 11:51:38.961053 10019 solver.cpp:238]     Train net output #0: loss = 0.00964231 (* 1 = 0.00964231 loss)
I0408 11:51:38.961057 10019 sgd_solver.cpp:105] Iteration 1400, lr = 0.00906403
I0408 11:51:41.709105 10019 solver.cpp:331] Iteration 1500, Testing net (#0)
I0408 11:51:43.827478 10027 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:51:43.922387 10019 solver.cpp:398]     Test net output #0: accuracy = 0.9779
I0408 11:51:43.922428 10019 solver.cpp:398]     Test net output #1: loss = 0.0674037 (* 1 = 0.0674037 loss)
I0408 11:51:43.950515 10019 solver.cpp:219] Iteration 1500 (20.0425 iter/s, 4.98939s/100 iters), loss = 0.118894
I0408 11:51:43.950538 10019 solver.cpp:238]     Train net output #0: loss = 0.118894 (* 1 = 0.118894 loss)
I0408 11:51:43.950544 10019 sgd_solver.cpp:105] Iteration 1500, lr = 0.00900485
I0408 11:51:46.748924 10019 solver.cpp:219] Iteration 1600 (35.7354 iter/s, 2.79834s/100 iters), loss = 0.173297
I0408 11:51:46.748953 10019 solver.cpp:238]     Train net output #0: loss = 0.173297 (* 1 = 0.173297 loss)
I0408 11:51:46.748958 10019 sgd_solver.cpp:105] Iteration 1600, lr = 0.00894657
I0408 11:51:49.542034 10019 solver.cpp:219] Iteration 1700 (35.8033 iter/s, 2.79304s/100 iters), loss = 0.0492498
I0408 11:51:49.542063 10019 solver.cpp:238]     Train net output #0: loss = 0.0492497 (* 1 = 0.0492497 loss)
I0408 11:51:49.542068 10019 sgd_solver.cpp:105] Iteration 1700, lr = 0.00888916
I0408 11:51:52.329483 10019 solver.cpp:219] Iteration 1800 (35.876 iter/s, 2.78738s/100 iters), loss = 0.0106812
I0408 11:51:52.329514 10019 solver.cpp:238]     Train net output #0: loss = 0.0106811 (* 1 = 0.0106811 loss)
I0408 11:51:52.329519 10019 sgd_solver.cpp:105] Iteration 1800, lr = 0.0088326
I0408 11:51:54.286747 10026 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:51:55.129366 10019 solver.cpp:219] Iteration 1900 (35.7167 iter/s, 2.79981s/100 iters), loss = 0.148097
I0408 11:51:55.129412 10019 solver.cpp:238]     Train net output #0: loss = 0.148097 (* 1 = 0.148097 loss)
I0408 11:51:55.129417 10019 sgd_solver.cpp:105] Iteration 1900, lr = 0.00877687
I0408 11:51:57.884400 10019 solver.cpp:331] Iteration 2000, Testing net (#0)
I0408 11:52:00.008826 10027 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:52:00.107365 10019 solver.cpp:398]     Test net output #0: accuracy = 0.9816
I0408 11:52:00.107389 10019 solver.cpp:398]     Test net output #1: loss = 0.0550463 (* 1 = 0.0550463 loss)
I0408 11:52:00.137637 10019 solver.cpp:219] Iteration 2000 (19.9674 iter/s, 5.00817s/100 iters), loss = 0.0386254
I0408 11:52:00.137657 10019 solver.cpp:238]     Train net output #0: loss = 0.0386253 (* 1 = 0.0386253 loss)
I0408 11:52:00.137682 10019 sgd_solver.cpp:105] Iteration 2000, lr = 0.00872196
I0408 11:52:02.936394 10019 solver.cpp:219] Iteration 2100 (35.7585 iter/s, 2.79654s/100 iters), loss = 0.0310006
I0408 11:52:02.936441 10019 solver.cpp:238]     Train net output #0: loss = 0.0310006 (* 1 = 0.0310006 loss)
I0408 11:52:02.936446 10019 sgd_solver.cpp:105] Iteration 2100, lr = 0.00866784
I0408 11:52:05.733677 10019 solver.cpp:219] Iteration 2200 (35.7501 iter/s, 2.79719s/100 iters), loss = 0.0213569
I0408 11:52:05.733723 10019 solver.cpp:238]     Train net output #0: loss = 0.0213568 (* 1 = 0.0213568 loss)
I0408 11:52:05.733728 10019 sgd_solver.cpp:105] Iteration 2200, lr = 0.0086145
I0408 11:52:08.527982 10019 solver.cpp:219] Iteration 2300 (35.7882 iter/s, 2.79422s/100 iters), loss = 0.0917881
I0408 11:52:08.528012 10019 solver.cpp:238]     Train net output #0: loss = 0.0917881 (* 1 = 0.0917881 loss)
I0408 11:52:08.528017 10019 sgd_solver.cpp:105] Iteration 2300, lr = 0.00856192
I0408 11:52:11.324761 10019 solver.cpp:219] Iteration 2400 (35.7563 iter/s, 2.79671s/100 iters), loss = 0.0123632
I0408 11:52:11.324790 10019 solver.cpp:238]     Train net output #0: loss = 0.0123632 (* 1 = 0.0123632 loss)
I0408 11:52:11.324795 10019 sgd_solver.cpp:105] Iteration 2400, lr = 0.00851008
I0408 11:52:14.075453 10019 solver.cpp:331] Iteration 2500, Testing net (#0)
I0408 11:52:16.198671 10027 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:52:16.292335 10019 solver.cpp:398]     Test net output #0: accuracy = 0.9778
I0408 11:52:16.292357 10019 solver.cpp:398]     Test net output #1: loss = 0.0668452 (* 1 = 0.0668452 loss)
I0408 11:52:16.320381 10019 solver.cpp:219] Iteration 2500 (20.0179 iter/s, 4.99553s/100 iters), loss = 0.037335
I0408 11:52:16.320402 10019 solver.cpp:238]     Train net output #0: loss = 0.0373349 (* 1 = 0.0373349 loss)
I0408 11:52:16.320408 10019 sgd_solver.cpp:105] Iteration 2500, lr = 0.00845897
I0408 11:52:19.119894 10019 solver.cpp:219] Iteration 2600 (35.7488 iter/s, 2.79729s/100 iters), loss = 0.1297
I0408 11:52:19.119930 10019 solver.cpp:238]     Train net output #0: loss = 0.1297 (* 1 = 0.1297 loss)
I0408 11:52:19.119954 10019 sgd_solver.cpp:105] Iteration 2600, lr = 0.00840857
I0408 11:52:21.908843 10019 solver.cpp:219] Iteration 2700 (35.8567 iter/s, 2.78888s/100 iters), loss = 0.163384
I0408 11:52:21.908888 10019 solver.cpp:238]     Train net output #0: loss = 0.163384 (* 1 = 0.163384 loss)
I0408 11:52:21.908893 10019 sgd_solver.cpp:105] Iteration 2700, lr = 0.00835886
I0408 11:52:24.698679 10019 solver.cpp:219] Iteration 2800 (35.8454 iter/s, 2.78976s/100 iters), loss = 0.00701432
I0408 11:52:24.698889 10019 solver.cpp:238]     Train net output #0: loss = 0.00701431 (* 1 = 0.00701431 loss)
I0408 11:52:24.698896 10019 sgd_solver.cpp:105] Iteration 2800, lr = 0.00830984
I0408 11:52:24.930258 10026 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:52:27.499651 10019 solver.cpp:219] Iteration 2900 (35.7048 iter/s, 2.80075s/100 iters), loss = 0.0284248
I0408 11:52:27.499680 10019 solver.cpp:238]     Train net output #0: loss = 0.0284248 (* 1 = 0.0284248 loss)
I0408 11:52:27.499686 10019 sgd_solver.cpp:105] Iteration 2900, lr = 0.00826148
I0408 11:52:30.268647 10019 solver.cpp:331] Iteration 3000, Testing net (#0)
I0408 11:52:32.401677 10027 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:52:32.495702 10019 solver.cpp:398]     Test net output #0: accuracy = 0.9787
I0408 11:52:32.495743 10019 solver.cpp:398]     Test net output #1: loss = 0.0655742 (* 1 = 0.0655742 loss)
I0408 11:52:32.523670 10019 solver.cpp:219] Iteration 3000 (19.9047 iter/s, 5.02393s/100 iters), loss = 0.0317166
I0408 11:52:32.523689 10019 solver.cpp:238]     Train net output #0: loss = 0.0317167 (* 1 = 0.0317167 loss)
I0408 11:52:32.523712 10019 sgd_solver.cpp:105] Iteration 3000, lr = 0.00821377
I0408 11:52:35.318439 10019 solver.cpp:219] Iteration 3100 (35.8095 iter/s, 2.79255s/100 iters), loss = 0.00472268
I0408 11:52:35.318469 10019 solver.cpp:238]     Train net output #0: loss = 0.00472274 (* 1 = 0.00472274 loss)
I0408 11:52:35.318473 10019 sgd_solver.cpp:105] Iteration 3100, lr = 0.0081667
I0408 11:52:38.111253 10019 solver.cpp:219] Iteration 3200 (35.8071 iter/s, 2.79274s/100 iters), loss = 0.0197176
I0408 11:52:38.111300 10019 solver.cpp:238]     Train net output #0: loss = 0.0197177 (* 1 = 0.0197177 loss)
I0408 11:52:38.111305 10019 sgd_solver.cpp:105] Iteration 3200, lr = 0.00812025
I0408 11:52:40.919950 10019 solver.cpp:219] Iteration 3300 (35.6048 iter/s, 2.80861s/100 iters), loss = 0.0593422
I0408 11:52:40.919999 10019 solver.cpp:238]     Train net output #0: loss = 0.0593423 (* 1 = 0.0593423 loss)
I0408 11:52:40.920003 10019 sgd_solver.cpp:105] Iteration 3300, lr = 0.00807442
I0408 11:52:43.744609 10019 solver.cpp:219] Iteration 3400 (35.4036 iter/s, 2.82457s/100 iters), loss = 0.0180237
I0408 11:52:43.744657 10019 solver.cpp:238]     Train net output #0: loss = 0.0180237 (* 1 = 0.0180237 loss)
I0408 11:52:43.744674 10019 sgd_solver.cpp:105] Iteration 3400, lr = 0.00802918
I0408 11:52:46.506139 10019 solver.cpp:331] Iteration 3500, Testing net (#0)
I0408 11:52:48.629057 10027 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:52:48.723942 10019 solver.cpp:398]     Test net output #0: accuracy = 0.9832
I0408 11:52:48.723965 10019 solver.cpp:398]     Test net output #1: loss = 0.0520104 (* 1 = 0.0520104 loss)
I0408 11:52:48.751992 10019 solver.cpp:219] Iteration 3500 (19.9709 iter/s, 5.00729s/100 iters), loss = 0.0183273
I0408 11:52:48.752012 10019 solver.cpp:238]     Train net output #0: loss = 0.0183273 (* 1 = 0.0183273 loss)
I0408 11:52:48.752018 10019 sgd_solver.cpp:105] Iteration 3500, lr = 0.00798454
I0408 11:52:51.547569 10019 solver.cpp:219] Iteration 3600 (35.7992 iter/s, 2.79336s/100 iters), loss = 0.0430584
I0408 11:52:51.547597 10019 solver.cpp:238]     Train net output #0: loss = 0.0430584 (* 1 = 0.0430584 loss)
I0408 11:52:51.547602 10019 sgd_solver.cpp:105] Iteration 3600, lr = 0.00794046
I0408 11:52:54.341811 10019 solver.cpp:219] Iteration 3700 (35.7887 iter/s, 2.79417s/100 iters), loss = 0.0655443
I0408 11:52:54.341840 10019 solver.cpp:238]     Train net output #0: loss = 0.0655443 (* 1 = 0.0655443 loss)
I0408 11:52:54.341845 10019 sgd_solver.cpp:105] Iteration 3700, lr = 0.00789695
I0408 11:52:55.604084 10026 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:52:57.141801 10019 solver.cpp:219] Iteration 3800 (35.7153 iter/s, 2.79992s/100 iters), loss = 0.0320129
I0408 11:52:57.141846 10019 solver.cpp:238]     Train net output #0: loss = 0.0320128 (* 1 = 0.0320128 loss)
I0408 11:52:57.141851 10019 sgd_solver.cpp:105] Iteration 3800, lr = 0.007854
I0408 11:52:59.941552 10019 solver.cpp:219] Iteration 3900 (35.7185 iter/s, 2.79967s/100 iters), loss = 0.0725316
I0408 11:52:59.941601 10019 solver.cpp:238]     Train net output #0: loss = 0.0725315 (* 1 = 0.0725315 loss)
I0408 11:52:59.941606 10019 sgd_solver.cpp:105] Iteration 3900, lr = 0.00781158
I0408 11:53:02.707350 10019 solver.cpp:331] Iteration 4000, Testing net (#0)
I0408 11:53:04.836441 10027 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:53:04.931368 10019 solver.cpp:398]     Test net output #0: accuracy = 0.986
I0408 11:53:04.931392 10019 solver.cpp:398]     Test net output #1: loss = 0.0424937 (* 1 = 0.0424937 loss)
I0408 11:53:04.959604 10019 solver.cpp:219] Iteration 4000 (19.9285 iter/s, 5.01795s/100 iters), loss = 0.0574037
I0408 11:53:04.959661 10019 solver.cpp:238]     Train net output #0: loss = 0.0574037 (* 1 = 0.0574037 loss)
I0408 11:53:04.959684 10019 sgd_solver.cpp:105] Iteration 4000, lr = 0.0077697
I0408 11:53:07.759912 10019 solver.cpp:219] Iteration 4100 (35.7386 iter/s, 2.79809s/100 iters), loss = 0.031951
I0408 11:53:07.759940 10019 solver.cpp:238]     Train net output #0: loss = 0.031951 (* 1 = 0.031951 loss)
I0408 11:53:07.759945 10019 sgd_solver.cpp:105] Iteration 4100, lr = 0.00772833
I0408 11:53:10.554775 10019 solver.cpp:219] Iteration 4200 (35.7808 iter/s, 2.7948s/100 iters), loss = 0.0163815
I0408 11:53:10.554822 10019 solver.cpp:238]     Train net output #0: loss = 0.0163815 (* 1 = 0.0163815 loss)
I0408 11:53:10.554826 10019 sgd_solver.cpp:105] Iteration 4200, lr = 0.00768748
I0408 11:53:13.349498 10019 solver.cpp:219] Iteration 4300 (35.7828 iter/s, 2.79464s/100 iters), loss = 0.0643636
I0408 11:53:13.349526 10019 solver.cpp:238]     Train net output #0: loss = 0.0643636 (* 1 = 0.0643636 loss)
I0408 11:53:13.349530 10019 sgd_solver.cpp:105] Iteration 4300, lr = 0.00764712
I0408 11:53:16.139025 10019 solver.cpp:219] Iteration 4400 (35.8492 iter/s, 2.78946s/100 iters), loss = 0.0289713
I0408 11:53:16.139053 10019 solver.cpp:238]     Train net output #0: loss = 0.0289712 (* 1 = 0.0289712 loss)
I0408 11:53:16.139060 10019 sgd_solver.cpp:105] Iteration 4400, lr = 0.00760726
I0408 11:53:18.888815 10019 solver.cpp:331] Iteration 4500, Testing net (#0)
I0408 11:53:21.016060 10027 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:53:21.110433 10019 solver.cpp:398]     Test net output #0: accuracy = 0.9835
I0408 11:53:21.110473 10019 solver.cpp:398]     Test net output #1: loss = 0.0467985 (* 1 = 0.0467985 loss)
I0408 11:53:21.138171 10019 solver.cpp:219] Iteration 4500 (20.0038 iter/s, 4.99906s/100 iters), loss = 0.0125068
I0408 11:53:21.138213 10019 solver.cpp:238]     Train net output #0: loss = 0.0125068 (* 1 = 0.0125068 loss)
I0408 11:53:21.138219 10019 sgd_solver.cpp:105] Iteration 4500, lr = 0.00756788
I0408 11:53:23.938493 10019 solver.cpp:219] Iteration 4600 (35.7112 iter/s, 2.80024s/100 iters), loss = 0.00526175
I0408 11:53:23.938521 10019 solver.cpp:238]     Train net output #0: loss = 0.00526169 (* 1 = 0.00526169 loss)
I0408 11:53:23.938526 10019 sgd_solver.cpp:105] Iteration 4600, lr = 0.00752897
I0408 11:53:26.258481 10026 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:53:26.739534 10019 solver.cpp:219] Iteration 4700 (35.7019 iter/s, 2.80097s/100 iters), loss = 0.0177594
I0408 11:53:26.739565 10019 solver.cpp:238]     Train net output #0: loss = 0.0177593 (* 1 = 0.0177593 loss)
I0408 11:53:26.739569 10019 sgd_solver.cpp:105] Iteration 4700, lr = 0.00749052
I0408 11:53:29.527465 10019 solver.cpp:219] Iteration 4800 (35.8698 iter/s, 2.78786s/100 iters), loss = 0.0431693
I0408 11:53:29.527493 10019 solver.cpp:238]     Train net output #0: loss = 0.0431692 (* 1 = 0.0431692 loss)
I0408 11:53:29.527498 10019 sgd_solver.cpp:105] Iteration 4800, lr = 0.00745253
I0408 11:53:32.312392 10019 solver.cpp:219] Iteration 4900 (35.9084 iter/s, 2.78486s/100 iters), loss = 0.00593109
I0408 11:53:32.312422 10019 solver.cpp:238]     Train net output #0: loss = 0.00593103 (* 1 = 0.00593103 loss)
I0408 11:53:32.312440 10019 sgd_solver.cpp:105] Iteration 4900, lr = 0.00741498
I0408 11:53:35.060091 10019 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_5000.caffemodel
I0408 11:53:35.073029 10019 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_5000.solverstate
I0408 11:53:35.073626 10019 solver.cpp:331] Iteration 5000, Testing net (#0)
I0408 11:53:37.182839 10027 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:53:37.277390 10019 solver.cpp:398]     Test net output #0: accuracy = 0.9852
I0408 11:53:37.277431 10019 solver.cpp:398]     Test net output #1: loss = 0.0425327 (* 1 = 0.0425327 loss)
I0408 11:53:37.305073 10019 solver.cpp:219] Iteration 5000 (20.0297 iter/s, 4.9926s/100 iters), loss = 0.05939
I0408 11:53:37.305094 10019 solver.cpp:238]     Train net output #0: loss = 0.0593899 (* 1 = 0.0593899 loss)
I0408 11:53:37.305117 10019 sgd_solver.cpp:105] Iteration 5000, lr = 0.00737788
I0408 11:53:40.104591 10019 solver.cpp:219] Iteration 5100 (35.7211 iter/s, 2.79946s/100 iters), loss = 0.0711563
I0408 11:53:40.104620 10019 solver.cpp:238]     Train net output #0: loss = 0.0711563 (* 1 = 0.0711563 loss)
I0408 11:53:40.104626 10019 sgd_solver.cpp:105] Iteration 5100, lr = 0.0073412
I0408 11:53:42.896226 10019 solver.cpp:219] Iteration 5200 (35.8222 iter/s, 2.79156s/100 iters), loss = 0.0419085
I0408 11:53:42.896255 10019 solver.cpp:238]     Train net output #0: loss = 0.0419085 (* 1 = 0.0419085 loss)
I0408 11:53:42.896260 10019 sgd_solver.cpp:105] Iteration 5200, lr = 0.00730495
I0408 11:53:45.687593 10019 solver.cpp:219] Iteration 5300 (35.8256 iter/s, 2.7913s/100 iters), loss = 0.00314254
I0408 11:53:45.687623 10019 solver.cpp:238]     Train net output #0: loss = 0.00314248 (* 1 = 0.00314248 loss)
I0408 11:53:45.687626 10019 sgd_solver.cpp:105] Iteration 5300, lr = 0.00726911
I0408 11:53:48.478698 10019 solver.cpp:219] Iteration 5400 (35.8289 iter/s, 2.79104s/100 iters), loss = 0.047193
I0408 11:53:48.478740 10019 solver.cpp:238]     Train net output #0: loss = 0.0471929 (* 1 = 0.0471929 loss)
I0408 11:53:48.478745 10019 sgd_solver.cpp:105] Iteration 5400, lr = 0.00723368
I0408 11:53:51.236984 10019 solver.cpp:331] Iteration 5500, Testing net (#0)
I0408 11:53:53.363770 10027 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:53:53.458061 10019 solver.cpp:398]     Test net output #0: accuracy = 0.9849
I0408 11:53:53.458102 10019 solver.cpp:398]     Test net output #1: loss = 0.0433363 (* 1 = 0.0433363 loss)
I0408 11:53:53.485692 10019 solver.cpp:219] Iteration 5500 (19.9724 iter/s, 5.0069s/100 iters), loss = 0.0212391
I0408 11:53:53.485730 10019 solver.cpp:238]     Train net output #0: loss = 0.021239 (* 1 = 0.021239 loss)
I0408 11:53:53.485738 10019 sgd_solver.cpp:105] Iteration 5500, lr = 0.00719865
I0408 11:53:56.284024 10019 solver.cpp:219] Iteration 5600 (35.7367 iter/s, 2.79824s/100 iters), loss = 0.00377253
I0408 11:53:56.284214 10019 solver.cpp:238]     Train net output #0: loss = 0.00377245 (* 1 = 0.00377245 loss)
I0408 11:53:56.284240 10019 sgd_solver.cpp:105] Iteration 5600, lr = 0.00716402
I0408 11:53:56.849426 10026 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:53:59.083463 10019 solver.cpp:219] Iteration 5700 (35.7242 iter/s, 2.79922s/100 iters), loss = 0.0396178
I0408 11:53:59.083492 10019 solver.cpp:238]     Train net output #0: loss = 0.0396178 (* 1 = 0.0396178 loss)
I0408 11:53:59.083497 10019 sgd_solver.cpp:105] Iteration 5700, lr = 0.00712977
I0408 11:54:01.876019 10019 solver.cpp:219] Iteration 5800 (35.8103 iter/s, 2.79249s/100 iters), loss = 0.0522444
I0408 11:54:01.876075 10019 solver.cpp:238]     Train net output #0: loss = 0.0522444 (* 1 = 0.0522444 loss)
I0408 11:54:01.876080 10019 sgd_solver.cpp:105] Iteration 5800, lr = 0.0070959
I0408 11:54:04.662451 10019 solver.cpp:219] Iteration 5900 (35.8891 iter/s, 2.78636s/100 iters), loss = 0.0153927
I0408 11:54:04.662480 10019 solver.cpp:238]     Train net output #0: loss = 0.0153927 (* 1 = 0.0153927 loss)
I0408 11:54:04.662484 10019 sgd_solver.cpp:105] Iteration 5900, lr = 0.0070624
I0408 11:54:07.414530 10019 solver.cpp:331] Iteration 6000, Testing net (#0)
I0408 11:54:09.537392 10027 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:54:09.632055 10019 solver.cpp:398]     Test net output #0: accuracy = 0.9878
I0408 11:54:09.632077 10019 solver.cpp:398]     Test net output #1: loss = 0.0358246 (* 1 = 0.0358246 loss)
I0408 11:54:09.660032 10019 solver.cpp:219] Iteration 6000 (20.01 iter/s, 4.9975s/100 iters), loss = 0.0114385
I0408 11:54:09.660053 10019 solver.cpp:238]     Train net output #0: loss = 0.0114384 (* 1 = 0.0114384 loss)
I0408 11:54:09.660059 10019 sgd_solver.cpp:105] Iteration 6000, lr = 0.00702927
I0408 11:54:12.456619 10019 solver.cpp:219] Iteration 6100 (35.7862 iter/s, 2.79437s/100 iters), loss = 0.0045878
I0408 11:54:12.456647 10019 solver.cpp:238]     Train net output #0: loss = 0.00458773 (* 1 = 0.00458773 loss)
I0408 11:54:12.456653 10019 sgd_solver.cpp:105] Iteration 6100, lr = 0.0069965
I0408 11:54:15.245524 10019 solver.cpp:219] Iteration 6200 (35.8572 iter/s, 2.78884s/100 iters), loss = 0.0177369
I0408 11:54:15.245554 10019 solver.cpp:238]     Train net output #0: loss = 0.0177368 (* 1 = 0.0177368 loss)
I0408 11:54:15.245560 10019 sgd_solver.cpp:105] Iteration 6200, lr = 0.00696408
I0408 11:54:18.036309 10019 solver.cpp:219] Iteration 6300 (35.833 iter/s, 2.79072s/100 iters), loss = 0.00866678
I0408 11:54:18.036339 10019 solver.cpp:238]     Train net output #0: loss = 0.00866672 (* 1 = 0.00866672 loss)
I0408 11:54:18.036345 10019 sgd_solver.cpp:105] Iteration 6300, lr = 0.00693201
I0408 11:54:20.825232 10019 solver.cpp:219] Iteration 6400 (35.857 iter/s, 2.78886s/100 iters), loss = 0.0525394
I0408 11:54:20.825274 10019 solver.cpp:238]     Train net output #0: loss = 0.0525393 (* 1 = 0.0525393 loss)
I0408 11:54:20.825280 10019 sgd_solver.cpp:105] Iteration 6400, lr = 0.00690029
I0408 11:54:23.576571 10019 solver.cpp:331] Iteration 6500, Testing net (#0)
I0408 11:54:25.708750 10027 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:54:25.804391 10019 solver.cpp:398]     Test net output #0: accuracy = 0.9864
I0408 11:54:25.804414 10019 solver.cpp:398]     Test net output #1: loss = 0.04051 (* 1 = 0.04051 loss)
I0408 11:54:25.831912 10019 solver.cpp:219] Iteration 6500 (19.9737 iter/s, 5.0066s/100 iters), loss = 0.00702458
I0408 11:54:25.831931 10019 solver.cpp:238]     Train net output #0: loss = 0.00702451 (* 1 = 0.00702451 loss)
I0408 11:54:25.831955 10019 sgd_solver.cpp:105] Iteration 6500, lr = 0.0068689
I0408 11:54:27.465147 10026 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:54:28.641808 10019 solver.cpp:219] Iteration 6600 (35.5892 iter/s, 2.80984s/100 iters), loss = 0.0284539
I0408 11:54:28.641870 10019 solver.cpp:238]     Train net output #0: loss = 0.0284539 (* 1 = 0.0284539 loss)
I0408 11:54:28.641873 10019 sgd_solver.cpp:105] Iteration 6600, lr = 0.00683784
I0408 11:54:31.440104 10019 solver.cpp:219] Iteration 6700 (35.7372 iter/s, 2.7982s/100 iters), loss = 0.0251771
I0408 11:54:31.440150 10019 solver.cpp:238]     Train net output #0: loss = 0.0251771 (* 1 = 0.0251771 loss)
I0408 11:54:31.440155 10019 sgd_solver.cpp:105] Iteration 6700, lr = 0.00680711
I0408 11:54:34.232221 10019 solver.cpp:219] Iteration 6800 (35.8161 iter/s, 2.79204s/100 iters), loss = 0.0122497
I0408 11:54:34.232250 10019 solver.cpp:238]     Train net output #0: loss = 0.0122497 (* 1 = 0.0122497 loss)
I0408 11:54:34.232254 10019 sgd_solver.cpp:105] Iteration 6800, lr = 0.0067767
I0408 11:54:37.028587 10019 solver.cpp:219] Iteration 6900 (35.7615 iter/s, 2.7963s/100 iters), loss = 0.023887
I0408 11:54:37.028633 10019 solver.cpp:238]     Train net output #0: loss = 0.023887 (* 1 = 0.023887 loss)
I0408 11:54:37.028640 10019 sgd_solver.cpp:105] Iteration 6900, lr = 0.0067466
I0408 11:54:39.807274 10019 solver.cpp:331] Iteration 7000, Testing net (#0)
I0408 11:54:41.935149 10027 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:54:42.029963 10019 solver.cpp:398]     Test net output #0: accuracy = 0.9853
I0408 11:54:42.030004 10019 solver.cpp:398]     Test net output #1: loss = 0.0414782 (* 1 = 0.0414782 loss)
I0408 11:54:42.057958 10019 solver.cpp:219] Iteration 7000 (19.8836 iter/s, 5.02928s/100 iters), loss = 0.0368137
I0408 11:54:42.057998 10019 solver.cpp:238]     Train net output #0: loss = 0.0368137 (* 1 = 0.0368137 loss)
I0408 11:54:42.058003 10019 sgd_solver.cpp:105] Iteration 7000, lr = 0.00671681
I0408 11:54:44.877252 10019 solver.cpp:219] Iteration 7100 (35.4739 iter/s, 2.81897s/100 iters), loss = 0.0746536
I0408 11:54:44.877300 10019 solver.cpp:238]     Train net output #0: loss = 0.0746536 (* 1 = 0.0746536 loss)
I0408 11:54:44.877305 10019 sgd_solver.cpp:105] Iteration 7100, lr = 0.00668733
I0408 11:54:47.668326 10019 solver.cpp:219] Iteration 7200 (35.8295 iter/s, 2.79099s/100 iters), loss = 0.0202258
I0408 11:54:47.668373 10019 solver.cpp:238]     Train net output #0: loss = 0.0202258 (* 1 = 0.0202258 loss)
I0408 11:54:47.668377 10019 sgd_solver.cpp:105] Iteration 7200, lr = 0.00665815
I0408 11:54:50.460582 10019 solver.cpp:219] Iteration 7300 (35.8143 iter/s, 2.79218s/100 iters), loss = 0.0649174
I0408 11:54:50.460610 10019 solver.cpp:238]     Train net output #0: loss = 0.0649174 (* 1 = 0.0649174 loss)
I0408 11:54:50.460616 10019 sgd_solver.cpp:105] Iteration 7300, lr = 0.00662927
I0408 11:54:53.251940 10019 solver.cpp:219] Iteration 7400 (35.8256 iter/s, 2.7913s/100 iters), loss = 0.0493896
I0408 11:54:53.251983 10019 solver.cpp:238]     Train net output #0: loss = 0.0493896 (* 1 = 0.0493896 loss)
I0408 11:54:53.251987 10019 sgd_solver.cpp:105] Iteration 7400, lr = 0.00660067
I0408 11:54:55.906772 10026 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:54:56.014535 10019 solver.cpp:331] Iteration 7500, Testing net (#0)
I0408 11:54:58.141021 10027 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:54:58.236656 10019 solver.cpp:398]     Test net output #0: accuracy = 0.9862
I0408 11:54:58.236680 10019 solver.cpp:398]     Test net output #1: loss = 0.0407004 (* 1 = 0.0407004 loss)
I0408 11:54:58.264307 10019 solver.cpp:219] Iteration 7500 (19.951 iter/s, 5.01228s/100 iters), loss = 0.0165231
I0408 11:54:58.264356 10019 solver.cpp:238]     Train net output #0: loss = 0.0165231 (* 1 = 0.0165231 loss)
I0408 11:54:58.264363 10019 sgd_solver.cpp:105] Iteration 7500, lr = 0.00657236
I0408 11:55:01.066864 10019 solver.cpp:219] Iteration 7600 (35.6827 iter/s, 2.80248s/100 iters), loss = 0.0566613
I0408 11:55:01.066910 10019 solver.cpp:238]     Train net output #0: loss = 0.0566613 (* 1 = 0.0566613 loss)
I0408 11:55:01.066915 10019 sgd_solver.cpp:105] Iteration 7600, lr = 0.00654433
I0408 11:55:03.864636 10019 solver.cpp:219] Iteration 7700 (35.7437 iter/s, 2.79769s/100 iters), loss = 0.0328668
I0408 11:55:03.864665 10019 solver.cpp:238]     Train net output #0: loss = 0.0328668 (* 1 = 0.0328668 loss)
I0408 11:55:03.864671 10019 sgd_solver.cpp:105] Iteration 7700, lr = 0.00651658
I0408 11:55:06.659531 10019 solver.cpp:219] Iteration 7800 (35.7803 iter/s, 2.79483s/100 iters), loss = 0.0154152
I0408 11:55:06.659560 10019 solver.cpp:238]     Train net output #0: loss = 0.0154152 (* 1 = 0.0154152 loss)
I0408 11:55:06.659564 10019 sgd_solver.cpp:105] Iteration 7800, lr = 0.00648911
I0408 11:55:09.455354 10019 solver.cpp:219] Iteration 7900 (35.7684 iter/s, 2.79577s/100 iters), loss = 0.0124285
I0408 11:55:09.455384 10019 solver.cpp:238]     Train net output #0: loss = 0.0124285 (* 1 = 0.0124285 loss)
I0408 11:55:09.455389 10019 sgd_solver.cpp:105] Iteration 7900, lr = 0.0064619
I0408 11:55:12.196156 10019 solver.cpp:331] Iteration 8000, Testing net (#0)
I0408 11:55:14.318291 10027 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:55:14.412925 10019 solver.cpp:398]     Test net output #0: accuracy = 0.987
I0408 11:55:14.412966 10019 solver.cpp:398]     Test net output #1: loss = 0.0403167 (* 1 = 0.0403167 loss)
I0408 11:55:14.440927 10019 solver.cpp:219] Iteration 8000 (20.0583 iter/s, 4.98548s/100 iters), loss = 0.0537245
I0408 11:55:14.440964 10019 solver.cpp:238]     Train net output #0: loss = 0.0537245 (* 1 = 0.0537245 loss)
I0408 11:55:14.440987 10019 sgd_solver.cpp:105] Iteration 8000, lr = 0.00643496
I0408 11:55:17.243082 10019 solver.cpp:219] Iteration 8100 (35.6877 iter/s, 2.80209s/100 iters), loss = 0.0914279
I0408 11:55:17.243108 10019 solver.cpp:238]     Train net output #0: loss = 0.0914278 (* 1 = 0.0914278 loss)
I0408 11:55:17.243113 10019 sgd_solver.cpp:105] Iteration 8100, lr = 0.00640827
I0408 11:55:20.025648 10019 solver.cpp:219] Iteration 8200 (35.9388 iter/s, 2.78251s/100 iters), loss = 0.0179094
I0408 11:55:20.025681 10019 solver.cpp:238]     Train net output #0: loss = 0.0179093 (* 1 = 0.0179093 loss)
I0408 11:55:20.025686 10019 sgd_solver.cpp:105] Iteration 8200, lr = 0.00638185
I0408 11:55:22.816041 10019 solver.cpp:219] Iteration 8300 (35.8381 iter/s, 2.79033s/100 iters), loss = 0.0728742
I0408 11:55:22.816071 10019 solver.cpp:238]     Train net output #0: loss = 0.0728741 (* 1 = 0.0728741 loss)
I0408 11:55:22.816076 10019 sgd_solver.cpp:105] Iteration 8300, lr = 0.00635567
I0408 11:55:25.606704 10019 solver.cpp:219] Iteration 8400 (35.8346 iter/s, 2.7906s/100 iters), loss = 0.0497257
I0408 11:55:25.606732 10019 solver.cpp:238]     Train net output #0: loss = 0.0497257 (* 1 = 0.0497257 loss)
I0408 11:55:25.606736 10019 sgd_solver.cpp:105] Iteration 8400, lr = 0.00632975
I0408 11:55:26.534170 10026 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:55:28.367043 10019 solver.cpp:331] Iteration 8500, Testing net (#0)
I0408 11:55:30.487640 10027 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:55:30.581655 10019 solver.cpp:398]     Test net output #0: accuracy = 0.9863
I0408 11:55:30.581694 10019 solver.cpp:398]     Test net output #1: loss = 0.0406861 (* 1 = 0.0406861 loss)
I0408 11:55:30.609412 10019 solver.cpp:219] Iteration 8500 (19.9895 iter/s, 5.00264s/100 iters), loss = 0.0235555
I0408 11:55:30.609457 10019 solver.cpp:238]     Train net output #0: loss = 0.0235554 (* 1 = 0.0235554 loss)
I0408 11:55:30.609462 10019 sgd_solver.cpp:105] Iteration 8500, lr = 0.00630407
I0408 11:55:33.407949 10019 solver.cpp:219] Iteration 8600 (35.7611 iter/s, 2.79633s/100 iters), loss = 0.00291742
I0408 11:55:33.407995 10019 solver.cpp:238]     Train net output #0: loss = 0.00291735 (* 1 = 0.00291735 loss)
I0408 11:55:33.408001 10019 sgd_solver.cpp:105] Iteration 8600, lr = 0.00627864
I0408 11:55:36.199137 10019 solver.cpp:219] Iteration 8700 (35.828 iter/s, 2.79111s/100 iters), loss = 0.00322029
I0408 11:55:36.199167 10019 solver.cpp:238]     Train net output #0: loss = 0.00322022 (* 1 = 0.00322022 loss)
I0408 11:55:36.199172 10019 sgd_solver.cpp:105] Iteration 8700, lr = 0.00625344
I0408 11:55:38.991686 10019 solver.cpp:219] Iteration 8800 (35.8103 iter/s, 2.79249s/100 iters), loss = 0.00555319
I0408 11:55:38.991716 10019 solver.cpp:238]     Train net output #0: loss = 0.00555312 (* 1 = 0.00555312 loss)
I0408 11:55:38.991721 10019 sgd_solver.cpp:105] Iteration 8800, lr = 0.00622847
I0408 11:55:41.777855 10019 solver.cpp:219] Iteration 8900 (35.8924 iter/s, 2.78611s/100 iters), loss = 0.00200217
I0408 11:55:41.777885 10019 solver.cpp:238]     Train net output #0: loss = 0.00200208 (* 1 = 0.00200208 loss)
I0408 11:55:41.777890 10019 sgd_solver.cpp:105] Iteration 8900, lr = 0.00620374
I0408 11:55:44.554204 10019 solver.cpp:331] Iteration 9000, Testing net (#0)
I0408 11:55:46.694109 10027 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:55:46.789600 10019 solver.cpp:398]     Test net output #0: accuracy = 0.9872
I0408 11:55:46.789624 10019 solver.cpp:398]     Test net output #1: loss = 0.0374344 (* 1 = 0.0374344 loss)
I0408 11:55:46.817216 10019 solver.cpp:219] Iteration 9000 (19.8441 iter/s, 5.03929s/100 iters), loss = 0.0240033
I0408 11:55:46.817245 10019 solver.cpp:238]     Train net output #0: loss = 0.0240032 (* 1 = 0.0240032 loss)
I0408 11:55:46.817271 10019 sgd_solver.cpp:105] Iteration 9000, lr = 0.00617924
I0408 11:55:49.613386 10019 solver.cpp:219] Iteration 9100 (35.7639 iter/s, 2.79612s/100 iters), loss = 0.0823596
I0408 11:55:49.613427 10019 solver.cpp:238]     Train net output #0: loss = 0.0823596 (* 1 = 0.0823596 loss)
I0408 11:55:49.613432 10019 sgd_solver.cpp:105] Iteration 9100, lr = 0.00615496
I0408 11:55:52.407939 10019 solver.cpp:219] Iteration 9200 (35.7846 iter/s, 2.7945s/100 iters), loss = 0.0274528
I0408 11:55:52.407985 10019 solver.cpp:238]     Train net output #0: loss = 0.0274526 (* 1 = 0.0274526 loss)
I0408 11:55:52.407990 10019 sgd_solver.cpp:105] Iteration 9200, lr = 0.0061309
I0408 11:55:55.200537 10019 solver.cpp:219] Iteration 9300 (35.8098 iter/s, 2.79253s/100 iters), loss = 0.004315
I0408 11:55:55.200567 10019 solver.cpp:238]     Train net output #0: loss = 0.00431487 (* 1 = 0.00431487 loss)
I0408 11:55:55.200572 10019 sgd_solver.cpp:105] Iteration 9300, lr = 0.00610706
I0408 11:55:57.155932 10026 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:55:58.001503 10019 solver.cpp:219] Iteration 9400 (35.7027 iter/s, 2.80091s/100 iters), loss = 0.077407
I0408 11:55:58.001533 10019 solver.cpp:238]     Train net output #0: loss = 0.0774069 (* 1 = 0.0774069 loss)
I0408 11:55:58.001538 10019 sgd_solver.cpp:105] Iteration 9400, lr = 0.00608343
I0408 11:56:00.762351 10019 solver.cpp:331] Iteration 9500, Testing net (#0)
I0408 11:56:02.888661 10027 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:56:02.982722 10019 solver.cpp:398]     Test net output #0: accuracy = 0.9863
I0408 11:56:02.982744 10019 solver.cpp:398]     Test net output #1: loss = 0.0409874 (* 1 = 0.0409874 loss)
I0408 11:56:03.010300 10019 solver.cpp:219] Iteration 9500 (19.9652 iter/s, 5.00872s/100 iters), loss = 0.0103646
I0408 11:56:03.010344 10019 solver.cpp:238]     Train net output #0: loss = 0.0103645 (* 1 = 0.0103645 loss)
I0408 11:56:03.010365 10019 sgd_solver.cpp:105] Iteration 9500, lr = 0.00606002
I0408 11:56:05.809684 10019 solver.cpp:219] Iteration 9600 (35.7231 iter/s, 2.79931s/100 iters), loss = 0.00742949
I0408 11:56:05.809711 10019 solver.cpp:238]     Train net output #0: loss = 0.00742938 (* 1 = 0.00742938 loss)
I0408 11:56:05.809715 10019 sgd_solver.cpp:105] Iteration 9600, lr = 0.00603682
I0408 11:56:08.597652 10019 solver.cpp:219] Iteration 9700 (35.8691 iter/s, 2.78791s/100 iters), loss = 0.0079373
I0408 11:56:08.597682 10019 solver.cpp:238]     Train net output #0: loss = 0.0079372 (* 1 = 0.0079372 loss)
I0408 11:56:08.597687 10019 sgd_solver.cpp:105] Iteration 9700, lr = 0.00601382
I0408 11:56:11.390491 10019 solver.cpp:219] Iteration 9800 (35.8066 iter/s, 2.79278s/100 iters), loss = 0.0454682
I0408 11:56:11.390521 10019 solver.cpp:238]     Train net output #0: loss = 0.0454681 (* 1 = 0.0454681 loss)
I0408 11:56:11.390524 10019 sgd_solver.cpp:105] Iteration 9800, lr = 0.00599102
I0408 11:56:14.183732 10019 solver.cpp:219] Iteration 9900 (35.8014 iter/s, 2.79318s/100 iters), loss = 0.00980932
I0408 11:56:14.183763 10019 solver.cpp:238]     Train net output #0: loss = 0.00980923 (* 1 = 0.00980923 loss)
I0408 11:56:14.183768 10019 sgd_solver.cpp:105] Iteration 9900, lr = 0.00596843
I0408 11:56:16.932862 10019 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_10000.caffemodel
I0408 11:56:16.945631 10019 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_10000.solverstate
I0408 11:56:16.960186 10019 solver.cpp:311] Iteration 10000, loss = 0.00541102
I0408 11:56:16.960206 10019 solver.cpp:331] Iteration 10000, Testing net (#0)
I0408 11:56:19.078276 10027 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:56:19.173789 10019 solver.cpp:398]     Test net output #0: accuracy = 0.9866
I0408 11:56:19.173812 10019 solver.cpp:398]     Test net output #1: loss = 0.0422574 (* 1 = 0.0422574 loss)
I0408 11:56:19.173816 10019 solver.cpp:316] Optimization Done.
I0408 11:56:19.173818 10019 caffe.cpp:259] Optimization Done.
