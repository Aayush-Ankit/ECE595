I0408 11:56:19.252748 10041 caffe.cpp:218] Using GPUs 0
I0408 11:56:19.267122 10041 caffe.cpp:223] GPU 0: GeForce GTX 950M
I0408 11:56:19.445332 10041 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_fc_size/lenet_train_test_fcl1_fcn500.prototxt"
train_state {
  level: 0
  stage: ""
}
I0408 11:56:19.445535 10041 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_fc_size/lenet_train_test_fcl1_fcn500.prototxt
I0408 11:56:19.445786 10041 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0408 11:56:19.445796 10041 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0408 11:56:19.445914 10041 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0408 11:56:19.445956 10041 layer_factory.hpp:77] Creating layer mnist
I0408 11:56:19.446063 10041 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0408 11:56:19.446084 10041 net.cpp:84] Creating Layer mnist
I0408 11:56:19.446091 10041 net.cpp:380] mnist -> data
I0408 11:56:19.446106 10041 net.cpp:380] mnist -> label
I0408 11:56:19.446707 10041 data_layer.cpp:45] output data size: 64,1,28,28
I0408 11:56:19.448249 10041 net.cpp:122] Setting up mnist
I0408 11:56:19.448261 10041 net.cpp:129] Top shape: 64 1 28 28 (50176)
I0408 11:56:19.448264 10041 net.cpp:129] Top shape: 64 (64)
I0408 11:56:19.448266 10041 net.cpp:137] Memory required for data: 200960
I0408 11:56:19.448290 10041 layer_factory.hpp:77] Creating layer conv0
I0408 11:56:19.448318 10041 net.cpp:84] Creating Layer conv0
I0408 11:56:19.448325 10041 net.cpp:406] conv0 <- data
I0408 11:56:19.448335 10041 net.cpp:380] conv0 -> conv0
I0408 11:56:19.449528 10041 net.cpp:122] Setting up conv0
I0408 11:56:19.449537 10041 net.cpp:129] Top shape: 64 50 24 24 (1843200)
I0408 11:56:19.449558 10041 net.cpp:137] Memory required for data: 7573760
I0408 11:56:19.449587 10041 layer_factory.hpp:77] Creating layer pool0
I0408 11:56:19.449612 10041 net.cpp:84] Creating Layer pool0
I0408 11:56:19.449615 10041 net.cpp:406] pool0 <- conv0
I0408 11:56:19.449618 10041 net.cpp:380] pool0 -> pool0
I0408 11:56:19.449668 10041 net.cpp:122] Setting up pool0
I0408 11:56:19.449673 10041 net.cpp:129] Top shape: 64 50 12 12 (460800)
I0408 11:56:19.449687 10041 net.cpp:137] Memory required for data: 9416960
I0408 11:56:19.449688 10041 layer_factory.hpp:77] Creating layer conv1
I0408 11:56:19.449694 10041 net.cpp:84] Creating Layer conv1
I0408 11:56:19.449697 10041 net.cpp:406] conv1 <- pool0
I0408 11:56:19.449702 10041 net.cpp:380] conv1 -> conv1
I0408 11:56:19.450423 10041 net.cpp:122] Setting up conv1
I0408 11:56:19.450430 10041 net.cpp:129] Top shape: 64 50 8 8 (204800)
I0408 11:56:19.450453 10041 net.cpp:137] Memory required for data: 10236160
I0408 11:56:19.450459 10041 layer_factory.hpp:77] Creating layer pool1
I0408 11:56:19.450464 10041 net.cpp:84] Creating Layer pool1
I0408 11:56:19.450466 10041 net.cpp:406] pool1 <- conv1
I0408 11:56:19.450471 10041 net.cpp:380] pool1 -> pool1
I0408 11:56:19.450547 10041 net.cpp:122] Setting up pool1
I0408 11:56:19.450551 10041 net.cpp:129] Top shape: 64 50 4 4 (51200)
I0408 11:56:19.450572 10041 net.cpp:137] Memory required for data: 10440960
I0408 11:56:19.450574 10041 layer_factory.hpp:77] Creating layer ip1
I0408 11:56:19.450579 10041 net.cpp:84] Creating Layer ip1
I0408 11:56:19.450595 10041 net.cpp:406] ip1 <- pool1
I0408 11:56:19.450599 10041 net.cpp:380] ip1 -> ip1
I0408 11:56:19.451179 10041 net.cpp:122] Setting up ip1
I0408 11:56:19.451187 10041 net.cpp:129] Top shape: 64 10 (640)
I0408 11:56:19.451189 10041 net.cpp:137] Memory required for data: 10443520
I0408 11:56:19.451195 10041 layer_factory.hpp:77] Creating layer relu1
I0408 11:56:19.451200 10041 net.cpp:84] Creating Layer relu1
I0408 11:56:19.451222 10041 net.cpp:406] relu1 <- ip1
I0408 11:56:19.451225 10041 net.cpp:367] relu1 -> ip1 (in-place)
I0408 11:56:19.451244 10041 net.cpp:122] Setting up relu1
I0408 11:56:19.451248 10041 net.cpp:129] Top shape: 64 10 (640)
I0408 11:56:19.451251 10041 net.cpp:137] Memory required for data: 10446080
I0408 11:56:19.451268 10041 layer_factory.hpp:77] Creating layer loss
I0408 11:56:19.451272 10041 net.cpp:84] Creating Layer loss
I0408 11:56:19.451274 10041 net.cpp:406] loss <- ip1
I0408 11:56:19.451277 10041 net.cpp:406] loss <- label
I0408 11:56:19.451282 10041 net.cpp:380] loss -> loss
I0408 11:56:19.451290 10041 layer_factory.hpp:77] Creating layer loss
I0408 11:56:19.451382 10041 net.cpp:122] Setting up loss
I0408 11:56:19.451385 10041 net.cpp:129] Top shape: (1)
I0408 11:56:19.451387 10041 net.cpp:132]     with loss weight 1
I0408 11:56:19.451417 10041 net.cpp:137] Memory required for data: 10446084
I0408 11:56:19.451421 10041 net.cpp:198] loss needs backward computation.
I0408 11:56:19.451427 10041 net.cpp:198] relu1 needs backward computation.
I0408 11:56:19.451429 10041 net.cpp:198] ip1 needs backward computation.
I0408 11:56:19.451431 10041 net.cpp:198] pool1 needs backward computation.
I0408 11:56:19.451452 10041 net.cpp:198] conv1 needs backward computation.
I0408 11:56:19.451453 10041 net.cpp:198] pool0 needs backward computation.
I0408 11:56:19.451455 10041 net.cpp:198] conv0 needs backward computation.
I0408 11:56:19.451457 10041 net.cpp:200] mnist does not need backward computation.
I0408 11:56:19.451473 10041 net.cpp:242] This network produces output loss
I0408 11:56:19.451480 10041 net.cpp:255] Network initialization done.
I0408 11:56:19.451648 10041 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_fc_size/lenet_train_test_fcl1_fcn500.prototxt
I0408 11:56:19.451681 10041 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0408 11:56:19.451756 10041 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0408 11:56:19.451879 10041 layer_factory.hpp:77] Creating layer mnist
I0408 11:56:19.451936 10041 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0408 11:56:19.451953 10041 net.cpp:84] Creating Layer mnist
I0408 11:56:19.451958 10041 net.cpp:380] mnist -> data
I0408 11:56:19.451967 10041 net.cpp:380] mnist -> label
I0408 11:56:19.452098 10041 data_layer.cpp:45] output data size: 100,1,28,28
I0408 11:56:19.453733 10041 net.cpp:122] Setting up mnist
I0408 11:56:19.453744 10041 net.cpp:129] Top shape: 100 1 28 28 (78400)
I0408 11:56:19.453747 10041 net.cpp:129] Top shape: 100 (100)
I0408 11:56:19.453749 10041 net.cpp:137] Memory required for data: 314000
I0408 11:56:19.453752 10041 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0408 11:56:19.453779 10041 net.cpp:84] Creating Layer label_mnist_1_split
I0408 11:56:19.453783 10041 net.cpp:406] label_mnist_1_split <- label
I0408 11:56:19.453785 10041 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_0
I0408 11:56:19.453791 10041 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_1
I0408 11:56:19.453860 10041 net.cpp:122] Setting up label_mnist_1_split
I0408 11:56:19.453866 10041 net.cpp:129] Top shape: 100 (100)
I0408 11:56:19.453867 10041 net.cpp:129] Top shape: 100 (100)
I0408 11:56:19.453871 10041 net.cpp:137] Memory required for data: 314800
I0408 11:56:19.453872 10041 layer_factory.hpp:77] Creating layer conv0
I0408 11:56:19.453881 10041 net.cpp:84] Creating Layer conv0
I0408 11:56:19.453884 10041 net.cpp:406] conv0 <- data
I0408 11:56:19.453889 10041 net.cpp:380] conv0 -> conv0
I0408 11:56:19.454090 10041 net.cpp:122] Setting up conv0
I0408 11:56:19.454095 10041 net.cpp:129] Top shape: 100 50 24 24 (2880000)
I0408 11:56:19.454098 10041 net.cpp:137] Memory required for data: 11834800
I0408 11:56:19.454123 10041 layer_factory.hpp:77] Creating layer pool0
I0408 11:56:19.454129 10041 net.cpp:84] Creating Layer pool0
I0408 11:56:19.454133 10041 net.cpp:406] pool0 <- conv0
I0408 11:56:19.454136 10041 net.cpp:380] pool0 -> pool0
I0408 11:56:19.454175 10041 net.cpp:122] Setting up pool0
I0408 11:56:19.454180 10041 net.cpp:129] Top shape: 100 50 12 12 (720000)
I0408 11:56:19.454182 10041 net.cpp:137] Memory required for data: 14714800
I0408 11:56:19.454185 10041 layer_factory.hpp:77] Creating layer conv1
I0408 11:56:19.454196 10041 net.cpp:84] Creating Layer conv1
I0408 11:56:19.454200 10041 net.cpp:406] conv1 <- pool0
I0408 11:56:19.454205 10041 net.cpp:380] conv1 -> conv1
I0408 11:56:19.454684 10041 net.cpp:122] Setting up conv1
I0408 11:56:19.454689 10041 net.cpp:129] Top shape: 100 50 8 8 (320000)
I0408 11:56:19.454692 10041 net.cpp:137] Memory required for data: 15994800
I0408 11:56:19.454699 10041 layer_factory.hpp:77] Creating layer pool1
I0408 11:56:19.454713 10041 net.cpp:84] Creating Layer pool1
I0408 11:56:19.454715 10041 net.cpp:406] pool1 <- conv1
I0408 11:56:19.454720 10041 net.cpp:380] pool1 -> pool1
I0408 11:56:19.454746 10041 net.cpp:122] Setting up pool1
I0408 11:56:19.454751 10041 net.cpp:129] Top shape: 100 50 4 4 (80000)
I0408 11:56:19.454752 10041 net.cpp:137] Memory required for data: 16314800
I0408 11:56:19.454769 10041 layer_factory.hpp:77] Creating layer ip1
I0408 11:56:19.454776 10041 net.cpp:84] Creating Layer ip1
I0408 11:56:19.454778 10041 net.cpp:406] ip1 <- pool1
I0408 11:56:19.454782 10041 net.cpp:380] ip1 -> ip1
I0408 11:56:19.454912 10041 net.cpp:122] Setting up ip1
I0408 11:56:19.454917 10041 net.cpp:129] Top shape: 100 10 (1000)
I0408 11:56:19.454919 10041 net.cpp:137] Memory required for data: 16318800
I0408 11:56:19.454924 10041 layer_factory.hpp:77] Creating layer relu1
I0408 11:56:19.454931 10041 net.cpp:84] Creating Layer relu1
I0408 11:56:19.454933 10041 net.cpp:406] relu1 <- ip1
I0408 11:56:19.454936 10041 net.cpp:367] relu1 -> ip1 (in-place)
I0408 11:56:19.454941 10041 net.cpp:122] Setting up relu1
I0408 11:56:19.454944 10041 net.cpp:129] Top shape: 100 10 (1000)
I0408 11:56:19.454946 10041 net.cpp:137] Memory required for data: 16322800
I0408 11:56:19.454947 10041 layer_factory.hpp:77] Creating layer ip1_relu1_0_split
I0408 11:56:19.454952 10041 net.cpp:84] Creating Layer ip1_relu1_0_split
I0408 11:56:19.454957 10041 net.cpp:406] ip1_relu1_0_split <- ip1
I0408 11:56:19.454959 10041 net.cpp:380] ip1_relu1_0_split -> ip1_relu1_0_split_0
I0408 11:56:19.454963 10041 net.cpp:380] ip1_relu1_0_split -> ip1_relu1_0_split_1
I0408 11:56:19.454988 10041 net.cpp:122] Setting up ip1_relu1_0_split
I0408 11:56:19.454993 10041 net.cpp:129] Top shape: 100 10 (1000)
I0408 11:56:19.454994 10041 net.cpp:129] Top shape: 100 10 (1000)
I0408 11:56:19.454996 10041 net.cpp:137] Memory required for data: 16330800
I0408 11:56:19.454998 10041 layer_factory.hpp:77] Creating layer accuracy
I0408 11:56:19.455003 10041 net.cpp:84] Creating Layer accuracy
I0408 11:56:19.455005 10041 net.cpp:406] accuracy <- ip1_relu1_0_split_0
I0408 11:56:19.455008 10041 net.cpp:406] accuracy <- label_mnist_1_split_0
I0408 11:56:19.455027 10041 net.cpp:380] accuracy -> accuracy
I0408 11:56:19.455034 10041 net.cpp:122] Setting up accuracy
I0408 11:56:19.455037 10041 net.cpp:129] Top shape: (1)
I0408 11:56:19.455039 10041 net.cpp:137] Memory required for data: 16330804
I0408 11:56:19.455040 10041 layer_factory.hpp:77] Creating layer loss
I0408 11:56:19.455044 10041 net.cpp:84] Creating Layer loss
I0408 11:56:19.455047 10041 net.cpp:406] loss <- ip1_relu1_0_split_1
I0408 11:56:19.455049 10041 net.cpp:406] loss <- label_mnist_1_split_1
I0408 11:56:19.455052 10041 net.cpp:380] loss -> loss
I0408 11:56:19.455057 10041 layer_factory.hpp:77] Creating layer loss
I0408 11:56:19.455159 10041 net.cpp:122] Setting up loss
I0408 11:56:19.455164 10041 net.cpp:129] Top shape: (1)
I0408 11:56:19.455166 10041 net.cpp:132]     with loss weight 1
I0408 11:56:19.455173 10041 net.cpp:137] Memory required for data: 16330808
I0408 11:56:19.455175 10041 net.cpp:198] loss needs backward computation.
I0408 11:56:19.455178 10041 net.cpp:200] accuracy does not need backward computation.
I0408 11:56:19.455181 10041 net.cpp:198] ip1_relu1_0_split needs backward computation.
I0408 11:56:19.455183 10041 net.cpp:198] relu1 needs backward computation.
I0408 11:56:19.455185 10041 net.cpp:198] ip1 needs backward computation.
I0408 11:56:19.455188 10041 net.cpp:198] pool1 needs backward computation.
I0408 11:56:19.455189 10041 net.cpp:198] conv1 needs backward computation.
I0408 11:56:19.455207 10041 net.cpp:198] pool0 needs backward computation.
I0408 11:56:19.455209 10041 net.cpp:198] conv0 needs backward computation.
I0408 11:56:19.455212 10041 net.cpp:200] label_mnist_1_split does not need backward computation.
I0408 11:56:19.455215 10041 net.cpp:200] mnist does not need backward computation.
I0408 11:56:19.455217 10041 net.cpp:242] This network produces output accuracy
I0408 11:56:19.455219 10041 net.cpp:242] This network produces output loss
I0408 11:56:19.455235 10041 net.cpp:255] Network initialization done.
I0408 11:56:19.455263 10041 solver.cpp:56] Solver scaffolding done.
I0408 11:56:19.455430 10041 caffe.cpp:248] Starting Optimization
I0408 11:56:19.455433 10041 solver.cpp:273] Solving LeNet
I0408 11:56:19.455435 10041 solver.cpp:274] Learning Rate Policy: inv
I0408 11:56:19.455953 10041 solver.cpp:331] Iteration 0, Testing net (#0)
I0408 11:56:21.575897 10050 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:56:21.672255 10041 solver.cpp:398]     Test net output #0: accuracy = 0.1163
I0408 11:56:21.672276 10041 solver.cpp:398]     Test net output #1: loss = 2.35497 (* 1 = 2.35497 loss)
I0408 11:56:21.703831 10041 solver.cpp:219] Iteration 0 (0 iter/s, 2.24831s/100 iters), loss = 2.44826
I0408 11:56:21.703853 10041 solver.cpp:238]     Train net output #0: loss = 2.44826 (* 1 = 2.44826 loss)
I0408 11:56:21.703882 10041 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0408 11:56:24.506028 10041 solver.cpp:219] Iteration 100 (35.7144 iter/s, 2.79999s/100 iters), loss = 1.32084
I0408 11:56:24.506054 10041 solver.cpp:238]     Train net output #0: loss = 1.32084 (* 1 = 1.32084 loss)
I0408 11:56:24.506060 10041 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0408 11:56:27.300735 10041 solver.cpp:219] Iteration 200 (35.7826 iter/s, 2.79465s/100 iters), loss = 0.907893
I0408 11:56:27.300765 10041 solver.cpp:238]     Train net output #0: loss = 0.907893 (* 1 = 0.907893 loss)
I0408 11:56:27.300770 10041 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0408 11:56:30.096700 10041 solver.cpp:219] Iteration 300 (35.7665 iter/s, 2.79591s/100 iters), loss = 0.163824
I0408 11:56:30.096746 10041 solver.cpp:238]     Train net output #0: loss = 0.163824 (* 1 = 0.163824 loss)
I0408 11:56:30.096763 10041 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0408 11:56:32.895006 10041 solver.cpp:219] Iteration 400 (35.7369 iter/s, 2.79823s/100 iters), loss = 0.146998
I0408 11:56:32.895071 10041 solver.cpp:238]     Train net output #0: loss = 0.146997 (* 1 = 0.146997 loss)
I0408 11:56:32.895074 10041 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0408 11:56:35.642856 10041 solver.cpp:331] Iteration 500, Testing net (#0)
I0408 11:56:37.761557 10050 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:56:37.856845 10041 solver.cpp:398]     Test net output #0: accuracy = 0.9682
I0408 11:56:37.856885 10041 solver.cpp:398]     Test net output #1: loss = 0.104938 (* 1 = 0.104938 loss)
I0408 11:56:37.884544 10041 solver.cpp:219] Iteration 500 (20.0423 iter/s, 4.98944s/100 iters), loss = 0.119858
I0408 11:56:37.884567 10041 solver.cpp:238]     Train net output #0: loss = 0.119858 (* 1 = 0.119858 loss)
I0408 11:56:37.884573 10041 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0408 11:56:40.700445 10041 solver.cpp:219] Iteration 600 (35.5132 iter/s, 2.81585s/100 iters), loss = 0.100073
I0408 11:56:40.700474 10041 solver.cpp:238]     Train net output #0: loss = 0.100073 (* 1 = 0.100073 loss)
I0408 11:56:40.700479 10041 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0408 11:56:43.501941 10041 solver.cpp:219] Iteration 700 (35.696 iter/s, 2.80143s/100 iters), loss = 0.125552
I0408 11:56:43.501969 10041 solver.cpp:238]     Train net output #0: loss = 0.125552 (* 1 = 0.125552 loss)
I0408 11:56:43.501973 10041 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0408 11:56:46.284674 10041 solver.cpp:219] Iteration 800 (35.9366 iter/s, 2.78268s/100 iters), loss = 0.210702
I0408 11:56:46.284701 10041 solver.cpp:238]     Train net output #0: loss = 0.210702 (* 1 = 0.210702 loss)
I0408 11:56:46.284706 10041 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0408 11:56:49.068449 10041 solver.cpp:219] Iteration 900 (35.9231 iter/s, 2.78372s/100 iters), loss = 0.166512
I0408 11:56:49.068477 10041 solver.cpp:238]     Train net output #0: loss = 0.166512 (* 1 = 0.166512 loss)
I0408 11:56:49.068482 10041 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0408 11:56:49.994343 10049 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:56:51.821317 10041 solver.cpp:331] Iteration 1000, Testing net (#0)
I0408 11:56:53.935111 10050 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:56:54.029839 10041 solver.cpp:398]     Test net output #0: accuracy = 0.9762
I0408 11:56:54.029881 10041 solver.cpp:398]     Test net output #1: loss = 0.0769233 (* 1 = 0.0769233 loss)
I0408 11:56:54.057869 10041 solver.cpp:219] Iteration 1000 (20.0427 iter/s, 4.98936s/100 iters), loss = 0.105949
I0408 11:56:54.057889 10041 solver.cpp:238]     Train net output #0: loss = 0.105949 (* 1 = 0.105949 loss)
I0408 11:56:54.057895 10041 sgd_solver.cpp:105] Iteration 1000, lr = 0.00931012
I0408 11:56:56.849783 10041 solver.cpp:219] Iteration 1100 (35.8183 iter/s, 2.79187s/100 iters), loss = 0.0107839
I0408 11:56:56.849812 10041 solver.cpp:238]     Train net output #0: loss = 0.0107838 (* 1 = 0.0107838 loss)
I0408 11:56:56.849815 10041 sgd_solver.cpp:105] Iteration 1100, lr = 0.00924715
I0408 11:56:59.634097 10041 solver.cpp:219] Iteration 1200 (35.9162 iter/s, 2.78426s/100 iters), loss = 0.0247488
I0408 11:56:59.634124 10041 solver.cpp:238]     Train net output #0: loss = 0.0247487 (* 1 = 0.0247487 loss)
I0408 11:56:59.634129 10041 sgd_solver.cpp:105] Iteration 1200, lr = 0.00918515
I0408 11:57:02.423606 10041 solver.cpp:219] Iteration 1300 (35.8492 iter/s, 2.78946s/100 iters), loss = 0.0189145
I0408 11:57:02.423635 10041 solver.cpp:238]     Train net output #0: loss = 0.0189144 (* 1 = 0.0189144 loss)
I0408 11:57:02.423640 10041 sgd_solver.cpp:105] Iteration 1300, lr = 0.00912412
I0408 11:57:05.210999 10041 solver.cpp:219] Iteration 1400 (35.8765 iter/s, 2.78734s/100 iters), loss = 0.0108341
I0408 11:57:05.211027 10041 solver.cpp:238]     Train net output #0: loss = 0.010834 (* 1 = 0.010834 loss)
I0408 11:57:05.211032 10041 sgd_solver.cpp:105] Iteration 1400, lr = 0.00906403
I0408 11:57:07.950781 10041 solver.cpp:331] Iteration 1500, Testing net (#0)
I0408 11:57:10.072988 10050 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:57:10.166908 10041 solver.cpp:398]     Test net output #0: accuracy = 0.9804
I0408 11:57:10.166930 10041 solver.cpp:398]     Test net output #1: loss = 0.0626062 (* 1 = 0.0626062 loss)
I0408 11:57:10.194416 10041 solver.cpp:219] Iteration 1500 (20.0668 iter/s, 4.98335s/100 iters), loss = 0.115293
I0408 11:57:10.194453 10041 solver.cpp:238]     Train net output #0: loss = 0.115293 (* 1 = 0.115293 loss)
I0408 11:57:10.194458 10041 sgd_solver.cpp:105] Iteration 1500, lr = 0.00900485
I0408 11:57:12.987864 10041 solver.cpp:219] Iteration 1600 (35.7988 iter/s, 2.79339s/100 iters), loss = 0.191169
I0408 11:57:12.987910 10041 solver.cpp:238]     Train net output #0: loss = 0.191168 (* 1 = 0.191168 loss)
I0408 11:57:12.987915 10041 sgd_solver.cpp:105] Iteration 1600, lr = 0.00894657
I0408 11:57:15.782310 10041 solver.cpp:219] Iteration 1700 (35.7862 iter/s, 2.79437s/100 iters), loss = 0.058395
I0408 11:57:15.782336 10041 solver.cpp:238]     Train net output #0: loss = 0.0583948 (* 1 = 0.0583948 loss)
I0408 11:57:15.782341 10041 sgd_solver.cpp:105] Iteration 1700, lr = 0.00888916
I0408 11:57:18.567850 10041 solver.cpp:219] Iteration 1800 (35.9003 iter/s, 2.78549s/100 iters), loss = 0.0123538
I0408 11:57:18.567878 10041 solver.cpp:238]     Train net output #0: loss = 0.0123537 (* 1 = 0.0123537 loss)
I0408 11:57:18.567883 10041 sgd_solver.cpp:105] Iteration 1800, lr = 0.0088326
I0408 11:57:20.519785 10049 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:57:21.361655 10041 solver.cpp:219] Iteration 1900 (35.7942 iter/s, 2.79375s/100 iters), loss = 0.155482
I0408 11:57:21.361682 10041 solver.cpp:238]     Train net output #0: loss = 0.155482 (* 1 = 0.155482 loss)
I0408 11:57:21.361686 10041 sgd_solver.cpp:105] Iteration 1900, lr = 0.00877687
I0408 11:57:24.107246 10041 solver.cpp:331] Iteration 2000, Testing net (#0)
I0408 11:57:26.222045 10050 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:57:26.316506 10041 solver.cpp:398]     Test net output #0: accuracy = 0.9817
I0408 11:57:26.316527 10041 solver.cpp:398]     Test net output #1: loss = 0.0543426 (* 1 = 0.0543426 loss)
I0408 11:57:26.344570 10041 solver.cpp:219] Iteration 2000 (20.0688 iter/s, 4.98285s/100 iters), loss = 0.0374027
I0408 11:57:26.344594 10041 solver.cpp:238]     Train net output #0: loss = 0.0374025 (* 1 = 0.0374025 loss)
I0408 11:57:26.344617 10041 sgd_solver.cpp:105] Iteration 2000, lr = 0.00872196
I0408 11:57:29.162452 10041 solver.cpp:219] Iteration 2100 (35.5154 iter/s, 2.81568s/100 iters), loss = 0.0318417
I0408 11:57:29.162479 10041 solver.cpp:238]     Train net output #0: loss = 0.0318416 (* 1 = 0.0318416 loss)
I0408 11:57:29.162484 10041 sgd_solver.cpp:105] Iteration 2100, lr = 0.00866784
I0408 11:57:31.953354 10041 solver.cpp:219] Iteration 2200 (35.8314 iter/s, 2.79085s/100 iters), loss = 0.036968
I0408 11:57:31.953383 10041 solver.cpp:238]     Train net output #0: loss = 0.0369679 (* 1 = 0.0369679 loss)
I0408 11:57:31.953387 10041 sgd_solver.cpp:105] Iteration 2200, lr = 0.0086145
I0408 11:57:34.738852 10041 solver.cpp:219] Iteration 2300 (35.9009 iter/s, 2.78544s/100 iters), loss = 0.139498
I0408 11:57:34.738880 10041 solver.cpp:238]     Train net output #0: loss = 0.139497 (* 1 = 0.139497 loss)
I0408 11:57:34.738884 10041 sgd_solver.cpp:105] Iteration 2300, lr = 0.00856192
I0408 11:57:37.523133 10041 solver.cpp:219] Iteration 2400 (35.9166 iter/s, 2.78423s/100 iters), loss = 0.0219558
I0408 11:57:37.523160 10041 solver.cpp:238]     Train net output #0: loss = 0.0219557 (* 1 = 0.0219557 loss)
I0408 11:57:37.523183 10041 sgd_solver.cpp:105] Iteration 2400, lr = 0.00851008
I0408 11:57:40.266139 10041 solver.cpp:331] Iteration 2500, Testing net (#0)
I0408 11:57:42.394439 10050 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:57:42.488400 10041 solver.cpp:398]     Test net output #0: accuracy = 0.9791
I0408 11:57:42.488422 10041 solver.cpp:398]     Test net output #1: loss = 0.0625014 (* 1 = 0.0625014 loss)
I0408 11:57:42.516438 10041 solver.cpp:219] Iteration 2500 (20.0271 iter/s, 4.99324s/100 iters), loss = 0.0306818
I0408 11:57:42.516482 10041 solver.cpp:238]     Train net output #0: loss = 0.0306816 (* 1 = 0.0306816 loss)
I0408 11:57:42.516501 10041 sgd_solver.cpp:105] Iteration 2500, lr = 0.00845897
I0408 11:57:45.305619 10041 solver.cpp:219] Iteration 2600 (35.8811 iter/s, 2.78698s/100 iters), loss = 0.129818
I0408 11:57:45.305665 10041 solver.cpp:238]     Train net output #0: loss = 0.129818 (* 1 = 0.129818 loss)
I0408 11:57:45.305670 10041 sgd_solver.cpp:105] Iteration 2600, lr = 0.00840857
I0408 11:57:48.089252 10041 solver.cpp:219] Iteration 2700 (35.9252 iter/s, 2.78356s/100 iters), loss = 0.157639
I0408 11:57:48.089279 10041 solver.cpp:238]     Train net output #0: loss = 0.157639 (* 1 = 0.157639 loss)
I0408 11:57:48.089284 10041 sgd_solver.cpp:105] Iteration 2700, lr = 0.00835886
I0408 11:57:50.871862 10041 solver.cpp:219] Iteration 2800 (35.9381 iter/s, 2.78256s/100 iters), loss = 0.00564779
I0408 11:57:50.872066 10041 solver.cpp:238]     Train net output #0: loss = 0.00564768 (* 1 = 0.00564768 loss)
I0408 11:57:50.872071 10041 sgd_solver.cpp:105] Iteration 2800, lr = 0.00830984
I0408 11:57:51.102035 10049 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:57:53.671430 10041 solver.cpp:219] Iteration 2900 (35.7224 iter/s, 2.79936s/100 iters), loss = 0.0215319
I0408 11:57:53.671458 10041 solver.cpp:238]     Train net output #0: loss = 0.0215318 (* 1 = 0.0215318 loss)
I0408 11:57:53.671479 10041 sgd_solver.cpp:105] Iteration 2900, lr = 0.00826148
I0408 11:57:56.426173 10041 solver.cpp:331] Iteration 3000, Testing net (#0)
I0408 11:57:58.552881 10050 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:57:58.648749 10041 solver.cpp:398]     Test net output #0: accuracy = 0.9804
I0408 11:57:58.648772 10041 solver.cpp:398]     Test net output #1: loss = 0.0623731 (* 1 = 0.0623731 loss)
I0408 11:57:58.676448 10041 solver.cpp:219] Iteration 3000 (19.9802 iter/s, 5.00496s/100 iters), loss = 0.0266153
I0408 11:57:58.676467 10041 solver.cpp:238]     Train net output #0: loss = 0.0266152 (* 1 = 0.0266152 loss)
I0408 11:57:58.676475 10041 sgd_solver.cpp:105] Iteration 3000, lr = 0.00821377
I0408 11:58:01.483283 10041 solver.cpp:219] Iteration 3100 (35.6279 iter/s, 2.80679s/100 iters), loss = 0.006061
I0408 11:58:01.483311 10041 solver.cpp:238]     Train net output #0: loss = 0.00606085 (* 1 = 0.00606085 loss)
I0408 11:58:01.483335 10041 sgd_solver.cpp:105] Iteration 3100, lr = 0.0081667
I0408 11:58:04.284258 10041 solver.cpp:219] Iteration 3200 (35.7025 iter/s, 2.80092s/100 iters), loss = 0.0254407
I0408 11:58:04.284286 10041 solver.cpp:238]     Train net output #0: loss = 0.0254406 (* 1 = 0.0254406 loss)
I0408 11:58:04.284308 10041 sgd_solver.cpp:105] Iteration 3200, lr = 0.00812025
I0408 11:58:07.077091 10041 solver.cpp:219] Iteration 3300 (35.8066 iter/s, 2.79278s/100 iters), loss = 0.0543784
I0408 11:58:07.077118 10041 solver.cpp:238]     Train net output #0: loss = 0.0543782 (* 1 = 0.0543782 loss)
I0408 11:58:07.077142 10041 sgd_solver.cpp:105] Iteration 3300, lr = 0.00807442
I0408 11:58:09.876415 10041 solver.cpp:219] Iteration 3400 (35.7236 iter/s, 2.79927s/100 iters), loss = 0.0203699
I0408 11:58:09.876459 10041 solver.cpp:238]     Train net output #0: loss = 0.0203697 (* 1 = 0.0203697 loss)
I0408 11:58:09.876466 10041 sgd_solver.cpp:105] Iteration 3400, lr = 0.00802918
I0408 11:58:12.637667 10041 solver.cpp:331] Iteration 3500, Testing net (#0)
I0408 11:58:14.764122 10050 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:58:14.857888 10041 solver.cpp:398]     Test net output #0: accuracy = 0.9826
I0408 11:58:14.857910 10041 solver.cpp:398]     Test net output #1: loss = 0.0509217 (* 1 = 0.0509217 loss)
I0408 11:58:14.885629 10041 solver.cpp:219] Iteration 3500 (19.9635 iter/s, 5.00914s/100 iters), loss = 0.0149175
I0408 11:58:14.885665 10041 solver.cpp:238]     Train net output #0: loss = 0.0149174 (* 1 = 0.0149174 loss)
I0408 11:58:14.885691 10041 sgd_solver.cpp:105] Iteration 3500, lr = 0.00798454
I0408 11:58:17.689913 10041 solver.cpp:219] Iteration 3600 (35.6605 iter/s, 2.80422s/100 iters), loss = 0.037491
I0408 11:58:17.689957 10041 solver.cpp:238]     Train net output #0: loss = 0.0374908 (* 1 = 0.0374908 loss)
I0408 11:58:17.689961 10041 sgd_solver.cpp:105] Iteration 3600, lr = 0.00794046
I0408 11:58:20.485764 10041 solver.cpp:219] Iteration 3700 (35.768 iter/s, 2.79579s/100 iters), loss = 0.0679461
I0408 11:58:20.485791 10041 solver.cpp:238]     Train net output #0: loss = 0.0679459 (* 1 = 0.0679459 loss)
I0408 11:58:20.485815 10041 sgd_solver.cpp:105] Iteration 3700, lr = 0.00789695
I0408 11:58:21.747942 10049 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:58:23.307780 10041 solver.cpp:219] Iteration 3800 (35.4363 iter/s, 2.82197s/100 iters), loss = 0.0352391
I0408 11:58:23.307806 10041 solver.cpp:238]     Train net output #0: loss = 0.0352389 (* 1 = 0.0352389 loss)
I0408 11:58:23.307828 10041 sgd_solver.cpp:105] Iteration 3800, lr = 0.007854
I0408 11:58:26.122081 10041 solver.cpp:219] Iteration 3900 (35.5334 iter/s, 2.81425s/100 iters), loss = 0.0354861
I0408 11:58:26.122126 10041 solver.cpp:238]     Train net output #0: loss = 0.0354859 (* 1 = 0.0354859 loss)
I0408 11:58:26.122131 10041 sgd_solver.cpp:105] Iteration 3900, lr = 0.00781158
I0408 11:58:28.876772 10041 solver.cpp:331] Iteration 4000, Testing net (#0)
I0408 11:58:31.005539 10050 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:58:31.099467 10041 solver.cpp:398]     Test net output #0: accuracy = 0.9853
I0408 11:58:31.099506 10041 solver.cpp:398]     Test net output #1: loss = 0.0399869 (* 1 = 0.0399869 loss)
I0408 11:58:31.127163 10041 solver.cpp:219] Iteration 4000 (19.98 iter/s, 5.00501s/100 iters), loss = 0.057123
I0408 11:58:31.127202 10041 solver.cpp:238]     Train net output #0: loss = 0.0571228 (* 1 = 0.0571228 loss)
I0408 11:58:31.127221 10041 sgd_solver.cpp:105] Iteration 4000, lr = 0.0077697
I0408 11:58:33.919543 10041 solver.cpp:219] Iteration 4100 (35.8125 iter/s, 2.79232s/100 iters), loss = 0.0385809
I0408 11:58:33.919571 10041 solver.cpp:238]     Train net output #0: loss = 0.0385807 (* 1 = 0.0385807 loss)
I0408 11:58:33.919576 10041 sgd_solver.cpp:105] Iteration 4100, lr = 0.00772833
I0408 11:58:36.701417 10041 solver.cpp:219] Iteration 4200 (35.9478 iter/s, 2.78181s/100 iters), loss = 0.0205186
I0408 11:58:36.701445 10041 solver.cpp:238]     Train net output #0: loss = 0.0205184 (* 1 = 0.0205184 loss)
I0408 11:58:36.701449 10041 sgd_solver.cpp:105] Iteration 4200, lr = 0.00768748
I0408 11:58:39.496940 10041 solver.cpp:219] Iteration 4300 (35.7721 iter/s, 2.79547s/100 iters), loss = 0.0720875
I0408 11:58:39.496980 10041 solver.cpp:238]     Train net output #0: loss = 0.0720873 (* 1 = 0.0720873 loss)
I0408 11:58:39.496985 10041 sgd_solver.cpp:105] Iteration 4300, lr = 0.00764712
I0408 11:58:42.305495 10041 solver.cpp:219] Iteration 4400 (35.6061 iter/s, 2.80851s/100 iters), loss = 0.0308991
I0408 11:58:42.305541 10041 solver.cpp:238]     Train net output #0: loss = 0.030899 (* 1 = 0.030899 loss)
I0408 11:58:42.305544 10041 sgd_solver.cpp:105] Iteration 4400, lr = 0.00760726
I0408 11:58:45.052919 10041 solver.cpp:331] Iteration 4500, Testing net (#0)
I0408 11:58:47.169211 10050 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:58:47.263279 10041 solver.cpp:398]     Test net output #0: accuracy = 0.9828
I0408 11:58:47.263303 10041 solver.cpp:398]     Test net output #1: loss = 0.0506665 (* 1 = 0.0506665 loss)
I0408 11:58:47.291074 10041 solver.cpp:219] Iteration 4500 (20.0581 iter/s, 4.98551s/100 iters), loss = 0.0140401
I0408 11:58:47.291093 10041 solver.cpp:238]     Train net output #0: loss = 0.0140399 (* 1 = 0.0140399 loss)
I0408 11:58:47.291100 10041 sgd_solver.cpp:105] Iteration 4500, lr = 0.00756788
I0408 11:58:50.089495 10041 solver.cpp:219] Iteration 4600 (35.7625 iter/s, 2.79622s/100 iters), loss = 0.00813032
I0408 11:58:50.089524 10041 solver.cpp:238]     Train net output #0: loss = 0.00813016 (* 1 = 0.00813016 loss)
I0408 11:58:50.089527 10041 sgd_solver.cpp:105] Iteration 4600, lr = 0.00752897
I0408 11:58:52.400544 10049 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:58:52.876708 10041 solver.cpp:219] Iteration 4700 (35.8788 iter/s, 2.78716s/100 iters), loss = 0.0152932
I0408 11:58:52.876736 10041 solver.cpp:238]     Train net output #0: loss = 0.015293 (* 1 = 0.015293 loss)
I0408 11:58:52.876741 10041 sgd_solver.cpp:105] Iteration 4700, lr = 0.00749052
I0408 11:58:55.656806 10041 solver.cpp:219] Iteration 4800 (35.9706 iter/s, 2.78005s/100 iters), loss = 0.0539391
I0408 11:58:55.656834 10041 solver.cpp:238]     Train net output #0: loss = 0.0539389 (* 1 = 0.0539389 loss)
I0408 11:58:55.656857 10041 sgd_solver.cpp:105] Iteration 4800, lr = 0.00745253
I0408 11:58:58.449724 10041 solver.cpp:219] Iteration 4900 (35.8055 iter/s, 2.79287s/100 iters), loss = 0.00400587
I0408 11:58:58.449753 10041 solver.cpp:238]     Train net output #0: loss = 0.00400571 (* 1 = 0.00400571 loss)
I0408 11:58:58.449757 10041 sgd_solver.cpp:105] Iteration 4900, lr = 0.00741498
I0408 11:59:01.202049 10041 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_5000.caffemodel
I0408 11:59:01.214736 10041 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_5000.solverstate
I0408 11:59:01.215219 10041 solver.cpp:331] Iteration 5000, Testing net (#0)
I0408 11:59:03.316054 10050 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:59:03.409410 10041 solver.cpp:398]     Test net output #0: accuracy = 0.9866
I0408 11:59:03.409432 10041 solver.cpp:398]     Test net output #1: loss = 0.0394481 (* 1 = 0.0394481 loss)
I0408 11:59:03.437010 10041 solver.cpp:219] Iteration 5000 (20.0512 iter/s, 4.98723s/100 iters), loss = 0.0482757
I0408 11:59:03.437036 10041 solver.cpp:238]     Train net output #0: loss = 0.0482756 (* 1 = 0.0482756 loss)
I0408 11:59:03.437041 10041 sgd_solver.cpp:105] Iteration 5000, lr = 0.00737788
I0408 11:59:06.235635 10041 solver.cpp:219] Iteration 5100 (35.7324 iter/s, 2.79858s/100 iters), loss = 0.0766814
I0408 11:59:06.235680 10041 solver.cpp:238]     Train net output #0: loss = 0.0766813 (* 1 = 0.0766813 loss)
I0408 11:59:06.235684 10041 sgd_solver.cpp:105] Iteration 5100, lr = 0.0073412
I0408 11:59:09.026631 10041 solver.cpp:219] Iteration 5200 (35.8304 iter/s, 2.79093s/100 iters), loss = 0.0317112
I0408 11:59:09.026659 10041 solver.cpp:238]     Train net output #0: loss = 0.031711 (* 1 = 0.031711 loss)
I0408 11:59:09.026664 10041 sgd_solver.cpp:105] Iteration 5200, lr = 0.00730495
I0408 11:59:11.825070 10041 solver.cpp:219] Iteration 5300 (35.7348 iter/s, 2.79839s/100 iters), loss = 0.00764965
I0408 11:59:11.825116 10041 solver.cpp:238]     Train net output #0: loss = 0.00764951 (* 1 = 0.00764951 loss)
I0408 11:59:11.825121 10041 sgd_solver.cpp:105] Iteration 5300, lr = 0.00726911
I0408 11:59:14.617202 10041 solver.cpp:219] Iteration 5400 (35.8158 iter/s, 2.79206s/100 iters), loss = 0.0496449
I0408 11:59:14.617245 10041 solver.cpp:238]     Train net output #0: loss = 0.0496447 (* 1 = 0.0496447 loss)
I0408 11:59:14.617250 10041 sgd_solver.cpp:105] Iteration 5400, lr = 0.00723368
I0408 11:59:17.375108 10041 solver.cpp:331] Iteration 5500, Testing net (#0)
I0408 11:59:19.500026 10050 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:59:19.593518 10041 solver.cpp:398]     Test net output #0: accuracy = 0.9861
I0408 11:59:19.593541 10041 solver.cpp:398]     Test net output #1: loss = 0.0423797 (* 1 = 0.0423797 loss)
I0408 11:59:19.621315 10041 solver.cpp:219] Iteration 5500 (19.9838 iter/s, 5.00405s/100 iters), loss = 0.0270112
I0408 11:59:19.621351 10041 solver.cpp:238]     Train net output #0: loss = 0.0270111 (* 1 = 0.0270111 loss)
I0408 11:59:19.621356 10041 sgd_solver.cpp:105] Iteration 5500, lr = 0.00719865
I0408 11:59:22.405638 10041 solver.cpp:219] Iteration 5600 (35.9161 iter/s, 2.78426s/100 iters), loss = 0.00385017
I0408 11:59:22.405815 10041 solver.cpp:238]     Train net output #0: loss = 0.00385005 (* 1 = 0.00385005 loss)
I0408 11:59:22.405822 10041 sgd_solver.cpp:105] Iteration 5600, lr = 0.00716402
I0408 11:59:22.966814 10049 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:59:25.200424 10041 solver.cpp:219] Iteration 5700 (35.7834 iter/s, 2.79459s/100 iters), loss = 0.0238434
I0408 11:59:25.200471 10041 solver.cpp:238]     Train net output #0: loss = 0.0238433 (* 1 = 0.0238433 loss)
I0408 11:59:25.200475 10041 sgd_solver.cpp:105] Iteration 5700, lr = 0.00712977
I0408 11:59:27.995189 10041 solver.cpp:219] Iteration 5800 (35.7821 iter/s, 2.7947s/100 iters), loss = 0.0402895
I0408 11:59:27.995216 10041 solver.cpp:238]     Train net output #0: loss = 0.0402893 (* 1 = 0.0402893 loss)
I0408 11:59:27.995221 10041 sgd_solver.cpp:105] Iteration 5800, lr = 0.0070959
I0408 11:59:30.777889 10041 solver.cpp:219] Iteration 5900 (35.937 iter/s, 2.78265s/100 iters), loss = 0.0205908
I0408 11:59:30.777916 10041 solver.cpp:238]     Train net output #0: loss = 0.0205907 (* 1 = 0.0205907 loss)
I0408 11:59:30.777921 10041 sgd_solver.cpp:105] Iteration 5900, lr = 0.0070624
I0408 11:59:33.524433 10041 solver.cpp:331] Iteration 6000, Testing net (#0)
I0408 11:59:35.645452 10050 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:59:35.740303 10041 solver.cpp:398]     Test net output #0: accuracy = 0.9872
I0408 11:59:35.740325 10041 solver.cpp:398]     Test net output #1: loss = 0.0360625 (* 1 = 0.0360625 loss)
I0408 11:59:35.767714 10041 solver.cpp:219] Iteration 6000 (20.041 iter/s, 4.98977s/100 iters), loss = 0.0144502
I0408 11:59:35.767732 10041 solver.cpp:238]     Train net output #0: loss = 0.0144501 (* 1 = 0.0144501 loss)
I0408 11:59:35.767737 10041 sgd_solver.cpp:105] Iteration 6000, lr = 0.00702927
I0408 11:59:38.553565 10041 solver.cpp:219] Iteration 6100 (35.8962 iter/s, 2.78581s/100 iters), loss = 0.00382308
I0408 11:59:38.553594 10041 solver.cpp:238]     Train net output #0: loss = 0.00382293 (* 1 = 0.00382293 loss)
I0408 11:59:38.553601 10041 sgd_solver.cpp:105] Iteration 6100, lr = 0.0069965
I0408 11:59:41.348915 10041 solver.cpp:219] Iteration 6200 (35.7743 iter/s, 2.7953s/100 iters), loss = 0.00869894
I0408 11:59:41.348944 10041 solver.cpp:238]     Train net output #0: loss = 0.00869881 (* 1 = 0.00869881 loss)
I0408 11:59:41.348949 10041 sgd_solver.cpp:105] Iteration 6200, lr = 0.00696408
I0408 11:59:44.139796 10041 solver.cpp:219] Iteration 6300 (35.8316 iter/s, 2.79083s/100 iters), loss = 0.0111551
I0408 11:59:44.139822 10041 solver.cpp:238]     Train net output #0: loss = 0.011155 (* 1 = 0.011155 loss)
I0408 11:59:44.139827 10041 sgd_solver.cpp:105] Iteration 6300, lr = 0.00693201
I0408 11:59:46.941401 10041 solver.cpp:219] Iteration 6400 (35.6944 iter/s, 2.80156s/100 iters), loss = 0.0494939
I0408 11:59:46.941464 10041 solver.cpp:238]     Train net output #0: loss = 0.0494938 (* 1 = 0.0494938 loss)
I0408 11:59:46.941469 10041 sgd_solver.cpp:105] Iteration 6400, lr = 0.00690029
I0408 11:59:49.697561 10041 solver.cpp:331] Iteration 6500, Testing net (#0)
I0408 11:59:51.819900 10050 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:59:51.913403 10041 solver.cpp:398]     Test net output #0: accuracy = 0.9869
I0408 11:59:51.913425 10041 solver.cpp:398]     Test net output #1: loss = 0.0402443 (* 1 = 0.0402443 loss)
I0408 11:59:51.941015 10041 solver.cpp:219] Iteration 6500 (20.0019 iter/s, 4.99953s/100 iters), loss = 0.00665311
I0408 11:59:51.941052 10041 solver.cpp:238]     Train net output #0: loss = 0.006653 (* 1 = 0.006653 loss)
I0408 11:59:51.941059 10041 sgd_solver.cpp:105] Iteration 6500, lr = 0.0068689
I0408 11:59:53.572500 10049 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:59:54.749400 10041 solver.cpp:219] Iteration 6600 (35.6083 iter/s, 2.80833s/100 iters), loss = 0.044132
I0408 11:59:54.749444 10041 solver.cpp:238]     Train net output #0: loss = 0.0441319 (* 1 = 0.0441319 loss)
I0408 11:59:54.749449 10041 sgd_solver.cpp:105] Iteration 6600, lr = 0.00683784
I0408 11:59:57.540971 10041 solver.cpp:219] Iteration 6700 (35.823 iter/s, 2.79151s/100 iters), loss = 0.0251432
I0408 11:59:57.540999 10041 solver.cpp:238]     Train net output #0: loss = 0.0251431 (* 1 = 0.0251431 loss)
I0408 11:59:57.541003 10041 sgd_solver.cpp:105] Iteration 6700, lr = 0.00680711
I0408 12:00:00.339159 10041 solver.cpp:219] Iteration 6800 (35.738 iter/s, 2.79814s/100 iters), loss = 0.0119899
I0408 12:00:00.339203 10041 solver.cpp:238]     Train net output #0: loss = 0.0119898 (* 1 = 0.0119898 loss)
I0408 12:00:00.339221 10041 sgd_solver.cpp:105] Iteration 6800, lr = 0.0067767
I0408 12:00:03.135367 10041 solver.cpp:219] Iteration 6900 (35.7635 iter/s, 2.79614s/100 iters), loss = 0.0277601
I0408 12:00:03.135413 10041 solver.cpp:238]     Train net output #0: loss = 0.0277601 (* 1 = 0.0277601 loss)
I0408 12:00:03.135431 10041 sgd_solver.cpp:105] Iteration 6900, lr = 0.0067466
I0408 12:00:05.888998 10041 solver.cpp:331] Iteration 7000, Testing net (#0)
I0408 12:00:08.014978 10050 data_layer.cpp:73] Restarting data prefetching from start.
I0408 12:00:08.110317 10041 solver.cpp:398]     Test net output #0: accuracy = 0.9873
I0408 12:00:08.110357 10041 solver.cpp:398]     Test net output #1: loss = 0.0398875 (* 1 = 0.0398875 loss)
I0408 12:00:08.138516 10041 solver.cpp:219] Iteration 7000 (19.9877 iter/s, 5.00308s/100 iters), loss = 0.0438895
I0408 12:00:08.138561 10041 solver.cpp:238]     Train net output #0: loss = 0.0438894 (* 1 = 0.0438894 loss)
I0408 12:00:08.138566 10041 sgd_solver.cpp:105] Iteration 7000, lr = 0.00671681
I0408 12:00:10.944463 10041 solver.cpp:219] Iteration 7100 (35.6666 iter/s, 2.80375s/100 iters), loss = 0.0535318
I0408 12:00:10.944509 10041 solver.cpp:238]     Train net output #0: loss = 0.0535317 (* 1 = 0.0535317 loss)
I0408 12:00:10.944526 10041 sgd_solver.cpp:105] Iteration 7100, lr = 0.00668733
I0408 12:00:13.739855 10041 solver.cpp:219] Iteration 7200 (35.774 iter/s, 2.79533s/100 iters), loss = 0.0126065
I0408 12:00:13.739882 10041 solver.cpp:238]     Train net output #0: loss = 0.0126064 (* 1 = 0.0126064 loss)
I0408 12:00:13.739886 10041 sgd_solver.cpp:105] Iteration 7200, lr = 0.00665815
I0408 12:00:16.538954 10041 solver.cpp:219] Iteration 7300 (35.7264 iter/s, 2.79905s/100 iters), loss = 0.064113
I0408 12:00:16.538997 10041 solver.cpp:238]     Train net output #0: loss = 0.0641129 (* 1 = 0.0641129 loss)
I0408 12:00:16.539016 10041 sgd_solver.cpp:105] Iteration 7300, lr = 0.00662927
I0408 12:00:19.337002 10041 solver.cpp:219] Iteration 7400 (35.74 iter/s, 2.79798s/100 iters), loss = 0.0646278
I0408 12:00:19.337029 10041 solver.cpp:238]     Train net output #0: loss = 0.0646277 (* 1 = 0.0646277 loss)
I0408 12:00:19.337052 10041 sgd_solver.cpp:105] Iteration 7400, lr = 0.00660067
I0408 12:00:21.992399 10049 data_layer.cpp:73] Restarting data prefetching from start.
I0408 12:00:22.099746 10041 solver.cpp:331] Iteration 7500, Testing net (#0)
I0408 12:00:24.224865 10050 data_layer.cpp:73] Restarting data prefetching from start.
I0408 12:00:24.320307 10041 solver.cpp:398]     Test net output #0: accuracy = 0.9866
I0408 12:00:24.320348 10041 solver.cpp:398]     Test net output #1: loss = 0.0389297 (* 1 = 0.0389297 loss)
I0408 12:00:24.348054 10041 solver.cpp:219] Iteration 7500 (19.9561 iter/s, 5.011s/100 iters), loss = 0.00728208
I0408 12:00:24.348073 10041 solver.cpp:238]     Train net output #0: loss = 0.00728203 (* 1 = 0.00728203 loss)
I0408 12:00:24.348078 10041 sgd_solver.cpp:105] Iteration 7500, lr = 0.00657236
I0408 12:00:27.150308 10041 solver.cpp:219] Iteration 7600 (35.6861 iter/s, 2.80221s/100 iters), loss = 0.0741554
I0408 12:00:27.150354 10041 solver.cpp:238]     Train net output #0: loss = 0.0741553 (* 1 = 0.0741553 loss)
I0408 12:00:27.150358 10041 sgd_solver.cpp:105] Iteration 7600, lr = 0.00654433
I0408 12:00:29.952494 10041 solver.cpp:219] Iteration 7700 (35.6873 iter/s, 2.80212s/100 iters), loss = 0.040907
I0408 12:00:29.952523 10041 solver.cpp:238]     Train net output #0: loss = 0.040907 (* 1 = 0.040907 loss)
I0408 12:00:29.952528 10041 sgd_solver.cpp:105] Iteration 7700, lr = 0.00651658
I0408 12:00:32.741333 10041 solver.cpp:219] Iteration 7800 (35.8579 iter/s, 2.78879s/100 iters), loss = 0.0215055
I0408 12:00:32.741377 10041 solver.cpp:238]     Train net output #0: loss = 0.0215054 (* 1 = 0.0215054 loss)
I0408 12:00:32.741395 10041 sgd_solver.cpp:105] Iteration 7800, lr = 0.00648911
I0408 12:00:35.535257 10041 solver.cpp:219] Iteration 7900 (35.7928 iter/s, 2.79386s/100 iters), loss = 0.00845849
I0408 12:00:35.535300 10041 solver.cpp:238]     Train net output #0: loss = 0.00845843 (* 1 = 0.00845843 loss)
I0408 12:00:35.535305 10041 sgd_solver.cpp:105] Iteration 7900, lr = 0.0064619
I0408 12:00:38.293624 10041 solver.cpp:331] Iteration 8000, Testing net (#0)
I0408 12:00:40.420776 10050 data_layer.cpp:73] Restarting data prefetching from start.
I0408 12:00:40.514323 10041 solver.cpp:398]     Test net output #0: accuracy = 0.9867
I0408 12:00:40.514345 10041 solver.cpp:398]     Test net output #1: loss = 0.0401417 (* 1 = 0.0401417 loss)
I0408 12:00:40.542369 10041 solver.cpp:219] Iteration 8000 (19.9719 iter/s, 5.00704s/100 iters), loss = 0.0506199
I0408 12:00:40.542394 10041 solver.cpp:238]     Train net output #0: loss = 0.0506199 (* 1 = 0.0506199 loss)
I0408 12:00:40.542400 10041 sgd_solver.cpp:105] Iteration 8000, lr = 0.00643496
I0408 12:00:43.340854 10041 solver.cpp:219] Iteration 8100 (35.7617 iter/s, 2.79629s/100 iters), loss = 0.0870492
I0408 12:00:43.340883 10041 solver.cpp:238]     Train net output #0: loss = 0.0870492 (* 1 = 0.0870492 loss)
I0408 12:00:43.340888 10041 sgd_solver.cpp:105] Iteration 8100, lr = 0.00640827
I0408 12:00:46.138687 10041 solver.cpp:219] Iteration 8200 (35.7425 iter/s, 2.79779s/100 iters), loss = 0.0186322
I0408 12:00:46.138715 10041 solver.cpp:238]     Train net output #0: loss = 0.0186322 (* 1 = 0.0186322 loss)
I0408 12:00:46.138720 10041 sgd_solver.cpp:105] Iteration 8200, lr = 0.00638185
I0408 12:00:48.926762 10041 solver.cpp:219] Iteration 8300 (35.8677 iter/s, 2.78803s/100 iters), loss = 0.0348723
I0408 12:00:48.926808 10041 solver.cpp:238]     Train net output #0: loss = 0.0348722 (* 1 = 0.0348722 loss)
I0408 12:00:48.926812 10041 sgd_solver.cpp:105] Iteration 8300, lr = 0.00635567
I0408 12:00:51.718686 10041 solver.cpp:219] Iteration 8400 (35.8184 iter/s, 2.79186s/100 iters), loss = 0.0419521
I0408 12:00:51.718713 10041 solver.cpp:238]     Train net output #0: loss = 0.041952 (* 1 = 0.041952 loss)
I0408 12:00:51.718719 10041 sgd_solver.cpp:105] Iteration 8400, lr = 0.00632975
I0408 12:00:52.647099 10049 data_layer.cpp:73] Restarting data prefetching from start.
I0408 12:00:54.478027 10041 solver.cpp:331] Iteration 8500, Testing net (#0)
I0408 12:00:56.597515 10050 data_layer.cpp:73] Restarting data prefetching from start.
I0408 12:00:56.691651 10041 solver.cpp:398]     Test net output #0: accuracy = 0.9869
I0408 12:00:56.691673 10041 solver.cpp:398]     Test net output #1: loss = 0.0375013 (* 1 = 0.0375013 loss)
I0408 12:00:56.719615 10041 solver.cpp:219] Iteration 8500 (19.9965 iter/s, 5.00088s/100 iters), loss = 0.0240877
I0408 12:00:56.719638 10041 solver.cpp:238]     Train net output #0: loss = 0.0240876 (* 1 = 0.0240876 loss)
I0408 12:00:56.719645 10041 sgd_solver.cpp:105] Iteration 8500, lr = 0.00630407
I0408 12:00:59.518681 10041 solver.cpp:219] Iteration 8600 (35.7543 iter/s, 2.79687s/100 iters), loss = 0.00129283
I0408 12:00:59.518707 10041 solver.cpp:238]     Train net output #0: loss = 0.00129273 (* 1 = 0.00129273 loss)
I0408 12:00:59.518712 10041 sgd_solver.cpp:105] Iteration 8600, lr = 0.00627864
I0408 12:01:02.311156 10041 solver.cpp:219] Iteration 8700 (35.8111 iter/s, 2.79243s/100 iters), loss = 0.00497002
I0408 12:01:02.311185 10041 solver.cpp:238]     Train net output #0: loss = 0.0049699 (* 1 = 0.0049699 loss)
I0408 12:01:02.311189 10041 sgd_solver.cpp:105] Iteration 8700, lr = 0.00625344
I0408 12:01:05.100741 10041 solver.cpp:219] Iteration 8800 (35.8482 iter/s, 2.78954s/100 iters), loss = 0.00799121
I0408 12:01:05.100787 10041 solver.cpp:238]     Train net output #0: loss = 0.00799109 (* 1 = 0.00799109 loss)
I0408 12:01:05.100791 10041 sgd_solver.cpp:105] Iteration 8800, lr = 0.00622847
I0408 12:01:07.896428 10041 solver.cpp:219] Iteration 8900 (35.7699 iter/s, 2.79564s/100 iters), loss = 0.00198094
I0408 12:01:07.896455 10041 solver.cpp:238]     Train net output #0: loss = 0.00198082 (* 1 = 0.00198082 loss)
I0408 12:01:07.896459 10041 sgd_solver.cpp:105] Iteration 8900, lr = 0.00620374
I0408 12:01:10.656455 10041 solver.cpp:331] Iteration 9000, Testing net (#0)
I0408 12:01:12.772259 10050 data_layer.cpp:73] Restarting data prefetching from start.
I0408 12:01:12.867465 10041 solver.cpp:398]     Test net output #0: accuracy = 0.9874
I0408 12:01:12.867504 10041 solver.cpp:398]     Test net output #1: loss = 0.0358477 (* 1 = 0.0358477 loss)
I0408 12:01:12.895565 10041 solver.cpp:219] Iteration 9000 (20.0036 iter/s, 4.99909s/100 iters), loss = 0.0341161
I0408 12:01:12.895584 10041 solver.cpp:238]     Train net output #0: loss = 0.034116 (* 1 = 0.034116 loss)
I0408 12:01:12.895591 10041 sgd_solver.cpp:105] Iteration 9000, lr = 0.00617924
I0408 12:01:15.714954 10041 solver.cpp:219] Iteration 9100 (35.4691 iter/s, 2.81935s/100 iters), loss = 0.0747824
I0408 12:01:15.714980 10041 solver.cpp:238]     Train net output #0: loss = 0.0747823 (* 1 = 0.0747823 loss)
I0408 12:01:15.714985 10041 sgd_solver.cpp:105] Iteration 9100, lr = 0.00615496
I0408 12:01:18.504941 10041 solver.cpp:219] Iteration 9200 (35.843 iter/s, 2.78994s/100 iters), loss = 0.027965
I0408 12:01:18.504971 10041 solver.cpp:238]     Train net output #0: loss = 0.0279648 (* 1 = 0.0279648 loss)
I0408 12:01:18.504974 10041 sgd_solver.cpp:105] Iteration 9200, lr = 0.0061309
I0408 12:01:21.308444 10041 solver.cpp:219] Iteration 9300 (35.6703 iter/s, 2.80345s/100 iters), loss = 0.00483502
I0408 12:01:21.308472 10041 solver.cpp:238]     Train net output #0: loss = 0.0048349 (* 1 = 0.0048349 loss)
I0408 12:01:21.308478 10041 sgd_solver.cpp:105] Iteration 9300, lr = 0.00610706
I0408 12:01:23.280944 10049 data_layer.cpp:73] Restarting data prefetching from start.
I0408 12:01:24.125435 10041 solver.cpp:219] Iteration 9400 (35.4995 iter/s, 2.81694s/100 iters), loss = 0.112486
I0408 12:01:24.125463 10041 solver.cpp:238]     Train net output #0: loss = 0.112486 (* 1 = 0.112486 loss)
I0408 12:01:24.125468 10041 sgd_solver.cpp:105] Iteration 9400, lr = 0.00608343
I0408 12:01:26.873069 10041 solver.cpp:331] Iteration 9500, Testing net (#0)
I0408 12:01:29.011056 10050 data_layer.cpp:73] Restarting data prefetching from start.
I0408 12:01:29.106058 10041 solver.cpp:398]     Test net output #0: accuracy = 0.987
I0408 12:01:29.106099 10041 solver.cpp:398]     Test net output #1: loss = 0.0398254 (* 1 = 0.0398254 loss)
I0408 12:01:29.133710 10041 solver.cpp:219] Iteration 9500 (19.9671 iter/s, 5.00823s/100 iters), loss = 0.014761
I0408 12:01:29.133736 10041 solver.cpp:238]     Train net output #0: loss = 0.0147609 (* 1 = 0.0147609 loss)
I0408 12:01:29.133762 10041 sgd_solver.cpp:105] Iteration 9500, lr = 0.00606002
I0408 12:01:31.936740 10041 solver.cpp:219] Iteration 9600 (35.6762 iter/s, 2.80299s/100 iters), loss = 0.00626727
I0408 12:01:31.936769 10041 solver.cpp:238]     Train net output #0: loss = 0.00626715 (* 1 = 0.00626715 loss)
I0408 12:01:31.936790 10041 sgd_solver.cpp:105] Iteration 9600, lr = 0.00603682
I0408 12:01:34.743722 10041 solver.cpp:219] Iteration 9700 (35.626 iter/s, 2.80694s/100 iters), loss = 0.00950084
I0408 12:01:34.743767 10041 solver.cpp:238]     Train net output #0: loss = 0.00950073 (* 1 = 0.00950073 loss)
I0408 12:01:34.743772 10041 sgd_solver.cpp:105] Iteration 9700, lr = 0.00601382
I0408 12:01:37.583742 10041 solver.cpp:219] Iteration 9800 (35.2118 iter/s, 2.83996s/100 iters), loss = 0.0323633
I0408 12:01:37.583770 10041 solver.cpp:238]     Train net output #0: loss = 0.0323631 (* 1 = 0.0323631 loss)
I0408 12:01:37.583775 10041 sgd_solver.cpp:105] Iteration 9800, lr = 0.00599102
I0408 12:01:40.380334 10041 solver.cpp:219] Iteration 9900 (35.7584 iter/s, 2.79655s/100 iters), loss = 0.0112461
I0408 12:01:40.380362 10041 solver.cpp:238]     Train net output #0: loss = 0.011246 (* 1 = 0.011246 loss)
I0408 12:01:40.380367 10041 sgd_solver.cpp:105] Iteration 9900, lr = 0.00596843
I0408 12:01:43.132072 10041 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_10000.caffemodel
I0408 12:01:43.144932 10041 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_10000.solverstate
I0408 12:01:43.159910 10041 solver.cpp:311] Iteration 10000, loss = 0.00847981
I0408 12:01:43.159929 10041 solver.cpp:331] Iteration 10000, Testing net (#0)
I0408 12:01:45.282812 10050 data_layer.cpp:73] Restarting data prefetching from start.
I0408 12:01:45.376658 10041 solver.cpp:398]     Test net output #0: accuracy = 0.9877
I0408 12:01:45.376679 10041 solver.cpp:398]     Test net output #1: loss = 0.0376683 (* 1 = 0.0376683 loss)
I0408 12:01:45.376703 10041 solver.cpp:316] Optimization Done.
I0408 12:01:45.376704 10041 caffe.cpp:259] Optimization Done.
