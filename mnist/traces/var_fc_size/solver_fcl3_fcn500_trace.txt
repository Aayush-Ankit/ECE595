I0408 13:23:59.386492 11169 caffe.cpp:218] Using GPUs 0
I0408 13:23:59.401190 11169 caffe.cpp:223] GPU 0: GeForce GTX 950M
I0408 13:23:59.581077 11169 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_fc_size/lenet_train_test_fcl3_fcn500.prototxt"
train_state {
  level: 0
  stage: ""
}
I0408 13:23:59.581266 11169 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_fc_size/lenet_train_test_fcl3_fcn500.prototxt
I0408 13:23:59.581468 11169 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0408 13:23:59.581482 11169 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0408 13:23:59.581588 11169 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0408 13:23:59.581682 11169 layer_factory.hpp:77] Creating layer mnist
I0408 13:23:59.581785 11169 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0408 13:23:59.581807 11169 net.cpp:84] Creating Layer mnist
I0408 13:23:59.581815 11169 net.cpp:380] mnist -> data
I0408 13:23:59.581835 11169 net.cpp:380] mnist -> label
I0408 13:23:59.582352 11169 data_layer.cpp:45] output data size: 64,1,28,28
I0408 13:23:59.583747 11169 net.cpp:122] Setting up mnist
I0408 13:23:59.583758 11169 net.cpp:129] Top shape: 64 1 28 28 (50176)
I0408 13:23:59.583776 11169 net.cpp:129] Top shape: 64 (64)
I0408 13:23:59.583781 11169 net.cpp:137] Memory required for data: 200960
I0408 13:23:59.583806 11169 layer_factory.hpp:77] Creating layer conv0
I0408 13:23:59.583868 11169 net.cpp:84] Creating Layer conv0
I0408 13:23:59.583891 11169 net.cpp:406] conv0 <- data
I0408 13:23:59.583904 11169 net.cpp:380] conv0 -> conv0
I0408 13:23:59.584877 11169 net.cpp:122] Setting up conv0
I0408 13:23:59.584900 11169 net.cpp:129] Top shape: 64 50 24 24 (1843200)
I0408 13:23:59.584903 11169 net.cpp:137] Memory required for data: 7573760
I0408 13:23:59.584934 11169 layer_factory.hpp:77] Creating layer pool0
I0408 13:23:59.584961 11169 net.cpp:84] Creating Layer pool0
I0408 13:23:59.584978 11169 net.cpp:406] pool0 <- conv0
I0408 13:23:59.584985 11169 net.cpp:380] pool0 -> pool0
I0408 13:23:59.585121 11169 net.cpp:122] Setting up pool0
I0408 13:23:59.585127 11169 net.cpp:129] Top shape: 64 50 12 12 (460800)
I0408 13:23:59.585130 11169 net.cpp:137] Memory required for data: 9416960
I0408 13:23:59.585134 11169 layer_factory.hpp:77] Creating layer conv1
I0408 13:23:59.585144 11169 net.cpp:84] Creating Layer conv1
I0408 13:23:59.585147 11169 net.cpp:406] conv1 <- pool0
I0408 13:23:59.585155 11169 net.cpp:380] conv1 -> conv1
I0408 13:23:59.586103 11169 net.cpp:122] Setting up conv1
I0408 13:23:59.586112 11169 net.cpp:129] Top shape: 64 50 8 8 (204800)
I0408 13:23:59.586115 11169 net.cpp:137] Memory required for data: 10236160
I0408 13:23:59.586123 11169 layer_factory.hpp:77] Creating layer pool1
I0408 13:23:59.586133 11169 net.cpp:84] Creating Layer pool1
I0408 13:23:59.586138 11169 net.cpp:406] pool1 <- conv1
I0408 13:23:59.586143 11169 net.cpp:380] pool1 -> pool1
I0408 13:23:59.586216 11169 net.cpp:122] Setting up pool1
I0408 13:23:59.586222 11169 net.cpp:129] Top shape: 64 50 4 4 (51200)
I0408 13:23:59.586239 11169 net.cpp:137] Memory required for data: 10440960
I0408 13:23:59.586243 11169 layer_factory.hpp:77] Creating layer ip1
I0408 13:23:59.586251 11169 net.cpp:84] Creating Layer ip1
I0408 13:23:59.586254 11169 net.cpp:406] ip1 <- pool1
I0408 13:23:59.586261 11169 net.cpp:380] ip1 -> ip1
I0408 13:23:59.588840 11169 net.cpp:122] Setting up ip1
I0408 13:23:59.588848 11169 net.cpp:129] Top shape: 64 500 (32000)
I0408 13:23:59.588851 11169 net.cpp:137] Memory required for data: 10568960
I0408 13:23:59.588863 11169 layer_factory.hpp:77] Creating layer relu1
I0408 13:23:59.588887 11169 net.cpp:84] Creating Layer relu1
I0408 13:23:59.588892 11169 net.cpp:406] relu1 <- ip1
I0408 13:23:59.588910 11169 net.cpp:367] relu1 -> ip1 (in-place)
I0408 13:23:59.588938 11169 net.cpp:122] Setting up relu1
I0408 13:23:59.588943 11169 net.cpp:129] Top shape: 64 500 (32000)
I0408 13:23:59.588945 11169 net.cpp:137] Memory required for data: 10696960
I0408 13:23:59.588964 11169 layer_factory.hpp:77] Creating layer ip2
I0408 13:23:59.588971 11169 net.cpp:84] Creating Layer ip2
I0408 13:23:59.588994 11169 net.cpp:406] ip2 <- ip1
I0408 13:23:59.588999 11169 net.cpp:380] ip2 -> ip2
I0408 13:23:59.590540 11169 net.cpp:122] Setting up ip2
I0408 13:23:59.590548 11169 net.cpp:129] Top shape: 64 500 (32000)
I0408 13:23:59.590551 11169 net.cpp:137] Memory required for data: 10824960
I0408 13:23:59.590575 11169 layer_factory.hpp:77] Creating layer relu2
I0408 13:23:59.590584 11169 net.cpp:84] Creating Layer relu2
I0408 13:23:59.590589 11169 net.cpp:406] relu2 <- ip2
I0408 13:23:59.590613 11169 net.cpp:367] relu2 -> ip2 (in-place)
I0408 13:23:59.590620 11169 net.cpp:122] Setting up relu2
I0408 13:23:59.590625 11169 net.cpp:129] Top shape: 64 500 (32000)
I0408 13:23:59.590626 11169 net.cpp:137] Memory required for data: 10952960
I0408 13:23:59.590643 11169 layer_factory.hpp:77] Creating layer ip3
I0408 13:23:59.590649 11169 net.cpp:84] Creating Layer ip3
I0408 13:23:59.590665 11169 net.cpp:406] ip3 <- ip2
I0408 13:23:59.590672 11169 net.cpp:380] ip3 -> ip3
I0408 13:23:59.591073 11169 net.cpp:122] Setting up ip3
I0408 13:23:59.591081 11169 net.cpp:129] Top shape: 64 10 (640)
I0408 13:23:59.591084 11169 net.cpp:137] Memory required for data: 10955520
I0408 13:23:59.591092 11169 layer_factory.hpp:77] Creating layer relu3
I0408 13:23:59.591099 11169 net.cpp:84] Creating Layer relu3
I0408 13:23:59.591104 11169 net.cpp:406] relu3 <- ip3
I0408 13:23:59.591140 11169 net.cpp:367] relu3 -> ip3 (in-place)
I0408 13:23:59.591146 11169 net.cpp:122] Setting up relu3
I0408 13:23:59.591152 11169 net.cpp:129] Top shape: 64 10 (640)
I0408 13:23:59.591156 11169 net.cpp:137] Memory required for data: 10958080
I0408 13:23:59.591158 11169 layer_factory.hpp:77] Creating layer loss
I0408 13:23:59.591164 11169 net.cpp:84] Creating Layer loss
I0408 13:23:59.591168 11169 net.cpp:406] loss <- ip3
I0408 13:23:59.591172 11169 net.cpp:406] loss <- label
I0408 13:23:59.591178 11169 net.cpp:380] loss -> loss
I0408 13:23:59.591204 11169 layer_factory.hpp:77] Creating layer loss
I0408 13:23:59.591269 11169 net.cpp:122] Setting up loss
I0408 13:23:59.591275 11169 net.cpp:129] Top shape: (1)
I0408 13:23:59.591277 11169 net.cpp:132]     with loss weight 1
I0408 13:23:59.591292 11169 net.cpp:137] Memory required for data: 10958084
I0408 13:23:59.591295 11169 net.cpp:198] loss needs backward computation.
I0408 13:23:59.591303 11169 net.cpp:198] relu3 needs backward computation.
I0408 13:23:59.591307 11169 net.cpp:198] ip3 needs backward computation.
I0408 13:23:59.591310 11169 net.cpp:198] relu2 needs backward computation.
I0408 13:23:59.591312 11169 net.cpp:198] ip2 needs backward computation.
I0408 13:23:59.591316 11169 net.cpp:198] relu1 needs backward computation.
I0408 13:23:59.591320 11169 net.cpp:198] ip1 needs backward computation.
I0408 13:23:59.591322 11169 net.cpp:198] pool1 needs backward computation.
I0408 13:23:59.591325 11169 net.cpp:198] conv1 needs backward computation.
I0408 13:23:59.591347 11169 net.cpp:198] pool0 needs backward computation.
I0408 13:23:59.591351 11169 net.cpp:198] conv0 needs backward computation.
I0408 13:23:59.591353 11169 net.cpp:200] mnist does not need backward computation.
I0408 13:23:59.591370 11169 net.cpp:242] This network produces output loss
I0408 13:23:59.591382 11169 net.cpp:255] Network initialization done.
I0408 13:23:59.591555 11169 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_fc_size/lenet_train_test_fcl3_fcn500.prototxt
I0408 13:23:59.591575 11169 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0408 13:23:59.591670 11169 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0408 13:23:59.591766 11169 layer_factory.hpp:77] Creating layer mnist
I0408 13:23:59.591814 11169 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0408 13:23:59.591826 11169 net.cpp:84] Creating Layer mnist
I0408 13:23:59.591831 11169 net.cpp:380] mnist -> data
I0408 13:23:59.591843 11169 net.cpp:380] mnist -> label
I0408 13:23:59.591931 11169 data_layer.cpp:45] output data size: 100,1,28,28
I0408 13:23:59.593633 11169 net.cpp:122] Setting up mnist
I0408 13:23:59.593653 11169 net.cpp:129] Top shape: 100 1 28 28 (78400)
I0408 13:23:59.593658 11169 net.cpp:129] Top shape: 100 (100)
I0408 13:23:59.593660 11169 net.cpp:137] Memory required for data: 314000
I0408 13:23:59.593678 11169 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0408 13:23:59.593690 11169 net.cpp:84] Creating Layer label_mnist_1_split
I0408 13:23:59.593695 11169 net.cpp:406] label_mnist_1_split <- label
I0408 13:23:59.593701 11169 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_0
I0408 13:23:59.593717 11169 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_1
I0408 13:23:59.593791 11169 net.cpp:122] Setting up label_mnist_1_split
I0408 13:23:59.593809 11169 net.cpp:129] Top shape: 100 (100)
I0408 13:23:59.593813 11169 net.cpp:129] Top shape: 100 (100)
I0408 13:23:59.593816 11169 net.cpp:137] Memory required for data: 314800
I0408 13:23:59.593818 11169 layer_factory.hpp:77] Creating layer conv0
I0408 13:23:59.593844 11169 net.cpp:84] Creating Layer conv0
I0408 13:23:59.593847 11169 net.cpp:406] conv0 <- data
I0408 13:23:59.593854 11169 net.cpp:380] conv0 -> conv0
I0408 13:23:59.594075 11169 net.cpp:122] Setting up conv0
I0408 13:23:59.594082 11169 net.cpp:129] Top shape: 100 50 24 24 (2880000)
I0408 13:23:59.594085 11169 net.cpp:137] Memory required for data: 11834800
I0408 13:23:59.594095 11169 layer_factory.hpp:77] Creating layer pool0
I0408 13:23:59.594101 11169 net.cpp:84] Creating Layer pool0
I0408 13:23:59.594105 11169 net.cpp:406] pool0 <- conv0
I0408 13:23:59.594112 11169 net.cpp:380] pool0 -> pool0
I0408 13:23:59.594142 11169 net.cpp:122] Setting up pool0
I0408 13:23:59.594149 11169 net.cpp:129] Top shape: 100 50 12 12 (720000)
I0408 13:23:59.594154 11169 net.cpp:137] Memory required for data: 14714800
I0408 13:23:59.594157 11169 layer_factory.hpp:77] Creating layer conv1
I0408 13:23:59.594166 11169 net.cpp:84] Creating Layer conv1
I0408 13:23:59.594169 11169 net.cpp:406] conv1 <- pool0
I0408 13:23:59.594177 11169 net.cpp:380] conv1 -> conv1
I0408 13:23:59.594647 11169 net.cpp:122] Setting up conv1
I0408 13:23:59.594653 11169 net.cpp:129] Top shape: 100 50 8 8 (320000)
I0408 13:23:59.594657 11169 net.cpp:137] Memory required for data: 15994800
I0408 13:23:59.594666 11169 layer_factory.hpp:77] Creating layer pool1
I0408 13:23:59.594673 11169 net.cpp:84] Creating Layer pool1
I0408 13:23:59.594677 11169 net.cpp:406] pool1 <- conv1
I0408 13:23:59.594682 11169 net.cpp:380] pool1 -> pool1
I0408 13:23:59.594728 11169 net.cpp:122] Setting up pool1
I0408 13:23:59.594735 11169 net.cpp:129] Top shape: 100 50 4 4 (80000)
I0408 13:23:59.594738 11169 net.cpp:137] Memory required for data: 16314800
I0408 13:23:59.594741 11169 layer_factory.hpp:77] Creating layer ip1
I0408 13:23:59.594748 11169 net.cpp:84] Creating Layer ip1
I0408 13:23:59.594751 11169 net.cpp:406] ip1 <- pool1
I0408 13:23:59.594758 11169 net.cpp:380] ip1 -> ip1
I0408 13:23:59.597286 11169 net.cpp:122] Setting up ip1
I0408 13:23:59.597307 11169 net.cpp:129] Top shape: 100 500 (50000)
I0408 13:23:59.597311 11169 net.cpp:137] Memory required for data: 16514800
I0408 13:23:59.597339 11169 layer_factory.hpp:77] Creating layer relu1
I0408 13:23:59.597365 11169 net.cpp:84] Creating Layer relu1
I0408 13:23:59.597369 11169 net.cpp:406] relu1 <- ip1
I0408 13:23:59.597393 11169 net.cpp:367] relu1 -> ip1 (in-place)
I0408 13:23:59.597400 11169 net.cpp:122] Setting up relu1
I0408 13:23:59.597405 11169 net.cpp:129] Top shape: 100 500 (50000)
I0408 13:23:59.597409 11169 net.cpp:137] Memory required for data: 16714800
I0408 13:23:59.597411 11169 layer_factory.hpp:77] Creating layer ip2
I0408 13:23:59.597421 11169 net.cpp:84] Creating Layer ip2
I0408 13:23:59.597424 11169 net.cpp:406] ip2 <- ip1
I0408 13:23:59.597430 11169 net.cpp:380] ip2 -> ip2
I0408 13:23:59.599022 11169 net.cpp:122] Setting up ip2
I0408 13:23:59.599030 11169 net.cpp:129] Top shape: 100 500 (50000)
I0408 13:23:59.599033 11169 net.cpp:137] Memory required for data: 16914800
I0408 13:23:59.599040 11169 layer_factory.hpp:77] Creating layer relu2
I0408 13:23:59.599047 11169 net.cpp:84] Creating Layer relu2
I0408 13:23:59.599051 11169 net.cpp:406] relu2 <- ip2
I0408 13:23:59.599057 11169 net.cpp:367] relu2 -> ip2 (in-place)
I0408 13:23:59.599063 11169 net.cpp:122] Setting up relu2
I0408 13:23:59.599069 11169 net.cpp:129] Top shape: 100 500 (50000)
I0408 13:23:59.599072 11169 net.cpp:137] Memory required for data: 17114800
I0408 13:23:59.599076 11169 layer_factory.hpp:77] Creating layer ip3
I0408 13:23:59.599081 11169 net.cpp:84] Creating Layer ip3
I0408 13:23:59.599086 11169 net.cpp:406] ip3 <- ip2
I0408 13:23:59.599092 11169 net.cpp:380] ip3 -> ip3
I0408 13:23:59.599190 11169 net.cpp:122] Setting up ip3
I0408 13:23:59.599195 11169 net.cpp:129] Top shape: 100 10 (1000)
I0408 13:23:59.599198 11169 net.cpp:137] Memory required for data: 17118800
I0408 13:23:59.599207 11169 layer_factory.hpp:77] Creating layer relu3
I0408 13:23:59.599212 11169 net.cpp:84] Creating Layer relu3
I0408 13:23:59.599215 11169 net.cpp:406] relu3 <- ip3
I0408 13:23:59.599221 11169 net.cpp:367] relu3 -> ip3 (in-place)
I0408 13:23:59.599227 11169 net.cpp:122] Setting up relu3
I0408 13:23:59.599231 11169 net.cpp:129] Top shape: 100 10 (1000)
I0408 13:23:59.599234 11169 net.cpp:137] Memory required for data: 17122800
I0408 13:23:59.599238 11169 layer_factory.hpp:77] Creating layer ip3_relu3_0_split
I0408 13:23:59.599246 11169 net.cpp:84] Creating Layer ip3_relu3_0_split
I0408 13:23:59.599249 11169 net.cpp:406] ip3_relu3_0_split <- ip3
I0408 13:23:59.599254 11169 net.cpp:380] ip3_relu3_0_split -> ip3_relu3_0_split_0
I0408 13:23:59.599263 11169 net.cpp:380] ip3_relu3_0_split -> ip3_relu3_0_split_1
I0408 13:23:59.599290 11169 net.cpp:122] Setting up ip3_relu3_0_split
I0408 13:23:59.599295 11169 net.cpp:129] Top shape: 100 10 (1000)
I0408 13:23:59.599299 11169 net.cpp:129] Top shape: 100 10 (1000)
I0408 13:23:59.599303 11169 net.cpp:137] Memory required for data: 17130800
I0408 13:23:59.599305 11169 layer_factory.hpp:77] Creating layer accuracy
I0408 13:23:59.599313 11169 net.cpp:84] Creating Layer accuracy
I0408 13:23:59.599316 11169 net.cpp:406] accuracy <- ip3_relu3_0_split_0
I0408 13:23:59.599321 11169 net.cpp:406] accuracy <- label_mnist_1_split_0
I0408 13:23:59.599328 11169 net.cpp:380] accuracy -> accuracy
I0408 13:23:59.599335 11169 net.cpp:122] Setting up accuracy
I0408 13:23:59.599340 11169 net.cpp:129] Top shape: (1)
I0408 13:23:59.599344 11169 net.cpp:137] Memory required for data: 17130804
I0408 13:23:59.599364 11169 layer_factory.hpp:77] Creating layer loss
I0408 13:23:59.599372 11169 net.cpp:84] Creating Layer loss
I0408 13:23:59.599375 11169 net.cpp:406] loss <- ip3_relu3_0_split_1
I0408 13:23:59.599380 11169 net.cpp:406] loss <- label_mnist_1_split_1
I0408 13:23:59.599385 11169 net.cpp:380] loss -> loss
I0408 13:23:59.599393 11169 layer_factory.hpp:77] Creating layer loss
I0408 13:23:59.599462 11169 net.cpp:122] Setting up loss
I0408 13:23:59.599467 11169 net.cpp:129] Top shape: (1)
I0408 13:23:59.599478 11169 net.cpp:132]     with loss weight 1
I0408 13:23:59.599488 11169 net.cpp:137] Memory required for data: 17130808
I0408 13:23:59.599490 11169 net.cpp:198] loss needs backward computation.
I0408 13:23:59.599496 11169 net.cpp:200] accuracy does not need backward computation.
I0408 13:23:59.599500 11169 net.cpp:198] ip3_relu3_0_split needs backward computation.
I0408 13:23:59.599504 11169 net.cpp:198] relu3 needs backward computation.
I0408 13:23:59.599508 11169 net.cpp:198] ip3 needs backward computation.
I0408 13:23:59.599510 11169 net.cpp:198] relu2 needs backward computation.
I0408 13:23:59.599514 11169 net.cpp:198] ip2 needs backward computation.
I0408 13:23:59.599516 11169 net.cpp:198] relu1 needs backward computation.
I0408 13:23:59.599519 11169 net.cpp:198] ip1 needs backward computation.
I0408 13:23:59.599524 11169 net.cpp:198] pool1 needs backward computation.
I0408 13:23:59.599526 11169 net.cpp:198] conv1 needs backward computation.
I0408 13:23:59.599529 11169 net.cpp:198] pool0 needs backward computation.
I0408 13:23:59.599532 11169 net.cpp:198] conv0 needs backward computation.
I0408 13:23:59.599537 11169 net.cpp:200] label_mnist_1_split does not need backward computation.
I0408 13:23:59.599541 11169 net.cpp:200] mnist does not need backward computation.
I0408 13:23:59.599545 11169 net.cpp:242] This network produces output accuracy
I0408 13:23:59.599548 11169 net.cpp:242] This network produces output loss
I0408 13:23:59.599561 11169 net.cpp:255] Network initialization done.
I0408 13:23:59.599601 11169 solver.cpp:56] Solver scaffolding done.
I0408 13:23:59.599851 11169 caffe.cpp:248] Starting Optimization
I0408 13:23:59.599856 11169 solver.cpp:273] Solving LeNet
I0408 13:23:59.599860 11169 solver.cpp:274] Learning Rate Policy: inv
I0408 13:23:59.600916 11169 solver.cpp:331] Iteration 0, Testing net (#0)
I0408 13:24:06.951150 11177 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:24:07.270009 11169 solver.cpp:398]     Test net output #0: accuracy = 0.109
I0408 13:24:07.270032 11169 solver.cpp:398]     Test net output #1: loss = 2.30147 (* 1 = 2.30147 loss)
I0408 13:24:07.377326 11169 solver.cpp:219] Iteration 0 (-2.54762e-12 iter/s, 7.7776s/100 iters), loss = 2.31196
I0408 13:24:07.377355 11169 solver.cpp:238]     Train net output #0: loss = 2.31196 (* 1 = 2.31196 loss)
I0408 13:24:07.377388 11169 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0408 13:24:16.888983 11169 solver.cpp:219] Iteration 100 (10.5132 iter/s, 9.51181s/100 iters), loss = 0.606809
I0408 13:24:16.889016 11169 solver.cpp:238]     Train net output #0: loss = 0.606809 (* 1 = 0.606809 loss)
I0408 13:24:16.889044 11169 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0408 13:24:26.399585 11169 solver.cpp:219] Iteration 200 (10.5144 iter/s, 9.51075s/100 iters), loss = 0.325742
I0408 13:24:26.399619 11169 solver.cpp:238]     Train net output #0: loss = 0.325742 (* 1 = 0.325742 loss)
I0408 13:24:26.399626 11169 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0408 13:24:35.918293 11169 solver.cpp:219] Iteration 300 (10.5055 iter/s, 9.51886s/100 iters), loss = 0.191764
I0408 13:24:35.918349 11169 solver.cpp:238]     Train net output #0: loss = 0.191764 (* 1 = 0.191764 loss)
I0408 13:24:35.918373 11169 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0408 13:24:45.423858 11169 solver.cpp:219] Iteration 400 (10.52 iter/s, 9.50569s/100 iters), loss = 0.0899145
I0408 13:24:45.423889 11169 solver.cpp:238]     Train net output #0: loss = 0.0899145 (* 1 = 0.0899145 loss)
I0408 13:24:45.423895 11169 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0408 13:24:54.784332 11169 solver.cpp:331] Iteration 500, Testing net (#0)
I0408 13:25:02.175572 11177 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:25:02.493341 11169 solver.cpp:398]     Test net output #0: accuracy = 0.9744
I0408 13:25:02.493366 11169 solver.cpp:398]     Test net output #1: loss = 0.0811372 (* 1 = 0.0811372 loss)
I0408 13:25:02.602048 11169 solver.cpp:219] Iteration 500 (5.82123 iter/s, 17.1785s/100 iters), loss = 0.113684
I0408 13:25:02.602077 11169 solver.cpp:238]     Train net output #0: loss = 0.113684 (* 1 = 0.113684 loss)
I0408 13:25:02.602102 11169 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0408 13:25:12.102705 11169 solver.cpp:219] Iteration 600 (10.5254 iter/s, 9.50081s/100 iters), loss = 0.111089
I0408 13:25:12.102916 11169 solver.cpp:238]     Train net output #0: loss = 0.111089 (* 1 = 0.111089 loss)
I0408 13:25:12.102923 11169 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0408 13:25:21.613440 11169 solver.cpp:219] Iteration 700 (10.5145 iter/s, 9.5107s/100 iters), loss = 0.0906175
I0408 13:25:21.613468 11169 solver.cpp:238]     Train net output #0: loss = 0.0906175 (* 1 = 0.0906175 loss)
I0408 13:25:21.613473 11169 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0408 13:25:31.132491 11169 solver.cpp:219] Iteration 800 (10.5051 iter/s, 9.51919s/100 iters), loss = 0.247613
I0408 13:25:31.132524 11169 solver.cpp:238]     Train net output #0: loss = 0.247613 (* 1 = 0.247613 loss)
I0408 13:25:31.132546 11169 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0408 13:25:40.651793 11169 solver.cpp:219] Iteration 900 (10.5048 iter/s, 9.51943s/100 iters), loss = 0.108324
I0408 13:25:40.651837 11169 solver.cpp:238]     Train net output #0: loss = 0.108324 (* 1 = 0.108324 loss)
I0408 13:25:40.651842 11169 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0408 13:25:43.804250 11176 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:25:50.036336 11169 solver.cpp:331] Iteration 1000, Testing net (#0)
I0408 13:25:57.410611 11177 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:25:57.727464 11169 solver.cpp:398]     Test net output #0: accuracy = 0.9824
I0408 13:25:57.727505 11169 solver.cpp:398]     Test net output #1: loss = 0.0548365 (* 1 = 0.0548365 loss)
I0408 13:25:57.836002 11169 solver.cpp:219] Iteration 1000 (5.81921 iter/s, 17.1845s/100 iters), loss = 0.0775183
I0408 13:25:57.836033 11169 solver.cpp:238]     Train net output #0: loss = 0.0775183 (* 1 = 0.0775183 loss)
I0408 13:25:57.836057 11169 sgd_solver.cpp:105] Iteration 1000, lr = 0.00931012
I0408 13:26:07.359638 11169 solver.cpp:219] Iteration 1100 (10.5001 iter/s, 9.52376s/100 iters), loss = 0.00482361
I0408 13:26:07.359668 11169 solver.cpp:238]     Train net output #0: loss = 0.00482362 (* 1 = 0.00482362 loss)
I0408 13:26:07.359673 11169 sgd_solver.cpp:105] Iteration 1100, lr = 0.00924715
I0408 13:26:16.903741 11169 solver.cpp:219] Iteration 1200 (10.4775 iter/s, 9.54422s/100 iters), loss = 0.0340094
I0408 13:26:16.903820 11169 solver.cpp:238]     Train net output #0: loss = 0.0340094 (* 1 = 0.0340094 loss)
I0408 13:26:16.903830 11169 sgd_solver.cpp:105] Iteration 1200, lr = 0.00918515
I0408 13:26:26.418582 11169 solver.cpp:219] Iteration 1300 (10.5098 iter/s, 9.51491s/100 iters), loss = 0.0110699
I0408 13:26:26.418612 11169 solver.cpp:238]     Train net output #0: loss = 0.0110699 (* 1 = 0.0110699 loss)
I0408 13:26:26.418637 11169 sgd_solver.cpp:105] Iteration 1300, lr = 0.00912412
I0408 13:26:35.914669 11169 solver.cpp:219] Iteration 1400 (10.5305 iter/s, 9.49621s/100 iters), loss = 0.00429734
I0408 13:26:35.914696 11169 solver.cpp:238]     Train net output #0: loss = 0.00429732 (* 1 = 0.00429732 loss)
I0408 13:26:35.914719 11169 sgd_solver.cpp:105] Iteration 1400, lr = 0.00906403
I0408 13:26:45.288844 11169 solver.cpp:331] Iteration 1500, Testing net (#0)
I0408 13:26:52.716887 11177 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:26:53.034236 11169 solver.cpp:398]     Test net output #0: accuracy = 0.9841
I0408 13:26:53.034277 11169 solver.cpp:398]     Test net output #1: loss = 0.0452464 (* 1 = 0.0452464 loss)
I0408 13:26:53.138474 11169 solver.cpp:219] Iteration 1500 (5.80584 iter/s, 17.224s/100 iters), loss = 0.0773823
I0408 13:26:53.138521 11169 solver.cpp:238]     Train net output #0: loss = 0.0773822 (* 1 = 0.0773822 loss)
I0408 13:26:53.138528 11169 sgd_solver.cpp:105] Iteration 1500, lr = 0.00900485
I0408 13:27:02.642704 11169 solver.cpp:219] Iteration 1600 (10.5215 iter/s, 9.50432s/100 iters), loss = 0.10047
I0408 13:27:02.642731 11169 solver.cpp:238]     Train net output #0: loss = 0.10047 (* 1 = 0.10047 loss)
I0408 13:27:02.642736 11169 sgd_solver.cpp:105] Iteration 1600, lr = 0.00894657
I0408 13:27:12.170671 11169 solver.cpp:219] Iteration 1700 (10.4953 iter/s, 9.52808s/100 iters), loss = 0.0202052
I0408 13:27:12.170742 11169 solver.cpp:238]     Train net output #0: loss = 0.0202051 (* 1 = 0.0202051 loss)
I0408 13:27:12.170766 11169 sgd_solver.cpp:105] Iteration 1700, lr = 0.00888916
I0408 13:27:21.683626 11169 solver.cpp:219] Iteration 1800 (10.5119 iter/s, 9.51302s/100 iters), loss = 0.0281197
I0408 13:27:21.683655 11169 solver.cpp:238]     Train net output #0: loss = 0.0281197 (* 1 = 0.0281197 loss)
I0408 13:27:21.683660 11169 sgd_solver.cpp:105] Iteration 1800, lr = 0.0088326
I0408 13:27:28.355909 11176 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:27:31.215170 11169 solver.cpp:219] Iteration 1900 (10.4914 iter/s, 9.53165s/100 iters), loss = 0.107334
I0408 13:27:31.215201 11169 solver.cpp:238]     Train net output #0: loss = 0.107334 (* 1 = 0.107334 loss)
I0408 13:27:31.215207 11169 sgd_solver.cpp:105] Iteration 1900, lr = 0.00877687
I0408 13:27:40.598155 11169 solver.cpp:331] Iteration 2000, Testing net (#0)
I0408 13:27:47.970773 11177 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:27:48.282543 11169 solver.cpp:398]     Test net output #0: accuracy = 0.985
I0408 13:27:48.282585 11169 solver.cpp:398]     Test net output #1: loss = 0.0461384 (* 1 = 0.0461384 loss)
I0408 13:27:48.388797 11169 solver.cpp:219] Iteration 2000 (5.82281 iter/s, 17.1738s/100 iters), loss = 0.00763629
I0408 13:27:48.388844 11169 solver.cpp:238]     Train net output #0: loss = 0.00763626 (* 1 = 0.00763626 loss)
I0408 13:27:48.388850 11169 sgd_solver.cpp:105] Iteration 2000, lr = 0.00872196
I0408 13:27:57.897706 11169 solver.cpp:219] Iteration 2100 (10.5164 iter/s, 9.50899s/100 iters), loss = 0.0367251
I0408 13:27:57.897735 11169 solver.cpp:238]     Train net output #0: loss = 0.0367251 (* 1 = 0.0367251 loss)
I0408 13:27:57.897742 11169 sgd_solver.cpp:105] Iteration 2100, lr = 0.00866784
I0408 13:28:07.429297 11169 solver.cpp:219] Iteration 2200 (10.4913 iter/s, 9.53169s/100 iters), loss = 0.0161651
I0408 13:28:07.429410 11169 solver.cpp:238]     Train net output #0: loss = 0.0161651 (* 1 = 0.0161651 loss)
I0408 13:28:07.429416 11169 sgd_solver.cpp:105] Iteration 2200, lr = 0.0086145
I0408 13:28:16.965693 11169 solver.cpp:219] Iteration 2300 (10.4861 iter/s, 9.53641s/100 iters), loss = 0.115528
I0408 13:28:16.965744 11169 solver.cpp:238]     Train net output #0: loss = 0.115528 (* 1 = 0.115528 loss)
I0408 13:28:16.965749 11169 sgd_solver.cpp:105] Iteration 2300, lr = 0.00856192
I0408 13:28:26.498214 11169 solver.cpp:219] Iteration 2400 (10.4903 iter/s, 9.53259s/100 iters), loss = 0.0170964
I0408 13:28:26.498242 11169 solver.cpp:238]     Train net output #0: loss = 0.0170964 (* 1 = 0.0170964 loss)
I0408 13:28:26.498246 11169 sgd_solver.cpp:105] Iteration 2400, lr = 0.00851008
I0408 13:28:35.884986 11169 solver.cpp:331] Iteration 2500, Testing net (#0)
I0408 13:28:43.267376 11177 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:28:43.635790 11169 solver.cpp:398]     Test net output #0: accuracy = 0.9858
I0408 13:28:43.635814 11169 solver.cpp:398]     Test net output #1: loss = 0.0427849 (* 1 = 0.0427849 loss)
I0408 13:28:43.742096 11169 solver.cpp:219] Iteration 2500 (5.79909 iter/s, 17.2441s/100 iters), loss = 0.0316156
I0408 13:28:43.742123 11169 solver.cpp:238]     Train net output #0: loss = 0.0316157 (* 1 = 0.0316157 loss)
I0408 13:28:43.742147 11169 sgd_solver.cpp:105] Iteration 2500, lr = 0.00845897
I0408 13:28:53.283815 11169 solver.cpp:219] Iteration 2600 (10.4802 iter/s, 9.54181s/100 iters), loss = 0.0384722
I0408 13:28:53.283843 11169 solver.cpp:238]     Train net output #0: loss = 0.0384723 (* 1 = 0.0384723 loss)
I0408 13:28:53.283849 11169 sgd_solver.cpp:105] Iteration 2600, lr = 0.00840857
I0408 13:29:02.834905 11169 solver.cpp:219] Iteration 2700 (10.4699 iter/s, 9.55118s/100 iters), loss = 0.0886806
I0408 13:29:02.834933 11169 solver.cpp:238]     Train net output #0: loss = 0.0886806 (* 1 = 0.0886806 loss)
I0408 13:29:02.834939 11169 sgd_solver.cpp:105] Iteration 2700, lr = 0.00835886
I0408 13:29:12.398757 11169 solver.cpp:219] Iteration 2800 (10.4559 iter/s, 9.56394s/100 iters), loss = 0.000850129
I0408 13:29:12.398804 11169 solver.cpp:238]     Train net output #0: loss = 0.000850206 (* 1 = 0.000850206 loss)
I0408 13:29:12.398809 11169 sgd_solver.cpp:105] Iteration 2800, lr = 0.00830984
I0408 13:29:13.166601 11176 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:29:22.123335 11169 solver.cpp:219] Iteration 2900 (10.2832 iter/s, 9.72464s/100 iters), loss = 0.0125479
I0408 13:29:22.123507 11169 solver.cpp:238]     Train net output #0: loss = 0.012548 (* 1 = 0.012548 loss)
I0408 13:29:22.123529 11169 sgd_solver.cpp:105] Iteration 2900, lr = 0.00826148
I0408 13:29:31.653118 11169 solver.cpp:331] Iteration 3000, Testing net (#0)
I0408 13:29:39.474555 11177 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:29:39.797976 11169 solver.cpp:398]     Test net output #0: accuracy = 0.9875
I0408 13:29:39.797999 11169 solver.cpp:398]     Test net output #1: loss = 0.0395655 (* 1 = 0.0395655 loss)
I0408 13:29:39.904580 11169 solver.cpp:219] Iteration 3000 (5.62389 iter/s, 17.7813s/100 iters), loss = 0.00618055
I0408 13:29:39.904636 11169 solver.cpp:238]     Train net output #0: loss = 0.00618065 (* 1 = 0.00618065 loss)
I0408 13:29:39.904644 11169 sgd_solver.cpp:105] Iteration 3000, lr = 0.00821377
I0408 13:29:49.457617 11169 solver.cpp:219] Iteration 3100 (10.4678 iter/s, 9.55309s/100 iters), loss = 0.0101897
I0408 13:29:49.457646 11169 solver.cpp:238]     Train net output #0: loss = 0.0101898 (* 1 = 0.0101898 loss)
I0408 13:29:49.457651 11169 sgd_solver.cpp:105] Iteration 3100, lr = 0.0081667
I0408 13:29:58.991781 11169 solver.cpp:219] Iteration 3200 (10.4885 iter/s, 9.53424s/100 iters), loss = 0.00323111
I0408 13:29:58.991876 11169 solver.cpp:238]     Train net output #0: loss = 0.00323123 (* 1 = 0.00323123 loss)
I0408 13:29:58.991883 11169 sgd_solver.cpp:105] Iteration 3200, lr = 0.00812025
I0408 13:30:08.531752 11169 solver.cpp:219] Iteration 3300 (10.4822 iter/s, 9.53998s/100 iters), loss = 0.0101705
I0408 13:30:08.531780 11169 solver.cpp:238]     Train net output #0: loss = 0.0101706 (* 1 = 0.0101706 loss)
I0408 13:30:08.531785 11169 sgd_solver.cpp:105] Iteration 3300, lr = 0.00807442
I0408 13:30:18.219265 11169 solver.cpp:219] Iteration 3400 (10.3225 iter/s, 9.68759s/100 iters), loss = 0.00892678
I0408 13:30:18.219295 11169 solver.cpp:238]     Train net output #0: loss = 0.00892691 (* 1 = 0.00892691 loss)
I0408 13:30:18.219317 11169 sgd_solver.cpp:105] Iteration 3400, lr = 0.00802918
I0408 13:30:27.729671 11169 solver.cpp:331] Iteration 3500, Testing net (#0)
I0408 13:30:36.474520 11177 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:30:36.856099 11169 solver.cpp:398]     Test net output #0: accuracy = 0.9884
I0408 13:30:36.856125 11169 solver.cpp:398]     Test net output #1: loss = 0.0347143 (* 1 = 0.0347143 loss)
I0408 13:30:36.978904 11169 solver.cpp:219] Iteration 3500 (5.33055 iter/s, 18.7598s/100 iters), loss = 0.00404793
I0408 13:30:36.978958 11169 solver.cpp:238]     Train net output #0: loss = 0.00404806 (* 1 = 0.00404806 loss)
I0408 13:30:36.978965 11169 sgd_solver.cpp:105] Iteration 3500, lr = 0.00798454
I0408 13:30:47.127593 11169 solver.cpp:219] Iteration 3600 (9.85342 iter/s, 10.1488s/100 iters), loss = 0.0376002
I0408 13:30:47.127640 11169 solver.cpp:238]     Train net output #0: loss = 0.0376003 (* 1 = 0.0376003 loss)
I0408 13:30:47.127646 11169 sgd_solver.cpp:105] Iteration 3600, lr = 0.00794046
I0408 13:30:56.690446 11169 solver.cpp:219] Iteration 3700 (10.4571 iter/s, 9.5629s/100 iters), loss = 0.00831127
I0408 13:30:56.690495 11169 solver.cpp:238]     Train net output #0: loss = 0.00831134 (* 1 = 0.00831134 loss)
I0408 13:30:56.690501 11169 sgd_solver.cpp:105] Iteration 3700, lr = 0.00789695
I0408 13:31:01.008841 11176 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:31:06.286686 11169 solver.cpp:219] Iteration 3800 (10.4207 iter/s, 9.59629s/100 iters), loss = 0.0183669
I0408 13:31:06.286717 11169 solver.cpp:238]     Train net output #0: loss = 0.018367 (* 1 = 0.018367 loss)
I0408 13:31:06.286722 11169 sgd_solver.cpp:105] Iteration 3800, lr = 0.007854
I0408 13:31:16.069661 11169 solver.cpp:219] Iteration 3900 (10.2218 iter/s, 9.78304s/100 iters), loss = 0.0208165
I0408 13:31:16.069846 11169 solver.cpp:238]     Train net output #0: loss = 0.0208166 (* 1 = 0.0208166 loss)
I0408 13:31:16.069852 11169 sgd_solver.cpp:105] Iteration 3900, lr = 0.00781158
I0408 13:31:25.653210 11169 solver.cpp:331] Iteration 4000, Testing net (#0)
I0408 13:31:33.034282 11177 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:31:33.345163 11169 solver.cpp:398]     Test net output #0: accuracy = 0.9899
I0408 13:31:33.345188 11169 solver.cpp:398]     Test net output #1: loss = 0.0276143 (* 1 = 0.0276143 loss)
I0408 13:31:33.457152 11169 solver.cpp:219] Iteration 4000 (5.75126 iter/s, 17.3875s/100 iters), loss = 0.00483635
I0408 13:31:33.457182 11169 solver.cpp:238]     Train net output #0: loss = 0.00483648 (* 1 = 0.00483648 loss)
I0408 13:31:33.457190 11169 sgd_solver.cpp:105] Iteration 4000, lr = 0.0077697
I0408 13:31:42.983419 11169 solver.cpp:219] Iteration 4100 (10.4972 iter/s, 9.52632s/100 iters), loss = 0.0122814
I0408 13:31:42.983449 11169 solver.cpp:238]     Train net output #0: loss = 0.0122816 (* 1 = 0.0122816 loss)
I0408 13:31:42.983455 11169 sgd_solver.cpp:105] Iteration 4100, lr = 0.00772833
I0408 13:31:52.553750 11169 solver.cpp:219] Iteration 4200 (10.4489 iter/s, 9.57038s/100 iters), loss = 0.00560207
I0408 13:31:52.553954 11169 solver.cpp:238]     Train net output #0: loss = 0.00560222 (* 1 = 0.00560222 loss)
I0408 13:31:52.553961 11169 sgd_solver.cpp:105] Iteration 4200, lr = 0.00768748
I0408 13:32:02.102663 11169 solver.cpp:219] Iteration 4300 (10.4725 iter/s, 9.54879s/100 iters), loss = 0.0522424
I0408 13:32:02.102712 11169 solver.cpp:238]     Train net output #0: loss = 0.0522426 (* 1 = 0.0522426 loss)
I0408 13:32:02.102718 11169 sgd_solver.cpp:105] Iteration 4300, lr = 0.00764712
I0408 13:32:11.626680 11169 solver.cpp:219] Iteration 4400 (10.4997 iter/s, 9.52405s/100 iters), loss = 0.0134965
I0408 13:32:11.626708 11169 solver.cpp:238]     Train net output #0: loss = 0.0134966 (* 1 = 0.0134966 loss)
I0408 13:32:11.626713 11169 sgd_solver.cpp:105] Iteration 4400, lr = 0.00760726
I0408 13:32:20.959761 11169 solver.cpp:331] Iteration 4500, Testing net (#0)
I0408 13:32:28.266644 11177 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:32:28.578765 11169 solver.cpp:398]     Test net output #0: accuracy = 0.9891
I0408 13:32:28.578789 11169 solver.cpp:398]     Test net output #1: loss = 0.0329824 (* 1 = 0.0329824 loss)
I0408 13:32:28.683437 11169 solver.cpp:219] Iteration 4500 (5.86274 iter/s, 17.0569s/100 iters), loss = 0.00318683
I0408 13:32:28.683465 11169 solver.cpp:238]     Train net output #0: loss = 0.00318697 (* 1 = 0.00318697 loss)
I0408 13:32:28.683490 11169 sgd_solver.cpp:105] Iteration 4500, lr = 0.00756788
I0408 13:32:38.117664 11169 solver.cpp:219] Iteration 4600 (10.5996 iter/s, 9.43428s/100 iters), loss = 0.00901759
I0408 13:32:38.117712 11169 solver.cpp:238]     Train net output #0: loss = 0.00901774 (* 1 = 0.00901774 loss)
I0408 13:32:38.117717 11169 sgd_solver.cpp:105] Iteration 4600, lr = 0.00752897
I0408 13:32:45.990739 11176 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:32:47.608281 11169 solver.cpp:219] Iteration 4700 (10.5367 iter/s, 9.49065s/100 iters), loss = 0.00289311
I0408 13:32:47.608328 11169 solver.cpp:238]     Train net output #0: loss = 0.00289323 (* 1 = 0.00289323 loss)
I0408 13:32:47.608332 11169 sgd_solver.cpp:105] Iteration 4700, lr = 0.00749052
I0408 13:32:57.063380 11169 solver.cpp:219] Iteration 4800 (10.5763 iter/s, 9.45513s/100 iters), loss = 0.0139519
I0408 13:32:57.063410 11169 solver.cpp:238]     Train net output #0: loss = 0.013952 (* 1 = 0.013952 loss)
I0408 13:32:57.063432 11169 sgd_solver.cpp:105] Iteration 4800, lr = 0.00745253
I0408 13:33:06.534330 11169 solver.cpp:219] Iteration 4900 (10.5586 iter/s, 9.47099s/100 iters), loss = 0.00411177
I0408 13:33:06.534561 11169 solver.cpp:238]     Train net output #0: loss = 0.00411192 (* 1 = 0.00411192 loss)
I0408 13:33:06.534581 11169 sgd_solver.cpp:105] Iteration 4900, lr = 0.00741498
I0408 13:33:15.853942 11169 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_5000.caffemodel
I0408 13:33:15.918517 11169 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_5000.solverstate
I0408 13:33:15.922545 11169 solver.cpp:331] Iteration 5000, Testing net (#0)
I0408 13:33:23.194541 11177 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:33:23.508601 11169 solver.cpp:398]     Test net output #0: accuracy = 0.9901
I0408 13:33:23.508625 11169 solver.cpp:398]     Test net output #1: loss = 0.0308326 (* 1 = 0.0308326 loss)
I0408 13:33:23.614961 11169 solver.cpp:219] Iteration 5000 (5.85462 iter/s, 17.0805s/100 iters), loss = 0.019648
I0408 13:33:23.614989 11169 solver.cpp:238]     Train net output #0: loss = 0.0196482 (* 1 = 0.0196482 loss)
I0408 13:33:23.614995 11169 sgd_solver.cpp:105] Iteration 5000, lr = 0.00737788
I0408 13:33:33.103381 11169 solver.cpp:219] Iteration 5100 (10.5391 iter/s, 9.48847s/100 iters), loss = 0.0143947
I0408 13:33:33.103430 11169 solver.cpp:238]     Train net output #0: loss = 0.0143948 (* 1 = 0.0143948 loss)
I0408 13:33:33.103435 11169 sgd_solver.cpp:105] Iteration 5100, lr = 0.0073412
I0408 13:33:42.585108 11169 solver.cpp:219] Iteration 5200 (10.5466 iter/s, 9.48175s/100 iters), loss = 0.00397314
I0408 13:33:42.585273 11169 solver.cpp:238]     Train net output #0: loss = 0.00397327 (* 1 = 0.00397327 loss)
I0408 13:33:42.585280 11169 sgd_solver.cpp:105] Iteration 5200, lr = 0.00730495
I0408 13:33:52.042408 11169 solver.cpp:219] Iteration 5300 (10.5739 iter/s, 9.45722s/100 iters), loss = 0.00078522
I0408 13:33:52.042471 11169 solver.cpp:238]     Train net output #0: loss = 0.000785371 (* 1 = 0.000785371 loss)
I0408 13:33:52.042476 11169 sgd_solver.cpp:105] Iteration 5300, lr = 0.00726911
I0408 13:34:01.499591 11169 solver.cpp:219] Iteration 5400 (10.574 iter/s, 9.4572s/100 iters), loss = 0.00909277
I0408 13:34:01.499621 11169 solver.cpp:238]     Train net output #0: loss = 0.00909292 (* 1 = 0.00909292 loss)
I0408 13:34:01.499627 11169 sgd_solver.cpp:105] Iteration 5400, lr = 0.00723368
I0408 13:34:10.817196 11169 solver.cpp:331] Iteration 5500, Testing net (#0)
I0408 13:34:18.152119 11177 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:34:18.464251 11169 solver.cpp:398]     Test net output #0: accuracy = 0.99
I0408 13:34:18.464293 11169 solver.cpp:398]     Test net output #1: loss = 0.0327225 (* 1 = 0.0327225 loss)
I0408 13:34:18.570966 11169 solver.cpp:219] Iteration 5500 (5.85773 iter/s, 17.0715s/100 iters), loss = 0.00437085
I0408 13:34:18.571012 11169 solver.cpp:238]     Train net output #0: loss = 0.00437099 (* 1 = 0.00437099 loss)
I0408 13:34:18.571035 11169 sgd_solver.cpp:105] Iteration 5500, lr = 0.00719865
I0408 13:34:28.033074 11169 solver.cpp:219] Iteration 5600 (10.5685 iter/s, 9.46212s/100 iters), loss = 0.000386017
I0408 13:34:28.033103 11169 solver.cpp:238]     Train net output #0: loss = 0.000386143 (* 1 = 0.000386143 loss)
I0408 13:34:28.033108 11169 sgd_solver.cpp:105] Iteration 5600, lr = 0.00716402
I0408 13:34:29.933260 11176 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:34:37.498493 11169 solver.cpp:219] Iteration 5700 (10.5647 iter/s, 9.46545s/100 iters), loss = 0.00242078
I0408 13:34:37.498522 11169 solver.cpp:238]     Train net output #0: loss = 0.00242091 (* 1 = 0.00242091 loss)
I0408 13:34:37.498528 11169 sgd_solver.cpp:105] Iteration 5700, lr = 0.00712977
I0408 13:34:46.959676 11169 solver.cpp:219] Iteration 5800 (10.5695 iter/s, 9.46121s/100 iters), loss = 0.0227994
I0408 13:34:46.959707 11169 solver.cpp:238]     Train net output #0: loss = 0.0227995 (* 1 = 0.0227995 loss)
I0408 13:34:46.959713 11169 sgd_solver.cpp:105] Iteration 5800, lr = 0.0070959
I0408 13:34:56.421515 11169 solver.cpp:219] Iteration 5900 (10.5687 iter/s, 9.46187s/100 iters), loss = 0.0044307
I0408 13:34:56.421720 11169 solver.cpp:238]     Train net output #0: loss = 0.00443084 (* 1 = 0.00443084 loss)
I0408 13:34:56.421726 11169 sgd_solver.cpp:105] Iteration 5900, lr = 0.0070624
I0408 13:35:05.774328 11169 solver.cpp:331] Iteration 6000, Testing net (#0)
I0408 13:35:13.105614 11177 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:35:13.420900 11169 solver.cpp:398]     Test net output #0: accuracy = 0.9903
I0408 13:35:13.420925 11169 solver.cpp:398]     Test net output #1: loss = 0.0291064 (* 1 = 0.0291064 loss)
I0408 13:35:13.525583 11169 solver.cpp:219] Iteration 6000 (5.84659 iter/s, 17.104s/100 iters), loss = 0.00202982
I0408 13:35:13.525630 11169 solver.cpp:238]     Train net output #0: loss = 0.00202996 (* 1 = 0.00202996 loss)
I0408 13:35:13.525636 11169 sgd_solver.cpp:105] Iteration 6000, lr = 0.00702927
I0408 13:35:23.025017 11169 solver.cpp:219] Iteration 6100 (10.5269 iter/s, 9.49944s/100 iters), loss = 0.00167702
I0408 13:35:23.025063 11169 solver.cpp:238]     Train net output #0: loss = 0.00167717 (* 1 = 0.00167717 loss)
I0408 13:35:23.025081 11169 sgd_solver.cpp:105] Iteration 6100, lr = 0.0069965
I0408 13:35:32.507243 11169 solver.cpp:219] Iteration 6200 (10.546 iter/s, 9.48224s/100 iters), loss = 0.00412104
I0408 13:35:32.507460 11169 solver.cpp:238]     Train net output #0: loss = 0.00412119 (* 1 = 0.00412119 loss)
I0408 13:35:32.507467 11169 sgd_solver.cpp:105] Iteration 6200, lr = 0.00696408
I0408 13:35:41.985590 11169 solver.cpp:219] Iteration 6300 (10.5505 iter/s, 9.47819s/100 iters), loss = 0.00796486
I0408 13:35:41.985640 11169 solver.cpp:238]     Train net output #0: loss = 0.00796501 (* 1 = 0.00796501 loss)
I0408 13:35:41.985646 11169 sgd_solver.cpp:105] Iteration 6300, lr = 0.00693201
I0408 13:35:51.473440 11169 solver.cpp:219] Iteration 6400 (10.5398 iter/s, 9.48785s/100 iters), loss = 0.00414737
I0408 13:35:51.473467 11169 solver.cpp:238]     Train net output #0: loss = 0.00414752 (* 1 = 0.00414752 loss)
I0408 13:35:51.473472 11169 sgd_solver.cpp:105] Iteration 6400, lr = 0.00690029
I0408 13:36:00.954927 11169 solver.cpp:331] Iteration 6500, Testing net (#0)
I0408 13:36:08.678414 11177 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:36:09.000558 11169 solver.cpp:398]     Test net output #0: accuracy = 0.991
I0408 13:36:09.000600 11169 solver.cpp:398]     Test net output #1: loss = 0.0286939 (* 1 = 0.0286939 loss)
I0408 13:36:09.111953 11169 solver.cpp:219] Iteration 6500 (5.66939 iter/s, 17.6386s/100 iters), loss = 0.00587743
I0408 13:36:09.111999 11169 solver.cpp:238]     Train net output #0: loss = 0.0058776 (* 1 = 0.0058776 loss)
I0408 13:36:09.112005 11169 sgd_solver.cpp:105] Iteration 6500, lr = 0.0068689
I0408 13:36:14.942780 11176 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:36:19.126294 11169 solver.cpp:219] Iteration 6600 (9.98568 iter/s, 10.0143s/100 iters), loss = 0.0166364
I0408 13:36:19.126345 11169 solver.cpp:238]     Train net output #0: loss = 0.0166365 (* 1 = 0.0166365 loss)
I0408 13:36:19.126351 11169 sgd_solver.cpp:105] Iteration 6600, lr = 0.00683784
I0408 13:36:29.124338 11169 solver.cpp:219] Iteration 6700 (10.002 iter/s, 9.99803s/100 iters), loss = 0.00285271
I0408 13:36:29.124408 11169 solver.cpp:238]     Train net output #0: loss = 0.00285286 (* 1 = 0.00285286 loss)
I0408 13:36:29.124416 11169 sgd_solver.cpp:105] Iteration 6700, lr = 0.00680711
I0408 13:36:39.170867 11169 solver.cpp:219] Iteration 6800 (9.95507 iter/s, 10.0451s/100 iters), loss = 0.00581332
I0408 13:36:39.171073 11169 solver.cpp:238]     Train net output #0: loss = 0.00581347 (* 1 = 0.00581347 loss)
I0408 13:36:39.171082 11169 sgd_solver.cpp:105] Iteration 6800, lr = 0.0067767
I0408 13:36:49.108217 11169 solver.cpp:219] Iteration 6900 (10.0632 iter/s, 9.93719s/100 iters), loss = 0.00255353
I0408 13:36:49.108258 11169 solver.cpp:238]     Train net output #0: loss = 0.00255369 (* 1 = 0.00255369 loss)
I0408 13:36:49.108266 11169 sgd_solver.cpp:105] Iteration 6900, lr = 0.0067466
I0408 13:36:58.494139 11169 solver.cpp:331] Iteration 7000, Testing net (#0)
I0408 13:37:05.907644 11177 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:37:06.221779 11169 solver.cpp:398]     Test net output #0: accuracy = 0.9911
I0408 13:37:06.221804 11169 solver.cpp:398]     Test net output #1: loss = 0.027726 (* 1 = 0.027726 loss)
I0408 13:37:06.326158 11169 solver.cpp:219] Iteration 7000 (5.80788 iter/s, 17.218s/100 iters), loss = 0.00377631
I0408 13:37:06.326189 11169 solver.cpp:238]     Train net output #0: loss = 0.00377646 (* 1 = 0.00377646 loss)
I0408 13:37:06.326196 11169 sgd_solver.cpp:105] Iteration 7000, lr = 0.00671681
I0408 13:37:15.778900 11169 solver.cpp:219] Iteration 7100 (10.5789 iter/s, 9.45275s/100 iters), loss = 0.00904499
I0408 13:37:15.779028 11169 solver.cpp:238]     Train net output #0: loss = 0.00904515 (* 1 = 0.00904515 loss)
I0408 13:37:15.779034 11169 sgd_solver.cpp:105] Iteration 7100, lr = 0.00668733
I0408 13:37:25.234199 11169 solver.cpp:219] Iteration 7200 (10.5762 iter/s, 9.45521s/100 iters), loss = 0.00209119
I0408 13:37:25.234228 11169 solver.cpp:238]     Train net output #0: loss = 0.00209135 (* 1 = 0.00209135 loss)
I0408 13:37:25.234235 11169 sgd_solver.cpp:105] Iteration 7200, lr = 0.00665815
I0408 13:37:34.703495 11169 solver.cpp:219] Iteration 7300 (10.5604 iter/s, 9.46931s/100 iters), loss = 0.0170017
I0408 13:37:34.703527 11169 solver.cpp:238]     Train net output #0: loss = 0.0170018 (* 1 = 0.0170018 loss)
I0408 13:37:34.703533 11169 sgd_solver.cpp:105] Iteration 7300, lr = 0.00662927
I0408 13:37:44.171372 11169 solver.cpp:219] Iteration 7400 (10.562 iter/s, 9.46789s/100 iters), loss = 0.00311272
I0408 13:37:44.171402 11169 solver.cpp:238]     Train net output #0: loss = 0.00311286 (* 1 = 0.00311286 loss)
I0408 13:37:44.171407 11169 sgd_solver.cpp:105] Iteration 7400, lr = 0.00660067
I0408 13:37:53.165894 11176 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:37:53.515408 11169 solver.cpp:331] Iteration 7500, Testing net (#0)
I0408 13:38:00.857482 11177 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:38:01.177577 11169 solver.cpp:398]     Test net output #0: accuracy = 0.9898
I0408 13:38:01.177599 11169 solver.cpp:398]     Test net output #1: loss = 0.0318938 (* 1 = 0.0318938 loss)
I0408 13:38:01.284314 11169 solver.cpp:219] Iteration 7500 (5.84351 iter/s, 17.113s/100 iters), loss = 0.00120911
I0408 13:38:01.284346 11169 solver.cpp:238]     Train net output #0: loss = 0.00120924 (* 1 = 0.00120924 loss)
I0408 13:38:01.284353 11169 sgd_solver.cpp:105] Iteration 7500, lr = 0.00657236
I0408 13:38:10.742205 11169 solver.cpp:219] Iteration 7600 (10.5732 iter/s, 9.4579s/100 iters), loss = 0.00550711
I0408 13:38:10.742236 11169 solver.cpp:238]     Train net output #0: loss = 0.00550724 (* 1 = 0.00550724 loss)
I0408 13:38:10.742243 11169 sgd_solver.cpp:105] Iteration 7600, lr = 0.00654433
I0408 13:38:20.200743 11169 solver.cpp:219] Iteration 7700 (10.5725 iter/s, 9.45854s/100 iters), loss = 0.0206608
I0408 13:38:20.200774 11169 solver.cpp:238]     Train net output #0: loss = 0.020661 (* 1 = 0.020661 loss)
I0408 13:38:20.200780 11169 sgd_solver.cpp:105] Iteration 7700, lr = 0.00651658
I0408 13:38:29.654654 11169 solver.cpp:219] Iteration 7800 (10.5776 iter/s, 9.45392s/100 iters), loss = 0.00182383
I0408 13:38:29.654793 11169 solver.cpp:238]     Train net output #0: loss = 0.00182395 (* 1 = 0.00182395 loss)
I0408 13:38:29.654799 11169 sgd_solver.cpp:105] Iteration 7800, lr = 0.00648911
I0408 13:38:39.119376 11169 solver.cpp:219] Iteration 7900 (10.5657 iter/s, 9.46463s/100 iters), loss = 0.00176412
I0408 13:38:39.119421 11169 solver.cpp:238]     Train net output #0: loss = 0.00176424 (* 1 = 0.00176424 loss)
I0408 13:38:39.119426 11169 sgd_solver.cpp:105] Iteration 7900, lr = 0.0064619
I0408 13:38:48.445133 11169 solver.cpp:331] Iteration 8000, Testing net (#0)
I0408 13:38:55.769299 11177 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:38:56.089519 11169 solver.cpp:398]     Test net output #0: accuracy = 0.991
I0408 13:38:56.089542 11169 solver.cpp:398]     Test net output #1: loss = 0.0276206 (* 1 = 0.0276206 loss)
I0408 13:38:56.195744 11169 solver.cpp:219] Iteration 8000 (5.85603 iter/s, 17.0764s/100 iters), loss = 0.00413985
I0408 13:38:56.195791 11169 solver.cpp:238]     Train net output #0: loss = 0.00413997 (* 1 = 0.00413997 loss)
I0408 13:38:56.195797 11169 sgd_solver.cpp:105] Iteration 8000, lr = 0.00643496
I0408 13:39:05.645208 11169 solver.cpp:219] Iteration 8100 (10.5826 iter/s, 9.44946s/100 iters), loss = 0.00632843
I0408 13:39:05.645440 11169 solver.cpp:238]     Train net output #0: loss = 0.00632855 (* 1 = 0.00632855 loss)
I0408 13:39:05.645447 11169 sgd_solver.cpp:105] Iteration 8100, lr = 0.00640827
I0408 13:39:15.093865 11169 solver.cpp:219] Iteration 8200 (10.5837 iter/s, 9.44848s/100 iters), loss = 0.00535713
I0408 13:39:15.093894 11169 solver.cpp:238]     Train net output #0: loss = 0.00535725 (* 1 = 0.00535725 loss)
I0408 13:39:15.093899 11169 sgd_solver.cpp:105] Iteration 8200, lr = 0.00638185
I0408 13:39:24.554016 11169 solver.cpp:219] Iteration 8300 (10.5706 iter/s, 9.46016s/100 iters), loss = 0.0181709
I0408 13:39:24.554065 11169 solver.cpp:238]     Train net output #0: loss = 0.018171 (* 1 = 0.018171 loss)
I0408 13:39:24.554071 11169 sgd_solver.cpp:105] Iteration 8300, lr = 0.00635567
I0408 13:39:34.007314 11169 solver.cpp:219] Iteration 8400 (10.5783 iter/s, 9.4533s/100 iters), loss = 0.0043345
I0408 13:39:34.007362 11169 solver.cpp:238]     Train net output #0: loss = 0.00433462 (* 1 = 0.00433462 loss)
I0408 13:39:34.007369 11169 sgd_solver.cpp:105] Iteration 8400, lr = 0.00632975
I0408 13:39:37.140327 11176 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:39:43.325017 11169 solver.cpp:331] Iteration 8500, Testing net (#0)
I0408 13:39:50.650874 11177 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:39:50.962710 11169 solver.cpp:398]     Test net output #0: accuracy = 0.9915
I0408 13:39:50.962733 11169 solver.cpp:398]     Test net output #1: loss = 0.027481 (* 1 = 0.027481 loss)
I0408 13:39:51.067190 11169 solver.cpp:219] Iteration 8500 (5.8617 iter/s, 17.0599s/100 iters), loss = 0.00315893
I0408 13:39:51.067239 11169 solver.cpp:238]     Train net output #0: loss = 0.00315907 (* 1 = 0.00315907 loss)
I0408 13:39:51.067245 11169 sgd_solver.cpp:105] Iteration 8500, lr = 0.00630407
I0408 13:40:00.516577 11169 solver.cpp:219] Iteration 8600 (10.5827 iter/s, 9.44937s/100 iters), loss = 0.000774481
I0408 13:40:00.516623 11169 solver.cpp:238]     Train net output #0: loss = 0.000774615 (* 1 = 0.000774615 loss)
I0408 13:40:00.516628 11169 sgd_solver.cpp:105] Iteration 8600, lr = 0.00627864
I0408 13:40:09.961942 11169 solver.cpp:219] Iteration 8700 (10.5872 iter/s, 9.44536s/100 iters), loss = 0.00326116
I0408 13:40:09.962050 11169 solver.cpp:238]     Train net output #0: loss = 0.00326129 (* 1 = 0.00326129 loss)
I0408 13:40:09.962071 11169 sgd_solver.cpp:105] Iteration 8700, lr = 0.00625344
I0408 13:40:19.410539 11169 solver.cpp:219] Iteration 8800 (10.5837 iter/s, 9.44852s/100 iters), loss = 0.000730774
I0408 13:40:19.410568 11169 solver.cpp:238]     Train net output #0: loss = 0.000730906 (* 1 = 0.000730906 loss)
I0408 13:40:19.410573 11169 sgd_solver.cpp:105] Iteration 8800, lr = 0.00622847
I0408 13:40:28.856925 11169 solver.cpp:219] Iteration 8900 (10.5861 iter/s, 9.44639s/100 iters), loss = 0.000324166
I0408 13:40:28.856951 11169 solver.cpp:238]     Train net output #0: loss = 0.000324306 (* 1 = 0.000324306 loss)
I0408 13:40:28.856957 11169 sgd_solver.cpp:105] Iteration 8900, lr = 0.00620374
I0408 13:40:38.172700 11169 solver.cpp:331] Iteration 9000, Testing net (#0)
I0408 13:40:45.486165 11177 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:40:45.797749 11169 solver.cpp:398]     Test net output #0: accuracy = 0.991
I0408 13:40:45.797772 11169 solver.cpp:398]     Test net output #1: loss = 0.0262056 (* 1 = 0.0262056 loss)
I0408 13:40:45.902123 11169 solver.cpp:219] Iteration 9000 (5.86674 iter/s, 17.0452s/100 iters), loss = 0.0129831
I0408 13:40:45.902166 11169 solver.cpp:238]     Train net output #0: loss = 0.0129833 (* 1 = 0.0129833 loss)
I0408 13:40:45.902186 11169 sgd_solver.cpp:105] Iteration 9000, lr = 0.00617924
I0408 13:40:55.357882 11169 solver.cpp:219] Iteration 9100 (10.5756 iter/s, 9.45575s/100 iters), loss = 0.00453642
I0408 13:40:55.357913 11169 solver.cpp:238]     Train net output #0: loss = 0.00453656 (* 1 = 0.00453656 loss)
I0408 13:40:55.357934 11169 sgd_solver.cpp:105] Iteration 9100, lr = 0.00615496
I0408 13:41:04.792577 11169 solver.cpp:219] Iteration 9200 (10.5992 iter/s, 9.4347s/100 iters), loss = 0.00194365
I0408 13:41:04.792606 11169 solver.cpp:238]     Train net output #0: loss = 0.00194378 (* 1 = 0.00194378 loss)
I0408 13:41:04.792611 11169 sgd_solver.cpp:105] Iteration 9200, lr = 0.0061309
I0408 13:41:14.252992 11169 solver.cpp:219] Iteration 9300 (10.5704 iter/s, 9.46042s/100 iters), loss = 0.00632582
I0408 13:41:14.253021 11169 solver.cpp:238]     Train net output #0: loss = 0.00632595 (* 1 = 0.00632595 loss)
I0408 13:41:14.253026 11169 sgd_solver.cpp:105] Iteration 9300, lr = 0.00610706
I0408 13:41:20.864792 11176 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:41:23.704075 11169 solver.cpp:219] Iteration 9400 (10.5808 iter/s, 9.45108s/100 iters), loss = 0.0110183
I0408 13:41:23.704104 11169 solver.cpp:238]     Train net output #0: loss = 0.0110184 (* 1 = 0.0110184 loss)
I0408 13:41:23.704109 11169 sgd_solver.cpp:105] Iteration 9400, lr = 0.00608343
I0408 13:41:33.036115 11169 solver.cpp:331] Iteration 9500, Testing net (#0)
I0408 13:41:40.347461 11177 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:41:40.659847 11169 solver.cpp:398]     Test net output #0: accuracy = 0.9902
I0408 13:41:40.659888 11169 solver.cpp:398]     Test net output #1: loss = 0.0318651 (* 1 = 0.0318651 loss)
I0408 13:41:40.766360 11169 solver.cpp:219] Iteration 9500 (5.86087 iter/s, 17.0623s/100 iters), loss = 0.00221022
I0408 13:41:40.766407 11169 solver.cpp:238]     Train net output #0: loss = 0.00221035 (* 1 = 0.00221035 loss)
I0408 13:41:40.766413 11169 sgd_solver.cpp:105] Iteration 9500, lr = 0.00606002
I0408 13:41:50.243293 11169 solver.cpp:219] Iteration 9600 (10.552 iter/s, 9.47692s/100 iters), loss = 0.00109837
I0408 13:41:50.243335 11169 solver.cpp:238]     Train net output #0: loss = 0.0010985 (* 1 = 0.0010985 loss)
I0408 13:41:50.243340 11169 sgd_solver.cpp:105] Iteration 9600, lr = 0.00603682
I0408 13:41:59.697998 11169 solver.cpp:219] Iteration 9700 (10.5768 iter/s, 9.4547s/100 iters), loss = 0.0033122
I0408 13:41:59.698122 11169 solver.cpp:238]     Train net output #0: loss = 0.00331232 (* 1 = 0.00331232 loss)
I0408 13:41:59.698144 11169 sgd_solver.cpp:105] Iteration 9700, lr = 0.00601382
I0408 13:42:09.162847 11169 solver.cpp:219] Iteration 9800 (10.5655 iter/s, 9.46476s/100 iters), loss = 0.010541
I0408 13:42:09.162894 11169 solver.cpp:238]     Train net output #0: loss = 0.0105411 (* 1 = 0.0105411 loss)
I0408 13:42:09.162897 11169 sgd_solver.cpp:105] Iteration 9800, lr = 0.00599102
I0408 13:42:18.631705 11169 solver.cpp:219] Iteration 9900 (10.561 iter/s, 9.46884s/100 iters), loss = 0.00426041
I0408 13:42:18.631752 11169 solver.cpp:238]     Train net output #0: loss = 0.00426053 (* 1 = 0.00426053 loss)
I0408 13:42:18.631757 11169 sgd_solver.cpp:105] Iteration 9900, lr = 0.00596843
I0408 13:42:27.933547 11169 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_10000.caffemodel
I0408 13:42:27.997004 11169 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_10000.solverstate
I0408 13:42:28.063139 11169 solver.cpp:311] Iteration 10000, loss = 0.0024608
I0408 13:42:28.063160 11169 solver.cpp:331] Iteration 10000, Testing net (#0)
I0408 13:42:35.361807 11177 data_layer.cpp:73] Restarting data prefetching from start.
I0408 13:42:35.676554 11169 solver.cpp:398]     Test net output #0: accuracy = 0.9916
I0408 13:42:35.676578 11169 solver.cpp:398]     Test net output #1: loss = 0.0254117 (* 1 = 0.0254117 loss)
I0408 13:42:35.676581 11169 solver.cpp:316] Optimization Done.
I0408 13:42:35.676583 11169 caffe.cpp:259] Optimization Done.
