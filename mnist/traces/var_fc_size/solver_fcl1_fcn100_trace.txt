I0408 11:45:24.926177  9985 caffe.cpp:218] Using GPUs 0
I0408 11:45:25.194964  9985 caffe.cpp:223] GPU 0: GeForce GTX 950M
I0408 11:45:26.972774  9985 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_fc_size/lenet_train_test_fcl1_fcn100.prototxt"
train_state {
  level: 0
  stage: ""
}
I0408 11:45:26.973086  9985 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_fc_size/lenet_train_test_fcl1_fcn100.prototxt
I0408 11:45:26.974026  9985 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0408 11:45:26.974071  9985 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0408 11:45:26.974290  9985 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0408 11:45:26.974470  9985 layer_factory.hpp:77] Creating layer mnist
I0408 11:45:27.030086  9985 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0408 11:45:27.036741  9985 net.cpp:84] Creating Layer mnist
I0408 11:45:27.036815  9985 net.cpp:380] mnist -> data
I0408 11:45:27.036903  9985 net.cpp:380] mnist -> label
I0408 11:45:27.043576  9985 data_layer.cpp:45] output data size: 64,1,28,28
I0408 11:45:27.045147  9985 net.cpp:122] Setting up mnist
I0408 11:45:27.045164  9985 net.cpp:129] Top shape: 64 1 28 28 (50176)
I0408 11:45:27.045171  9985 net.cpp:129] Top shape: 64 (64)
I0408 11:45:27.045173  9985 net.cpp:137] Memory required for data: 200960
I0408 11:45:27.045186  9985 layer_factory.hpp:77] Creating layer conv0
I0408 11:45:27.045209  9985 net.cpp:84] Creating Layer conv0
I0408 11:45:27.045215  9985 net.cpp:406] conv0 <- data
I0408 11:45:27.045231  9985 net.cpp:380] conv0 -> conv0
I0408 11:45:27.046236  9985 net.cpp:122] Setting up conv0
I0408 11:45:27.046255  9985 net.cpp:129] Top shape: 64 50 24 24 (1843200)
I0408 11:45:27.046259  9985 net.cpp:137] Memory required for data: 7573760
I0408 11:45:27.046286  9985 layer_factory.hpp:77] Creating layer pool0
I0408 11:45:27.046298  9985 net.cpp:84] Creating Layer pool0
I0408 11:45:27.046306  9985 net.cpp:406] pool0 <- conv0
I0408 11:45:27.046317  9985 net.cpp:380] pool0 -> pool0
I0408 11:45:27.046433  9985 net.cpp:122] Setting up pool0
I0408 11:45:27.046443  9985 net.cpp:129] Top shape: 64 50 12 12 (460800)
I0408 11:45:27.046463  9985 net.cpp:137] Memory required for data: 9416960
I0408 11:45:27.046468  9985 layer_factory.hpp:77] Creating layer conv1
I0408 11:45:27.046483  9985 net.cpp:84] Creating Layer conv1
I0408 11:45:27.046489  9985 net.cpp:406] conv1 <- pool0
I0408 11:45:27.046499  9985 net.cpp:380] conv1 -> conv1
I0408 11:45:27.047610  9985 net.cpp:122] Setting up conv1
I0408 11:45:27.047623  9985 net.cpp:129] Top shape: 64 50 8 8 (204800)
I0408 11:45:27.047629  9985 net.cpp:137] Memory required for data: 10236160
I0408 11:45:27.047641  9985 layer_factory.hpp:77] Creating layer pool1
I0408 11:45:27.047657  9985 net.cpp:84] Creating Layer pool1
I0408 11:45:27.047662  9985 net.cpp:406] pool1 <- conv1
I0408 11:45:27.047670  9985 net.cpp:380] pool1 -> pool1
I0408 11:45:27.047710  9985 net.cpp:122] Setting up pool1
I0408 11:45:27.047719  9985 net.cpp:129] Top shape: 64 50 4 4 (51200)
I0408 11:45:27.047722  9985 net.cpp:137] Memory required for data: 10440960
I0408 11:45:27.047726  9985 layer_factory.hpp:77] Creating layer ip1
I0408 11:45:27.047740  9985 net.cpp:84] Creating Layer ip1
I0408 11:45:27.047745  9985 net.cpp:406] ip1 <- pool1
I0408 11:45:27.047755  9985 net.cpp:380] ip1 -> ip1
I0408 11:45:27.048310  9985 net.cpp:122] Setting up ip1
I0408 11:45:27.048321  9985 net.cpp:129] Top shape: 64 10 (640)
I0408 11:45:27.048324  9985 net.cpp:137] Memory required for data: 10443520
I0408 11:45:27.048337  9985 layer_factory.hpp:77] Creating layer relu1
I0408 11:45:27.048346  9985 net.cpp:84] Creating Layer relu1
I0408 11:45:27.048353  9985 net.cpp:406] relu1 <- ip1
I0408 11:45:27.048362  9985 net.cpp:367] relu1 -> ip1 (in-place)
I0408 11:45:27.048379  9985 net.cpp:122] Setting up relu1
I0408 11:45:27.048387  9985 net.cpp:129] Top shape: 64 10 (640)
I0408 11:45:27.048391  9985 net.cpp:137] Memory required for data: 10446080
I0408 11:45:27.048395  9985 layer_factory.hpp:77] Creating layer loss
I0408 11:45:27.048403  9985 net.cpp:84] Creating Layer loss
I0408 11:45:27.048408  9985 net.cpp:406] loss <- ip1
I0408 11:45:27.048414  9985 net.cpp:406] loss <- label
I0408 11:45:27.048424  9985 net.cpp:380] loss -> loss
I0408 11:45:27.048439  9985 layer_factory.hpp:77] Creating layer loss
I0408 11:45:27.048548  9985 net.cpp:122] Setting up loss
I0408 11:45:27.048558  9985 net.cpp:129] Top shape: (1)
I0408 11:45:27.048563  9985 net.cpp:132]     with loss weight 1
I0408 11:45:27.048583  9985 net.cpp:137] Memory required for data: 10446084
I0408 11:45:27.048588  9985 net.cpp:198] loss needs backward computation.
I0408 11:45:27.048599  9985 net.cpp:198] relu1 needs backward computation.
I0408 11:45:27.048604  9985 net.cpp:198] ip1 needs backward computation.
I0408 11:45:27.048609  9985 net.cpp:198] pool1 needs backward computation.
I0408 11:45:27.048614  9985 net.cpp:198] conv1 needs backward computation.
I0408 11:45:27.048620  9985 net.cpp:198] pool0 needs backward computation.
I0408 11:45:27.048625  9985 net.cpp:198] conv0 needs backward computation.
I0408 11:45:27.048630  9985 net.cpp:200] mnist does not need backward computation.
I0408 11:45:27.048635  9985 net.cpp:242] This network produces output loss
I0408 11:45:27.048646  9985 net.cpp:255] Network initialization done.
I0408 11:45:27.048831  9985 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_fc_size/lenet_train_test_fcl1_fcn100.prototxt
I0408 11:45:27.048856  9985 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0408 11:45:27.048938  9985 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0408 11:45:27.049033  9985 layer_factory.hpp:77] Creating layer mnist
I0408 11:45:27.053309  9985 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0408 11:45:27.067035  9985 net.cpp:84] Creating Layer mnist
I0408 11:45:27.067101  9985 net.cpp:380] mnist -> data
I0408 11:45:27.067134  9985 net.cpp:380] mnist -> label
I0408 11:45:27.067383  9985 data_layer.cpp:45] output data size: 100,1,28,28
I0408 11:45:27.070637  9985 net.cpp:122] Setting up mnist
I0408 11:45:27.070668  9985 net.cpp:129] Top shape: 100 1 28 28 (78400)
I0408 11:45:27.070683  9985 net.cpp:129] Top shape: 100 (100)
I0408 11:45:27.070690  9985 net.cpp:137] Memory required for data: 314000
I0408 11:45:27.070703  9985 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0408 11:45:27.070731  9985 net.cpp:84] Creating Layer label_mnist_1_split
I0408 11:45:27.070744  9985 net.cpp:406] label_mnist_1_split <- label
I0408 11:45:27.070761  9985 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_0
I0408 11:45:27.070791  9985 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_1
I0408 11:45:27.070998  9985 net.cpp:122] Setting up label_mnist_1_split
I0408 11:45:27.071032  9985 net.cpp:129] Top shape: 100 (100)
I0408 11:45:27.071043  9985 net.cpp:129] Top shape: 100 (100)
I0408 11:45:27.071051  9985 net.cpp:137] Memory required for data: 314800
I0408 11:45:27.071060  9985 layer_factory.hpp:77] Creating layer conv0
I0408 11:45:27.071099  9985 net.cpp:84] Creating Layer conv0
I0408 11:45:27.071110  9985 net.cpp:406] conv0 <- data
I0408 11:45:27.071131  9985 net.cpp:380] conv0 -> conv0
I0408 11:45:27.071727  9985 net.cpp:122] Setting up conv0
I0408 11:45:27.071755  9985 net.cpp:129] Top shape: 100 50 24 24 (2880000)
I0408 11:45:27.071768  9985 net.cpp:137] Memory required for data: 11834800
I0408 11:45:27.071800  9985 layer_factory.hpp:77] Creating layer pool0
I0408 11:45:27.071821  9985 net.cpp:84] Creating Layer pool0
I0408 11:45:27.071838  9985 net.cpp:406] pool0 <- conv0
I0408 11:45:27.071862  9985 net.cpp:380] pool0 -> pool0
I0408 11:45:27.071962  9985 net.cpp:122] Setting up pool0
I0408 11:45:27.071982  9985 net.cpp:129] Top shape: 100 50 12 12 (720000)
I0408 11:45:27.071996  9985 net.cpp:137] Memory required for data: 14714800
I0408 11:45:27.072006  9985 layer_factory.hpp:77] Creating layer conv1
I0408 11:45:27.072042  9985 net.cpp:84] Creating Layer conv1
I0408 11:45:27.072055  9985 net.cpp:406] conv1 <- pool0
I0408 11:45:27.072080  9985 net.cpp:380] conv1 -> conv1
I0408 11:45:27.074064  9985 net.cpp:122] Setting up conv1
I0408 11:45:27.074100  9985 net.cpp:129] Top shape: 100 50 8 8 (320000)
I0408 11:45:27.074111  9985 net.cpp:137] Memory required for data: 15994800
I0408 11:45:27.074146  9985 layer_factory.hpp:77] Creating layer pool1
I0408 11:45:27.074199  9985 net.cpp:84] Creating Layer pool1
I0408 11:45:27.074213  9985 net.cpp:406] pool1 <- conv1
I0408 11:45:27.074234  9985 net.cpp:380] pool1 -> pool1
I0408 11:45:27.074347  9985 net.cpp:122] Setting up pool1
I0408 11:45:27.074368  9985 net.cpp:129] Top shape: 100 50 4 4 (80000)
I0408 11:45:27.074379  9985 net.cpp:137] Memory required for data: 16314800
I0408 11:45:27.074393  9985 layer_factory.hpp:77] Creating layer ip1
I0408 11:45:27.074425  9985 net.cpp:84] Creating Layer ip1
I0408 11:45:27.074441  9985 net.cpp:406] ip1 <- pool1
I0408 11:45:27.074460  9985 net.cpp:380] ip1 -> ip1
I0408 11:45:27.074863  9985 net.cpp:122] Setting up ip1
I0408 11:45:27.074890  9985 net.cpp:129] Top shape: 100 10 (1000)
I0408 11:45:27.074900  9985 net.cpp:137] Memory required for data: 16318800
I0408 11:45:27.074928  9985 layer_factory.hpp:77] Creating layer relu1
I0408 11:45:27.074949  9985 net.cpp:84] Creating Layer relu1
I0408 11:45:27.074962  9985 net.cpp:406] relu1 <- ip1
I0408 11:45:27.074983  9985 net.cpp:367] relu1 -> ip1 (in-place)
I0408 11:45:27.075006  9985 net.cpp:122] Setting up relu1
I0408 11:45:27.075023  9985 net.cpp:129] Top shape: 100 10 (1000)
I0408 11:45:27.075038  9985 net.cpp:137] Memory required for data: 16322800
I0408 11:45:27.075049  9985 layer_factory.hpp:77] Creating layer ip1_relu1_0_split
I0408 11:45:27.075076  9985 net.cpp:84] Creating Layer ip1_relu1_0_split
I0408 11:45:27.075116  9985 net.cpp:406] ip1_relu1_0_split <- ip1
I0408 11:45:27.075139  9985 net.cpp:380] ip1_relu1_0_split -> ip1_relu1_0_split_0
I0408 11:45:27.075163  9985 net.cpp:380] ip1_relu1_0_split -> ip1_relu1_0_split_1
I0408 11:45:27.075273  9985 net.cpp:122] Setting up ip1_relu1_0_split
I0408 11:45:27.075291  9985 net.cpp:129] Top shape: 100 10 (1000)
I0408 11:45:27.075309  9985 net.cpp:129] Top shape: 100 10 (1000)
I0408 11:45:27.075321  9985 net.cpp:137] Memory required for data: 16330800
I0408 11:45:27.075332  9985 layer_factory.hpp:77] Creating layer accuracy
I0408 11:45:27.075351  9985 net.cpp:84] Creating Layer accuracy
I0408 11:45:27.075369  9985 net.cpp:406] accuracy <- ip1_relu1_0_split_0
I0408 11:45:27.075384  9985 net.cpp:406] accuracy <- label_mnist_1_split_0
I0408 11:45:27.075403  9985 net.cpp:380] accuracy -> accuracy
I0408 11:45:27.075433  9985 net.cpp:122] Setting up accuracy
I0408 11:45:27.075451  9985 net.cpp:129] Top shape: (1)
I0408 11:45:27.075461  9985 net.cpp:137] Memory required for data: 16330804
I0408 11:45:27.075471  9985 layer_factory.hpp:77] Creating layer loss
I0408 11:45:27.075494  9985 net.cpp:84] Creating Layer loss
I0408 11:45:27.075511  9985 net.cpp:406] loss <- ip1_relu1_0_split_1
I0408 11:45:27.075525  9985 net.cpp:406] loss <- label_mnist_1_split_1
I0408 11:45:27.075543  9985 net.cpp:380] loss -> loss
I0408 11:45:27.075573  9985 layer_factory.hpp:77] Creating layer loss
I0408 11:45:27.075817  9985 net.cpp:122] Setting up loss
I0408 11:45:27.075836  9985 net.cpp:129] Top shape: (1)
I0408 11:45:27.075845  9985 net.cpp:132]     with loss weight 1
I0408 11:45:27.075875  9985 net.cpp:137] Memory required for data: 16330808
I0408 11:45:27.075889  9985 net.cpp:198] loss needs backward computation.
I0408 11:45:27.075909  9985 net.cpp:200] accuracy does not need backward computation.
I0408 11:45:27.075927  9985 net.cpp:198] ip1_relu1_0_split needs backward computation.
I0408 11:45:27.075939  9985 net.cpp:198] relu1 needs backward computation.
I0408 11:45:27.075955  9985 net.cpp:198] ip1 needs backward computation.
I0408 11:45:27.075968  9985 net.cpp:198] pool1 needs backward computation.
I0408 11:45:27.075978  9985 net.cpp:198] conv1 needs backward computation.
I0408 11:45:27.075989  9985 net.cpp:198] pool0 needs backward computation.
I0408 11:45:27.076002  9985 net.cpp:198] conv0 needs backward computation.
I0408 11:45:27.076017  9985 net.cpp:200] label_mnist_1_split does not need backward computation.
I0408 11:45:27.076036  9985 net.cpp:200] mnist does not need backward computation.
I0408 11:45:27.076047  9985 net.cpp:242] This network produces output accuracy
I0408 11:45:27.076066  9985 net.cpp:242] This network produces output loss
I0408 11:45:27.076128  9985 net.cpp:255] Network initialization done.
I0408 11:45:27.076227  9985 solver.cpp:56] Solver scaffolding done.
I0408 11:45:27.076786  9985 caffe.cpp:248] Starting Optimization
I0408 11:45:27.076808  9985 solver.cpp:273] Solving LeNet
I0408 11:45:27.076819  9985 solver.cpp:274] Learning Rate Policy: inv
I0408 11:45:27.078347  9985 solver.cpp:331] Iteration 0, Testing net (#0)
I0408 11:45:29.222290  9993 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:45:29.316112  9985 solver.cpp:398]     Test net output #0: accuracy = 0.1074
I0408 11:45:29.316136  9985 solver.cpp:398]     Test net output #1: loss = 2.50147 (* 1 = 2.50147 loss)
I0408 11:45:29.347688  9985 solver.cpp:219] Iteration 0 (0 iter/s, 2.27076s/100 iters), loss = 2.5159
I0408 11:45:29.347712  9985 solver.cpp:238]     Train net output #0: loss = 2.5159 (* 1 = 2.5159 loss)
I0408 11:45:29.347746  9985 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0408 11:45:32.157238  9985 solver.cpp:219] Iteration 100 (35.6216 iter/s, 2.80729s/100 iters), loss = 0.497541
I0408 11:45:32.157284  9985 solver.cpp:238]     Train net output #0: loss = 0.497541 (* 1 = 0.497541 loss)
I0408 11:45:32.157289  9985 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0408 11:45:34.958329  9985 solver.cpp:219] Iteration 200 (35.702 iter/s, 2.80097s/100 iters), loss = 0.336706
I0408 11:45:34.958359  9985 solver.cpp:238]     Train net output #0: loss = 0.336706 (* 1 = 0.336706 loss)
I0408 11:45:34.958362  9985 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0408 11:45:37.748075  9985 solver.cpp:219] Iteration 300 (35.847 iter/s, 2.78963s/100 iters), loss = 0.151288
I0408 11:45:37.748102  9985 solver.cpp:238]     Train net output #0: loss = 0.151288 (* 1 = 0.151288 loss)
I0408 11:45:37.748126  9985 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0408 11:45:40.531939  9985 solver.cpp:219] Iteration 400 (35.9227 iter/s, 2.78376s/100 iters), loss = 0.0622547
I0408 11:45:40.531970  9985 solver.cpp:238]     Train net output #0: loss = 0.0622547 (* 1 = 0.0622547 loss)
I0408 11:45:40.531976  9985 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0408 11:45:43.296200  9985 solver.cpp:331] Iteration 500, Testing net (#0)
I0408 11:45:45.414355  9993 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:45:45.509234  9985 solver.cpp:398]     Test net output #0: accuracy = 0.9684
I0408 11:45:45.509258  9985 solver.cpp:398]     Test net output #1: loss = 0.103972 (* 1 = 0.103972 loss)
I0408 11:45:45.536720  9985 solver.cpp:219] Iteration 500 (19.9816 iter/s, 5.00461s/100 iters), loss = 0.159843
I0408 11:45:45.536747  9985 solver.cpp:238]     Train net output #0: loss = 0.159843 (* 1 = 0.159843 loss)
I0408 11:45:45.536773  9985 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0408 11:45:48.330237  9985 solver.cpp:219] Iteration 600 (35.7985 iter/s, 2.79341s/100 iters), loss = 0.0704773
I0408 11:45:48.330283  9985 solver.cpp:238]     Train net output #0: loss = 0.0704773 (* 1 = 0.0704773 loss)
I0408 11:45:48.330287  9985 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0408 11:45:51.115809  9985 solver.cpp:219] Iteration 700 (35.9008 iter/s, 2.78545s/100 iters), loss = 0.144007
I0408 11:45:51.115854  9985 solver.cpp:238]     Train net output #0: loss = 0.144007 (* 1 = 0.144007 loss)
I0408 11:45:51.115860  9985 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0408 11:45:53.904453  9985 solver.cpp:219] Iteration 800 (35.8613 iter/s, 2.78852s/100 iters), loss = 0.195852
I0408 11:45:53.904500  9985 solver.cpp:238]     Train net output #0: loss = 0.195853 (* 1 = 0.195853 loss)
I0408 11:45:53.904505  9985 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0408 11:45:56.691468  9985 solver.cpp:219] Iteration 900 (35.8823 iter/s, 2.78689s/100 iters), loss = 0.168073
I0408 11:45:56.691722  9985 solver.cpp:238]     Train net output #0: loss = 0.168073 (* 1 = 0.168073 loss)
I0408 11:45:56.691730  9985 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0408 11:45:57.619561  9992 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:45:59.449555  9985 solver.cpp:331] Iteration 1000, Testing net (#0)
I0408 11:46:01.570886  9993 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:46:01.666420  9985 solver.cpp:398]     Test net output #0: accuracy = 0.9764
I0408 11:46:01.666443  9985 solver.cpp:398]     Test net output #1: loss = 0.0676454 (* 1 = 0.0676454 loss)
I0408 11:46:01.694380  9985 solver.cpp:219] Iteration 1000 (19.9899 iter/s, 5.00253s/100 iters), loss = 0.114885
I0408 11:46:01.694404  9985 solver.cpp:238]     Train net output #0: loss = 0.114885 (* 1 = 0.114885 loss)
I0408 11:46:01.694411  9985 sgd_solver.cpp:105] Iteration 1000, lr = 0.00931012
I0408 11:46:04.486028  9985 solver.cpp:219] Iteration 1100 (35.8501 iter/s, 2.78939s/100 iters), loss = 0.00817726
I0408 11:46:04.486059  9985 solver.cpp:238]     Train net output #0: loss = 0.00817738 (* 1 = 0.00817738 loss)
I0408 11:46:04.486066  9985 sgd_solver.cpp:105] Iteration 1100, lr = 0.00924715
I0408 11:46:07.264107  9985 solver.cpp:219] Iteration 1200 (35.9975 iter/s, 2.77797s/100 iters), loss = 0.0203702
I0408 11:46:07.264139  9985 solver.cpp:238]     Train net output #0: loss = 0.0203703 (* 1 = 0.0203703 loss)
I0408 11:46:07.264147  9985 sgd_solver.cpp:105] Iteration 1200, lr = 0.00918515
I0408 11:46:10.047580  9985 solver.cpp:219] Iteration 1300 (35.9277 iter/s, 2.78336s/100 iters), loss = 0.0113779
I0408 11:46:10.047606  9985 solver.cpp:238]     Train net output #0: loss = 0.011378 (* 1 = 0.011378 loss)
I0408 11:46:10.047612  9985 sgd_solver.cpp:105] Iteration 1300, lr = 0.00912412
I0408 11:46:12.847667  9985 solver.cpp:219] Iteration 1400 (35.7145 iter/s, 2.79999s/100 iters), loss = 0.0099348
I0408 11:46:12.847698  9985 solver.cpp:238]     Train net output #0: loss = 0.00993495 (* 1 = 0.00993495 loss)
I0408 11:46:12.847705  9985 sgd_solver.cpp:105] Iteration 1400, lr = 0.00906403
I0408 11:46:15.600879  9985 solver.cpp:331] Iteration 1500, Testing net (#0)
I0408 11:46:17.726236  9993 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:46:17.820428  9985 solver.cpp:398]     Test net output #0: accuracy = 0.9792
I0408 11:46:17.820453  9985 solver.cpp:398]     Test net output #1: loss = 0.0634693 (* 1 = 0.0634693 loss)
I0408 11:46:17.847920  9985 solver.cpp:219] Iteration 1500 (19.9996 iter/s, 5.0001s/100 iters), loss = 0.11276
I0408 11:46:17.847942  9985 solver.cpp:238]     Train net output #0: loss = 0.11276 (* 1 = 0.11276 loss)
I0408 11:46:17.847952  9985 sgd_solver.cpp:105] Iteration 1500, lr = 0.00900485
I0408 11:46:20.637102  9985 solver.cpp:219] Iteration 1600 (35.854 iter/s, 2.78909s/100 iters), loss = 0.195644
I0408 11:46:20.637132  9985 solver.cpp:238]     Train net output #0: loss = 0.195644 (* 1 = 0.195644 loss)
I0408 11:46:20.637140  9985 sgd_solver.cpp:105] Iteration 1600, lr = 0.00894657
I0408 11:46:23.417613  9985 solver.cpp:219] Iteration 1700 (35.966 iter/s, 2.78041s/100 iters), loss = 0.0406324
I0408 11:46:23.417644  9985 solver.cpp:238]     Train net output #0: loss = 0.0406326 (* 1 = 0.0406326 loss)
I0408 11:46:23.417650  9985 sgd_solver.cpp:105] Iteration 1700, lr = 0.00888916
I0408 11:46:26.204577  9985 solver.cpp:219] Iteration 1800 (35.8827 iter/s, 2.78686s/100 iters), loss = 0.017619
I0408 11:46:26.204608  9985 solver.cpp:238]     Train net output #0: loss = 0.0176192 (* 1 = 0.0176192 loss)
I0408 11:46:26.204615  9985 sgd_solver.cpp:105] Iteration 1800, lr = 0.0088326
I0408 11:46:28.155303  9992 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:46:28.994745  9985 solver.cpp:219] Iteration 1900 (35.8415 iter/s, 2.79006s/100 iters), loss = 0.141873
I0408 11:46:28.994793  9985 solver.cpp:238]     Train net output #0: loss = 0.141873 (* 1 = 0.141873 loss)
I0408 11:46:28.994801  9985 sgd_solver.cpp:105] Iteration 1900, lr = 0.00877687
I0408 11:46:31.741302  9985 solver.cpp:331] Iteration 2000, Testing net (#0)
I0408 11:46:33.864058  9993 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:46:33.959197  9985 solver.cpp:398]     Test net output #0: accuracy = 0.9809
I0408 11:46:33.959218  9985 solver.cpp:398]     Test net output #1: loss = 0.05548 (* 1 = 0.05548 loss)
I0408 11:46:33.986809  9985 solver.cpp:219] Iteration 2000 (20.0325 iter/s, 4.99189s/100 iters), loss = 0.0242588
I0408 11:46:33.986840  9985 solver.cpp:238]     Train net output #0: loss = 0.0242589 (* 1 = 0.0242589 loss)
I0408 11:46:33.986868  9985 sgd_solver.cpp:105] Iteration 2000, lr = 0.00872196
I0408 11:46:36.774682  9985 solver.cpp:219] Iteration 2100 (35.871 iter/s, 2.78777s/100 iters), loss = 0.0300502
I0408 11:46:36.774729  9985 solver.cpp:238]     Train net output #0: loss = 0.0300503 (* 1 = 0.0300503 loss)
I0408 11:46:36.774732  9985 sgd_solver.cpp:105] Iteration 2100, lr = 0.00866784
I0408 11:46:39.561801  9985 solver.cpp:219] Iteration 2200 (35.8809 iter/s, 2.787s/100 iters), loss = 0.0334662
I0408 11:46:39.561830  9985 solver.cpp:238]     Train net output #0: loss = 0.0334664 (* 1 = 0.0334664 loss)
I0408 11:46:39.561836  9985 sgd_solver.cpp:105] Iteration 2200, lr = 0.0086145
I0408 11:46:42.367385  9985 solver.cpp:219] Iteration 2300 (35.6445 iter/s, 2.80548s/100 iters), loss = 0.166525
I0408 11:46:42.367413  9985 solver.cpp:238]     Train net output #0: loss = 0.166525 (* 1 = 0.166525 loss)
I0408 11:46:42.367419  9985 sgd_solver.cpp:105] Iteration 2300, lr = 0.00856192
I0408 11:46:45.179297  9985 solver.cpp:219] Iteration 2400 (35.573 iter/s, 2.81112s/100 iters), loss = 0.0133745
I0408 11:46:45.179325  9985 solver.cpp:238]     Train net output #0: loss = 0.0133747 (* 1 = 0.0133747 loss)
I0408 11:46:45.179330  9985 sgd_solver.cpp:105] Iteration 2400, lr = 0.00851008
I0408 11:46:47.937434  9985 solver.cpp:331] Iteration 2500, Testing net (#0)
I0408 11:46:50.057412  9993 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:46:50.153121  9985 solver.cpp:398]     Test net output #0: accuracy = 0.9796
I0408 11:46:50.153146  9985 solver.cpp:398]     Test net output #1: loss = 0.0627716 (* 1 = 0.0627716 loss)
I0408 11:46:50.180698  9985 solver.cpp:219] Iteration 2500 (19.995 iter/s, 5.00125s/100 iters), loss = 0.0213071
I0408 11:46:50.180738  9985 solver.cpp:238]     Train net output #0: loss = 0.0213073 (* 1 = 0.0213073 loss)
I0408 11:46:50.180744  9985 sgd_solver.cpp:105] Iteration 2500, lr = 0.00845897
I0408 11:46:52.973127  9985 solver.cpp:219] Iteration 2600 (35.8126 iter/s, 2.79232s/100 iters), loss = 0.0783914
I0408 11:46:52.973155  9985 solver.cpp:238]     Train net output #0: loss = 0.0783915 (* 1 = 0.0783915 loss)
I0408 11:46:52.973160  9985 sgd_solver.cpp:105] Iteration 2600, lr = 0.00840857
I0408 11:46:55.770208  9985 solver.cpp:219] Iteration 2700 (35.7528 iter/s, 2.79698s/100 iters), loss = 0.151787
I0408 11:46:55.770236  9985 solver.cpp:238]     Train net output #0: loss = 0.151787 (* 1 = 0.151787 loss)
I0408 11:46:55.770259  9985 sgd_solver.cpp:105] Iteration 2700, lr = 0.00835886
I0408 11:46:58.551626  9985 solver.cpp:219] Iteration 2800 (35.9542 iter/s, 2.78132s/100 iters), loss = 0.0133714
I0408 11:46:58.551774  9985 solver.cpp:238]     Train net output #0: loss = 0.0133716 (* 1 = 0.0133716 loss)
I0408 11:46:58.551779  9985 sgd_solver.cpp:105] Iteration 2800, lr = 0.00830984
I0408 11:46:58.781808  9992 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:47:01.349133  9985 solver.cpp:219] Iteration 2900 (35.7488 iter/s, 2.7973s/100 iters), loss = 0.0247011
I0408 11:47:01.349161  9985 solver.cpp:238]     Train net output #0: loss = 0.0247013 (* 1 = 0.0247013 loss)
I0408 11:47:01.349166  9985 sgd_solver.cpp:105] Iteration 2900, lr = 0.00826148
I0408 11:47:04.096350  9985 solver.cpp:331] Iteration 3000, Testing net (#0)
I0408 11:47:06.216756  9993 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:47:06.311656  9985 solver.cpp:398]     Test net output #0: accuracy = 0.979
I0408 11:47:06.311681  9985 solver.cpp:398]     Test net output #1: loss = 0.0672402 (* 1 = 0.0672402 loss)
I0408 11:47:06.339242  9985 solver.cpp:219] Iteration 3000 (20.0402 iter/s, 4.98996s/100 iters), loss = 0.0306296
I0408 11:47:06.339270  9985 solver.cpp:238]     Train net output #0: loss = 0.0306299 (* 1 = 0.0306299 loss)
I0408 11:47:06.339296  9985 sgd_solver.cpp:105] Iteration 3000, lr = 0.00821377
I0408 11:47:09.130563  9985 solver.cpp:219] Iteration 3100 (35.8265 iter/s, 2.79123s/100 iters), loss = 0.0141626
I0408 11:47:09.130589  9985 solver.cpp:238]     Train net output #0: loss = 0.0141628 (* 1 = 0.0141628 loss)
I0408 11:47:09.130594  9985 sgd_solver.cpp:105] Iteration 3100, lr = 0.0081667
I0408 11:47:11.919916  9985 solver.cpp:219] Iteration 3200 (35.8518 iter/s, 2.78926s/100 iters), loss = 0.014231
I0408 11:47:11.919945  9985 solver.cpp:238]     Train net output #0: loss = 0.0142313 (* 1 = 0.0142313 loss)
I0408 11:47:11.919950  9985 sgd_solver.cpp:105] Iteration 3200, lr = 0.00812025
I0408 11:47:14.707695  9985 solver.cpp:219] Iteration 3300 (35.8721 iter/s, 2.78768s/100 iters), loss = 0.0608703
I0408 11:47:14.707723  9985 solver.cpp:238]     Train net output #0: loss = 0.0608705 (* 1 = 0.0608705 loss)
I0408 11:47:14.707728  9985 sgd_solver.cpp:105] Iteration 3300, lr = 0.00807442
I0408 11:47:17.490479  9985 solver.cpp:219] Iteration 3400 (35.9365 iter/s, 2.78269s/100 iters), loss = 0.0252409
I0408 11:47:17.490507  9985 solver.cpp:238]     Train net output #0: loss = 0.0252411 (* 1 = 0.0252411 loss)
I0408 11:47:17.490530  9985 sgd_solver.cpp:105] Iteration 3400, lr = 0.00802918
I0408 11:47:20.240486  9985 solver.cpp:331] Iteration 3500, Testing net (#0)
I0408 11:47:22.356597  9993 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:47:22.451709  9985 solver.cpp:398]     Test net output #0: accuracy = 0.9848
I0408 11:47:22.451731  9985 solver.cpp:398]     Test net output #1: loss = 0.0478745 (* 1 = 0.0478745 loss)
I0408 11:47:22.479269  9985 solver.cpp:219] Iteration 3500 (20.0455 iter/s, 4.98865s/100 iters), loss = 0.00684557
I0408 11:47:22.479298  9985 solver.cpp:238]     Train net output #0: loss = 0.00684583 (* 1 = 0.00684583 loss)
I0408 11:47:22.479324  9985 sgd_solver.cpp:105] Iteration 3500, lr = 0.00798454
I0408 11:47:25.271054  9985 solver.cpp:219] Iteration 3600 (35.8206 iter/s, 2.79169s/100 iters), loss = 0.0434902
I0408 11:47:25.271083  9985 solver.cpp:238]     Train net output #0: loss = 0.0434904 (* 1 = 0.0434904 loss)
I0408 11:47:25.271087  9985 sgd_solver.cpp:105] Iteration 3600, lr = 0.00794046
I0408 11:47:28.059204  9985 solver.cpp:219] Iteration 3700 (35.8673 iter/s, 2.78805s/100 iters), loss = 0.0487422
I0408 11:47:28.059232  9985 solver.cpp:238]     Train net output #0: loss = 0.0487424 (* 1 = 0.0487424 loss)
I0408 11:47:28.059237  9985 sgd_solver.cpp:105] Iteration 3700, lr = 0.00789695
I0408 11:47:29.317533  9992 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:47:30.861070  9985 solver.cpp:219] Iteration 3800 (35.6917 iter/s, 2.80177s/100 iters), loss = 0.0110005
I0408 11:47:30.861116  9985 solver.cpp:238]     Train net output #0: loss = 0.0110008 (* 1 = 0.0110008 loss)
I0408 11:47:30.861121  9985 sgd_solver.cpp:105] Iteration 3800, lr = 0.007854
I0408 11:47:33.657414  9985 solver.cpp:219] Iteration 3900 (35.7624 iter/s, 2.79623s/100 iters), loss = 0.0915544
I0408 11:47:33.657443  9985 solver.cpp:238]     Train net output #0: loss = 0.0915546 (* 1 = 0.0915546 loss)
I0408 11:47:33.657447  9985 sgd_solver.cpp:105] Iteration 3900, lr = 0.00781158
I0408 11:47:36.402467  9985 solver.cpp:331] Iteration 4000, Testing net (#0)
I0408 11:47:38.514799  9993 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:47:38.610257  9985 solver.cpp:398]     Test net output #0: accuracy = 0.986
I0408 11:47:38.610281  9985 solver.cpp:398]     Test net output #1: loss = 0.0413974 (* 1 = 0.0413974 loss)
I0408 11:47:38.637792  9985 solver.cpp:219] Iteration 4000 (20.0794 iter/s, 4.98024s/100 iters), loss = 0.0506862
I0408 11:47:38.637837  9985 solver.cpp:238]     Train net output #0: loss = 0.0506864 (* 1 = 0.0506864 loss)
I0408 11:47:38.637845  9985 sgd_solver.cpp:105] Iteration 4000, lr = 0.0077697
I0408 11:47:41.428555  9985 solver.cpp:219] Iteration 4100 (35.8336 iter/s, 2.79067s/100 iters), loss = 0.0281166
I0408 11:47:41.428583  9985 solver.cpp:238]     Train net output #0: loss = 0.0281169 (* 1 = 0.0281169 loss)
I0408 11:47:41.428587  9985 sgd_solver.cpp:105] Iteration 4100, lr = 0.00772833
I0408 11:47:44.223271  9985 solver.cpp:219] Iteration 4200 (35.783 iter/s, 2.79462s/100 iters), loss = 0.00989493
I0408 11:47:44.223299  9985 solver.cpp:238]     Train net output #0: loss = 0.00989515 (* 1 = 0.00989515 loss)
I0408 11:47:44.223304  9985 sgd_solver.cpp:105] Iteration 4200, lr = 0.00768748
I0408 11:47:47.007171  9985 solver.cpp:219] Iteration 4300 (35.9221 iter/s, 2.78381s/100 iters), loss = 0.0848612
I0408 11:47:47.007200  9985 solver.cpp:238]     Train net output #0: loss = 0.0848614 (* 1 = 0.0848614 loss)
I0408 11:47:47.007205  9985 sgd_solver.cpp:105] Iteration 4300, lr = 0.00764712
I0408 11:47:49.790526  9985 solver.cpp:219] Iteration 4400 (35.9291 iter/s, 2.78326s/100 iters), loss = 0.0303008
I0408 11:47:49.790555  9985 solver.cpp:238]     Train net output #0: loss = 0.0303011 (* 1 = 0.0303011 loss)
I0408 11:47:49.790558  9985 sgd_solver.cpp:105] Iteration 4400, lr = 0.00760726
I0408 11:47:52.538807  9985 solver.cpp:331] Iteration 4500, Testing net (#0)
I0408 11:47:54.659255  9993 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:47:54.753563  9985 solver.cpp:398]     Test net output #0: accuracy = 0.9838
I0408 11:47:54.753587  9985 solver.cpp:398]     Test net output #1: loss = 0.0482657 (* 1 = 0.0482657 loss)
I0408 11:47:54.781549  9985 solver.cpp:219] Iteration 4500 (20.0365 iter/s, 4.99089s/100 iters), loss = 0.0138226
I0408 11:47:54.781574  9985 solver.cpp:238]     Train net output #0: loss = 0.0138229 (* 1 = 0.0138229 loss)
I0408 11:47:54.781581  9985 sgd_solver.cpp:105] Iteration 4500, lr = 0.00756788
I0408 11:47:57.571202  9985 solver.cpp:219] Iteration 4600 (35.8755 iter/s, 2.78741s/100 iters), loss = 0.0127184
I0408 11:47:57.571229  9985 solver.cpp:238]     Train net output #0: loss = 0.0127186 (* 1 = 0.0127186 loss)
I0408 11:47:57.571234  9985 sgd_solver.cpp:105] Iteration 4600, lr = 0.00752897
I0408 11:47:59.883796  9992 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:48:00.366832  9985 solver.cpp:219] Iteration 4700 (35.7713 iter/s, 2.79554s/100 iters), loss = 0.00981411
I0408 11:48:00.366858  9985 solver.cpp:238]     Train net output #0: loss = 0.00981438 (* 1 = 0.00981438 loss)
I0408 11:48:00.366863  9985 sgd_solver.cpp:105] Iteration 4700, lr = 0.00749052
I0408 11:48:03.147975  9985 solver.cpp:219] Iteration 4800 (35.9576 iter/s, 2.78105s/100 iters), loss = 0.0559852
I0408 11:48:03.148020  9985 solver.cpp:238]     Train net output #0: loss = 0.0559855 (* 1 = 0.0559855 loss)
I0408 11:48:03.148025  9985 sgd_solver.cpp:105] Iteration 4800, lr = 0.00745253
I0408 11:48:05.932227  9985 solver.cpp:219] Iteration 4900 (35.9177 iter/s, 2.78414s/100 iters), loss = 0.00689434
I0408 11:48:05.932256  9985 solver.cpp:238]     Train net output #0: loss = 0.00689462 (* 1 = 0.00689462 loss)
I0408 11:48:05.932261  9985 sgd_solver.cpp:105] Iteration 4900, lr = 0.00741498
I0408 11:48:08.680245  9985 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_5000.caffemodel
I0408 11:48:08.693346  9985 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_5000.solverstate
I0408 11:48:08.693884  9985 solver.cpp:331] Iteration 5000, Testing net (#0)
I0408 11:48:10.806753  9993 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:48:10.900806  9985 solver.cpp:398]     Test net output #0: accuracy = 0.9864
I0408 11:48:10.900830  9985 solver.cpp:398]     Test net output #1: loss = 0.0417644 (* 1 = 0.0417644 loss)
I0408 11:48:10.928360  9985 solver.cpp:219] Iteration 5000 (20.016 iter/s, 4.996s/100 iters), loss = 0.0544118
I0408 11:48:10.928390  9985 solver.cpp:238]     Train net output #0: loss = 0.0544121 (* 1 = 0.0544121 loss)
I0408 11:48:10.928416  9985 sgd_solver.cpp:105] Iteration 5000, lr = 0.00737788
I0408 11:48:13.720075  9985 solver.cpp:219] Iteration 5100 (35.8214 iter/s, 2.79163s/100 iters), loss = 0.0972443
I0408 11:48:13.720104  9985 solver.cpp:238]     Train net output #0: loss = 0.0972447 (* 1 = 0.0972447 loss)
I0408 11:48:13.720108  9985 sgd_solver.cpp:105] Iteration 5100, lr = 0.0073412
I0408 11:48:16.508517  9985 solver.cpp:219] Iteration 5200 (35.8635 iter/s, 2.78835s/100 iters), loss = 0.0806652
I0408 11:48:16.508545  9985 solver.cpp:238]     Train net output #0: loss = 0.0806655 (* 1 = 0.0806655 loss)
I0408 11:48:16.508550  9985 sgd_solver.cpp:105] Iteration 5200, lr = 0.00730495
I0408 11:48:19.293751  9985 solver.cpp:219] Iteration 5300 (35.9047 iter/s, 2.78515s/100 iters), loss = 0.00474738
I0408 11:48:19.293781  9985 solver.cpp:238]     Train net output #0: loss = 0.0047477 (* 1 = 0.0047477 loss)
I0408 11:48:19.293787  9985 sgd_solver.cpp:105] Iteration 5300, lr = 0.00726911
I0408 11:48:22.081178  9985 solver.cpp:219] Iteration 5400 (35.8765 iter/s, 2.78734s/100 iters), loss = 0.0631891
I0408 11:48:22.081209  9985 solver.cpp:238]     Train net output #0: loss = 0.0631895 (* 1 = 0.0631895 loss)
I0408 11:48:22.081215  9985 sgd_solver.cpp:105] Iteration 5400, lr = 0.00723368
I0408 11:48:24.826728  9985 solver.cpp:331] Iteration 5500, Testing net (#0)
I0408 11:48:26.944317  9993 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:48:27.038816  9985 solver.cpp:398]     Test net output #0: accuracy = 0.9861
I0408 11:48:27.038841  9985 solver.cpp:398]     Test net output #1: loss = 0.043619 (* 1 = 0.043619 loss)
I0408 11:48:27.066857  9985 solver.cpp:219] Iteration 5500 (20.058 iter/s, 4.98555s/100 iters), loss = 0.0203677
I0408 11:48:27.066881  9985 solver.cpp:238]     Train net output #0: loss = 0.020368 (* 1 = 0.020368 loss)
I0408 11:48:27.066889  9985 sgd_solver.cpp:105] Iteration 5500, lr = 0.00719865
I0408 11:48:29.863034  9985 solver.cpp:219] Iteration 5600 (35.7919 iter/s, 2.79393s/100 iters), loss = 0.00316124
I0408 11:48:29.863065  9985 solver.cpp:238]     Train net output #0: loss = 0.00316159 (* 1 = 0.00316159 loss)
I0408 11:48:29.863071  9985 sgd_solver.cpp:105] Iteration 5600, lr = 0.00716402
I0408 11:48:30.426175  9992 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:48:32.654176  9985 solver.cpp:219] Iteration 5700 (35.8288 iter/s, 2.79105s/100 iters), loss = 0.0288352
I0408 11:48:32.654206  9985 solver.cpp:238]     Train net output #0: loss = 0.0288355 (* 1 = 0.0288355 loss)
I0408 11:48:32.654213  9985 sgd_solver.cpp:105] Iteration 5700, lr = 0.00712977
I0408 11:48:35.445119  9985 solver.cpp:219] Iteration 5800 (35.8313 iter/s, 2.79085s/100 iters), loss = 0.0640218
I0408 11:48:35.445153  9985 solver.cpp:238]     Train net output #0: loss = 0.0640222 (* 1 = 0.0640222 loss)
I0408 11:48:35.445188  9985 sgd_solver.cpp:105] Iteration 5800, lr = 0.0070959
I0408 11:48:38.243127  9985 solver.cpp:219] Iteration 5900 (35.7409 iter/s, 2.79791s/100 iters), loss = 0.0193043
I0408 11:48:38.243160  9985 solver.cpp:238]     Train net output #0: loss = 0.0193046 (* 1 = 0.0193046 loss)
I0408 11:48:38.243166  9985 sgd_solver.cpp:105] Iteration 5900, lr = 0.0070624
I0408 11:48:40.999348  9985 solver.cpp:331] Iteration 6000, Testing net (#0)
I0408 11:48:43.114131  9993 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:48:43.207847  9985 solver.cpp:398]     Test net output #0: accuracy = 0.9876
I0408 11:48:43.207872  9985 solver.cpp:398]     Test net output #1: loss = 0.0362253 (* 1 = 0.0362253 loss)
I0408 11:48:43.235754  9985 solver.cpp:219] Iteration 6000 (20.03 iter/s, 4.9925s/100 iters), loss = 0.0118251
I0408 11:48:43.235776  9985 solver.cpp:238]     Train net output #0: loss = 0.0118254 (* 1 = 0.0118254 loss)
I0408 11:48:43.235785  9985 sgd_solver.cpp:105] Iteration 6000, lr = 0.00702927
I0408 11:48:46.033932  9985 solver.cpp:219] Iteration 6100 (35.7661 iter/s, 2.79594s/100 iters), loss = 0.00682828
I0408 11:48:46.033963  9985 solver.cpp:238]     Train net output #0: loss = 0.00682861 (* 1 = 0.00682861 loss)
I0408 11:48:46.033970  9985 sgd_solver.cpp:105] Iteration 6100, lr = 0.0069965
I0408 11:48:48.822129  9985 solver.cpp:219] Iteration 6200 (35.8666 iter/s, 2.78811s/100 iters), loss = 0.0135353
I0408 11:48:48.822160  9985 solver.cpp:238]     Train net output #0: loss = 0.0135357 (* 1 = 0.0135357 loss)
I0408 11:48:48.822166  9985 sgd_solver.cpp:105] Iteration 6200, lr = 0.00696408
I0408 11:48:51.608784  9985 solver.cpp:219] Iteration 6300 (35.8865 iter/s, 2.78656s/100 iters), loss = 0.0094822
I0408 11:48:51.608822  9985 solver.cpp:238]     Train net output #0: loss = 0.00948254 (* 1 = 0.00948254 loss)
I0408 11:48:51.608830  9985 sgd_solver.cpp:105] Iteration 6300, lr = 0.00693201
I0408 11:48:54.392335  9985 solver.cpp:219] Iteration 6400 (35.9265 iter/s, 2.78346s/100 iters), loss = 0.0378227
I0408 11:48:54.392364  9985 solver.cpp:238]     Train net output #0: loss = 0.037823 (* 1 = 0.037823 loss)
I0408 11:48:54.392370  9985 sgd_solver.cpp:105] Iteration 6400, lr = 0.00690029
I0408 11:48:57.140300  9985 solver.cpp:331] Iteration 6500, Testing net (#0)
I0408 11:48:59.258958  9993 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:48:59.354586  9985 solver.cpp:398]     Test net output #0: accuracy = 0.9863
I0408 11:48:59.354609  9985 solver.cpp:398]     Test net output #1: loss = 0.0414816 (* 1 = 0.0414816 loss)
I0408 11:48:59.382594  9985 solver.cpp:219] Iteration 6500 (20.0395 iter/s, 4.99014s/100 iters), loss = 0.0101445
I0408 11:48:59.382617  9985 solver.cpp:238]     Train net output #0: loss = 0.0101448 (* 1 = 0.0101448 loss)
I0408 11:48:59.382625  9985 sgd_solver.cpp:105] Iteration 6500, lr = 0.0068689
I0408 11:49:01.011387  9992 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:49:02.187482  9985 solver.cpp:219] Iteration 6600 (35.6805 iter/s, 2.80265s/100 iters), loss = 0.0344354
I0408 11:49:02.187510  9985 solver.cpp:238]     Train net output #0: loss = 0.0344358 (* 1 = 0.0344358 loss)
I0408 11:49:02.187532  9985 sgd_solver.cpp:105] Iteration 6600, lr = 0.00683784
I0408 11:49:04.978003  9985 solver.cpp:219] Iteration 6700 (35.8367 iter/s, 2.79044s/100 iters), loss = 0.0331974
I0408 11:49:04.978049  9985 solver.cpp:238]     Train net output #0: loss = 0.0331977 (* 1 = 0.0331977 loss)
I0408 11:49:04.978055  9985 sgd_solver.cpp:105] Iteration 6700, lr = 0.00680711
I0408 11:49:07.766119  9985 solver.cpp:219] Iteration 6800 (35.8679 iter/s, 2.78801s/100 iters), loss = 0.0189747
I0408 11:49:07.766147  9985 solver.cpp:238]     Train net output #0: loss = 0.018975 (* 1 = 0.018975 loss)
I0408 11:49:07.766170  9985 sgd_solver.cpp:105] Iteration 6800, lr = 0.0067767
I0408 11:49:10.553328  9985 solver.cpp:219] Iteration 6900 (35.8792 iter/s, 2.78713s/100 iters), loss = 0.0133014
I0408 11:49:10.553355  9985 solver.cpp:238]     Train net output #0: loss = 0.0133017 (* 1 = 0.0133017 loss)
I0408 11:49:10.553360  9985 sgd_solver.cpp:105] Iteration 6900, lr = 0.0067466
I0408 11:49:13.303529  9985 solver.cpp:331] Iteration 7000, Testing net (#0)
I0408 11:49:15.422433  9993 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:49:15.516168  9985 solver.cpp:398]     Test net output #0: accuracy = 0.9863
I0408 11:49:15.516193  9985 solver.cpp:398]     Test net output #1: loss = 0.0387184 (* 1 = 0.0387184 loss)
I0408 11:49:15.543786  9985 solver.cpp:219] Iteration 7000 (20.0387 iter/s, 4.99034s/100 iters), loss = 0.0500214
I0408 11:49:15.543803  9985 solver.cpp:238]     Train net output #0: loss = 0.0500217 (* 1 = 0.0500217 loss)
I0408 11:49:15.543809  9985 sgd_solver.cpp:105] Iteration 7000, lr = 0.00671681
I0408 11:49:18.338033  9985 solver.cpp:219] Iteration 7100 (35.7887 iter/s, 2.79418s/100 iters), loss = 0.0629965
I0408 11:49:18.338060  9985 solver.cpp:238]     Train net output #0: loss = 0.0629968 (* 1 = 0.0629968 loss)
I0408 11:49:18.338064  9985 sgd_solver.cpp:105] Iteration 7100, lr = 0.00668733
I0408 11:49:21.125494  9985 solver.cpp:219] Iteration 7200 (35.876 iter/s, 2.78738s/100 iters), loss = 0.0101964
I0408 11:49:21.125538  9985 solver.cpp:238]     Train net output #0: loss = 0.0101967 (* 1 = 0.0101967 loss)
I0408 11:49:21.125556  9985 sgd_solver.cpp:105] Iteration 7200, lr = 0.00665815
I0408 11:49:23.916378  9985 solver.cpp:219] Iteration 7300 (35.8322 iter/s, 2.79078s/100 iters), loss = 0.0620623
I0408 11:49:23.916406  9985 solver.cpp:238]     Train net output #0: loss = 0.0620626 (* 1 = 0.0620626 loss)
I0408 11:49:23.916411  9985 sgd_solver.cpp:105] Iteration 7300, lr = 0.00662927
I0408 11:49:26.701494  9985 solver.cpp:219] Iteration 7400 (35.9062 iter/s, 2.78503s/100 iters), loss = 0.0575061
I0408 11:49:26.701540  9985 solver.cpp:238]     Train net output #0: loss = 0.0575064 (* 1 = 0.0575064 loss)
I0408 11:49:26.701546  9985 sgd_solver.cpp:105] Iteration 7400, lr = 0.00660067
I0408 11:49:29.353536  9992 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:49:29.460052  9985 solver.cpp:331] Iteration 7500, Testing net (#0)
I0408 11:49:31.578805  9993 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:49:31.673530  9985 solver.cpp:398]     Test net output #0: accuracy = 0.9857
I0408 11:49:31.673573  9985 solver.cpp:398]     Test net output #1: loss = 0.0404123 (* 1 = 0.0404123 loss)
I0408 11:49:31.701591  9985 solver.cpp:219] Iteration 7500 (20.0001 iter/s, 4.99996s/100 iters), loss = 0.00864911
I0408 11:49:31.701608  9985 solver.cpp:238]     Train net output #0: loss = 0.00864946 (* 1 = 0.00864946 loss)
I0408 11:49:31.701614  9985 sgd_solver.cpp:105] Iteration 7500, lr = 0.00657236
I0408 11:49:34.496495  9985 solver.cpp:219] Iteration 7600 (35.808 iter/s, 2.79267s/100 iters), loss = 0.0701475
I0408 11:49:34.496523  9985 solver.cpp:238]     Train net output #0: loss = 0.0701479 (* 1 = 0.0701479 loss)
I0408 11:49:34.496527  9985 sgd_solver.cpp:105] Iteration 7600, lr = 0.00654433
I0408 11:49:37.287333  9985 solver.cpp:219] Iteration 7700 (35.8326 iter/s, 2.79075s/100 iters), loss = 0.0291526
I0408 11:49:37.287361  9985 solver.cpp:238]     Train net output #0: loss = 0.029153 (* 1 = 0.029153 loss)
I0408 11:49:37.287365  9985 sgd_solver.cpp:105] Iteration 7700, lr = 0.00651658
I0408 11:49:40.071530  9985 solver.cpp:219] Iteration 7800 (35.918 iter/s, 2.78412s/100 iters), loss = 0.0204006
I0408 11:49:40.071558  9985 solver.cpp:238]     Train net output #0: loss = 0.0204009 (* 1 = 0.0204009 loss)
I0408 11:49:40.071564  9985 sgd_solver.cpp:105] Iteration 7800, lr = 0.00648911
I0408 11:49:42.880756  9985 solver.cpp:219] Iteration 7900 (35.598 iter/s, 2.80914s/100 iters), loss = 0.0104067
I0408 11:49:42.880800  9985 solver.cpp:238]     Train net output #0: loss = 0.0104071 (* 1 = 0.0104071 loss)
I0408 11:49:42.880805  9985 sgd_solver.cpp:105] Iteration 7900, lr = 0.0064619
I0408 11:49:45.628067  9985 solver.cpp:331] Iteration 8000, Testing net (#0)
I0408 11:49:47.748908  9993 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:49:47.842142  9985 solver.cpp:398]     Test net output #0: accuracy = 0.987
I0408 11:49:47.842164  9985 solver.cpp:398]     Test net output #1: loss = 0.0385894 (* 1 = 0.0385894 loss)
I0408 11:49:47.874764  9985 solver.cpp:219] Iteration 8000 (20.0245 iter/s, 4.99388s/100 iters), loss = 0.0441845
I0408 11:49:47.874785  9985 solver.cpp:238]     Train net output #0: loss = 0.0441849 (* 1 = 0.0441849 loss)
I0408 11:49:47.874791  9985 sgd_solver.cpp:105] Iteration 8000, lr = 0.00643496
I0408 11:49:50.666501  9985 solver.cpp:219] Iteration 8100 (35.8486 iter/s, 2.78951s/100 iters), loss = 0.0702996
I0408 11:49:50.666529  9985 solver.cpp:238]     Train net output #0: loss = 0.0703 (* 1 = 0.0703 loss)
I0408 11:49:50.666533  9985 sgd_solver.cpp:105] Iteration 8100, lr = 0.00640827
I0408 11:49:53.462862  9985 solver.cpp:219] Iteration 8200 (35.7618 iter/s, 2.79628s/100 iters), loss = 0.0114942
I0408 11:49:53.462890  9985 solver.cpp:238]     Train net output #0: loss = 0.0114946 (* 1 = 0.0114946 loss)
I0408 11:49:53.462913  9985 sgd_solver.cpp:105] Iteration 8200, lr = 0.00638185
I0408 11:49:56.251271  9985 solver.cpp:219] Iteration 8300 (35.8638 iter/s, 2.78833s/100 iters), loss = 0.056487
I0408 11:49:56.251298  9985 solver.cpp:238]     Train net output #0: loss = 0.0564874 (* 1 = 0.0564874 loss)
I0408 11:49:56.251302  9985 sgd_solver.cpp:105] Iteration 8300, lr = 0.00635567
I0408 11:49:59.039803  9985 solver.cpp:219] Iteration 8400 (35.8622 iter/s, 2.78845s/100 iters), loss = 0.0434017
I0408 11:49:59.039846  9985 solver.cpp:238]     Train net output #0: loss = 0.0434021 (* 1 = 0.0434021 loss)
I0408 11:49:59.039850  9985 sgd_solver.cpp:105] Iteration 8400, lr = 0.00632975
I0408 11:49:59.964556  9992 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:50:01.796979  9985 solver.cpp:331] Iteration 8500, Testing net (#0)
I0408 11:50:03.921635  9993 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:50:04.015535  9985 solver.cpp:398]     Test net output #0: accuracy = 0.987
I0408 11:50:04.015576  9985 solver.cpp:398]     Test net output #1: loss = 0.0391491 (* 1 = 0.0391491 loss)
I0408 11:50:04.043469  9985 solver.cpp:219] Iteration 8500 (19.9858 iter/s, 5.00355s/100 iters), loss = 0.0232832
I0408 11:50:04.043512  9985 solver.cpp:238]     Train net output #0: loss = 0.0232836 (* 1 = 0.0232836 loss)
I0408 11:50:04.043519  9985 sgd_solver.cpp:105] Iteration 8500, lr = 0.00630407
I0408 11:50:06.835181  9985 solver.cpp:219] Iteration 8600 (35.8492 iter/s, 2.78947s/100 iters), loss = 0.00172017
I0408 11:50:06.835211  9985 solver.cpp:238]     Train net output #0: loss = 0.00172055 (* 1 = 0.00172055 loss)
I0408 11:50:06.835216  9985 sgd_solver.cpp:105] Iteration 8600, lr = 0.00627864
I0408 11:50:09.630687  9985 solver.cpp:219] Iteration 8700 (35.7727 iter/s, 2.79542s/100 iters), loss = 0.00507413
I0408 11:50:09.630715  9985 solver.cpp:238]     Train net output #0: loss = 0.00507453 (* 1 = 0.00507453 loss)
I0408 11:50:09.630719  9985 sgd_solver.cpp:105] Iteration 8700, lr = 0.00625344
I0408 11:50:12.414037  9985 solver.cpp:219] Iteration 8800 (35.929 iter/s, 2.78327s/100 iters), loss = 0.00897231
I0408 11:50:12.414065  9985 solver.cpp:238]     Train net output #0: loss = 0.00897271 (* 1 = 0.00897271 loss)
I0408 11:50:12.414070  9985 sgd_solver.cpp:105] Iteration 8800, lr = 0.00622847
I0408 11:50:15.225153  9985 solver.cpp:219] Iteration 8900 (35.5741 iter/s, 2.81104s/100 iters), loss = 0.00400923
I0408 11:50:15.225181  9985 solver.cpp:238]     Train net output #0: loss = 0.00400962 (* 1 = 0.00400962 loss)
I0408 11:50:15.225186  9985 sgd_solver.cpp:105] Iteration 8900, lr = 0.00620374
I0408 11:50:17.975893  9985 solver.cpp:331] Iteration 9000, Testing net (#0)
I0408 11:50:20.091900  9993 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:50:20.186432  9985 solver.cpp:398]     Test net output #0: accuracy = 0.9876
I0408 11:50:20.186457  9985 solver.cpp:398]     Test net output #1: loss = 0.0375089 (* 1 = 0.0375089 loss)
I0408 11:50:20.214382  9985 solver.cpp:219] Iteration 9000 (20.0436 iter/s, 4.98912s/100 iters), loss = 0.0292944
I0408 11:50:20.214407  9985 solver.cpp:238]     Train net output #0: loss = 0.0292948 (* 1 = 0.0292948 loss)
I0408 11:50:20.214432  9985 sgd_solver.cpp:105] Iteration 9000, lr = 0.00617924
I0408 11:50:23.004111  9985 solver.cpp:219] Iteration 9100 (35.8744 iter/s, 2.7875s/100 iters), loss = 0.0434946
I0408 11:50:23.004139  9985 solver.cpp:238]     Train net output #0: loss = 0.043495 (* 1 = 0.043495 loss)
I0408 11:50:23.004144  9985 sgd_solver.cpp:105] Iteration 9100, lr = 0.00615496
I0408 11:50:25.792662  9985 solver.cpp:219] Iteration 9200 (35.8619 iter/s, 2.78847s/100 iters), loss = 0.0159435
I0408 11:50:25.792709  9985 solver.cpp:238]     Train net output #0: loss = 0.0159439 (* 1 = 0.0159439 loss)
I0408 11:50:25.792714  9985 sgd_solver.cpp:105] Iteration 9200, lr = 0.0061309
I0408 11:50:28.579789  9985 solver.cpp:219] Iteration 9300 (35.8804 iter/s, 2.78704s/100 iters), loss = 0.00831004
I0408 11:50:28.579818  9985 solver.cpp:238]     Train net output #0: loss = 0.00831042 (* 1 = 0.00831042 loss)
I0408 11:50:28.579823  9985 sgd_solver.cpp:105] Iteration 9300, lr = 0.00610706
I0408 11:50:30.531584  9992 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:50:31.371395  9985 solver.cpp:219] Iteration 9400 (35.8227 iter/s, 2.79153s/100 iters), loss = 0.0815984
I0408 11:50:31.371423  9985 solver.cpp:238]     Train net output #0: loss = 0.0815988 (* 1 = 0.0815988 loss)
I0408 11:50:31.371428  9985 sgd_solver.cpp:105] Iteration 9400, lr = 0.00608343
I0408 11:50:34.129696  9985 solver.cpp:331] Iteration 9500, Testing net (#0)
I0408 11:50:36.256827  9993 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:50:36.350867  9985 solver.cpp:398]     Test net output #0: accuracy = 0.9885
I0408 11:50:36.350888  9985 solver.cpp:398]     Test net output #1: loss = 0.03853 (* 1 = 0.03853 loss)
I0408 11:50:36.378459  9985 solver.cpp:219] Iteration 9500 (19.9722 iter/s, 5.00696s/100 iters), loss = 0.00891825
I0408 11:50:36.378479  9985 solver.cpp:238]     Train net output #0: loss = 0.00891862 (* 1 = 0.00891862 loss)
I0408 11:50:36.378484  9985 sgd_solver.cpp:105] Iteration 9500, lr = 0.00606002
I0408 11:50:39.180548  9985 solver.cpp:219] Iteration 9600 (35.6885 iter/s, 2.80202s/100 iters), loss = 0.00761242
I0408 11:50:39.180577  9985 solver.cpp:238]     Train net output #0: loss = 0.0076128 (* 1 = 0.0076128 loss)
I0408 11:50:39.180582  9985 sgd_solver.cpp:105] Iteration 9600, lr = 0.00603682
I0408 11:50:42.041096  9985 solver.cpp:219] Iteration 9700 (34.9593 iter/s, 2.86047s/100 iters), loss = 0.0115229
I0408 11:50:42.041124  9985 solver.cpp:238]     Train net output #0: loss = 0.0115232 (* 1 = 0.0115232 loss)
I0408 11:50:42.041128  9985 sgd_solver.cpp:105] Iteration 9700, lr = 0.00601382
I0408 11:50:44.833086  9985 solver.cpp:219] Iteration 9800 (35.8177 iter/s, 2.79191s/100 iters), loss = 0.0537419
I0408 11:50:44.833114  9985 solver.cpp:238]     Train net output #0: loss = 0.0537423 (* 1 = 0.0537423 loss)
I0408 11:50:44.833119  9985 sgd_solver.cpp:105] Iteration 9800, lr = 0.00599102
I0408 11:50:47.622879  9985 solver.cpp:219] Iteration 9900 (35.8459 iter/s, 2.78972s/100 iters), loss = 0.00712024
I0408 11:50:47.622908  9985 solver.cpp:238]     Train net output #0: loss = 0.00712062 (* 1 = 0.00712062 loss)
I0408 11:50:47.622912  9985 sgd_solver.cpp:105] Iteration 9900, lr = 0.00596843
I0408 11:50:50.375931  9985 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_10000.caffemodel
I0408 11:50:50.388582  9985 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_10000.solverstate
I0408 11:50:50.403048  9985 solver.cpp:311] Iteration 10000, loss = 0.00861146
I0408 11:50:50.403064  9985 solver.cpp:331] Iteration 10000, Testing net (#0)
I0408 11:50:52.519752  9993 data_layer.cpp:73] Restarting data prefetching from start.
I0408 11:50:52.613862  9985 solver.cpp:398]     Test net output #0: accuracy = 0.9866
I0408 11:50:52.613903  9985 solver.cpp:398]     Test net output #1: loss = 0.0389491 (* 1 = 0.0389491 loss)
I0408 11:50:52.613906  9985 solver.cpp:316] Optimization Done.
I0408 11:50:52.613909  9985 caffe.cpp:259] Optimization Done.
