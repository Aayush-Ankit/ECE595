I0426 20:51:07.725028 31915 caffe.cpp:218] Using GPUs 0
I0426 20:51:07.763909 31915 caffe.cpp:223] GPU 0: TITAN X (Pascal)
I0426 20:51:08.288226 31915 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 1000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_everything/lenet_train_test79.prototxt"
train_state {
  level: 0
  stage: ""
}
I0426 20:51:08.288370 31915 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_everything/lenet_train_test79.prototxt
I0426 20:51:08.288772 31915 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0426 20:51:08.288790 31915 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0426 20:51:08.288895 31915 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 10
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0426 20:51:08.288972 31915 layer_factory.hpp:77] Creating layer mnist
I0426 20:51:08.289075 31915 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0426 20:51:08.289098 31915 net.cpp:86] Creating Layer mnist
I0426 20:51:08.289106 31915 net.cpp:382] mnist -> data
I0426 20:51:08.289129 31915 net.cpp:382] mnist -> label
I0426 20:51:08.290313 31915 data_layer.cpp:45] output data size: 64,1,28,28
I0426 20:51:08.292915 31915 net.cpp:124] Setting up mnist
I0426 20:51:08.292933 31915 net.cpp:131] Top shape: 64 1 28 28 (50176)
I0426 20:51:08.292939 31915 net.cpp:131] Top shape: 64 (64)
I0426 20:51:08.292943 31915 net.cpp:139] Memory required for data: 200960
I0426 20:51:08.292951 31915 layer_factory.hpp:77] Creating layer conv0
I0426 20:51:08.292968 31915 net.cpp:86] Creating Layer conv0
I0426 20:51:08.292989 31915 net.cpp:408] conv0 <- data
I0426 20:51:08.293001 31915 net.cpp:382] conv0 -> conv0
I0426 20:51:08.543949 31915 net.cpp:124] Setting up conv0
I0426 20:51:08.543974 31915 net.cpp:131] Top shape: 64 10 24 24 (368640)
I0426 20:51:08.543978 31915 net.cpp:139] Memory required for data: 1675520
I0426 20:51:08.543992 31915 layer_factory.hpp:77] Creating layer pool0
I0426 20:51:08.544003 31915 net.cpp:86] Creating Layer pool0
I0426 20:51:08.544008 31915 net.cpp:408] pool0 <- conv0
I0426 20:51:08.544013 31915 net.cpp:382] pool0 -> pool0
I0426 20:51:08.544071 31915 net.cpp:124] Setting up pool0
I0426 20:51:08.544076 31915 net.cpp:131] Top shape: 64 10 12 12 (92160)
I0426 20:51:08.544080 31915 net.cpp:139] Memory required for data: 2044160
I0426 20:51:08.544082 31915 layer_factory.hpp:77] Creating layer conv1
I0426 20:51:08.544092 31915 net.cpp:86] Creating Layer conv1
I0426 20:51:08.544095 31915 net.cpp:408] conv1 <- pool0
I0426 20:51:08.544100 31915 net.cpp:382] conv1 -> conv1
I0426 20:51:08.546775 31915 net.cpp:124] Setting up conv1
I0426 20:51:08.546804 31915 net.cpp:131] Top shape: 64 25 8 8 (102400)
I0426 20:51:08.546808 31915 net.cpp:139] Memory required for data: 2453760
I0426 20:51:08.546830 31915 layer_factory.hpp:77] Creating layer pool1
I0426 20:51:08.546838 31915 net.cpp:86] Creating Layer pool1
I0426 20:51:08.546841 31915 net.cpp:408] pool1 <- conv1
I0426 20:51:08.546845 31915 net.cpp:382] pool1 -> pool1
I0426 20:51:08.546911 31915 net.cpp:124] Setting up pool1
I0426 20:51:08.546916 31915 net.cpp:131] Top shape: 64 25 4 4 (25600)
I0426 20:51:08.546919 31915 net.cpp:139] Memory required for data: 2556160
I0426 20:51:08.546921 31915 layer_factory.hpp:77] Creating layer ip1
I0426 20:51:08.546928 31915 net.cpp:86] Creating Layer ip1
I0426 20:51:08.546931 31915 net.cpp:408] ip1 <- pool1
I0426 20:51:08.546936 31915 net.cpp:382] ip1 -> ip1
I0426 20:51:08.547253 31915 net.cpp:124] Setting up ip1
I0426 20:51:08.547274 31915 net.cpp:131] Top shape: 64 100 (6400)
I0426 20:51:08.547277 31915 net.cpp:139] Memory required for data: 2581760
I0426 20:51:08.547299 31915 layer_factory.hpp:77] Creating layer relu1
I0426 20:51:08.547304 31915 net.cpp:86] Creating Layer relu1
I0426 20:51:08.547307 31915 net.cpp:408] relu1 <- ip1
I0426 20:51:08.547312 31915 net.cpp:369] relu1 -> ip1 (in-place)
I0426 20:51:08.547477 31915 net.cpp:124] Setting up relu1
I0426 20:51:08.547485 31915 net.cpp:131] Top shape: 64 100 (6400)
I0426 20:51:08.547489 31915 net.cpp:139] Memory required for data: 2607360
I0426 20:51:08.547492 31915 layer_factory.hpp:77] Creating layer ip2
I0426 20:51:08.547497 31915 net.cpp:86] Creating Layer ip2
I0426 20:51:08.547502 31915 net.cpp:408] ip2 <- ip1
I0426 20:51:08.547507 31915 net.cpp:382] ip2 -> ip2
I0426 20:51:08.547780 31915 net.cpp:124] Setting up ip2
I0426 20:51:08.547788 31915 net.cpp:131] Top shape: 64 300 (19200)
I0426 20:51:08.547791 31915 net.cpp:139] Memory required for data: 2684160
I0426 20:51:08.547797 31915 layer_factory.hpp:77] Creating layer relu2
I0426 20:51:08.547803 31915 net.cpp:86] Creating Layer relu2
I0426 20:51:08.547806 31915 net.cpp:408] relu2 <- ip2
I0426 20:51:08.547811 31915 net.cpp:369] relu2 -> ip2 (in-place)
I0426 20:51:08.548583 31915 net.cpp:124] Setting up relu2
I0426 20:51:08.548593 31915 net.cpp:131] Top shape: 64 300 (19200)
I0426 20:51:08.548611 31915 net.cpp:139] Memory required for data: 2760960
I0426 20:51:08.548615 31915 layer_factory.hpp:77] Creating layer ip3
I0426 20:51:08.548621 31915 net.cpp:86] Creating Layer ip3
I0426 20:51:08.548640 31915 net.cpp:408] ip3 <- ip2
I0426 20:51:08.548645 31915 net.cpp:382] ip3 -> ip3
I0426 20:51:08.549701 31915 net.cpp:124] Setting up ip3
I0426 20:51:08.549713 31915 net.cpp:131] Top shape: 64 10 (640)
I0426 20:51:08.549731 31915 net.cpp:139] Memory required for data: 2763520
I0426 20:51:08.549739 31915 layer_factory.hpp:77] Creating layer relu3
I0426 20:51:08.549744 31915 net.cpp:86] Creating Layer relu3
I0426 20:51:08.549748 31915 net.cpp:408] relu3 <- ip3
I0426 20:51:08.549752 31915 net.cpp:369] relu3 -> ip3 (in-place)
I0426 20:51:08.549955 31915 net.cpp:124] Setting up relu3
I0426 20:51:08.549964 31915 net.cpp:131] Top shape: 64 10 (640)
I0426 20:51:08.549968 31915 net.cpp:139] Memory required for data: 2766080
I0426 20:51:08.549971 31915 layer_factory.hpp:77] Creating layer loss
I0426 20:51:08.549976 31915 net.cpp:86] Creating Layer loss
I0426 20:51:08.549979 31915 net.cpp:408] loss <- ip3
I0426 20:51:08.549983 31915 net.cpp:408] loss <- label
I0426 20:51:08.549988 31915 net.cpp:382] loss -> loss
I0426 20:51:08.550002 31915 layer_factory.hpp:77] Creating layer loss
I0426 20:51:08.550242 31915 net.cpp:124] Setting up loss
I0426 20:51:08.550251 31915 net.cpp:131] Top shape: (1)
I0426 20:51:08.550256 31915 net.cpp:134]     with loss weight 1
I0426 20:51:08.550269 31915 net.cpp:139] Memory required for data: 2766084
I0426 20:51:08.550272 31915 net.cpp:200] loss needs backward computation.
I0426 20:51:08.550276 31915 net.cpp:200] relu3 needs backward computation.
I0426 20:51:08.550279 31915 net.cpp:200] ip3 needs backward computation.
I0426 20:51:08.550282 31915 net.cpp:200] relu2 needs backward computation.
I0426 20:51:08.550285 31915 net.cpp:200] ip2 needs backward computation.
I0426 20:51:08.550288 31915 net.cpp:200] relu1 needs backward computation.
I0426 20:51:08.550292 31915 net.cpp:200] ip1 needs backward computation.
I0426 20:51:08.550294 31915 net.cpp:200] pool1 needs backward computation.
I0426 20:51:08.550297 31915 net.cpp:200] conv1 needs backward computation.
I0426 20:51:08.550300 31915 net.cpp:200] pool0 needs backward computation.
I0426 20:51:08.550303 31915 net.cpp:200] conv0 needs backward computation.
I0426 20:51:08.550307 31915 net.cpp:202] mnist does not need backward computation.
I0426 20:51:08.550310 31915 net.cpp:244] This network produces output loss
I0426 20:51:08.550319 31915 net.cpp:257] Network initialization done.
I0426 20:51:08.550626 31915 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_everything/lenet_train_test79.prototxt
I0426 20:51:08.550653 31915 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0426 20:51:08.550741 31915 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 10
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0426 20:51:08.550817 31915 layer_factory.hpp:77] Creating layer mnist
I0426 20:51:08.550861 31915 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0426 20:51:08.550873 31915 net.cpp:86] Creating Layer mnist
I0426 20:51:08.550878 31915 net.cpp:382] mnist -> data
I0426 20:51:08.550900 31915 net.cpp:382] mnist -> label
I0426 20:51:08.550981 31915 data_layer.cpp:45] output data size: 100,1,28,28
I0426 20:51:08.552971 31915 net.cpp:124] Setting up mnist
I0426 20:51:08.552999 31915 net.cpp:131] Top shape: 100 1 28 28 (78400)
I0426 20:51:08.553004 31915 net.cpp:131] Top shape: 100 (100)
I0426 20:51:08.553009 31915 net.cpp:139] Memory required for data: 314000
I0426 20:51:08.553012 31915 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0426 20:51:08.553019 31915 net.cpp:86] Creating Layer label_mnist_1_split
I0426 20:51:08.553022 31915 net.cpp:408] label_mnist_1_split <- label
I0426 20:51:08.553026 31915 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_0
I0426 20:51:08.553048 31915 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_1
I0426 20:51:08.553115 31915 net.cpp:124] Setting up label_mnist_1_split
I0426 20:51:08.553122 31915 net.cpp:131] Top shape: 100 (100)
I0426 20:51:08.553125 31915 net.cpp:131] Top shape: 100 (100)
I0426 20:51:08.553143 31915 net.cpp:139] Memory required for data: 314800
I0426 20:51:08.553146 31915 layer_factory.hpp:77] Creating layer conv0
I0426 20:51:08.553154 31915 net.cpp:86] Creating Layer conv0
I0426 20:51:08.553158 31915 net.cpp:408] conv0 <- data
I0426 20:51:08.553163 31915 net.cpp:382] conv0 -> conv0
I0426 20:51:08.554780 31915 net.cpp:124] Setting up conv0
I0426 20:51:08.554792 31915 net.cpp:131] Top shape: 100 10 24 24 (576000)
I0426 20:51:08.554796 31915 net.cpp:139] Memory required for data: 2618800
I0426 20:51:08.554805 31915 layer_factory.hpp:77] Creating layer pool0
I0426 20:51:08.554826 31915 net.cpp:86] Creating Layer pool0
I0426 20:51:08.554829 31915 net.cpp:408] pool0 <- conv0
I0426 20:51:08.554848 31915 net.cpp:382] pool0 -> pool0
I0426 20:51:08.554918 31915 net.cpp:124] Setting up pool0
I0426 20:51:08.554924 31915 net.cpp:131] Top shape: 100 10 12 12 (144000)
I0426 20:51:08.554926 31915 net.cpp:139] Memory required for data: 3194800
I0426 20:51:08.554929 31915 layer_factory.hpp:77] Creating layer conv1
I0426 20:51:08.554939 31915 net.cpp:86] Creating Layer conv1
I0426 20:51:08.554942 31915 net.cpp:408] conv1 <- pool0
I0426 20:51:08.554949 31915 net.cpp:382] conv1 -> conv1
I0426 20:51:08.557298 31915 net.cpp:124] Setting up conv1
I0426 20:51:08.557312 31915 net.cpp:131] Top shape: 100 25 8 8 (160000)
I0426 20:51:08.557317 31915 net.cpp:139] Memory required for data: 3834800
I0426 20:51:08.557325 31915 layer_factory.hpp:77] Creating layer pool1
I0426 20:51:08.557332 31915 net.cpp:86] Creating Layer pool1
I0426 20:51:08.557334 31915 net.cpp:408] pool1 <- conv1
I0426 20:51:08.557363 31915 net.cpp:382] pool1 -> pool1
I0426 20:51:08.557399 31915 net.cpp:124] Setting up pool1
I0426 20:51:08.557404 31915 net.cpp:131] Top shape: 100 25 4 4 (40000)
I0426 20:51:08.557409 31915 net.cpp:139] Memory required for data: 3994800
I0426 20:51:08.557411 31915 layer_factory.hpp:77] Creating layer ip1
I0426 20:51:08.557416 31915 net.cpp:86] Creating Layer ip1
I0426 20:51:08.557420 31915 net.cpp:408] ip1 <- pool1
I0426 20:51:08.557425 31915 net.cpp:382] ip1 -> ip1
I0426 20:51:08.557780 31915 net.cpp:124] Setting up ip1
I0426 20:51:08.557790 31915 net.cpp:131] Top shape: 100 100 (10000)
I0426 20:51:08.557802 31915 net.cpp:139] Memory required for data: 4034800
I0426 20:51:08.557809 31915 layer_factory.hpp:77] Creating layer relu1
I0426 20:51:08.557814 31915 net.cpp:86] Creating Layer relu1
I0426 20:51:08.557817 31915 net.cpp:408] relu1 <- ip1
I0426 20:51:08.557821 31915 net.cpp:369] relu1 -> ip1 (in-place)
I0426 20:51:08.557987 31915 net.cpp:124] Setting up relu1
I0426 20:51:08.557996 31915 net.cpp:131] Top shape: 100 100 (10000)
I0426 20:51:08.558007 31915 net.cpp:139] Memory required for data: 4074800
I0426 20:51:08.558012 31915 layer_factory.hpp:77] Creating layer ip2
I0426 20:51:08.558017 31915 net.cpp:86] Creating Layer ip2
I0426 20:51:08.558022 31915 net.cpp:408] ip2 <- ip1
I0426 20:51:08.558027 31915 net.cpp:382] ip2 -> ip2
I0426 20:51:08.558321 31915 net.cpp:124] Setting up ip2
I0426 20:51:08.558329 31915 net.cpp:131] Top shape: 100 300 (30000)
I0426 20:51:08.558332 31915 net.cpp:139] Memory required for data: 4194800
I0426 20:51:08.558338 31915 layer_factory.hpp:77] Creating layer relu2
I0426 20:51:08.558349 31915 net.cpp:86] Creating Layer relu2
I0426 20:51:08.558353 31915 net.cpp:408] relu2 <- ip2
I0426 20:51:08.558357 31915 net.cpp:369] relu2 -> ip2 (in-place)
I0426 20:51:08.558502 31915 net.cpp:124] Setting up relu2
I0426 20:51:08.558511 31915 net.cpp:131] Top shape: 100 300 (30000)
I0426 20:51:08.558514 31915 net.cpp:139] Memory required for data: 4314800
I0426 20:51:08.558517 31915 layer_factory.hpp:77] Creating layer ip3
I0426 20:51:08.558522 31915 net.cpp:86] Creating Layer ip3
I0426 20:51:08.558526 31915 net.cpp:408] ip3 <- ip2
I0426 20:51:08.558531 31915 net.cpp:382] ip3 -> ip3
I0426 20:51:08.558666 31915 net.cpp:124] Setting up ip3
I0426 20:51:08.558675 31915 net.cpp:131] Top shape: 100 10 (1000)
I0426 20:51:08.558678 31915 net.cpp:139] Memory required for data: 4318800
I0426 20:51:08.558686 31915 layer_factory.hpp:77] Creating layer relu3
I0426 20:51:08.558691 31915 net.cpp:86] Creating Layer relu3
I0426 20:51:08.558693 31915 net.cpp:408] relu3 <- ip3
I0426 20:51:08.558698 31915 net.cpp:369] relu3 -> ip3 (in-place)
I0426 20:51:08.559554 31915 net.cpp:124] Setting up relu3
I0426 20:51:08.559567 31915 net.cpp:131] Top shape: 100 10 (1000)
I0426 20:51:08.559571 31915 net.cpp:139] Memory required for data: 4322800
I0426 20:51:08.559574 31915 layer_factory.hpp:77] Creating layer ip3_relu3_0_split
I0426 20:51:08.559579 31915 net.cpp:86] Creating Layer ip3_relu3_0_split
I0426 20:51:08.559582 31915 net.cpp:408] ip3_relu3_0_split <- ip3
I0426 20:51:08.559587 31915 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_0
I0426 20:51:08.559593 31915 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_1
I0426 20:51:08.559649 31915 net.cpp:124] Setting up ip3_relu3_0_split
I0426 20:51:08.559655 31915 net.cpp:131] Top shape: 100 10 (1000)
I0426 20:51:08.559659 31915 net.cpp:131] Top shape: 100 10 (1000)
I0426 20:51:08.559661 31915 net.cpp:139] Memory required for data: 4330800
I0426 20:51:08.559664 31915 layer_factory.hpp:77] Creating layer accuracy
I0426 20:51:08.559669 31915 net.cpp:86] Creating Layer accuracy
I0426 20:51:08.559672 31915 net.cpp:408] accuracy <- ip3_relu3_0_split_0
I0426 20:51:08.559684 31915 net.cpp:408] accuracy <- label_mnist_1_split_0
I0426 20:51:08.559687 31915 net.cpp:382] accuracy -> accuracy
I0426 20:51:08.559695 31915 net.cpp:124] Setting up accuracy
I0426 20:51:08.559700 31915 net.cpp:131] Top shape: (1)
I0426 20:51:08.559701 31915 net.cpp:139] Memory required for data: 4330804
I0426 20:51:08.559705 31915 layer_factory.hpp:77] Creating layer loss
I0426 20:51:08.559710 31915 net.cpp:86] Creating Layer loss
I0426 20:51:08.559712 31915 net.cpp:408] loss <- ip3_relu3_0_split_1
I0426 20:51:08.559715 31915 net.cpp:408] loss <- label_mnist_1_split_1
I0426 20:51:08.559720 31915 net.cpp:382] loss -> loss
I0426 20:51:08.559726 31915 layer_factory.hpp:77] Creating layer loss
I0426 20:51:08.559958 31915 net.cpp:124] Setting up loss
I0426 20:51:08.559983 31915 net.cpp:131] Top shape: (1)
I0426 20:51:08.559993 31915 net.cpp:134]     with loss weight 1
I0426 20:51:08.560009 31915 net.cpp:139] Memory required for data: 4330808
I0426 20:51:08.560014 31915 net.cpp:200] loss needs backward computation.
I0426 20:51:08.560017 31915 net.cpp:202] accuracy does not need backward computation.
I0426 20:51:08.560021 31915 net.cpp:200] ip3_relu3_0_split needs backward computation.
I0426 20:51:08.560024 31915 net.cpp:200] relu3 needs backward computation.
I0426 20:51:08.560027 31915 net.cpp:200] ip3 needs backward computation.
I0426 20:51:08.560030 31915 net.cpp:200] relu2 needs backward computation.
I0426 20:51:08.560034 31915 net.cpp:200] ip2 needs backward computation.
I0426 20:51:08.560055 31915 net.cpp:200] relu1 needs backward computation.
I0426 20:51:08.560057 31915 net.cpp:200] ip1 needs backward computation.
I0426 20:51:08.560060 31915 net.cpp:200] pool1 needs backward computation.
I0426 20:51:08.560063 31915 net.cpp:200] conv1 needs backward computation.
I0426 20:51:08.560067 31915 net.cpp:200] pool0 needs backward computation.
I0426 20:51:08.560070 31915 net.cpp:200] conv0 needs backward computation.
I0426 20:51:08.560075 31915 net.cpp:202] label_mnist_1_split does not need backward computation.
I0426 20:51:08.560078 31915 net.cpp:202] mnist does not need backward computation.
I0426 20:51:08.560081 31915 net.cpp:244] This network produces output accuracy
I0426 20:51:08.560084 31915 net.cpp:244] This network produces output loss
I0426 20:51:08.560096 31915 net.cpp:257] Network initialization done.
I0426 20:51:08.560142 31915 solver.cpp:56] Solver scaffolding done.
I0426 20:51:08.560473 31915 caffe.cpp:248] Starting Optimization
I0426 20:51:08.560482 31915 solver.cpp:273] Solving LeNet
I0426 20:51:08.560485 31915 solver.cpp:274] Learning Rate Policy: inv
I0426 20:51:08.561446 31915 solver.cpp:331] Iteration 0, Testing net (#0)
I0426 20:51:08.566098 31915 blocking_queue.cpp:49] Waiting for data
I0426 20:51:08.636512 31922 data_layer.cpp:73] Restarting data prefetching from start.
I0426 20:51:08.637101 31915 solver.cpp:398]     Test net output #0: accuracy = 0.0973
I0426 20:51:08.637120 31915 solver.cpp:398]     Test net output #1: loss = 2.32824 (* 1 = 2.32824 loss)
I0426 20:51:08.640244 31915 solver.cpp:219] Iteration 0 (-1.10733e-31 iter/s, 0.0797286s/100 iters), loss = 2.30706
I0426 20:51:08.640267 31915 solver.cpp:238]     Train net output #0: loss = 2.30706 (* 1 = 2.30706 loss)
I0426 20:51:08.640277 31915 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0426 20:51:08.744526 31915 solver.cpp:219] Iteration 100 (959.248 iter/s, 0.104248s/100 iters), loss = 1.12442
I0426 20:51:08.744552 31915 solver.cpp:238]     Train net output #0: loss = 1.12442 (* 1 = 1.12442 loss)
I0426 20:51:08.744575 31915 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0426 20:51:08.849037 31915 solver.cpp:219] Iteration 200 (957.18 iter/s, 0.104474s/100 iters), loss = 0.556738
I0426 20:51:08.849062 31915 solver.cpp:238]     Train net output #0: loss = 0.556738 (* 1 = 0.556738 loss)
I0426 20:51:08.849069 31915 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0426 20:51:08.953408 31915 solver.cpp:219] Iteration 300 (958.457 iter/s, 0.104334s/100 iters), loss = 0.249423
I0426 20:51:08.953433 31915 solver.cpp:238]     Train net output #0: loss = 0.249423 (* 1 = 0.249423 loss)
I0426 20:51:08.953438 31915 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0426 20:51:09.054149 31915 solver.cpp:219] Iteration 400 (992.985 iter/s, 0.100706s/100 iters), loss = 0.303888
I0426 20:51:09.054174 31915 solver.cpp:238]     Train net output #0: loss = 0.303888 (* 1 = 0.303888 loss)
I0426 20:51:09.054195 31915 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0426 20:51:09.160953 31915 solver.cpp:331] Iteration 500, Testing net (#0)
I0426 20:51:09.216341 31922 data_layer.cpp:73] Restarting data prefetching from start.
I0426 20:51:09.216969 31915 solver.cpp:398]     Test net output #0: accuracy = 0.881
I0426 20:51:09.216991 31915 solver.cpp:398]     Test net output #1: loss = 0.314812 (* 1 = 0.314812 loss)
I0426 20:51:09.218001 31915 solver.cpp:219] Iteration 500 (610.508 iter/s, 0.163798s/100 iters), loss = 0.387418
I0426 20:51:09.218073 31915 solver.cpp:238]     Train net output #0: loss = 0.387418 (* 1 = 0.387418 loss)
I0426 20:51:09.218082 31915 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0426 20:51:09.326298 31915 solver.cpp:219] Iteration 600 (924.07 iter/s, 0.108217s/100 iters), loss = 0.274062
I0426 20:51:09.326339 31915 solver.cpp:238]     Train net output #0: loss = 0.274062 (* 1 = 0.274062 loss)
I0426 20:51:09.326345 31915 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0426 20:51:09.428366 31915 solver.cpp:219] Iteration 700 (980.081 iter/s, 0.102032s/100 iters), loss = 0.503608
I0426 20:51:09.428391 31915 solver.cpp:238]     Train net output #0: loss = 0.503608 (* 1 = 0.503608 loss)
I0426 20:51:09.428398 31915 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0426 20:51:09.535953 31915 solver.cpp:219] Iteration 800 (929.793 iter/s, 0.107551s/100 iters), loss = 0.472507
I0426 20:51:09.535995 31915 solver.cpp:238]     Train net output #0: loss = 0.472507 (* 1 = 0.472507 loss)
I0426 20:51:09.536001 31915 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0426 20:51:09.637801 31915 solver.cpp:219] Iteration 900 (982.35 iter/s, 0.101797s/100 iters), loss = 0.312446
I0426 20:51:09.637845 31915 solver.cpp:238]     Train net output #0: loss = 0.312446 (* 1 = 0.312446 loss)
I0426 20:51:09.637851 31915 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0426 20:51:09.675242 31921 data_layer.cpp:73] Restarting data prefetching from start.
I0426 20:51:09.747375 31915 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_1000.caffemodel
I0426 20:51:09.749317 31915 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_1000.solverstate
I0426 20:51:09.750514 31915 solver.cpp:311] Iteration 1000, loss = 0.385071
I0426 20:51:09.750533 31915 solver.cpp:331] Iteration 1000, Testing net (#0)
I0426 20:51:09.824590 31922 data_layer.cpp:73] Restarting data prefetching from start.
I0426 20:51:09.825202 31915 solver.cpp:398]     Test net output #0: accuracy = 0.8926
I0426 20:51:09.825223 31915 solver.cpp:398]     Test net output #1: loss = 0.272953 (* 1 = 0.272953 loss)
I0426 20:51:09.825229 31915 solver.cpp:316] Optimization Done.
I0426 20:51:09.825232 31915 caffe.cpp:259] Optimization Done.
