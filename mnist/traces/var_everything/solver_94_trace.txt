I0426 20:51:43.646610 32045 caffe.cpp:218] Using GPUs 0
I0426 20:51:43.676733 32045 caffe.cpp:223] GPU 0: TITAN X (Pascal)
I0426 20:51:44.132267 32045 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 1000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_everything/lenet_train_test94.prototxt"
train_state {
  level: 0
  stage: ""
}
I0426 20:51:44.132392 32045 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_everything/lenet_train_test94.prototxt
I0426 20:51:44.132748 32045 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0426 20:51:44.132776 32045 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0426 20:51:44.132923 32045 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 10
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0426 20:51:44.132994 32045 layer_factory.hpp:77] Creating layer mnist
I0426 20:51:44.133080 32045 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0426 20:51:44.133100 32045 net.cpp:86] Creating Layer mnist
I0426 20:51:44.133105 32045 net.cpp:382] mnist -> data
I0426 20:51:44.133124 32045 net.cpp:382] mnist -> label
I0426 20:51:44.134052 32045 data_layer.cpp:45] output data size: 64,1,28,28
I0426 20:51:44.136116 32045 net.cpp:124] Setting up mnist
I0426 20:51:44.136145 32045 net.cpp:131] Top shape: 64 1 28 28 (50176)
I0426 20:51:44.136150 32045 net.cpp:131] Top shape: 64 (64)
I0426 20:51:44.136153 32045 net.cpp:139] Memory required for data: 200960
I0426 20:51:44.136158 32045 layer_factory.hpp:77] Creating layer conv0
I0426 20:51:44.136171 32045 net.cpp:86] Creating Layer conv0
I0426 20:51:44.136188 32045 net.cpp:408] conv0 <- data
I0426 20:51:44.136212 32045 net.cpp:382] conv0 -> conv0
I0426 20:51:44.366791 32045 net.cpp:124] Setting up conv0
I0426 20:51:44.366817 32045 net.cpp:131] Top shape: 64 10 24 24 (368640)
I0426 20:51:44.366822 32045 net.cpp:139] Memory required for data: 1675520
I0426 20:51:44.366837 32045 layer_factory.hpp:77] Creating layer pool0
I0426 20:51:44.366848 32045 net.cpp:86] Creating Layer pool0
I0426 20:51:44.366852 32045 net.cpp:408] pool0 <- conv0
I0426 20:51:44.366858 32045 net.cpp:382] pool0 -> pool0
I0426 20:51:44.366916 32045 net.cpp:124] Setting up pool0
I0426 20:51:44.366922 32045 net.cpp:131] Top shape: 64 10 12 12 (92160)
I0426 20:51:44.366925 32045 net.cpp:139] Memory required for data: 2044160
I0426 20:51:44.366927 32045 layer_factory.hpp:77] Creating layer conv1
I0426 20:51:44.366937 32045 net.cpp:86] Creating Layer conv1
I0426 20:51:44.366940 32045 net.cpp:408] conv1 <- pool0
I0426 20:51:44.366960 32045 net.cpp:382] conv1 -> conv1
I0426 20:51:44.369704 32045 net.cpp:124] Setting up conv1
I0426 20:51:44.369716 32045 net.cpp:131] Top shape: 64 50 8 8 (204800)
I0426 20:51:44.369720 32045 net.cpp:139] Memory required for data: 2863360
I0426 20:51:44.369729 32045 layer_factory.hpp:77] Creating layer pool1
I0426 20:51:44.369735 32045 net.cpp:86] Creating Layer pool1
I0426 20:51:44.369738 32045 net.cpp:408] pool1 <- conv1
I0426 20:51:44.369743 32045 net.cpp:382] pool1 -> pool1
I0426 20:51:44.369793 32045 net.cpp:124] Setting up pool1
I0426 20:51:44.369798 32045 net.cpp:131] Top shape: 64 50 4 4 (51200)
I0426 20:51:44.369801 32045 net.cpp:139] Memory required for data: 3068160
I0426 20:51:44.369803 32045 layer_factory.hpp:77] Creating layer ip1
I0426 20:51:44.369809 32045 net.cpp:86] Creating Layer ip1
I0426 20:51:44.369812 32045 net.cpp:408] ip1 <- pool1
I0426 20:51:44.369817 32045 net.cpp:382] ip1 -> ip1
I0426 20:51:44.371927 32045 net.cpp:124] Setting up ip1
I0426 20:51:44.371938 32045 net.cpp:131] Top shape: 64 300 (19200)
I0426 20:51:44.371942 32045 net.cpp:139] Memory required for data: 3144960
I0426 20:51:44.371948 32045 layer_factory.hpp:77] Creating layer relu1
I0426 20:51:44.371954 32045 net.cpp:86] Creating Layer relu1
I0426 20:51:44.371958 32045 net.cpp:408] relu1 <- ip1
I0426 20:51:44.371961 32045 net.cpp:369] relu1 -> ip1 (in-place)
I0426 20:51:44.372169 32045 net.cpp:124] Setting up relu1
I0426 20:51:44.372179 32045 net.cpp:131] Top shape: 64 300 (19200)
I0426 20:51:44.372181 32045 net.cpp:139] Memory required for data: 3221760
I0426 20:51:44.372185 32045 layer_factory.hpp:77] Creating layer ip2
I0426 20:51:44.372191 32045 net.cpp:86] Creating Layer ip2
I0426 20:51:44.372195 32045 net.cpp:408] ip2 <- ip1
I0426 20:51:44.372200 32045 net.cpp:382] ip2 -> ip2
I0426 20:51:44.372478 32045 net.cpp:124] Setting up ip2
I0426 20:51:44.372484 32045 net.cpp:131] Top shape: 64 100 (6400)
I0426 20:51:44.372488 32045 net.cpp:139] Memory required for data: 3247360
I0426 20:51:44.372493 32045 layer_factory.hpp:77] Creating layer relu2
I0426 20:51:44.372498 32045 net.cpp:86] Creating Layer relu2
I0426 20:51:44.372501 32045 net.cpp:408] relu2 <- ip2
I0426 20:51:44.372505 32045 net.cpp:369] relu2 -> ip2 (in-place)
I0426 20:51:44.373314 32045 net.cpp:124] Setting up relu2
I0426 20:51:44.373327 32045 net.cpp:131] Top shape: 64 100 (6400)
I0426 20:51:44.373344 32045 net.cpp:139] Memory required for data: 3272960
I0426 20:51:44.373348 32045 layer_factory.hpp:77] Creating layer ip3
I0426 20:51:44.373354 32045 net.cpp:86] Creating Layer ip3
I0426 20:51:44.373358 32045 net.cpp:408] ip3 <- ip2
I0426 20:51:44.373363 32045 net.cpp:382] ip3 -> ip3
I0426 20:51:44.373463 32045 net.cpp:124] Setting up ip3
I0426 20:51:44.373471 32045 net.cpp:131] Top shape: 64 10 (640)
I0426 20:51:44.373473 32045 net.cpp:139] Memory required for data: 3275520
I0426 20:51:44.373481 32045 layer_factory.hpp:77] Creating layer relu3
I0426 20:51:44.373486 32045 net.cpp:86] Creating Layer relu3
I0426 20:51:44.373488 32045 net.cpp:408] relu3 <- ip3
I0426 20:51:44.373492 32045 net.cpp:369] relu3 -> ip3 (in-place)
I0426 20:51:44.373651 32045 net.cpp:124] Setting up relu3
I0426 20:51:44.373658 32045 net.cpp:131] Top shape: 64 10 (640)
I0426 20:51:44.373661 32045 net.cpp:139] Memory required for data: 3278080
I0426 20:51:44.373664 32045 layer_factory.hpp:77] Creating layer loss
I0426 20:51:44.373690 32045 net.cpp:86] Creating Layer loss
I0426 20:51:44.373694 32045 net.cpp:408] loss <- ip3
I0426 20:51:44.373698 32045 net.cpp:408] loss <- label
I0426 20:51:44.373703 32045 net.cpp:382] loss -> loss
I0426 20:51:44.373716 32045 layer_factory.hpp:77] Creating layer loss
I0426 20:51:44.373940 32045 net.cpp:124] Setting up loss
I0426 20:51:44.373950 32045 net.cpp:131] Top shape: (1)
I0426 20:51:44.373952 32045 net.cpp:134]     with loss weight 1
I0426 20:51:44.373965 32045 net.cpp:139] Memory required for data: 3278084
I0426 20:51:44.373970 32045 net.cpp:200] loss needs backward computation.
I0426 20:51:44.373973 32045 net.cpp:200] relu3 needs backward computation.
I0426 20:51:44.373976 32045 net.cpp:200] ip3 needs backward computation.
I0426 20:51:44.373980 32045 net.cpp:200] relu2 needs backward computation.
I0426 20:51:44.373982 32045 net.cpp:200] ip2 needs backward computation.
I0426 20:51:44.373986 32045 net.cpp:200] relu1 needs backward computation.
I0426 20:51:44.373987 32045 net.cpp:200] ip1 needs backward computation.
I0426 20:51:44.373991 32045 net.cpp:200] pool1 needs backward computation.
I0426 20:51:44.373993 32045 net.cpp:200] conv1 needs backward computation.
I0426 20:51:44.373996 32045 net.cpp:200] pool0 needs backward computation.
I0426 20:51:44.373999 32045 net.cpp:200] conv0 needs backward computation.
I0426 20:51:44.374003 32045 net.cpp:202] mnist does not need backward computation.
I0426 20:51:44.374006 32045 net.cpp:244] This network produces output loss
I0426 20:51:44.374029 32045 net.cpp:257] Network initialization done.
I0426 20:51:44.374358 32045 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_everything/lenet_train_test94.prototxt
I0426 20:51:44.374414 32045 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0426 20:51:44.374506 32045 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 10
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0426 20:51:44.374601 32045 layer_factory.hpp:77] Creating layer mnist
I0426 20:51:44.374642 32045 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0426 20:51:44.374655 32045 net.cpp:86] Creating Layer mnist
I0426 20:51:44.374660 32045 net.cpp:382] mnist -> data
I0426 20:51:44.374667 32045 net.cpp:382] mnist -> label
I0426 20:51:44.374754 32045 data_layer.cpp:45] output data size: 100,1,28,28
I0426 20:51:44.376626 32045 net.cpp:124] Setting up mnist
I0426 20:51:44.376654 32045 net.cpp:131] Top shape: 100 1 28 28 (78400)
I0426 20:51:44.376658 32045 net.cpp:131] Top shape: 100 (100)
I0426 20:51:44.376662 32045 net.cpp:139] Memory required for data: 314000
I0426 20:51:44.376664 32045 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0426 20:51:44.376670 32045 net.cpp:86] Creating Layer label_mnist_1_split
I0426 20:51:44.376673 32045 net.cpp:408] label_mnist_1_split <- label
I0426 20:51:44.376694 32045 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_0
I0426 20:51:44.376711 32045 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_1
I0426 20:51:44.376761 32045 net.cpp:124] Setting up label_mnist_1_split
I0426 20:51:44.376766 32045 net.cpp:131] Top shape: 100 (100)
I0426 20:51:44.376770 32045 net.cpp:131] Top shape: 100 (100)
I0426 20:51:44.376772 32045 net.cpp:139] Memory required for data: 314800
I0426 20:51:44.376775 32045 layer_factory.hpp:77] Creating layer conv0
I0426 20:51:44.376785 32045 net.cpp:86] Creating Layer conv0
I0426 20:51:44.376787 32045 net.cpp:408] conv0 <- data
I0426 20:51:44.376793 32045 net.cpp:382] conv0 -> conv0
I0426 20:51:44.378689 32045 net.cpp:124] Setting up conv0
I0426 20:51:44.378701 32045 net.cpp:131] Top shape: 100 10 24 24 (576000)
I0426 20:51:44.378705 32045 net.cpp:139] Memory required for data: 2618800
I0426 20:51:44.378712 32045 layer_factory.hpp:77] Creating layer pool0
I0426 20:51:44.378731 32045 net.cpp:86] Creating Layer pool0
I0426 20:51:44.378734 32045 net.cpp:408] pool0 <- conv0
I0426 20:51:44.378739 32045 net.cpp:382] pool0 -> pool0
I0426 20:51:44.378784 32045 net.cpp:124] Setting up pool0
I0426 20:51:44.378789 32045 net.cpp:131] Top shape: 100 10 12 12 (144000)
I0426 20:51:44.378793 32045 net.cpp:139] Memory required for data: 3194800
I0426 20:51:44.378795 32045 layer_factory.hpp:77] Creating layer conv1
I0426 20:51:44.378803 32045 net.cpp:86] Creating Layer conv1
I0426 20:51:44.378806 32045 net.cpp:408] conv1 <- pool0
I0426 20:51:44.378813 32045 net.cpp:382] conv1 -> conv1
I0426 20:51:44.380451 32045 net.cpp:124] Setting up conv1
I0426 20:51:44.380465 32045 net.cpp:131] Top shape: 100 50 8 8 (320000)
I0426 20:51:44.380467 32045 net.cpp:139] Memory required for data: 4474800
I0426 20:51:44.380475 32045 layer_factory.hpp:77] Creating layer pool1
I0426 20:51:44.380481 32045 net.cpp:86] Creating Layer pool1
I0426 20:51:44.380496 32045 net.cpp:408] pool1 <- conv1
I0426 20:51:44.380501 32045 net.cpp:382] pool1 -> pool1
I0426 20:51:44.380545 32045 net.cpp:124] Setting up pool1
I0426 20:51:44.380556 32045 net.cpp:131] Top shape: 100 50 4 4 (80000)
I0426 20:51:44.380559 32045 net.cpp:139] Memory required for data: 4794800
I0426 20:51:44.380561 32045 layer_factory.hpp:77] Creating layer ip1
I0426 20:51:44.380573 32045 net.cpp:86] Creating Layer ip1
I0426 20:51:44.380576 32045 net.cpp:408] ip1 <- pool1
I0426 20:51:44.380583 32045 net.cpp:382] ip1 -> ip1
I0426 20:51:44.382025 32045 net.cpp:124] Setting up ip1
I0426 20:51:44.382035 32045 net.cpp:131] Top shape: 100 300 (30000)
I0426 20:51:44.382056 32045 net.cpp:139] Memory required for data: 4914800
I0426 20:51:44.382074 32045 layer_factory.hpp:77] Creating layer relu1
I0426 20:51:44.382079 32045 net.cpp:86] Creating Layer relu1
I0426 20:51:44.382082 32045 net.cpp:408] relu1 <- ip1
I0426 20:51:44.382086 32045 net.cpp:369] relu1 -> ip1 (in-place)
I0426 20:51:44.382248 32045 net.cpp:124] Setting up relu1
I0426 20:51:44.382256 32045 net.cpp:131] Top shape: 100 300 (30000)
I0426 20:51:44.382259 32045 net.cpp:139] Memory required for data: 5034800
I0426 20:51:44.382262 32045 layer_factory.hpp:77] Creating layer ip2
I0426 20:51:44.382277 32045 net.cpp:86] Creating Layer ip2
I0426 20:51:44.382280 32045 net.cpp:408] ip2 <- ip1
I0426 20:51:44.382287 32045 net.cpp:382] ip2 -> ip2
I0426 20:51:44.382580 32045 net.cpp:124] Setting up ip2
I0426 20:51:44.382587 32045 net.cpp:131] Top shape: 100 100 (10000)
I0426 20:51:44.382591 32045 net.cpp:139] Memory required for data: 5074800
I0426 20:51:44.382596 32045 layer_factory.hpp:77] Creating layer relu2
I0426 20:51:44.382601 32045 net.cpp:86] Creating Layer relu2
I0426 20:51:44.382603 32045 net.cpp:408] relu2 <- ip2
I0426 20:51:44.382608 32045 net.cpp:369] relu2 -> ip2 (in-place)
I0426 20:51:44.382779 32045 net.cpp:124] Setting up relu2
I0426 20:51:44.382787 32045 net.cpp:131] Top shape: 100 100 (10000)
I0426 20:51:44.382791 32045 net.cpp:139] Memory required for data: 5114800
I0426 20:51:44.382792 32045 layer_factory.hpp:77] Creating layer ip3
I0426 20:51:44.382805 32045 net.cpp:86] Creating Layer ip3
I0426 20:51:44.382807 32045 net.cpp:408] ip3 <- ip2
I0426 20:51:44.382812 32045 net.cpp:382] ip3 -> ip3
I0426 20:51:44.382911 32045 net.cpp:124] Setting up ip3
I0426 20:51:44.382918 32045 net.cpp:131] Top shape: 100 10 (1000)
I0426 20:51:44.382922 32045 net.cpp:139] Memory required for data: 5118800
I0426 20:51:44.382930 32045 layer_factory.hpp:77] Creating layer relu3
I0426 20:51:44.382935 32045 net.cpp:86] Creating Layer relu3
I0426 20:51:44.382937 32045 net.cpp:408] relu3 <- ip3
I0426 20:51:44.382941 32045 net.cpp:369] relu3 -> ip3 (in-place)
I0426 20:51:44.383749 32045 net.cpp:124] Setting up relu3
I0426 20:51:44.383760 32045 net.cpp:131] Top shape: 100 10 (1000)
I0426 20:51:44.383764 32045 net.cpp:139] Memory required for data: 5122800
I0426 20:51:44.383766 32045 layer_factory.hpp:77] Creating layer ip3_relu3_0_split
I0426 20:51:44.383772 32045 net.cpp:86] Creating Layer ip3_relu3_0_split
I0426 20:51:44.383775 32045 net.cpp:408] ip3_relu3_0_split <- ip3
I0426 20:51:44.383780 32045 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_0
I0426 20:51:44.383785 32045 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_1
I0426 20:51:44.383836 32045 net.cpp:124] Setting up ip3_relu3_0_split
I0426 20:51:44.383842 32045 net.cpp:131] Top shape: 100 10 (1000)
I0426 20:51:44.383846 32045 net.cpp:131] Top shape: 100 10 (1000)
I0426 20:51:44.383847 32045 net.cpp:139] Memory required for data: 5130800
I0426 20:51:44.383858 32045 layer_factory.hpp:77] Creating layer accuracy
I0426 20:51:44.383863 32045 net.cpp:86] Creating Layer accuracy
I0426 20:51:44.383867 32045 net.cpp:408] accuracy <- ip3_relu3_0_split_0
I0426 20:51:44.383869 32045 net.cpp:408] accuracy <- label_mnist_1_split_0
I0426 20:51:44.383874 32045 net.cpp:382] accuracy -> accuracy
I0426 20:51:44.383882 32045 net.cpp:124] Setting up accuracy
I0426 20:51:44.383885 32045 net.cpp:131] Top shape: (1)
I0426 20:51:44.383888 32045 net.cpp:139] Memory required for data: 5130804
I0426 20:51:44.383890 32045 layer_factory.hpp:77] Creating layer loss
I0426 20:51:44.383894 32045 net.cpp:86] Creating Layer loss
I0426 20:51:44.383898 32045 net.cpp:408] loss <- ip3_relu3_0_split_1
I0426 20:51:44.383900 32045 net.cpp:408] loss <- label_mnist_1_split_1
I0426 20:51:44.383905 32045 net.cpp:382] loss -> loss
I0426 20:51:44.383911 32045 layer_factory.hpp:77] Creating layer loss
I0426 20:51:44.384217 32045 net.cpp:124] Setting up loss
I0426 20:51:44.384227 32045 net.cpp:131] Top shape: (1)
I0426 20:51:44.384230 32045 net.cpp:134]     with loss weight 1
I0426 20:51:44.384245 32045 net.cpp:139] Memory required for data: 5130808
I0426 20:51:44.384248 32045 net.cpp:200] loss needs backward computation.
I0426 20:51:44.384253 32045 net.cpp:202] accuracy does not need backward computation.
I0426 20:51:44.384256 32045 net.cpp:200] ip3_relu3_0_split needs backward computation.
I0426 20:51:44.384259 32045 net.cpp:200] relu3 needs backward computation.
I0426 20:51:44.384263 32045 net.cpp:200] ip3 needs backward computation.
I0426 20:51:44.384265 32045 net.cpp:200] relu2 needs backward computation.
I0426 20:51:44.384268 32045 net.cpp:200] ip2 needs backward computation.
I0426 20:51:44.384279 32045 net.cpp:200] relu1 needs backward computation.
I0426 20:51:44.384281 32045 net.cpp:200] ip1 needs backward computation.
I0426 20:51:44.384284 32045 net.cpp:200] pool1 needs backward computation.
I0426 20:51:44.384287 32045 net.cpp:200] conv1 needs backward computation.
I0426 20:51:44.384291 32045 net.cpp:200] pool0 needs backward computation.
I0426 20:51:44.384294 32045 net.cpp:200] conv0 needs backward computation.
I0426 20:51:44.384297 32045 net.cpp:202] label_mnist_1_split does not need backward computation.
I0426 20:51:44.384301 32045 net.cpp:202] mnist does not need backward computation.
I0426 20:51:44.384305 32045 net.cpp:244] This network produces output accuracy
I0426 20:51:44.384307 32045 net.cpp:244] This network produces output loss
I0426 20:51:44.384320 32045 net.cpp:257] Network initialization done.
I0426 20:51:44.384389 32045 solver.cpp:56] Solver scaffolding done.
I0426 20:51:44.384706 32045 caffe.cpp:248] Starting Optimization
I0426 20:51:44.384711 32045 solver.cpp:273] Solving LeNet
I0426 20:51:44.384714 32045 solver.cpp:274] Learning Rate Policy: inv
I0426 20:51:44.386277 32045 solver.cpp:331] Iteration 0, Testing net (#0)
I0426 20:51:44.390794 32045 blocking_queue.cpp:49] Waiting for data
I0426 20:51:44.461483 32052 data_layer.cpp:73] Restarting data prefetching from start.
I0426 20:51:44.462100 32045 solver.cpp:398]     Test net output #0: accuracy = 0.0773
I0426 20:51:44.462148 32045 solver.cpp:398]     Test net output #1: loss = 2.31764 (* 1 = 2.31764 loss)
I0426 20:51:44.465472 32045 solver.cpp:219] Iteration 0 (0 iter/s, 0.0807332s/100 iters), loss = 2.31718
I0426 20:51:44.465494 32045 solver.cpp:238]     Train net output #0: loss = 2.31718 (* 1 = 2.31718 loss)
I0426 20:51:44.465522 32045 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0426 20:51:44.600119 32045 solver.cpp:219] Iteration 100 (742.91 iter/s, 0.134606s/100 iters), loss = 0.273026
I0426 20:51:44.600157 32045 solver.cpp:238]     Train net output #0: loss = 0.273026 (* 1 = 0.273026 loss)
I0426 20:51:44.600167 32045 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0426 20:51:44.732444 32045 solver.cpp:219] Iteration 200 (755.988 iter/s, 0.132277s/100 iters), loss = 0.154946
I0426 20:51:44.732468 32045 solver.cpp:238]     Train net output #0: loss = 0.154946 (* 1 = 0.154946 loss)
I0426 20:51:44.732475 32045 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0426 20:51:44.863457 32045 solver.cpp:219] Iteration 300 (763.506 iter/s, 0.130975s/100 iters), loss = 0.157044
I0426 20:51:44.863497 32045 solver.cpp:238]     Train net output #0: loss = 0.157044 (* 1 = 0.157044 loss)
I0426 20:51:44.863505 32045 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0426 20:51:44.988981 32045 solver.cpp:219] Iteration 400 (796.978 iter/s, 0.125474s/100 iters), loss = 0.105041
I0426 20:51:44.989011 32045 solver.cpp:238]     Train net output #0: loss = 0.105041 (* 1 = 0.105041 loss)
I0426 20:51:44.989017 32045 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0426 20:51:45.110009 32045 solver.cpp:331] Iteration 500, Testing net (#0)
I0426 20:51:45.187042 32052 data_layer.cpp:73] Restarting data prefetching from start.
I0426 20:51:45.187662 32045 solver.cpp:398]     Test net output #0: accuracy = 0.9689
I0426 20:51:45.187685 32045 solver.cpp:398]     Test net output #1: loss = 0.0945646 (* 1 = 0.0945646 loss)
I0426 20:51:45.188938 32045 solver.cpp:219] Iteration 500 (500.217 iter/s, 0.199913s/100 iters), loss = 0.104102
I0426 20:51:45.188990 32045 solver.cpp:238]     Train net output #0: loss = 0.104102 (* 1 = 0.104102 loss)
I0426 20:51:45.188998 32045 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0426 20:51:45.319464 32045 solver.cpp:219] Iteration 600 (766.518 iter/s, 0.13046s/100 iters), loss = 0.102184
I0426 20:51:45.319509 32045 solver.cpp:238]     Train net output #0: loss = 0.102184 (* 1 = 0.102184 loss)
I0426 20:51:45.319520 32045 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0426 20:51:45.454869 32045 solver.cpp:219] Iteration 700 (738.841 iter/s, 0.135347s/100 iters), loss = 0.101129
I0426 20:51:45.454911 32045 solver.cpp:238]     Train net output #0: loss = 0.101129 (* 1 = 0.101129 loss)
I0426 20:51:45.454922 32045 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0426 20:51:45.592147 32045 solver.cpp:219] Iteration 800 (728.74 iter/s, 0.137223s/100 iters), loss = 0.227982
I0426 20:51:45.592191 32045 solver.cpp:238]     Train net output #0: loss = 0.227982 (* 1 = 0.227982 loss)
I0426 20:51:45.592202 32045 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0426 20:51:45.720782 32045 solver.cpp:219] Iteration 900 (777.728 iter/s, 0.12858s/100 iters), loss = 0.173662
I0426 20:51:45.720825 32045 solver.cpp:238]     Train net output #0: loss = 0.173662 (* 1 = 0.173662 loss)
I0426 20:51:45.720834 32045 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0426 20:51:45.762493 32051 data_layer.cpp:73] Restarting data prefetching from start.
I0426 20:51:45.844291 32045 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_1000.caffemodel
I0426 20:51:45.849465 32045 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_1000.solverstate
I0426 20:51:45.852190 32045 solver.cpp:311] Iteration 1000, loss = 0.0706696
I0426 20:51:45.852211 32045 solver.cpp:331] Iteration 1000, Testing net (#0)
I0426 20:51:45.927832 32052 data_layer.cpp:73] Restarting data prefetching from start.
I0426 20:51:45.928469 32045 solver.cpp:398]     Test net output #0: accuracy = 0.9822
I0426 20:51:45.928495 32045 solver.cpp:398]     Test net output #1: loss = 0.0578022 (* 1 = 0.0578022 loss)
I0426 20:51:45.928501 32045 solver.cpp:316] Optimization Done.
I0426 20:51:45.928505 32045 caffe.cpp:259] Optimization Done.
