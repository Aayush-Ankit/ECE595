I0426 20:51:03.036422 31899 caffe.cpp:218] Using GPUs 0
I0426 20:51:03.066771 31899 caffe.cpp:223] GPU 0: TITAN X (Pascal)
I0426 20:51:03.526085 31899 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 1000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "ECE595/mnist/train_test/var_everything/lenet_train_test77.prototxt"
train_state {
  level: 0
  stage: ""
}
I0426 20:51:03.526229 31899 solver.cpp:87] Creating training net from net file: ECE595/mnist/train_test/var_everything/lenet_train_test77.prototxt
I0426 20:51:03.526624 31899 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0426 20:51:03.526640 31899 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0426 20:51:03.526757 31899 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 10
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0426 20:51:03.526823 31899 layer_factory.hpp:77] Creating layer mnist
I0426 20:51:03.526906 31899 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0426 20:51:03.526926 31899 net.cpp:86] Creating Layer mnist
I0426 20:51:03.526934 31899 net.cpp:382] mnist -> data
I0426 20:51:03.526953 31899 net.cpp:382] mnist -> label
I0426 20:51:03.527928 31899 data_layer.cpp:45] output data size: 64,1,28,28
I0426 20:51:03.530112 31899 net.cpp:124] Setting up mnist
I0426 20:51:03.530140 31899 net.cpp:131] Top shape: 64 1 28 28 (50176)
I0426 20:51:03.530145 31899 net.cpp:131] Top shape: 64 (64)
I0426 20:51:03.530148 31899 net.cpp:139] Memory required for data: 200960
I0426 20:51:03.530153 31899 layer_factory.hpp:77] Creating layer conv0
I0426 20:51:03.530181 31899 net.cpp:86] Creating Layer conv0
I0426 20:51:03.530200 31899 net.cpp:408] conv0 <- data
I0426 20:51:03.530210 31899 net.cpp:382] conv0 -> conv0
I0426 20:51:03.759838 31899 net.cpp:124] Setting up conv0
I0426 20:51:03.759881 31899 net.cpp:131] Top shape: 64 10 24 24 (368640)
I0426 20:51:03.759884 31899 net.cpp:139] Memory required for data: 1675520
I0426 20:51:03.759899 31899 layer_factory.hpp:77] Creating layer pool0
I0426 20:51:03.759912 31899 net.cpp:86] Creating Layer pool0
I0426 20:51:03.759930 31899 net.cpp:408] pool0 <- conv0
I0426 20:51:03.759937 31899 net.cpp:382] pool0 -> pool0
I0426 20:51:03.759982 31899 net.cpp:124] Setting up pool0
I0426 20:51:03.759990 31899 net.cpp:131] Top shape: 64 10 12 12 (92160)
I0426 20:51:03.759994 31899 net.cpp:139] Memory required for data: 2044160
I0426 20:51:03.759996 31899 layer_factory.hpp:77] Creating layer conv1
I0426 20:51:03.760007 31899 net.cpp:86] Creating Layer conv1
I0426 20:51:03.760010 31899 net.cpp:408] conv1 <- pool0
I0426 20:51:03.760030 31899 net.cpp:382] conv1 -> conv1
I0426 20:51:03.762818 31899 net.cpp:124] Setting up conv1
I0426 20:51:03.762831 31899 net.cpp:131] Top shape: 64 25 8 8 (102400)
I0426 20:51:03.762835 31899 net.cpp:139] Memory required for data: 2453760
I0426 20:51:03.762842 31899 layer_factory.hpp:77] Creating layer pool1
I0426 20:51:03.762850 31899 net.cpp:86] Creating Layer pool1
I0426 20:51:03.762852 31899 net.cpp:408] pool1 <- conv1
I0426 20:51:03.762856 31899 net.cpp:382] pool1 -> pool1
I0426 20:51:03.762905 31899 net.cpp:124] Setting up pool1
I0426 20:51:03.762910 31899 net.cpp:131] Top shape: 64 25 4 4 (25600)
I0426 20:51:03.762913 31899 net.cpp:139] Memory required for data: 2556160
I0426 20:51:03.762915 31899 layer_factory.hpp:77] Creating layer ip1
I0426 20:51:03.762926 31899 net.cpp:86] Creating Layer ip1
I0426 20:51:03.762929 31899 net.cpp:408] ip1 <- pool1
I0426 20:51:03.762933 31899 net.cpp:382] ip1 -> ip1
I0426 20:51:03.763324 31899 net.cpp:124] Setting up ip1
I0426 20:51:03.763331 31899 net.cpp:131] Top shape: 64 100 (6400)
I0426 20:51:03.763334 31899 net.cpp:139] Memory required for data: 2581760
I0426 20:51:03.763356 31899 layer_factory.hpp:77] Creating layer relu1
I0426 20:51:03.763362 31899 net.cpp:86] Creating Layer relu1
I0426 20:51:03.763365 31899 net.cpp:408] relu1 <- ip1
I0426 20:51:03.763370 31899 net.cpp:369] relu1 -> ip1 (in-place)
I0426 20:51:03.763558 31899 net.cpp:124] Setting up relu1
I0426 20:51:03.763567 31899 net.cpp:131] Top shape: 64 100 (6400)
I0426 20:51:03.763571 31899 net.cpp:139] Memory required for data: 2607360
I0426 20:51:03.763573 31899 layer_factory.hpp:77] Creating layer ip2
I0426 20:51:03.763579 31899 net.cpp:86] Creating Layer ip2
I0426 20:51:03.763582 31899 net.cpp:408] ip2 <- ip1
I0426 20:51:03.763586 31899 net.cpp:382] ip2 -> ip2
I0426 20:51:03.763738 31899 net.cpp:124] Setting up ip2
I0426 20:51:03.763746 31899 net.cpp:131] Top shape: 64 100 (6400)
I0426 20:51:03.763748 31899 net.cpp:139] Memory required for data: 2632960
I0426 20:51:03.763753 31899 layer_factory.hpp:77] Creating layer relu2
I0426 20:51:03.763759 31899 net.cpp:86] Creating Layer relu2
I0426 20:51:03.763762 31899 net.cpp:408] relu2 <- ip2
I0426 20:51:03.763767 31899 net.cpp:369] relu2 -> ip2 (in-place)
I0426 20:51:03.764596 31899 net.cpp:124] Setting up relu2
I0426 20:51:03.764607 31899 net.cpp:131] Top shape: 64 100 (6400)
I0426 20:51:03.764626 31899 net.cpp:139] Memory required for data: 2658560
I0426 20:51:03.764629 31899 layer_factory.hpp:77] Creating layer ip3
I0426 20:51:03.764636 31899 net.cpp:86] Creating Layer ip3
I0426 20:51:03.764638 31899 net.cpp:408] ip3 <- ip2
I0426 20:51:03.764643 31899 net.cpp:382] ip3 -> ip3
I0426 20:51:03.764773 31899 net.cpp:124] Setting up ip3
I0426 20:51:03.764780 31899 net.cpp:131] Top shape: 64 10 (640)
I0426 20:51:03.764783 31899 net.cpp:139] Memory required for data: 2661120
I0426 20:51:03.764791 31899 layer_factory.hpp:77] Creating layer relu3
I0426 20:51:03.764796 31899 net.cpp:86] Creating Layer relu3
I0426 20:51:03.764798 31899 net.cpp:408] relu3 <- ip3
I0426 20:51:03.764802 31899 net.cpp:369] relu3 -> ip3 (in-place)
I0426 20:51:03.765005 31899 net.cpp:124] Setting up relu3
I0426 20:51:03.765013 31899 net.cpp:131] Top shape: 64 10 (640)
I0426 20:51:03.765017 31899 net.cpp:139] Memory required for data: 2663680
I0426 20:51:03.765020 31899 layer_factory.hpp:77] Creating layer loss
I0426 20:51:03.765027 31899 net.cpp:86] Creating Layer loss
I0426 20:51:03.765029 31899 net.cpp:408] loss <- ip3
I0426 20:51:03.765033 31899 net.cpp:408] loss <- label
I0426 20:51:03.765038 31899 net.cpp:382] loss -> loss
I0426 20:51:03.765055 31899 layer_factory.hpp:77] Creating layer loss
I0426 20:51:03.765324 31899 net.cpp:124] Setting up loss
I0426 20:51:03.765339 31899 net.cpp:131] Top shape: (1)
I0426 20:51:03.765357 31899 net.cpp:134]     with loss weight 1
I0426 20:51:03.765370 31899 net.cpp:139] Memory required for data: 2663684
I0426 20:51:03.765374 31899 net.cpp:200] loss needs backward computation.
I0426 20:51:03.765377 31899 net.cpp:200] relu3 needs backward computation.
I0426 20:51:03.765380 31899 net.cpp:200] ip3 needs backward computation.
I0426 20:51:03.765383 31899 net.cpp:200] relu2 needs backward computation.
I0426 20:51:03.765386 31899 net.cpp:200] ip2 needs backward computation.
I0426 20:51:03.765389 31899 net.cpp:200] relu1 needs backward computation.
I0426 20:51:03.765391 31899 net.cpp:200] ip1 needs backward computation.
I0426 20:51:03.765394 31899 net.cpp:200] pool1 needs backward computation.
I0426 20:51:03.765398 31899 net.cpp:200] conv1 needs backward computation.
I0426 20:51:03.765401 31899 net.cpp:200] pool0 needs backward computation.
I0426 20:51:03.765404 31899 net.cpp:200] conv0 needs backward computation.
I0426 20:51:03.765408 31899 net.cpp:202] mnist does not need backward computation.
I0426 20:51:03.765410 31899 net.cpp:244] This network produces output loss
I0426 20:51:03.765434 31899 net.cpp:257] Network initialization done.
I0426 20:51:03.765765 31899 solver.cpp:173] Creating test net (#0) specified by net file: ECE595/mnist/train_test/var_everything/lenet_train_test77.prototxt
I0426 20:51:03.765791 31899 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0426 20:51:03.765883 31899 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 10
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "pool0"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 25
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0426 20:51:03.765960 31899 layer_factory.hpp:77] Creating layer mnist
I0426 20:51:03.766002 31899 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0426 20:51:03.766014 31899 net.cpp:86] Creating Layer mnist
I0426 20:51:03.766018 31899 net.cpp:382] mnist -> data
I0426 20:51:03.766026 31899 net.cpp:382] mnist -> label
I0426 20:51:03.766108 31899 data_layer.cpp:45] output data size: 100,1,28,28
I0426 20:51:03.768265 31899 net.cpp:124] Setting up mnist
I0426 20:51:03.768291 31899 net.cpp:131] Top shape: 100 1 28 28 (78400)
I0426 20:51:03.768296 31899 net.cpp:131] Top shape: 100 (100)
I0426 20:51:03.768301 31899 net.cpp:139] Memory required for data: 314000
I0426 20:51:03.768303 31899 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0426 20:51:03.768353 31899 net.cpp:86] Creating Layer label_mnist_1_split
I0426 20:51:03.768357 31899 net.cpp:408] label_mnist_1_split <- label
I0426 20:51:03.768362 31899 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_0
I0426 20:51:03.768368 31899 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_1
I0426 20:51:03.768429 31899 net.cpp:124] Setting up label_mnist_1_split
I0426 20:51:03.768445 31899 net.cpp:131] Top shape: 100 (100)
I0426 20:51:03.768447 31899 net.cpp:131] Top shape: 100 (100)
I0426 20:51:03.768450 31899 net.cpp:139] Memory required for data: 314800
I0426 20:51:03.768453 31899 layer_factory.hpp:77] Creating layer conv0
I0426 20:51:03.768461 31899 net.cpp:86] Creating Layer conv0
I0426 20:51:03.768465 31899 net.cpp:408] conv0 <- data
I0426 20:51:03.768468 31899 net.cpp:382] conv0 -> conv0
I0426 20:51:03.770221 31899 net.cpp:124] Setting up conv0
I0426 20:51:03.770234 31899 net.cpp:131] Top shape: 100 10 24 24 (576000)
I0426 20:51:03.770238 31899 net.cpp:139] Memory required for data: 2618800
I0426 20:51:03.770246 31899 layer_factory.hpp:77] Creating layer pool0
I0426 20:51:03.770269 31899 net.cpp:86] Creating Layer pool0
I0426 20:51:03.770272 31899 net.cpp:408] pool0 <- conv0
I0426 20:51:03.770277 31899 net.cpp:382] pool0 -> pool0
I0426 20:51:03.770313 31899 net.cpp:124] Setting up pool0
I0426 20:51:03.770318 31899 net.cpp:131] Top shape: 100 10 12 12 (144000)
I0426 20:51:03.770321 31899 net.cpp:139] Memory required for data: 3194800
I0426 20:51:03.770324 31899 layer_factory.hpp:77] Creating layer conv1
I0426 20:51:03.770334 31899 net.cpp:86] Creating Layer conv1
I0426 20:51:03.770336 31899 net.cpp:408] conv1 <- pool0
I0426 20:51:03.770357 31899 net.cpp:382] conv1 -> conv1
I0426 20:51:03.772629 31899 net.cpp:124] Setting up conv1
I0426 20:51:03.772642 31899 net.cpp:131] Top shape: 100 25 8 8 (160000)
I0426 20:51:03.772645 31899 net.cpp:139] Memory required for data: 3834800
I0426 20:51:03.772670 31899 layer_factory.hpp:77] Creating layer pool1
I0426 20:51:03.772676 31899 net.cpp:86] Creating Layer pool1
I0426 20:51:03.772680 31899 net.cpp:408] pool1 <- conv1
I0426 20:51:03.772686 31899 net.cpp:382] pool1 -> pool1
I0426 20:51:03.772742 31899 net.cpp:124] Setting up pool1
I0426 20:51:03.772765 31899 net.cpp:131] Top shape: 100 25 4 4 (40000)
I0426 20:51:03.772768 31899 net.cpp:139] Memory required for data: 3994800
I0426 20:51:03.772771 31899 layer_factory.hpp:77] Creating layer ip1
I0426 20:51:03.772778 31899 net.cpp:86] Creating Layer ip1
I0426 20:51:03.772780 31899 net.cpp:408] ip1 <- pool1
I0426 20:51:03.772786 31899 net.cpp:382] ip1 -> ip1
I0426 20:51:03.773273 31899 net.cpp:124] Setting up ip1
I0426 20:51:03.773283 31899 net.cpp:131] Top shape: 100 100 (10000)
I0426 20:51:03.773309 31899 net.cpp:139] Memory required for data: 4034800
I0426 20:51:03.773317 31899 layer_factory.hpp:77] Creating layer relu1
I0426 20:51:03.773324 31899 net.cpp:86] Creating Layer relu1
I0426 20:51:03.773327 31899 net.cpp:408] relu1 <- ip1
I0426 20:51:03.773331 31899 net.cpp:369] relu1 -> ip1 (in-place)
I0426 20:51:03.773499 31899 net.cpp:124] Setting up relu1
I0426 20:51:03.773507 31899 net.cpp:131] Top shape: 100 100 (10000)
I0426 20:51:03.773511 31899 net.cpp:139] Memory required for data: 4074800
I0426 20:51:03.773514 31899 layer_factory.hpp:77] Creating layer ip2
I0426 20:51:03.773522 31899 net.cpp:86] Creating Layer ip2
I0426 20:51:03.773525 31899 net.cpp:408] ip2 <- ip1
I0426 20:51:03.773530 31899 net.cpp:382] ip2 -> ip2
I0426 20:51:03.773681 31899 net.cpp:124] Setting up ip2
I0426 20:51:03.773689 31899 net.cpp:131] Top shape: 100 100 (10000)
I0426 20:51:03.773691 31899 net.cpp:139] Memory required for data: 4114800
I0426 20:51:03.773697 31899 layer_factory.hpp:77] Creating layer relu2
I0426 20:51:03.773702 31899 net.cpp:86] Creating Layer relu2
I0426 20:51:03.773706 31899 net.cpp:408] relu2 <- ip2
I0426 20:51:03.773710 31899 net.cpp:369] relu2 -> ip2 (in-place)
I0426 20:51:03.773885 31899 net.cpp:124] Setting up relu2
I0426 20:51:03.773893 31899 net.cpp:131] Top shape: 100 100 (10000)
I0426 20:51:03.773896 31899 net.cpp:139] Memory required for data: 4154800
I0426 20:51:03.773900 31899 layer_factory.hpp:77] Creating layer ip3
I0426 20:51:03.773906 31899 net.cpp:86] Creating Layer ip3
I0426 20:51:03.773910 31899 net.cpp:408] ip3 <- ip2
I0426 20:51:03.773914 31899 net.cpp:382] ip3 -> ip3
I0426 20:51:03.774054 31899 net.cpp:124] Setting up ip3
I0426 20:51:03.774060 31899 net.cpp:131] Top shape: 100 10 (1000)
I0426 20:51:03.774063 31899 net.cpp:139] Memory required for data: 4158800
I0426 20:51:03.774070 31899 layer_factory.hpp:77] Creating layer relu3
I0426 20:51:03.774075 31899 net.cpp:86] Creating Layer relu3
I0426 20:51:03.774078 31899 net.cpp:408] relu3 <- ip3
I0426 20:51:03.774082 31899 net.cpp:369] relu3 -> ip3 (in-place)
I0426 20:51:03.774956 31899 net.cpp:124] Setting up relu3
I0426 20:51:03.774968 31899 net.cpp:131] Top shape: 100 10 (1000)
I0426 20:51:03.774971 31899 net.cpp:139] Memory required for data: 4162800
I0426 20:51:03.774974 31899 layer_factory.hpp:77] Creating layer ip3_relu3_0_split
I0426 20:51:03.774994 31899 net.cpp:86] Creating Layer ip3_relu3_0_split
I0426 20:51:03.774998 31899 net.cpp:408] ip3_relu3_0_split <- ip3
I0426 20:51:03.775004 31899 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_0
I0426 20:51:03.775012 31899 net.cpp:382] ip3_relu3_0_split -> ip3_relu3_0_split_1
I0426 20:51:03.775065 31899 net.cpp:124] Setting up ip3_relu3_0_split
I0426 20:51:03.775073 31899 net.cpp:131] Top shape: 100 10 (1000)
I0426 20:51:03.775077 31899 net.cpp:131] Top shape: 100 10 (1000)
I0426 20:51:03.775080 31899 net.cpp:139] Memory required for data: 4170800
I0426 20:51:03.775089 31899 layer_factory.hpp:77] Creating layer accuracy
I0426 20:51:03.775094 31899 net.cpp:86] Creating Layer accuracy
I0426 20:51:03.775096 31899 net.cpp:408] accuracy <- ip3_relu3_0_split_0
I0426 20:51:03.775101 31899 net.cpp:408] accuracy <- label_mnist_1_split_0
I0426 20:51:03.775105 31899 net.cpp:382] accuracy -> accuracy
I0426 20:51:03.775118 31899 net.cpp:124] Setting up accuracy
I0426 20:51:03.775122 31899 net.cpp:131] Top shape: (1)
I0426 20:51:03.775125 31899 net.cpp:139] Memory required for data: 4170804
I0426 20:51:03.775128 31899 layer_factory.hpp:77] Creating layer loss
I0426 20:51:03.775135 31899 net.cpp:86] Creating Layer loss
I0426 20:51:03.775138 31899 net.cpp:408] loss <- ip3_relu3_0_split_1
I0426 20:51:03.775142 31899 net.cpp:408] loss <- label_mnist_1_split_1
I0426 20:51:03.775146 31899 net.cpp:382] loss -> loss
I0426 20:51:03.775152 31899 layer_factory.hpp:77] Creating layer loss
I0426 20:51:03.775409 31899 net.cpp:124] Setting up loss
I0426 20:51:03.775418 31899 net.cpp:131] Top shape: (1)
I0426 20:51:03.775421 31899 net.cpp:134]     with loss weight 1
I0426 20:51:03.775436 31899 net.cpp:139] Memory required for data: 4170808
I0426 20:51:03.775440 31899 net.cpp:200] loss needs backward computation.
I0426 20:51:03.775444 31899 net.cpp:202] accuracy does not need backward computation.
I0426 20:51:03.775449 31899 net.cpp:200] ip3_relu3_0_split needs backward computation.
I0426 20:51:03.775451 31899 net.cpp:200] relu3 needs backward computation.
I0426 20:51:03.775454 31899 net.cpp:200] ip3 needs backward computation.
I0426 20:51:03.775457 31899 net.cpp:200] relu2 needs backward computation.
I0426 20:51:03.775460 31899 net.cpp:200] ip2 needs backward computation.
I0426 20:51:03.775462 31899 net.cpp:200] relu1 needs backward computation.
I0426 20:51:03.775465 31899 net.cpp:200] ip1 needs backward computation.
I0426 20:51:03.775468 31899 net.cpp:200] pool1 needs backward computation.
I0426 20:51:03.775471 31899 net.cpp:200] conv1 needs backward computation.
I0426 20:51:03.775475 31899 net.cpp:200] pool0 needs backward computation.
I0426 20:51:03.775477 31899 net.cpp:200] conv0 needs backward computation.
I0426 20:51:03.775481 31899 net.cpp:202] label_mnist_1_split does not need backward computation.
I0426 20:51:03.775485 31899 net.cpp:202] mnist does not need backward computation.
I0426 20:51:03.775487 31899 net.cpp:244] This network produces output accuracy
I0426 20:51:03.775490 31899 net.cpp:244] This network produces output loss
I0426 20:51:03.775502 31899 net.cpp:257] Network initialization done.
I0426 20:51:03.775543 31899 solver.cpp:56] Solver scaffolding done.
I0426 20:51:03.775895 31899 caffe.cpp:248] Starting Optimization
I0426 20:51:03.775902 31899 solver.cpp:273] Solving LeNet
I0426 20:51:03.775904 31899 solver.cpp:274] Learning Rate Policy: inv
I0426 20:51:03.776898 31899 solver.cpp:331] Iteration 0, Testing net (#0)
I0426 20:51:03.780891 31899 blocking_queue.cpp:49] Waiting for data
I0426 20:51:03.852574 31906 data_layer.cpp:73] Restarting data prefetching from start.
I0426 20:51:03.853215 31899 solver.cpp:398]     Test net output #0: accuracy = 0.0966
I0426 20:51:03.853248 31899 solver.cpp:398]     Test net output #1: loss = 2.31381 (* 1 = 2.31381 loss)
I0426 20:51:03.855805 31899 solver.cpp:219] Iteration 0 (-6.64197e-31 iter/s, 0.0798505s/100 iters), loss = 2.31386
I0426 20:51:03.855844 31899 solver.cpp:238]     Train net output #0: loss = 2.31386 (* 1 = 2.31386 loss)
I0426 20:51:03.855855 31899 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0426 20:51:03.967434 31899 solver.cpp:219] Iteration 100 (896.126 iter/s, 0.111591s/100 iters), loss = 1.89822
I0426 20:51:03.967459 31899 solver.cpp:238]     Train net output #0: loss = 1.89822 (* 1 = 1.89822 loss)
I0426 20:51:03.967465 31899 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0426 20:51:04.069635 31899 solver.cpp:219] Iteration 200 (978.804 iter/s, 0.102166s/100 iters), loss = 1.6431
I0426 20:51:04.069674 31899 solver.cpp:238]     Train net output #0: loss = 1.6431 (* 1 = 1.6431 loss)
I0426 20:51:04.069680 31899 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0426 20:51:04.168325 31899 solver.cpp:219] Iteration 300 (1013.78 iter/s, 0.0986409s/100 iters), loss = 1.76404
I0426 20:51:04.168365 31899 solver.cpp:238]     Train net output #0: loss = 1.76404 (* 1 = 1.76404 loss)
I0426 20:51:04.168370 31899 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0426 20:51:04.266968 31899 solver.cpp:219] Iteration 400 (1014.25 iter/s, 0.0985948s/100 iters), loss = 1.3877
I0426 20:51:04.267007 31899 solver.cpp:238]     Train net output #0: loss = 1.3877 (* 1 = 1.3877 loss)
I0426 20:51:04.267014 31899 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0426 20:51:04.367617 31899 solver.cpp:331] Iteration 500, Testing net (#0)
I0426 20:51:04.442721 31906 data_layer.cpp:73] Restarting data prefetching from start.
I0426 20:51:04.443338 31899 solver.cpp:398]     Test net output #0: accuracy = 0.4933
I0426 20:51:04.443362 31899 solver.cpp:398]     Test net output #1: loss = 1.24765 (* 1 = 1.24765 loss)
I0426 20:51:04.444377 31899 solver.cpp:219] Iteration 500 (563.842 iter/s, 0.177355s/100 iters), loss = 1.33061
I0426 20:51:04.444434 31899 solver.cpp:238]     Train net output #0: loss = 1.33061 (* 1 = 1.33061 loss)
I0426 20:51:04.444442 31899 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0426 20:51:04.548166 31899 solver.cpp:219] Iteration 600 (964.264 iter/s, 0.103706s/100 iters), loss = 1.14637
I0426 20:51:04.548225 31899 solver.cpp:238]     Train net output #0: loss = 1.14637 (* 1 = 1.14637 loss)
I0426 20:51:04.548238 31899 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0426 20:51:04.653798 31899 solver.cpp:219] Iteration 700 (947.282 iter/s, 0.105565s/100 iters), loss = 1.05207
I0426 20:51:04.653831 31899 solver.cpp:238]     Train net output #0: loss = 1.05207 (* 1 = 1.05207 loss)
I0426 20:51:04.653839 31899 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0426 20:51:04.759083 31899 solver.cpp:219] Iteration 800 (950.204 iter/s, 0.105241s/100 iters), loss = 1.40168
I0426 20:51:04.759115 31899 solver.cpp:238]     Train net output #0: loss = 1.40168 (* 1 = 1.40168 loss)
I0426 20:51:04.759124 31899 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0426 20:51:04.865469 31899 solver.cpp:219] Iteration 900 (940.386 iter/s, 0.106339s/100 iters), loss = 1.07377
I0426 20:51:04.865525 31899 solver.cpp:238]     Train net output #0: loss = 1.07377 (* 1 = 1.07377 loss)
I0426 20:51:04.865537 31899 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0426 20:51:04.903715 31905 data_layer.cpp:73] Restarting data prefetching from start.
I0426 20:51:04.972025 31899 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_1000.caffemodel
I0426 20:51:04.973835 31899 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_1000.solverstate
I0426 20:51:04.974839 31899 solver.cpp:311] Iteration 1000, loss = 1.09672
I0426 20:51:04.974864 31899 solver.cpp:331] Iteration 1000, Testing net (#0)
I0426 20:51:05.050514 31906 data_layer.cpp:73] Restarting data prefetching from start.
I0426 20:51:05.051126 31899 solver.cpp:398]     Test net output #0: accuracy = 0.4987
I0426 20:51:05.051151 31899 solver.cpp:398]     Test net output #1: loss = 1.20339 (* 1 = 1.20339 loss)
I0426 20:51:05.051156 31899 solver.cpp:316] Optimization Done.
I0426 20:51:05.051161 31899 caffe.cpp:259] Optimization Done.
